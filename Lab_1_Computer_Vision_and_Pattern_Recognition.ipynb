{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9JmOGUZ+H0ygNsCXWLq6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cd208713a744d34ab10be32ffc31de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08d34110ead94febbf0915ef74e4fad1",
              "IPY_MODEL_6c24cc611f9a46008b87541425931fe9",
              "IPY_MODEL_dc0ec7587fc5481795addd4ff7500f6d"
            ],
            "layout": "IPY_MODEL_90faa2c852f749c28e2708369a7558be"
          }
        },
        "08d34110ead94febbf0915ef74e4fad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f66b4a559d40cd9f77e1132ac534d3",
            "placeholder": "​",
            "style": "IPY_MODEL_582b2c5af7b844bd91292e5113970ba3",
            "value": "config.json: "
          }
        },
        "6c24cc611f9a46008b87541425931fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe17ff134734cc2b82626ac76b4f731",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_928b1987f8a24b05a95cedbf9dd86ead",
            "value": 1
          }
        },
        "dc0ec7587fc5481795addd4ff7500f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0668d36dcd741ab9c2b82506a46c545",
            "placeholder": "​",
            "style": "IPY_MODEL_4145f0e5ef41467793bfd429948524cc",
            "value": " 1.71k/? [00:00&lt;00:00, 62.2kB/s]"
          }
        },
        "90faa2c852f749c28e2708369a7558be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f66b4a559d40cd9f77e1132ac534d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582b2c5af7b844bd91292e5113970ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe17ff134734cc2b82626ac76b4f731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "928b1987f8a24b05a95cedbf9dd86ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0668d36dcd741ab9c2b82506a46c545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4145f0e5ef41467793bfd429948524cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4753824af4254fa8ac86c785f5204286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8c08d042854411ba5368ad2ff6b3b11",
              "IPY_MODEL_1367b7e8346f4251a1f4988125511e58",
              "IPY_MODEL_0323f0b6e2e54f97bc1303b1f9bee77b"
            ],
            "layout": "IPY_MODEL_e48b410fea744c20a9a2304f67c2d1c9"
          }
        },
        "f8c08d042854411ba5368ad2ff6b3b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_231075132b0548d185777aa4cdd145c5",
            "placeholder": "​",
            "style": "IPY_MODEL_315c8439af614fd28d09be398e213003",
            "value": "model.safetensors: 100%"
          }
        },
        "1367b7e8346f4251a1f4988125511e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644cb1bd592f42279c540798e7876b81",
            "max": 1625426996,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_821fa5d0c02f4d1cb3ded788fd985eb8",
            "value": 1625426996
          }
        },
        "0323f0b6e2e54f97bc1303b1f9bee77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bfdd05560474d878178cd6c124ac48a",
            "placeholder": "​",
            "style": "IPY_MODEL_f8a63d8b2b9a4200ae50ee265e33ddaa",
            "value": " 1.63G/1.63G [00:33&lt;00:00, 125MB/s]"
          }
        },
        "e48b410fea744c20a9a2304f67c2d1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231075132b0548d185777aa4cdd145c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315c8439af614fd28d09be398e213003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "644cb1bd592f42279c540798e7876b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821fa5d0c02f4d1cb3ded788fd985eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bfdd05560474d878178cd6c124ac48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a63d8b2b9a4200ae50ee265e33ddaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f179ad4ae948481484499434afeaaa75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45e8b59247a84991bdcf60f34c589932",
              "IPY_MODEL_bce058ea9de44192a5adc241ba6cdd93",
              "IPY_MODEL_0d4012fe2e714488b57a8dc255d3664d"
            ],
            "layout": "IPY_MODEL_8b58a25937d9465aa594c18c4b649a36"
          }
        },
        "45e8b59247a84991bdcf60f34c589932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef439dbac29e4da59c101e04fcf0f338",
            "placeholder": "​",
            "style": "IPY_MODEL_f408c0ba29b84c1b8d0709b456478918",
            "value": "generation_config.json: 100%"
          }
        },
        "bce058ea9de44192a5adc241ba6cdd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42b0eac383a46b69e1e5d69fe300e9c",
            "max": 292,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edb1100414a24a15909275a6e1127274",
            "value": 292
          }
        },
        "0d4012fe2e714488b57a8dc255d3664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b7fdc74d6347d386ee0733340559d3",
            "placeholder": "​",
            "style": "IPY_MODEL_5d2e6d49782744b58c0849c8ba827634",
            "value": " 292/292 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "8b58a25937d9465aa594c18c4b649a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef439dbac29e4da59c101e04fcf0f338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f408c0ba29b84c1b8d0709b456478918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f42b0eac383a46b69e1e5d69fe300e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb1100414a24a15909275a6e1127274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40b7fdc74d6347d386ee0733340559d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d2e6d49782744b58c0849c8ba827634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce4a4c38756342958d83dd4e04e700ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0397b48b919d4ac393fc1f23cbd69c78",
              "IPY_MODEL_318d510babc84c43926144b09d8d15e6",
              "IPY_MODEL_6c0fecca17b542d7852458fb0bab2fc2"
            ],
            "layout": "IPY_MODEL_38e44eedc5134049acf156a1a13ff13e"
          }
        },
        "0397b48b919d4ac393fc1f23cbd69c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa2abba2917447be8981457564d2b05f",
            "placeholder": "​",
            "style": "IPY_MODEL_fca947425a364c7e806e09088e315b19",
            "value": "tokenizer_config.json: "
          }
        },
        "318d510babc84c43926144b09d8d15e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_099cdfb398014299bb1b098af008117d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6011f15b358242a6849d007e13f88cb4",
            "value": 1
          }
        },
        "6c0fecca17b542d7852458fb0bab2fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a74c7e743d45a5942da2c5624ba83d",
            "placeholder": "​",
            "style": "IPY_MODEL_dab11a2befdb4f18970d6632b600a975",
            "value": " 1.21k/? [00:00&lt;00:00, 78.5kB/s]"
          }
        },
        "38e44eedc5134049acf156a1a13ff13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa2abba2917447be8981457564d2b05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca947425a364c7e806e09088e315b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "099cdfb398014299bb1b098af008117d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6011f15b358242a6849d007e13f88cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59a74c7e743d45a5942da2c5624ba83d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab11a2befdb4f18970d6632b600a975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e5d2057cdb0406284c1203ff5d655a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86691730d264f9e8fa7ccee82eb91dc",
              "IPY_MODEL_d1741e5b36af481795c789a8c8331fbc",
              "IPY_MODEL_84ec6f0884c34b2fa5b115e726e118fa"
            ],
            "layout": "IPY_MODEL_a0e289884bd3464d811924bde3ca3ed3"
          }
        },
        "e86691730d264f9e8fa7ccee82eb91dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6050bb7b8dc244e4a2f6b36c5296639f",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd07c961daa4d5a87bae39d8119bc61",
            "value": "vocab.json: "
          }
        },
        "d1741e5b36af481795c789a8c8331fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37568c0198c42d0926a28bc66a90700",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c364f7077e3d42a785f116d8f0fbee28",
            "value": 1
          }
        },
        "84ec6f0884c34b2fa5b115e726e118fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027ee9c3e7d843f699f612b3d105acdb",
            "placeholder": "​",
            "style": "IPY_MODEL_346334c81ecd4b9c94ccc19455cf29f4",
            "value": " 798k/? [00:00&lt;00:00, 17.4MB/s]"
          }
        },
        "a0e289884bd3464d811924bde3ca3ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6050bb7b8dc244e4a2f6b36c5296639f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd07c961daa4d5a87bae39d8119bc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c37568c0198c42d0926a28bc66a90700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c364f7077e3d42a785f116d8f0fbee28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "027ee9c3e7d843f699f612b3d105acdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "346334c81ecd4b9c94ccc19455cf29f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c079ca15456450a866b22d8c777e808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cf6f72aea2d47d5a77db38da32bc931",
              "IPY_MODEL_e1c3e0c520b44231a8a0918a3a15bfac",
              "IPY_MODEL_3de84ae2ec6c4ff98b2a633fcba095b0"
            ],
            "layout": "IPY_MODEL_0724410e8ade4f7e8dfb2eeb76f383ee"
          }
        },
        "6cf6f72aea2d47d5a77db38da32bc931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92c117b4bcf54932be0c1902e2d3f1b1",
            "placeholder": "​",
            "style": "IPY_MODEL_07dc5ba139fa4edd973987bc8332fc87",
            "value": "merges.txt: "
          }
        },
        "e1c3e0c520b44231a8a0918a3a15bfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb35f2cf0f74ab1bb6852c9be8088f7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06d072840039401ea674b0e3c1bdc8ca",
            "value": 1
          }
        },
        "3de84ae2ec6c4ff98b2a633fcba095b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c36b147f77c4f6db3ccb57b67e41b1f",
            "placeholder": "​",
            "style": "IPY_MODEL_8dfb96135df342d986ab40118369788d",
            "value": " 456k/? [00:00&lt;00:00, 18.8MB/s]"
          }
        },
        "0724410e8ade4f7e8dfb2eeb76f383ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c117b4bcf54932be0c1902e2d3f1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07dc5ba139fa4edd973987bc8332fc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb35f2cf0f74ab1bb6852c9be8088f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "06d072840039401ea674b0e3c1bdc8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c36b147f77c4f6db3ccb57b67e41b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dfb96135df342d986ab40118369788d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "201085b3d1c349109664088c6e0047d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce020eb3100243f991bdb64e5b66645d",
              "IPY_MODEL_6d2b9a6e1a304f99acb4ce3522867dff",
              "IPY_MODEL_c8933ad6030d4daaaac7f87851c91dfc"
            ],
            "layout": "IPY_MODEL_c3d8ccff78bd48dfbd6c50f1e550f9db"
          }
        },
        "ce020eb3100243f991bdb64e5b66645d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b73f48d43be44e5821efd1ce09b0e24",
            "placeholder": "​",
            "style": "IPY_MODEL_60988f288d4f4634a02fb46039ac16b9",
            "value": "tokenizer.json: "
          }
        },
        "6d2b9a6e1a304f99acb4ce3522867dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07142a04bd36461286f7b1f2fa06a6de",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6f9955843664d6d8d0b03a5cf954185",
            "value": 1
          }
        },
        "c8933ad6030d4daaaac7f87851c91dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68b27f76c6134e65b694f3e546e89112",
            "placeholder": "​",
            "style": "IPY_MODEL_b2d87cfa44644e6f8ae03517b58ebd3f",
            "value": " 2.11M/? [00:00&lt;00:00, 50.3MB/s]"
          }
        },
        "c3d8ccff78bd48dfbd6c50f1e550f9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b73f48d43be44e5821efd1ce09b0e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60988f288d4f4634a02fb46039ac16b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07142a04bd36461286f7b1f2fa06a6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d6f9955843664d6d8d0b03a5cf954185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68b27f76c6134e65b694f3e546e89112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d87cfa44644e6f8ae03517b58ebd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "599716614d404edea6d474ca8930842c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b191b5529244fc6beed41de59d156ec",
              "IPY_MODEL_8f404437390d42189757efac328d04fb",
              "IPY_MODEL_a6ffb62637144bd28a06d790c48510f1"
            ],
            "layout": "IPY_MODEL_0efc2dcbf9cd4cc08136a3a8a3268feb"
          }
        },
        "2b191b5529244fc6beed41de59d156ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241e0fed153549d29e4d0e0e48fa5ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_2d0f25caa42f411a814d040e65a14090",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8f404437390d42189757efac328d04fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20febd182f26473aa33774634fcd088f",
            "max": 279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ec4174bac394b519397da34f50328aa",
            "value": 279
          }
        },
        "a6ffb62637144bd28a06d790c48510f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b90074efbc434c9bdb34cde12a45c9",
            "placeholder": "​",
            "style": "IPY_MODEL_da07fe6d6c4a48c2b4f09d2f68c9c828",
            "value": " 279/279 [00:00&lt;00:00, 19.7kB/s]"
          }
        },
        "0efc2dcbf9cd4cc08136a3a8a3268feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241e0fed153549d29e4d0e0e48fa5ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d0f25caa42f411a814d040e65a14090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20febd182f26473aa33774634fcd088f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec4174bac394b519397da34f50328aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69b90074efbc434c9bdb34cde12a45c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da07fe6d6c4a48c2b4f09d2f68c9c828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21092004Goda/data_anal/blob/main/Lab_1_Computer_Vision_and_Pattern_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа 1\n",
        "**Сбор, визуализация и анализ данных по графу (cs.CV, arXiv)**\n",
        "\n",
        "Кратко:\n",
        "- Скачиваем метаданные arXiv.\n",
        "- Извлекаем ключевые слова моделью Transformers.\n",
        "- Строим граф ключевых слов и граф публикаций.\n",
        "- Анализируем сообщества и центральные узлы.\n",
        "\n",
        "*Внимание:* извлечение ключевых слов может быть долгим. Рекомендуется GPU и кеширование промежуточных результатов.\n"
      ],
      "metadata": {
        "id": "www_mTav2gQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install feedparser"
      ],
      "metadata": {
        "id": "eYFALvcWH6d-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "import urllib.request as libreq\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "B5ltoBcHH71T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сбор данных с arXiv"
      ],
      "metadata": {
        "id": "Awsii-w1pUGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data collection\n",
        "\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?search_query=all:cs.CV&start=0&max_results=500') as url:\n",
        "  r = url.read()\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXgzYztPH7xm",
        "outputId": "5182a05d-73e1-4c70-f902-25705b980688"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3Acs.CV%26id_list%3D%26start%3D0%26max_results%3D500\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=all:cs.CV&amp;id_list=&amp;start=0&amp;max_results=500</title>\\n  <id>http://arxiv.org/api/z4PXAfIIeZ2GtEBWISFkuSpCy9o</id>\\n  <updated>2025-09-22T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">167528</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">500</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/0903.0134v2</id>\\n    <updated>2010-01-08T10:32:52Z</updated>\\n    <published>2009-03-01T11:10:27Z</published>\\n    <title>Recognition of Regular Shapes in Satelite Images</title>\\n    <summary>  This paper has been withdrawn by the author ali pourmohammad.\\n</summary>\\n    <author>\\n      <name>Ahmad Reza Eskandari</name>\\n    </author>\\n    <author>\\n      <name>Ali Pourmohammad</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been withdrawn</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0903.0134v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0903.0134v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1010.0422v1</id>\\n    <updated>2010-10-03T16:55:56Z</updated>\\n    <published>2010-10-03T16:55:56Z</published>\\n    <title>Convolutional Matching Pursuit and Dictionary Training</title>\\n    <summary>  Matching pursuit and K-SVD is demonstrated in the translation invariant\\nsetting\\n</summary>\\n    <author>\\n      <name>Arthur Szlam</name>\\n    </author>\\n    <author>\\n      <name>Koray Kavukcuoglu</name>\\n    </author>\\n    <author>\\n      <name>Yann LeCun</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1010.0422v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1010.0422v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1406.7120v1</id>\\n    <updated>2014-06-27T09:18:44Z</updated>\\n    <published>2014-06-27T09:18:44Z</published>\\n    <title>Template Matching based Object Detection Using HOG Feature Pyramid</title>\\n    <summary>  This article provides a step by step development of designing a Object\\nDetection scheme using the HOG based Feature Pyramid aligned with the concept\\nof Template Matching.\\n</summary>\\n    <author>\\n      <name>Anish Acharya</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1406.7120v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1406.7120v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.01243v1</id>\\n    <updated>2017-07-05T07:43:00Z</updated>\\n    <published>2017-07-05T07:43:00Z</published>\\n    <title>Exploration of object recognition from 3D point cloud</title>\\n    <summary>  We present our latest experiment results of object recognition from 3D point\\ncloud data collected through moving car.\\n</summary>\\n    <author>\\n      <name>Lin Duan</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1707.01243v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.01243v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.11643v1</id>\\n    <updated>2018-07-31T02:51:21Z</updated>\\n    <published>2018-07-31T02:51:21Z</published>\\n    <title>Brain MRI Image Super Resolution using Phase Stretch Transform and\\n  Transfer Learning</title>\\n    <summary>  A hallucination-free and computationally efficient algorithm for enhancing\\nthe resolution of brain MRI images is demonstrated.\\n</summary>\\n    <author>\\n      <name>Sifeng He</name>\\n    </author>\\n    <author>\\n      <name>Bahram Jalali</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.11643v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.11643v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.10788v1</id>\\n    <updated>2019-01-30T12:47:44Z</updated>\\n    <published>2019-01-30T12:47:44Z</published>\\n    <title>Blurred Images Lead to Bad Local Minima</title>\\n    <summary>  Blurred Images Lead to Bad Local Minima\\n</summary>\\n    <author>\\n      <name>Gal Katzhendler</name>\\n    </author>\\n    <author>\\n      <name>Daphna Weinshall</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1901.10788v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.10788v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1909.07245v1</id>\\n    <updated>2019-09-16T14:44:19Z</updated>\\n    <published>2019-09-16T14:44:19Z</published>\\n    <title>BMVC 2019: Workshop on Interpretable and Explainable Machine Vision</title>\\n    <summary>  Proceedings of the BMVC 2019 Workshop on Interpretable and Explainable\\nMachine Vision, Cardiff, UK, September 12, 2019.\\n</summary>\\n    <author>\\n      <name>Alun Preece</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1909.07245v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1909.07245v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2010.09016v1</id>\\n    <updated>2020-10-18T16:16:50Z</updated>\\n    <published>2020-10-18T16:16:50Z</published>\\n    <title>Covapixels</title>\\n    <summary>  We propose and discuss the summarization of superpixel-type image\\ntiles/patches using mean and covariance information. We refer to the resulting\\nobjects as covapixels.\\n</summary>\\n    <author>\\n      <name>Jeffrey Uhlmann</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2010.09016v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2010.09016v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1812.05219v1</id>\\n    <updated>2018-12-13T01:36:36Z</updated>\\n    <published>2018-12-13T01:36:36Z</published>\\n    <title>Advances of Scene Text Datasets</title>\\n    <summary>  This article introduces publicly available datasets in scene text detection\\nand recognition. The information is as of 2017.\\n</summary>\\n    <author>\\n      <name>Masakazu Iwamura</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1812.05219v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1812.05219v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2110.13806v1</id>\\n    <updated>2021-10-25T15:51:35Z</updated>\\n    <published>2021-10-25T15:51:35Z</published>\\n    <title>Detecting speaking persons in video</title>\\n    <summary>  We present a novel method for detecting speaking persons in video, by\\nextracting facial landmarks with a neural network and analysing these landmarks\\nstatistically over time\\n</summary>\\n    <author>\\n      <name>Hannes Fassold</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted for MMSP 2021</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2110.13806v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2110.13806v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2205.10556v1</id>\\n    <updated>2022-05-21T10:25:00Z</updated>\\n    <published>2022-05-21T10:25:00Z</published>\\n    <title>Cycle-GAN for eye-tracking</title>\\n    <summary>  This manuscript presents a not typical implementation of the cycle generative\\nadversarial networks (Cycle-GAN) method for eye-tracking tasks.\\n</summary>\\n    <author>\\n      <name>Ildar Rakhmatulin</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 11 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2205.10556v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2205.10556v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0406047v1</id>\\n    <updated>2004-06-24T13:14:58Z</updated>\\n    <published>2004-06-24T13:14:58Z</published>\\n    <title>Self-organizing neural networks in classification and image recognition</title>\\n    <summary>  Self-organizing neural networks are used for brick finding in OPERA\\nexperiment. Self-organizing neural networks and wavelet analysis used for\\nrecognition and extraction of car numbers from images.\\n</summary>\\n    <author>\\n      <name>G. A. Ososkov</name>\\n    </author>\\n    <author>\\n      <name>S. G. Dmitrievskiy</name>\\n    </author>\\n    <author>\\n      <name>A. V. Stadnik</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/cs/0406047v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0406047v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0902.2788v2</id>\\n    <updated>2010-01-08T10:23:17Z</updated>\\n    <published>2009-02-16T21:13:35Z</published>\\n    <title>Using SLP Neural Network to Persian Handwritten Digits Recognition</title>\\n    <summary>  This paper has been withdrawn by the author ali pourmohammad.\\n</summary>\\n    <author>\\n      <name>Ali Pourmohammad</name>\\n    </author>\\n    <author>\\n      <name>Seyed Mohammad Ahadi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been withdrawn</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0902.2788v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0902.2788v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0906.5120v1</id>\\n    <updated>2009-06-28T08:10:33Z</updated>\\n    <published>2009-06-28T08:10:33Z</published>\\n    <title>Comments on \"A new combination of evidence based on compromise\" by K.\\n  Yamada</title>\\n    <summary>  Comments on ``A new combination of evidence based on compromise\\'\\' by K.\\nYamada\\n</summary>\\n    <author>\\n      <name>Jean Dezert</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ONERA</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Arnaud Martin</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">E3I2</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Florentin Smarandache</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">UNM</arxiv:affiliation>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Fuzzy Sets and Systems 160, 6 (2009) 853-855</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/0906.5120v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0906.5120v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4; I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1004.4793v1</id>\\n    <updated>2010-04-27T13:22:36Z</updated>\\n    <published>2010-04-27T13:22:36Z</published>\\n    <title>Logical methods of object recognition on satellite images using spatial\\n  constraints</title>\\n    <summary>  A logical approach to object recognition on image is proposed. The main idea\\nof the approach is to perform the object recognition as a logical inference on\\na set of rules describing an object shape.\\n</summary>\\n    <author>\\n      <name>R. K. Fedorov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1004.4793v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1004.4793v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8; I.5.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1107.2085v1</id>\\n    <updated>2011-07-11T18:44:17Z</updated>\\n    <published>2011-07-11T18:44:17Z</published>\\n    <title>Kunchenko\\'s Polynomials for Template Matching</title>\\n    <summary>  This paper reviews Kunchenko\\'s polynomials using as template matching method\\nto recognize template in one-dimensional input signal. Kunchenko\\'s polynomials\\nmethod is compared with classical methods - cross-correlation and sum of\\nsquared differences according to numerical statistical example.\\n</summary>\\n    <author>\\n      <name>Oleg Chertov</name>\\n    </author>\\n    <author>\\n      <name>Taras Slipets</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1107.2085v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1107.2085v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.5.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1111.0466v1</id>\\n    <updated>2011-11-02T11:42:37Z</updated>\\n    <published>2011-11-02T11:42:37Z</published>\\n    <title>Kernel diff-hash</title>\\n    <summary>  This paper presents a kernel formulation of the recently introduced diff-hash\\nalgorithm for the construction of similarity-sensitive hash functions. Our\\nkernel diff-hash algorithm that shows superior performance on the problem of\\nimage feature descriptor matching.\\n</summary>\\n    <author>\\n      <name>Michael M Bronstein</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1111.0466v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1111.0466v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1204.1615v1</id>\\n    <updated>2012-04-07T09:28:19Z</updated>\\n    <published>2012-04-07T09:28:19Z</published>\\n    <title>Discrimination between Arabic and Latin from bilingual documents</title>\\n    <summary>  2011 International Conference on Communications, Computing and Control\\nApplications (CCCA)\\n</summary>\\n    <author>\\n      <name>Sofiene Haboubi</name>\\n    </author>\\n    <author>\\n      <name>Samia Maddouri</name>\\n    </author>\\n    <author>\\n      <name>Hamid Amiri</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/CCCA.2011.6031496</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/CCCA.2011.6031496\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1204.1615v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1204.1615v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1212.0819v1</id>\\n    <updated>2012-12-04T18:39:14Z</updated>\\n    <published>2012-12-04T18:39:14Z</published>\\n    <title>A Topological Code for Plane Images</title>\\n    <summary>  It is proposed a new code for contours of plane images. This code was applied\\nfor optical character recognition of printed and handwritten characters. One\\ncan apply it to recognition of any visual images.\\n</summary>\\n    <author>\\n      <name>Evgeny Shchepin</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1212.0819v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1212.0819v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.GT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1303.1829v1</id>\\n    <updated>2013-03-07T21:15:29Z</updated>\\n    <published>2013-03-07T21:15:29Z</published>\\n    <title>Watersheds on edge or node weighted graphs \"par l\\'exemple\"</title>\\n    <summary>  Watersheds have been defined both for node and edge weighted graphs. We show\\nthat they are identical: for each edge (resp.\\\\ node) weighted graph exists a\\nnode (resp. edge) weighted graph with the same minima and catchment basin.\\n</summary>\\n    <author>\\n      <name>Fernand Meyer</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">21 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1303.1829v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1303.1829v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.7948v2</id>\\n    <updated>2013-06-02T20:32:05Z</updated>\\n    <published>2013-04-30T10:41:26Z</published>\\n    <title>Convolutional Neural Networks learn compact local image descriptors</title>\\n    <summary>  A standard deep convolutional neural network paired with a suitable loss\\nfunction learns compact local image descriptors that perform comparably to\\nstate-of-the art approaches.\\n</summary>\\n    <author>\\n      <name>Christian Osendorfer</name>\\n    </author>\\n    <author>\\n      <name>Justin Bayer</name>\\n    </author>\\n    <author>\\n      <name>Patrick van der Smagt</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1304.7948v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.7948v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1305.5905v1</id>\\n    <updated>2013-05-25T09:30:49Z</updated>\\n    <published>2013-05-25T09:30:49Z</published>\\n    <title>\\xc3\\x96AGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association\\n  for Pattern Recognition</title>\\n    <summary>  In this editorial, the organizers summarize facts and background about the\\nevent.\\n</summary>\\n    <author>\\n      <name>Justus Piater</name>\\n    </author>\\n    <author>\\n      <name>Antonio J. Rodr\\xc3\\xadguez S\\xc3\\xa1nchez</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1305.5905v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1305.5905v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1309.0261v1</id>\\n    <updated>2013-09-01T20:35:17Z</updated>\\n    <published>2013-09-01T20:35:17Z</published>\\n    <title>Multi-Column Deep Neural Networks for Offline Handwritten Chinese\\n  Character Classification</title>\\n    <summary>  Our Multi-Column Deep Neural Networks achieve best known recognition rates on\\nChinese characters from the ICDAR 2011 and 2013 offline handwriting\\ncompetitions, approaching human performance.\\n</summary>\\n    <author>\\n      <name>Dan Cire\\xc5\\x9fan</name>\\n    </author>\\n    <author>\\n      <name>J\\xc3\\xbcrgen Schmidhuber</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 1 figure, IDSIA tech report</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1309.0261v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1309.0261v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1310.0365v1</id>\\n    <updated>2013-10-01T16:06:00Z</updated>\\n    <published>2013-10-01T16:06:00Z</published>\\n    <title>The complex-valued encoding for dicision-making based on aliasing data</title>\\n    <summary>  It is proposed a complex valued channel encoding for multidimensional data.\\nThe basic approach contains overlapping of complex nonlinear mappings. Its\\ndevelopment leads to sparse representation of multi-channel data, increasing\\ntheir dimensions and the distance between the images.\\n</summary>\\n    <author>\\n      <name>P. A. Golovinski</name>\\n    </author>\\n    <author>\\n      <name>V. A. Astapenko</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1310.0365v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1310.0365v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1403.5590v1</id>\\n    <updated>2014-03-21T23:26:47Z</updated>\\n    <published>2014-03-21T23:26:47Z</published>\\n    <title>Continuous Optimization for Fields of Experts Denoising Works</title>\\n    <summary>  Several recent papers use image denoising with a Fields of Experts prior to\\nbenchmark discrete optimization methods. We show that a non-linear least\\nsquares solver significantly outperforms all known discrete methods on this\\nproblem.\\n</summary>\\n    <author>\\n      <name>Petter Strandmark</name>\\n    </author>\\n    <author>\\n      <name>Sameer Agarwal</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1403.5590v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1403.5590v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1411.1446v1</id>\\n    <updated>2014-11-05T23:14:10Z</updated>\\n    <published>2014-11-05T23:14:10Z</published>\\n    <title>Electrocardiography Separation of Mother and Baby</title>\\n    <summary>  Extraction of Electrocardiography (ECG or EKG) signals of mother and baby is\\na challenging task, because one single device is used and it receives a mixture\\nof multiple heart beats. In this paper, we would like to design a filter to\\nseparate the signals from each other.\\n</summary>\\n    <author>\\n      <name>Wei Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1411.1446v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1411.1446v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1412.5796v1</id>\\n    <updated>2014-12-18T10:32:57Z</updated>\\n    <published>2014-12-18T10:32:57Z</published>\\n    <title>Image Enhancement Using a Generalization of Homographic Function</title>\\n    <summary>  This paper presents a new method of gray level image enhancement, based on\\npoint transforms. In order to define the transform function, it was used a\\ngeneralization of the homographic function.\\n</summary>\\n    <author>\\n      <name>Vasile Patrascu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The IEEE International Conference COMMUNICATIONS 2002, pp. 429-434,\\n  December 5-7, 2002, Bucharest, Romania</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1412.5796v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1412.5796v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1601.07021v1</id>\\n    <updated>2016-01-26T13:41:48Z</updated>\\n    <published>2016-01-26T13:41:48Z</published>\\n    <title>Polyhedron Volume-Ratio-based Classification for Image Recognition</title>\\n    <summary>  In this paper, a novel method, called polyhedron volume ratio classification\\n(PVRC) is proposed for image recognition\\n</summary>\\n    <author>\\n      <name>Qingxiang Feng</name>\\n    </author>\\n    <author>\\n      <name>Jeng-Shyang Pan</name>\\n    </author>\\n    <author>\\n      <name>Jar-Ferr Yang</name>\\n    </author>\\n    <author>\\n      <name>Yang-Ting Chou</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1601.07021v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1601.07021v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1608.05518v2</id>\\n    <updated>2020-11-12T06:45:06Z</updated>\\n    <published>2016-08-19T07:30:33Z</published>\\n    <title>On the Existence of a Projective Reconstruction</title>\\n    <summary>  In this note we study the connection between the existence of a projective\\nreconstruction and the existence of a fundamental matrix satisfying the\\nepipolar constraints.\\n</summary>\\n    <author>\\n      <name>Hon-Leung Lee</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1608.05518v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1608.05518v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1701.08380v1</id>\\n    <updated>2017-01-29T13:42:14Z</updated>\\n    <published>2017-01-29T13:42:14Z</published>\\n    <title>The HASYv2 dataset</title>\\n    <summary>  This paper describes the HASYv2 dataset. HASY is a publicly available, free\\nof charge dataset of single symbols similar to MNIST. It contains 168233\\ninstances of 369 classes. HASY contains two challenges: A classification\\nchallenge with 10 pre-defined folds for 10-fold cross-validation and a\\nverification challenge.\\n</summary>\\n    <author>\\n      <name>Martin Thoma</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1701.08380v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1701.08380v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1702.01507v1</id>\\n    <updated>2017-02-06T06:32:14Z</updated>\\n    <published>2017-02-06T06:32:14Z</published>\\n    <title>Challenge of Multi-Camera Tracking</title>\\n    <summary>  Multi-camera tracking is quite different from single camera tracking, and it\\nfaces new technology and system architecture challenges. By analyzing the\\ncorresponding characteristics and disadvantages of the existing algorithms,\\nproblems in multi-camera tracking are summarized and some new directions for\\nfuture work are also generalized.\\n</summary>\\n    <author>\\n      <name>Yong Wang</name>\\n    </author>\\n    <author>\\n      <name>Ke Lu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1702.01507v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1702.01507v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.00523v1</id>\\n    <updated>2017-03-01T21:41:58Z</updated>\\n    <published>2017-03-01T21:41:58Z</published>\\n    <title>ISIC 2017 - Skin Lesion Analysis Towards Melanoma Detection</title>\\n    <summary>  Our system addresses Part 1, Lesion Segmentation and Part 3, Lesion\\nClassification of the ISIC 2017 challenge. Both algorithms make use of deep\\nconvolutional networks to achieve the challenge objective.\\n</summary>\\n    <author>\\n      <name>Matt Berseth</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ISIC2017</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1703.00523v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.00523v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.05165v2</id>\\n    <updated>2017-09-28T02:26:32Z</updated>\\n    <published>2017-03-15T14:18:23Z</published>\\n    <title>Automatic skin lesion segmentation with fully\\n  convolutional-deconvolutional networks</title>\\n    <summary>  This paper summarizes our method and validation results for the ISBI\\nChallenge 2017 - Skin Lesion Analysis Towards Melanoma Detection - Part I:\\nLesion Segmentation\\n</summary>\\n    <author>\\n      <name>Yading Yuan</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/JBHI.2017.2787487</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/JBHI.2017.2787487\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ISIC2017 challenge, 4 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Journal of Biomedical and Health Informatics, 2018</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1703.05165v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.05165v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1706.06942v1</id>\\n    <updated>2017-06-21T14:54:15Z</updated>\\n    <published>2017-06-21T14:54:15Z</published>\\n    <title>Graphcut Texture Synthesis for Single-Image Superresolution</title>\\n    <summary>  Texture synthesis has proven successful at imitating a wide variety of\\ntextures. Adding additional constraints (in the form of a low-resolution\\nversion of the texture to be synthesized) makes it possible to use texture\\nsynthesis methods for texture superresolution.\\n</summary>\\n    <author>\\n      <name>Douglas Summers-Stay</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NYU Master\\'s Thesis from 2006</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1706.06942v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.06942v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.03088v2</id>\\n    <updated>2017-07-12T04:38:13Z</updated>\\n    <published>2017-07-11T00:28:23Z</published>\\n    <title>Online Handwritten Mathematical Expressions Recognition System Using\\n  Fuzzy Neural Network</title>\\n    <summary>  The article describes developed information technology for online recognition\\nof handwritten mathematical expressions that based on proposed approaches to\\nhandwritten symbols recognition and structural analysis.\\n</summary>\\n    <author>\\n      <name>E. Naderan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">in Russian</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ITHEA, Information Content and Processing, 2014, 1 (3) , 262-268</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1707.03088v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.03088v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1712.02890v1</id>\\n    <updated>2017-12-07T23:35:11Z</updated>\\n    <published>2017-12-07T23:35:11Z</published>\\n    <title>Network Analysis for Explanation</title>\\n    <summary>  Safety critical systems strongly require the quality aspects of artificial\\nintelligence including explainability. In this paper, we analyzed a trained\\nnetwork to extract features which mainly contribute the inference. Based on the\\nanalysis, we developed a simple solution to generate explanations of the\\ninference processes.\\n</summary>\\n    <author>\\n      <name>Hiroshi Kuwajima</name>\\n    </author>\\n    <author>\\n      <name>Masayuki Tanaka</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1712.02890v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1712.02890v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1803.10864v1</id>\\n    <updated>2018-03-28T21:44:21Z</updated>\\n    <published>2018-03-28T21:44:21Z</published>\\n    <title>Human Emotional Facial Expression Recognition</title>\\n    <summary>  An automatic Facial Expression Recognition (FER) model with Adaboost face\\ndetector, feature selection based on manifold learning and synergetic prototype\\nbased classifier has been proposed. Improved feature selection method and\\nproposed classifier can achieve favorable effectiveness to performance FER in\\nreasonable processing time.\\n</summary>\\n    <author>\\n      <name>Chendi Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1803.10864v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1803.10864v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.00487v1</id>\\n    <updated>2018-07-02T06:47:47Z</updated>\\n    <published>2018-07-02T06:47:47Z</published>\\n    <title>An initial study on estimating area of a leaf using image processing</title>\\n    <summary>  Calculating leaf area is very important. Computer aided image processing can\\nmake this faster and more accurate. This include scanning the leaf , converting\\nit to binary image and calculation of number of pixels covered. Later this is\\nconverted to mm2.\\n</summary>\\n    <author>\\n      <name>G. D. Illeperuma</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.00487v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.00487v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.06466v1</id>\\n    <updated>2018-07-17T14:24:37Z</updated>\\n    <published>2018-07-17T14:24:37Z</published>\\n    <title>Automatic Skin Lesion Segmentation Using Deep Fully Convolutional\\n  Networks</title>\\n    <summary>  This paper summarizes our method and validation results for the ISIC\\nChallenge 2018 - Skin Lesion Analysis Towards Melanoma Detection - Task 1:\\nLesion Segmentation\\n</summary>\\n    <author>\\n      <name>Hongming Xu</name>\\n    </author>\\n    <author>\\n      <name>Tae Hyun Hwang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, ISIC Challenge 2018</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1807.06466v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.06466v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1811.07502v3</id>\\n    <updated>2020-02-20T01:38:30Z</updated>\\n    <published>2018-11-19T05:07:50Z</published>\\n    <title>Fast Efficient Object Detection Using Selective Attention</title>\\n    <summary>  Retraction due to significant oversight\\n</summary>\\n    <author>\\n      <name>Shivanthan Yohanandan</name>\\n    </author>\\n    <author>\\n      <name>Andy Song</name>\\n    </author>\\n    <author>\\n      <name>Adrian G. Dyer</name>\\n    </author>\\n    <author>\\n      <name>Angela Faragasso</name>\\n    </author>\\n    <author>\\n      <name>Subhrajit Roy</name>\\n    </author>\\n    <author>\\n      <name>Dacheng Tao</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Retraction due to significant oversight</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1811.07502v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1811.07502v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1811.12797v1</id>\\n    <updated>2018-11-30T14:05:37Z</updated>\\n    <published>2018-11-30T14:05:37Z</published>\\n    <title>Structure and Motion from Multiframes</title>\\n    <summary>  The paper gives an overview of the problems and methods of recovery of\\nstructure and motion parameters of rigid bodies from multiframes.\\n</summary>\\n    <author>\\n      <name>Mieczys\\xc5\\x82aw A. K\\xc5\\x82opotek</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 figures, 20 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">M.A. K{\\\\l}opotek: Structure and Motion from Multiframes. Machine\\n  Graphics and Vision , Vol. 7, nos 1/2, 1998,pp. 383-396</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1811.12797v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1811.12797v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.03068v1</id>\\n    <updated>2019-01-10T09:13:16Z</updated>\\n    <published>2019-01-10T09:13:16Z</published>\\n    <title>New Radon Transform Based Texture Features of Handwritten Document</title>\\n    <summary>  In this paper, we present some new features describing the handwritten\\ndocument as a texture. These features are based on the Radon transform. All\\nvalues can be obtained easily and suit for the coarse classification of\\ndocuments.\\n</summary>\\n    <author>\\n      <name>Rustam Latypov</name>\\n    </author>\\n    <author>\\n      <name>Evgeni Stolov</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1901.03068v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.03068v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1904.05712v1</id>\\n    <updated>2019-04-11T14:17:52Z</updated>\\n    <published>2019-04-11T14:17:52Z</published>\\n    <title>Reconstructing Network Inputs with Additive Perturbation Signatures</title>\\n    <summary>  In this work, we present preliminary results demonstrating the ability to\\nrecover a significant amount of information about secret model inputs given\\nonly very limited access to model outputs and the ability evaluate the model on\\nadditive perturbations to the input.\\n</summary>\\n    <author>\\n      <name>Nick Moran</name>\\n    </author>\\n    <author>\\n      <name>Chiraag Juvekar</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1904.05712v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1904.05712v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2005.13734v1</id>\\n    <updated>2020-05-28T01:53:57Z</updated>\\n    <published>2020-05-28T01:53:57Z</published>\\n    <title>Anomaly Detection Based on Deep Learning Using Video for Prevention of\\n  Industrial Accidents</title>\\n    <summary>  This paper proposes an anomaly detection method for the prevention of\\nindustrial accidents using machine learning technology.\\n</summary>\\n    <author>\\n      <name>Satoshi Hashimoto</name>\\n    </author>\\n    <author>\\n      <name>Yonghoon Ji</name>\\n    </author>\\n    <author>\\n      <name>Kenichi Kudo</name>\\n    </author>\\n    <author>\\n      <name>Takayuki Takahashi</name>\\n    </author>\\n    <author>\\n      <name>Kazunori Umeda</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2005.13734v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2005.13734v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2005.14386v1</id>\\n    <updated>2020-05-29T05:03:15Z</updated>\\n    <published>2020-05-29T05:03:15Z</published>\\n    <title>Controlling Length in Image Captioning</title>\\n    <summary>  We develop and evaluate captioning models that allow control of caption\\nlength. Our models can leverage this control to generate captions of different\\nstyle and descriptiveness.\\n</summary>\\n    <author>\\n      <name>Ruotian Luo</name>\\n    </author>\\n    <author>\\n      <name>Greg Shakhnarovich</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2005.14386v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2005.14386v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2112.15483v1</id>\\n    <updated>2021-12-23T07:25:19Z</updated>\\n    <published>2021-12-23T07:25:19Z</published>\\n    <title>Cloud Removal from Satellite Images</title>\\n    <summary>  In this report, we have analyzed available cloud detection technique using\\nsentinel hub. We have also implemented spatial attention generative adversarial\\nnetwork and improved quality of generated image compared to previous solution\\n[7].\\n</summary>\\n    <author>\\n      <name>Rutvik Chauhan</name>\\n    </author>\\n    <author>\\n      <name>Antarpuneet Singh</name>\\n    </author>\\n    <author>\\n      <name>Sujoy Saha</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2112.15483v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2112.15483v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0908.1369v1</id>\\n    <updated>2009-08-10T18:33:51Z</updated>\\n    <published>2009-08-10T18:33:51Z</published>\\n    <title>Segmentation for radar images based on active contour</title>\\n    <summary>  We exam various geometric active contour methods for radar image\\nsegmentation. Due to special properties of radar images, we propose our new\\nmodel based on modified Chan-Vese functional. Our method is efficient in\\nseparating non-meteorological noises from meteorological images.\\n</summary>\\n    <author>\\n      <name>Meijun Zhu</name>\\n    </author>\\n    <author>\\n      <name>Pengfei Zhang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0908.1369v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0908.1369v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1511.01994v1</id>\\n    <updated>2015-11-06T07:18:56Z</updated>\\n    <published>2015-11-06T07:18:56Z</published>\\n    <title>Next Generation Multicuts for Semi-Planar Graphs</title>\\n    <summary>  We study the problem of multicut segmentation. We introduce modified versions\\nof the Semi-PlanarCC based on bounding Lagrange multipliers. We apply our work\\nto natural image segmentation.\\n</summary>\\n    <author>\\n      <name>Julian Yarkony</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1511.01994v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1511.01994v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1511.07963v1</id>\\n    <updated>2015-11-25T06:09:42Z</updated>\\n    <published>2015-11-25T06:09:42Z</published>\\n    <title>Calculate distance to object in the area where car, using video analysis</title>\\n    <summary>  The method of using video cameras installed on the car, to calculate the\\ndistance to the object in its area of movement.\\n</summary>\\n    <author>\\n      <name>Elena Legchekova</name>\\n    </author>\\n    <author>\\n      <name>Oleg Titov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, in Russian</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1511.07963v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1511.07963v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1805.00503v1</id>\\n    <updated>2018-04-30T03:49:22Z</updated>\\n    <published>2018-04-30T03:49:22Z</published>\\n    <title>Machine Learning for Exam Triage</title>\\n    <summary>  In this project, we extend the state-of-the-art CheXNet (Rajpurkar et al.\\n[2017]) by making use of the additional non-image features in the dataset. Our\\nmodel produced better AUROC scores than the original CheXNet.\\n</summary>\\n    <author>\\n      <name>Xinyu Guan</name>\\n    </author>\\n    <author>\\n      <name>Jessica Lee</name>\\n    </author>\\n    <author>\\n      <name>Peter Wu</name>\\n    </author>\\n    <author>\\n      <name>Yue Wu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1805.00503v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1805.00503v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1805.00638v2</id>\\n    <updated>2019-06-25T05:11:09Z</updated>\\n    <published>2018-05-02T06:03:47Z</published>\\n    <title>A Deep Network for Arousal-Valence Emotion Prediction with\\n  Acoustic-Visual Cues</title>\\n    <summary>  In this paper, we comprehensively describe the methodology of our submissions\\nto the One-Minute Gradual-Emotion Behavior Challenge 2018.\\n</summary>\\n    <author>\\n      <name>Songyou Peng</name>\\n    </author>\\n    <author>\\n      <name>Le Zhang</name>\\n    </author>\\n    <author>\\n      <name>Yutong Ban</name>\\n    </author>\\n    <author>\\n      <name>Meng Fang</name>\\n    </author>\\n    <author>\\n      <name>Stefan Winkler</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1805.00638v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1805.00638v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1805.08174v1</id>\\n    <updated>2018-05-21T16:50:55Z</updated>\\n    <published>2018-05-21T16:50:55Z</published>\\n    <title>Reproducibility Report for \"Learning To Count Objects In Natural Images\\n  For Visual Question Answering\"</title>\\n    <summary>  This is the reproducibility report for the paper \"Learning To Count Objects\\nIn Natural Images For Visual QuestionAnswering\"\\n</summary>\\n    <author>\\n      <name>Shagun Sodhani</name>\\n    </author>\\n    <author>\\n      <name>Vardaan Pahuja</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Submitted to Reproducibility in ML Workshop, ICML\\'18</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1805.08174v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1805.08174v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1907.06483v1</id>\\n    <updated>2019-07-15T13:04:31Z</updated>\\n    <published>2019-07-15T13:04:31Z</published>\\n    <title>Color Cerberus</title>\\n    <summary>  Simple convolutional neural network was able to win ISISPA color constancy\\ncompetition. Partial reimplementation of (Bianco, 2017) neural architecture\\nwould have shown even better results in this setup.\\n</summary>\\n    <author>\\n      <name>A. ~Savchik</name>\\n    </author>\\n    <author>\\n      <name>E. ~Ershov</name>\\n    </author>\\n    <author>\\n      <name>S. ~Karpenko</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/ISPA.2019.8868425</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/ISPA.2019.8868425\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/1907.06483v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1907.06483v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2008.00947v1</id>\\n    <updated>2020-07-27T15:31:27Z</updated>\\n    <published>2020-07-27T15:31:27Z</published>\\n    <title>Pre-training for Video Captioning Challenge 2020 Summary</title>\\n    <summary>  The Pre-training for Video Captioning Challenge 2020 Summary: results and\\nchallenge participants\\' technical reports.\\n</summary>\\n    <author>\\n      <name>Yingwei Pan</name>\\n    </author>\\n    <author>\\n      <name>Jun Xu</name>\\n    </author>\\n    <author>\\n      <name>Yehao Li</name>\\n    </author>\\n    <author>\\n      <name>Ting Yao</name>\\n    </author>\\n    <author>\\n      <name>Tao Mei</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2008.00947v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2008.00947v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2009.05388v1</id>\\n    <updated>2020-09-02T17:14:05Z</updated>\\n    <published>2020-09-02T17:14:05Z</published>\\n    <title>Automatic cinematography for 360 video</title>\\n    <summary>  We describe our method for automatic generation of a visually interesting\\ncamera path (automatic cinematography)from a 360 video. Based on the\\ninformation from the scene objects, multiple shot hypotheses for different shot\\ntypes are constructed and the best one is rendered.\\n</summary>\\n    <author>\\n      <name>Hannes Fassold</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted as demo paper for IEEE MMSP 2020</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2009.05388v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2009.05388v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2104.02651v1</id>\\n    <updated>2021-04-04T04:23:36Z</updated>\\n    <published>2021-04-04T04:23:36Z</published>\\n    <title>A Modified Convolutional Network for Auto-encoding based on Pattern\\n  Theory Growth Function</title>\\n    <summary>  This brief paper reports the shortcoming of a variant of convolutional neural\\nnetwork whose components are developed based on the pattern theory framework.\\n</summary>\\n    <author>\\n      <name>Erico Tjoa</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2104.02651v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2104.02651v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2104.08657v1</id>\\n    <updated>2021-04-17T22:59:15Z</updated>\\n    <published>2021-04-17T22:59:15Z</published>\\n    <title>IUPUI Driving Videos and Images in All Weather and Illumination\\n  Conditions</title>\\n    <summary>  This document describes an image and video dataset of driving views captured\\nin all weather and illumination conditions. The data set has been submitted to\\nCDVL.\\n</summary>\\n    <author>\\n      <name>Jiang Yu Zheng</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, 5 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2104.08657v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2104.08657v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2108.04466v2</id>\\n    <updated>2021-08-11T02:35:11Z</updated>\\n    <published>2021-08-10T06:21:42Z</published>\\n    <title>Method Towards CVPR 2021 SimLocMatch Challenge</title>\\n    <summary>  This report describes Megvii-3D team\\'s approach towards SimLocMatch Challenge\\n@ CVPR 2021 Image Matching Workshop.\\n</summary>\\n    <author>\\n      <name>Xiaopeng Bi</name>\\n    </author>\\n    <author>\\n      <name>Ran Yan</name>\\n    </author>\\n    <author>\\n      <name>Zheng Chai</name>\\n    </author>\\n    <author>\\n      <name>Haotian Zhang</name>\\n    </author>\\n    <author>\\n      <name>Xiao Liu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2108.04466v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2108.04466v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2109.07843v2</id>\\n    <updated>2021-09-18T06:00:56Z</updated>\\n    <published>2021-09-16T10:11:58Z</published>\\n    <title>Label Assignment Distillation for Object Detection</title>\\n    <summary>  This article has been removed by arXiv administrators due to a claim of\\ncopyright infringement\\n</summary>\\n    <author>\\n      <name>Hailun Zhang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This article has been removed by arXiv administrators due to a claim\\n  of copyright infringement. Author list truncated to the submitter</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2109.07843v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2109.07843v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2201.00975v1</id>\\n    <updated>2022-01-04T04:44:05Z</updated>\\n    <published>2022-01-04T04:44:05Z</published>\\n    <title>StyleM: Stylized Metrics for Image Captioning Built with Contrastive\\n  N-grams</title>\\n    <summary>  In this paper, we build two automatic evaluation metrics for evaluating the\\nassociation between a machine-generated caption and a ground truth stylized\\ncaption: OnlyStyle and StyleCIDEr.\\n</summary>\\n    <author>\\n      <name>Chengxi Li</name>\\n    </author>\\n    <author>\\n      <name>Brent Harrison</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2201.00975v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2201.00975v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2201.09388v1</id>\\n    <updated>2022-01-23T22:44:45Z</updated>\\n    <published>2022-01-23T22:44:45Z</published>\\n    <title>A Survey on Patients Privacy Protection with Stganography and Visual\\n  Encryption</title>\\n    <summary>  In this survey, thirty models for steganography and visual encryption methods\\nhave been discussed to provide patients privacy protection.\\n</summary>\\n    <author>\\n      <name>Hussein K. Alzubaidy</name>\\n    </author>\\n    <author>\\n      <name>Dhiah Al-Shammary</name>\\n    </author>\\n    <author>\\n      <name>Mohammed Hamzah Abed</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2201.09388v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2201.09388v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.MM\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2204.12318v2</id>\\n    <updated>2022-04-27T08:40:43Z</updated>\\n    <published>2022-04-26T13:53:40Z</published>\\n    <title>Evaluating the Quality of a Synthesized Motion with the Fr\\xc3\\xa9chet Motion\\n  Distance</title>\\n    <summary>  Evaluating the Quality of a Synthesized Motion with the Fr\\\\\\'echet Motion\\nDistance\\n</summary>\\n    <author>\\n      <name>Antoine Maiorca</name>\\n    </author>\\n    <author>\\n      <name>Youngwoo Yoon</name>\\n    </author>\\n    <author>\\n      <name>Thierry Dutoit</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2 pages, 2 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2204.12318v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2204.12318v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2207.04639v1</id>\\n    <updated>2022-07-11T05:47:27Z</updated>\\n    <published>2022-07-11T05:47:27Z</published>\\n    <title>A Dual-Polarization Information Guided Network for SAR Ship\\n  Classification</title>\\n    <summary>  How to fully utilize polarization to enhance synthetic aperture radar (SAR)\\nship classification remains an unresolved issue. Thus, we propose a\\ndual-polarization information guided network (DPIG-Net) to solve it.\\n</summary>\\n    <author>\\n      <name>Tianwen Zhang</name>\\n    </author>\\n    <author>\\n      <name>Xiaoling Zhang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2207.04639v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.04639v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2207.07604v1</id>\\n    <updated>2022-07-15T17:02:55Z</updated>\\n    <published>2022-07-15T17:02:55Z</published>\\n    <title>Image and Texture Independent Deep Learning Noise Estimation using\\n  Multiple Frames</title>\\n    <summary>  In this study, a novel multiple-frame based image and texture independent\\nconvolutional Neural Network (CNN) noise estimator is introduced. The estimator\\nworks.\\n</summary>\\n    <author>\\n      <name>Hikmet Kirmizitas</name>\\n    </author>\\n    <author>\\n      <name>Nurettin Besli</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.5755/j02.eie.30586</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.5755/j02.eie.30586\" rel=\"related\"/>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Elektronika Ir Elektrotechnika 2022 28(6) (42-47)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2207.07604v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.07604v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2211.04998v1</id>\\n    <updated>2022-11-09T16:22:34Z</updated>\\n    <published>2022-11-09T16:22:34Z</published>\\n    <title>Similarity among the 2D-shapes and the analysis of dissimilarity scores</title>\\n    <summary>  We present a conceptually simple and intuitive method to calculate and to\\nmeasure the dissimilarities among 2D shapes. Several methods to interpret and\\nto visualize the resulting dissimilarity matrix are presented and compared.\\n</summary>\\n    <author>\\n      <name>Karel Zimmermann</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2211.04998v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2211.04998v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"G.1; I.4; I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2303.17361v1</id>\\n    <updated>2023-03-30T13:19:07Z</updated>\\n    <published>2023-03-30T13:19:07Z</published>\\n    <title>Invertible Convolution with Symmetric Paddings</title>\\n    <summary>  We show that symmetrically padded convolution can be analytically inverted\\nvia DFT. We comprehensively analyze several different symmetric and\\nanti-symmetric padding modes and show that multiple cases exist where the\\ninversion can be achieved. The implementation is available at\\n\\\\url{https://github.com/prclibo/iconv_dft}.\\n</summary>\\n    <author>\\n      <name>Bo Li</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2303.17361v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2303.17361v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2308.03340v1</id>\\n    <updated>2023-08-07T06:47:36Z</updated>\\n    <published>2023-08-07T06:47:36Z</published>\\n    <title>A Hybrid CNN-Transformer Architecture with Frequency Domain Contrastive\\n  Learning for Image Deraining</title>\\n    <summary>  Image deraining is a challenging task that involves restoring degraded images\\naffected by rain streaks.\\n</summary>\\n    <author>\\n      <name>Cheng Wang</name>\\n    </author>\\n    <author>\\n      <name>Wei Li</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">21 pages,6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2308.03340v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2308.03340v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2401.01134v1</id>\\n    <updated>2024-01-02T10:22:06Z</updated>\\n    <published>2024-01-02T10:22:06Z</published>\\n    <title>Hybrid Pooling and Convolutional Network for Improving Accuracy and\\n  Training Convergence Speed in Object Detection</title>\\n    <summary>  This paper introduces HPC-Net, a high-precision and rapidly convergent object\\ndetection network.\\n</summary>\\n    <author>\\n      <name>Shiwen Zhao</name>\\n    </author>\\n    <author>\\n      <name>Wei Wang</name>\\n    </author>\\n    <author>\\n      <name>Junhui Hou</name>\\n    </author>\\n    <author>\\n      <name>Hai Wu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages,5 figures, conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2401.01134v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2401.01134v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2407.18682v1</id>\\n    <updated>2024-07-26T11:56:23Z</updated>\\n    <published>2024-07-26T11:56:23Z</published>\\n    <title>Rapid Object Annotation</title>\\n    <summary>  In this report we consider the problem of rapidly annotating a video with\\nbounding boxes for a novel object. We describe a UI and associated workflow\\ndesigned to make this process fast for an arbitrary novel target.\\n</summary>\\n    <author>\\n      <name>Misha Denil</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2407.18682v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.18682v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2412.18136v1</id>\\n    <updated>2024-12-24T03:44:26Z</updated>\\n    <published>2024-12-24T03:44:26Z</published>\\n    <title>ERVD: An Efficient and Robust ViT-Based Distillation Framework for\\n  Remote Sensing Image Retrieval</title>\\n    <summary>  ERVD: An Efficient and Robust ViT-Based Distillation Framework for Remote\\nSensing Image Retrieval\\n</summary>\\n    <author>\\n      <name>Le Dong</name>\\n    </author>\\n    <author>\\n      <name>Qixuan Cao</name>\\n    </author>\\n    <author>\\n      <name>Lei Pu</name>\\n    </author>\\n    <author>\\n      <name>Fangfang Wu</name>\\n    </author>\\n    <author>\\n      <name>Weisheng Dong</name>\\n    </author>\\n    <author>\\n      <name>Xin Li</name>\\n    </author>\\n    <author>\\n      <name>Guangming Shi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2412.18136v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.18136v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2505.11424v1</id>\\n    <updated>2025-05-16T16:38:01Z</updated>\\n    <published>2025-05-16T16:38:01Z</published>\\n    <title>Improving Object Detection Performance through YOLOv8: A Comprehensive\\n  Training and Evaluation Study</title>\\n    <summary>  This study evaluated the performance of a YOLOv8-based segmentation model for\\ndetecting and segmenting wrinkles in facial images.\\n</summary>\\n    <author>\\n      <name>Rana Poureskandar</name>\\n    </author>\\n    <author>\\n      <name>Shiva Razzagzadeh</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2505.11424v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2505.11424v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2506.04081v1</id>\\n    <updated>2025-06-04T15:44:03Z</updated>\\n    <published>2025-06-04T15:44:03Z</published>\\n    <title>Point Cloud Quality Assessment Using the Perceptual Clustering Weighted\\n  Graph (PCW-Graph) and Attention Fusion Network</title>\\n    <summary>  No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for\\nevaluating 3D content in real-world applications where reference models are\\nunavailable.\\n</summary>\\n    <author>\\n      <name>Abdelouahed Laazoufi</name>\\n    </author>\\n    <author>\\n      <name>Mohammed El Hassouni</name>\\n    </author>\\n    <author>\\n      <name>Hocine Cherifi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2506.04081v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2506.04081v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/9810003v1</id>\\n    <updated>1998-10-02T03:34:38Z</updated>\\n    <published>1998-10-02T03:34:38Z</published>\\n    <title>A Linear Shift Invariant Multiscale Transform</title>\\n    <summary>  This paper presents a multiscale decomposition algorithm. Unlike standard\\nwavelet transforms, the proposed operator is both linear and shift invariant.\\nThe central idea is to obtain shift invariance by averaging the aligned wavelet\\ntransform projections over all circular shifts of the signal. It is shown how\\nthe same transform can be obtained by a linear filter bank.\\n</summary>\\n    <author>\\n      <name>Andreas Siebert</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 5 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings 1998 International Conference on Image Processing,\\n  Chicago, 4-7 October 1998</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/9810003v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9810003v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/9810017v1</id>\\n    <updated>1998-10-19T20:46:16Z</updated>\\n    <published>1998-10-19T20:46:16Z</published>\\n    <title>General Theory of Image Normalization</title>\\n    <summary>  We give a systematic, abstract formulation of the image normalization method\\nas applied to a general group of image transformations, and then illustrate the\\nabstract analysis by applying it to the hierarchy of viewing transformations of\\na planar object.\\n</summary>\\n    <author>\\n      <name>Stephen L. Adler</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">33 pages, plain tex, no figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/9810017v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9810017v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10, I.4.7, I.4.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/9908017v1</id>\\n    <updated>1999-08-26T17:18:49Z</updated>\\n    <published>1999-08-26T17:18:49Z</published>\\n    <title>A Differential Invariant for Zooming</title>\\n    <summary>  This paper presents an invariant under scaling and linear brightness change.\\nThe invariant is based on differentials and therefore is a local feature.\\nRotationally invariant 2-d differential Gaussian operators up to third order\\nare proposed for the implementation of the invariant. The performance is\\nanalyzed by simulating a camera zoom-out.\\n</summary>\\n    <author>\\n      <name>Andreas Siebert</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 7 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings 1999 International Conference on Image Processing,\\n  Kobe, 25-28 October 1999</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/9908017v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9908017v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0001024v1</id>\\n    <updated>2000-01-25T16:09:37Z</updated>\\n    <published>2000-01-25T16:09:37Z</published>\\n    <title>A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images</title>\\n    <summary>  We describe a simple, but efficient algorithm for the generation of dilated\\ncontours from bilevel images. The initial part of the contour extraction is\\nexplained to be a good candidate for parallel computer code generation. The\\nremainder of the algorithm is of linear nature.\\n</summary>\\n    <author>\\n      <name>B. R. Schlei</name>\\n    </author>\\n    <author>\\n      <name>L. Prasad</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, including 3 figures. For additional detail check\\n  http://www.nis.lanl.gov/~bschlei/labvis/index.html</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0001024v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0001024v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10, D.1.3, G.1.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0003079v1</id>\\n    <updated>2000-03-26T23:18:43Z</updated>\\n    <published>2000-03-26T23:18:43Z</published>\\n    <title>Differential Invariants under Gamma Correction</title>\\n    <summary>  This paper presents invariants under gamma correction and similarity\\ntransformations. The invariants are local features based on differentials which\\nare implemented using derivatives of the Gaussian. The use of the proposed\\ninvariant representation is shown to yield improved correlation results in a\\ntemplate matching scenario.\\n</summary>\\n    <author>\\n      <name>Andreas Siebert</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 12 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Vision Interface 2000, Montreal, 2000</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0003079v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0003079v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0006001v1</id>\\n    <updated>2000-05-31T23:37:48Z</updated>\\n    <published>2000-05-31T23:37:48Z</published>\\n    <title>Boosting the Differences: A fast Bayesian classifier neural network</title>\\n    <summary>  A Bayesian classifier that up-weights the differences in the attribute values\\nis discussed. Using four popular datasets from the UCI repository, some\\ninteresting features of the network are illustrated. The network is suitable\\nfor classification problems.\\n</summary>\\n    <author>\\n      <name>Ninan Sajeeth Philip</name>\\n    </author>\\n    <author>\\n      <name>K. Babu Joseph</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">latex 18pages no figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0006001v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0006001v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I1.2;F.1.1;F1.2;C1.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0006002v1</id>\\n    <updated>2000-05-31T23:52:31Z</updated>\\n    <published>2000-05-31T23:52:31Z</published>\\n    <title>Distorted English Alphabet Identification : An application of Difference\\n  Boosting Algorithm</title>\\n    <summary>  The difference-boosting algorithm is used on letters dataset from the UCI\\nrepository to classify distorted raster images of English alphabets. In\\ncontrast to rather complex networks, the difference-boosting is found to\\nproduce comparable or better classification efficiency on this complex problem.\\n</summary>\\n    <author>\\n      <name>Ninan Sajeeth Philip</name>\\n    </author>\\n    <author>\\n      <name>K. Babu Joseph</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">latex 14pages no figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0006002v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0006002v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I1.2;F.1.1;F1.2;C1.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0006040v1</id>\\n    <updated>2000-06-28T18:34:14Z</updated>\\n    <published>2000-06-28T18:34:14Z</published>\\n    <title>Correlation over Decomposed Signals: A Non-Linear Approach to Fast and\\n  Effective Sequences Comparison</title>\\n    <summary>  A novel non-linear approach to fast and effective comparison of sequences is\\npresented, compared to the traditional cross-correlation operator, and\\nillustrated with respect to DNA sequences.\\n</summary>\\n    <author>\\n      <name>Luciano da Fontoura Costa</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0006040v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0006040v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"q-bio\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.5.4; F.2.2; I.5.4; J.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0301001v1</id>\\n    <updated>2003-01-01T19:58:03Z</updated>\\n    <published>2003-01-01T19:58:03Z</published>\\n    <title>Least squares fitting of circles and lines</title>\\n    <summary>  We study theoretical and computational aspects of the least squares fit (LSF)\\nof circles and circular arcs. First we discuss the existence and uniqueness of\\nLSF and various parametrization schemes. Then we evaluate several popular\\ncircle fitting algorithms and propose a new one that surpasses the existing\\nmethods in reliability. We also discuss and compare direct (algebraic) circle\\nfits.\\n</summary>\\n    <author>\\n      <name>N. Chernov</name>\\n    </author>\\n    <author>\\n      <name>C. Lesort</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">26 pages, 14 figures, submitted</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0301001v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0301001v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8; I.5.1; I.2.10; G.1.2; G.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0308034v1</id>\\n    <updated>2003-08-21T10:47:27Z</updated>\\n    <published>2003-08-21T10:47:27Z</published>\\n    <title>Fingerprint based bio-starter and bio-access</title>\\n    <summary>  In the paper will be presented a safety and security system based on\\nfingerprint technology. The results suggest a new scenario where the new cars\\ncan use a fingerprint sensor integrated in car handle to allow access and in\\nthe dashboard as starter button.\\n</summary>\\n    <author>\\n      <name>G. Iovane</name>\\n    </author>\\n    <author>\\n      <name>P. Giordano</name>\\n    </author>\\n    <author>\\n      <name>C. Iovane</name>\\n    </author>\\n    <author>\\n      <name>F. Rotulo</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, Proceeding of Automotive 2003, Turin (Italy)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0308034v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0308034v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10, I.4, I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0308035v1</id>\\n    <updated>2003-08-21T10:52:53Z</updated>\\n    <published>2003-08-21T10:52:53Z</published>\\n    <title>IS (Iris Security)</title>\\n    <summary>  In the paper will be presented a safety system based on iridology. The\\nresults suggest a new scenario where the security problem in supervised and\\nunsupervised areas can be treat with the present system and the iris image\\nrecognition.\\n</summary>\\n    <author>\\n      <name>G. Iovane</name>\\n    </author>\\n    <author>\\n      <name>F. S. Tortoriello</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, Proceeding of NIDays 2003 (Sponsored by National\\n  Instruments), Rome (Italy)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0308035v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0308035v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.5, I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0401018v1</id>\\n    <updated>2004-01-22T05:53:30Z</updated>\\n    <published>2004-01-22T05:53:30Z</published>\\n    <title>Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on\\n  the South of Russian Far East</title>\\n    <summary>  A method of temporal factor prognosis of TE (tick-borne encephalitis)\\ninfection has been developed. The high precision of the prognosis results for a\\nnumber of geographical regions of Primorsky Krai has been achieved. The method\\ncan be applied not only to epidemiological research but also to others.\\n</summary>\\n    <author>\\n      <name>E. I. Bolotin</name>\\n    </author>\\n    <author>\\n      <name>G. Sh. Tsitsiashvili</name>\\n    </author>\\n    <author>\\n      <name>I. V. Golycheva</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0401018v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0401018v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"B.1.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0608073v1</id>\\n    <updated>2006-08-18T08:28:23Z</updated>\\n    <published>2006-08-18T08:28:23Z</published>\\n    <title>Parametrical Neural Networks and Some Other Similar Architectures</title>\\n    <summary>  A review of works on associative neural networks accomplished during last\\nfour years in the Institute of Optical Neural Technologies RAS is given. The\\npresentation is based on description of parametrical neural networks (PNN). For\\ntoday PNN have record recognizing characteristics (storage capacity, noise\\nimmunity and speed of operation). Presentation of basic ideas and principles is\\naccentuated.\\n</summary>\\n    <author>\\n      <name>Leonid B. Litinskii</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages, 2 figures, accepted for publication in \"Optical Memory &amp;\\n  Neural Networks\" (2006)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0608073v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0608073v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0609164v1</id>\\n    <updated>2006-09-29T13:48:35Z</updated>\\n    <published>2006-09-29T13:48:35Z</published>\\n    <title>Conditional Expressions for Blind Deconvolution: Multi-point form</title>\\n    <summary>  We present conditional expression (CE) for finding blurs convolved in given\\nimages. The CE is given in terms of the zero-values of the blurs evaluated at\\nmulti-point. The CE can detect multiple blur all at once. We illustrate the\\nmultiple blur-detection by using a test image.\\n</summary>\\n    <author>\\n      <name>S. Aogaki</name>\\n    </author>\\n    <author>\\n      <name>I. Moritani</name>\\n    </author>\\n    <author>\\n      <name>T. Sugai</name>\\n    </author>\\n    <author>\\n      <name>F. Takeutchi</name>\\n    </author>\\n    <author>\\n      <name>F. M. Toyama</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 3 figures, conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0609164v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0609164v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0609165v1</id>\\n    <updated>2006-09-29T13:50:12Z</updated>\\n    <published>2006-09-29T13:50:12Z</published>\\n    <title>Simple method to eliminate blur based on Lane and Bates algorithm</title>\\n    <summary>  A simple search method for finding a blur convolved in a given image is\\npresented. The method can be easily extended to a large blur. The method has\\nbeen experimentally tested with a model blurred image.\\n</summary>\\n    <author>\\n      <name>S. Aogaki</name>\\n    </author>\\n    <author>\\n      <name>I. Moritani</name>\\n    </author>\\n    <author>\\n      <name>T. Sugai</name>\\n    </author>\\n    <author>\\n      <name>F. Takeutchi</name>\\n    </author>\\n    <author>\\n      <name>F. M. Toyama</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 2 figures, conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0609165v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0609165v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0705.0214v1</id>\\n    <updated>2007-05-02T07:32:58Z</updated>\\n    <published>2007-05-02T07:32:58Z</published>\\n    <title>Riemannian level-set methods for tensor-valued data</title>\\n    <summary>  We present a novel approach for the derivation of PDE modeling\\ncurvature-driven flows for matrix-valued data. This approach is based on the\\nRiemannian geometry of the manifold of Symmetric Positive Definite Matrices\\nPos(n).\\n</summary>\\n    <author>\\n      <name>Mourad Zerai</name>\\n    </author>\\n    <author>\\n      <name>Maher Moakher</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages, 03 figures, to be published in the proceedings of SSVM\\n  2007, LNCS Springer</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0705.0214v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0705.0214v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0706.0300v1</id>\\n    <updated>2007-06-03T05:17:38Z</updated>\\n    <published>2007-06-03T05:17:38Z</published>\\n    <title>Automatic Detection of Pulmonary Embolism using Computational\\n  Intelligence</title>\\n    <summary>  This article describes the implementation of a system designed to\\nautomatically detect the presence of pulmonary embolism in lung scans. These\\nimages are firstly segmented, before alignment and feature extraction using\\nPCA. The neural network was trained using the Hybrid Monte Carlo method,\\nresulting in a committee of 250 neural networks and good results are obtained.\\n</summary>\\n    <author>\\n      <name>Simon Scurrell</name>\\n    </author>\\n    <author>\\n      <name>Tshilidzi Marwala</name>\\n    </author>\\n    <author>\\n      <name>David Rubin</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0706.0300v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0706.0300v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0712.0131v1</id>\\n    <updated>2007-12-02T10:02:01Z</updated>\\n    <published>2007-12-02T10:02:01Z</published>\\n    <title>Learning Similarity for Character Recognition and 3D Object Recognition</title>\\n    <summary>  I describe an approach to similarity motivated by Bayesian methods. This\\nyields a similarity function that is learnable using a standard Bayesian\\nmethods. The relationship of the approach to variable kernel and variable\\nmetric methods is discussed. The approach is related to variable kernel\\nExperimental results on character recognition and 3D object recognition are\\npresented..\\n</summary>\\n    <author>\\n      <name>Thomas M. Breuel</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0712.0131v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0712.0131v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0712.2923v1</id>\\n    <updated>2007-12-18T10:43:23Z</updated>\\n    <published>2007-12-18T10:43:23Z</published>\\n    <title>A Class of LULU Operators on Multi-Dimensional Arrays</title>\\n    <summary>  The LULU operators for sequences are extended to multi-dimensional arrays via\\nthe morphological concept of connection in a way which preserves their\\nessential properties, e.g. they are separators and form a four element fully\\nordered semi-group. The power of the operators is demonstrated by deriving a\\ntotal variation preserving discrete pulse decomposition of images.\\n</summary>\\n    <author>\\n      <name>Roumen Anguelov</name>\\n    </author>\\n    <author>\\n      <name>Inger Plaskitt</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0712.2923v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0712.2923v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0802.1258v1</id>\\n    <updated>2008-02-09T12:22:47Z</updated>\\n    <published>2008-02-09T12:22:47Z</published>\\n    <title>Bayesian Nonlinear Principal Component Analysis Using Random Fields</title>\\n    <summary>  We propose a novel model for nonlinear dimension reduction motivated by the\\nprobabilistic formulation of principal component analysis. Nonlinearity is\\nachieved by specifying different transformation matrices at different locations\\nof the latent space and smoothing the transformation using a Markov random\\nfield type prior. The computation is made feasible by the recent advances in\\nsampling from von Mises-Fisher distributions.\\n</summary>\\n    <author>\\n      <name>Heng Lian</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0802.1258v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0802.1258v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0805.2690v1</id>\\n    <updated>2008-05-17T17:15:26Z</updated>\\n    <published>2008-05-17T17:15:26Z</published>\\n    <title>Increasing Linear Dynamic Range of Commercial Digital Photocamera Used\\n  in Imaging Systems with Optical Coding</title>\\n    <summary>  Methods of increasing linear optical dynamic range of commercial photocamera\\nfor optical-digital imaging systems are described. Use of such methods allows\\nto use commercial photocameras for optical measurements. Experimental results\\nare reported.\\n</summary>\\n    <author>\\n      <name>M. V. Konnik</name>\\n    </author>\\n    <author>\\n      <name>E. A. Manykin</name>\\n    </author>\\n    <author>\\n      <name>S. N. Starikov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">unnecessary figures were removed; typos corrected</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0805.2690v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0805.2690v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0806.3885v1</id>\\n    <updated>2008-06-24T13:43:06Z</updated>\\n    <published>2008-06-24T13:43:06Z</published>\\n    <title>Conceptualization of seeded region growing by pixels aggregation. Part\\n  1: the framework</title>\\n    <summary>  Adams and Bishop have proposed in 1994 a novel region growing algorithm\\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\\nintroduces a framework to implement an algorithm using SRGPA. This framework is\\nbuilt around two concepts: localization and organization of applied action.\\nThis conceptualization gives a quick implementation of algorithms, a direct\\ntranslation between the mathematical idea and the numerical implementation, and\\nan improvement of algorithms efficiency.\\n</summary>\\n    <author>\\n      <name>Vincent Tariel</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0806.3885v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0806.3885v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0808.2227v1</id>\\n    <updated>2008-08-16T01:34:48Z</updated>\\n    <published>2008-08-16T01:34:48Z</published>\\n    <title>Higher Order Moments Generation by Mellin Transform for Compound Models\\n  of Clutter</title>\\n    <summary>  The compound models of clutter statistics are found suitable to describe the\\nnonstationary nature of radar backscattering from high-resolution observations.\\nIn this letter, we show that the properties of Mellin transform can be utilized\\nto generate higher order moments of simple and compound models of clutter\\nstatistics in a compact manner.\\n</summary>\\n    <author>\\n      <name>C Bhattacharya</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0808.2227v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0808.2227v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0811.4699v2</id>\\n    <updated>2009-03-03T09:49:07Z</updated>\\n    <published>2008-11-28T12:11:21Z</published>\\n    <title>Mapping Images with the Coherence Length Diagrams</title>\\n    <summary>  Statistical pattern recognition methods based on the Coherence Length Diagram\\n(CLD) have been proposed for medical image analyses, such as quantitative\\ncharacterisation of human skin textures, and for polarized light microscopy of\\nliquid crystal textures. Further investigations are made on image maps\\noriginated from such diagram and some examples related to irregularity of\\nmicrostructures are shown.\\n</summary>\\n    <author>\\n      <name>A. Sparavigna</name>\\n    </author>\\n    <author>\\n      <name>R. Marazzato</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">International Journal of Software Engineering and Computing, pp.\\n  53-57, 2009, Vol. 1</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/0811.4699v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0811.4699v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0812.0340v2</id>\\n    <updated>2009-10-01T18:44:03Z</updated>\\n    <published>2008-12-01T18:59:52Z</published>\\n    <title>A Matlab Implementation of a Flat Norm Motivated Polygonal Edge Matching\\n  Method using a Decomposition of Boundary into Four 1-Dimensional Currents</title>\\n    <summary>  We describe and provide code and examples for a polygonal edge matching\\nmethod.\\n</summary>\\n    <author>\\n      <name>Simon P. Morgan</name>\\n    </author>\\n    <author>\\n      <name>Wotao Yin</name>\\n    </author>\\n    <author>\\n      <name>Kevin R. Vixie</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Contains Matlab code and 4 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0812.0340v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0812.0340v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0812.1340v2</id>\\n    <updated>2009-02-03T16:31:46Z</updated>\\n    <published>2008-12-07T11:42:41Z</published>\\n    <title>Obtaining Depth Maps From Color Images By Region Based Stereo Matching\\n  Algorithms</title>\\n    <summary>  In the paper, region based stereo matching algorithms are developed for\\nextraction depth information from two color stereo image pair. A filter\\neliminating unreliable disparity estimation was used for increasing reliability\\nof the disparity map. Obtained results by algorithms were represented and\\ncompared.\\n</summary>\\n    <author>\\n      <name>B. Baykant Alagoz</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">New figures were added</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">OncuBilim Algorithm And Systems Labs. Vol.08, Art.No:04,(2008)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/0812.1340v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0812.1340v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0902.4073v1</id>\\n    <updated>2009-02-24T20:34:43Z</updated>\\n    <published>2009-02-24T20:34:43Z</published>\\n    <title>Dipole and Quadrupole Moments in Image Processing</title>\\n    <summary>  This paper proposes an algorithm for image processing, obtained by adapting\\nto image maps the definitions of two well-known physical quantities. These\\nquantities are the dipole and quadrupole moments of a charge distribution. We\\nwill see how it is possible to define dipole and quadrupole moments for the\\ngray-tone maps and apply them in the development of algorithms for edge\\ndetection.\\n</summary>\\n    <author>\\n      <name>Amelia Sparavigna</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0902.4073v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0902.4073v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0902.4663v1</id>\\n    <updated>2009-02-26T18:42:30Z</updated>\\n    <published>2009-02-26T18:42:30Z</published>\\n    <title>Dipole Vectors in Images Processing</title>\\n    <summary>  Instead of evaluating the gradient field of the brightness map of an image,\\nwe propose the use of dipole vectors. This approach is obtained by adapting to\\nthe image gray-tone distribution the definition of the dipole moment of charge\\ndistributions. We will show how to evaluate the dipoles and obtain a vector\\nfield, which can be a good alternative to the gradient field in pattern\\nrecognition.\\n</summary>\\n    <author>\\n      <name>Amelia Sparavigna</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0902.4663v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0902.4663v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0909.1608v1</id>\\n    <updated>2009-09-09T02:12:22Z</updated>\\n    <published>2009-09-09T02:12:22Z</published>\\n    <title>Motion Segmentation by SCC on the Hopkins 155 Database</title>\\n    <summary>  We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark\\ndatabase of 155 motion sequences, and show that it outperforms all other\\nstate-of-the-art methods. The average misclassification rate by SCC is 1.41%\\nfor sequences having two motions and 4.85% for three motions.\\n</summary>\\n    <author>\\n      <name>G. Chen</name>\\n    </author>\\n    <author>\\n      <name>G. Lerman</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/ICCVW.2009.5457626</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/ICCVW.2009.5457626\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted to 2009 ICCV Workshop on Dynamical Vision</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th\\n  International Conference on, 2009, pp. 759 - 764</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/0909.1608v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0909.1608v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1003.0776v1</id>\\n    <updated>2010-03-03T10:58:20Z</updated>\\n    <published>2010-03-03T10:58:20Z</published>\\n    <title>Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays</title>\\n    <summary>  This report presents properties of the Discrete Pulse Transform on\\nmulti-dimensional arrays introduced by the authors two or so years ago. The\\nmain result given here in Lemma 2.1 is also formulated in a paper to appear in\\nIEEE Transactions on Image Processing. However, the proof, being too technical,\\nwas omitted there and hence it appears in full in this publication.\\n</summary>\\n    <author>\\n      <name>Roumen Anguelov</name>\\n    </author>\\n    <author>\\n      <name>Inger Fabris-Rotelli</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1003.0776v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1003.0776v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1003.5249v1</id>\\n    <updated>2010-03-27T00:17:19Z</updated>\\n    <published>2010-03-27T00:17:19Z</published>\\n    <title>Active Testing for Face Detection and Localization</title>\\n    <summary>  We provide a novel search technique, which uses a hierarchical model and a\\nmutual information gain heuristic to efficiently prune the search space when\\nlocalizing faces in images. We show exponential gains in computation over\\ntraditional sliding window approaches, while keeping similar performance\\nlevels.\\n</summary>\\n    <author>\\n      <name>Raphael Sznitman</name>\\n    </author>\\n    <author>\\n      <name>Bruno Jedynak</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/TPAMI.2010.106</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/TPAMI.2010.106\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 pages, 5 figures, accepted in IEEE Transactions on Pattern\\n  Analysis and Machine Intelligence (TPAMI), 2010</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1003.5249v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1003.5249v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1006.2368v1</id>\\n    <updated>2010-06-11T19:05:05Z</updated>\\n    <published>2010-06-11T19:05:05Z</published>\\n    <title>L2-optimal image interpolation and its applications to medical imaging</title>\\n    <summary>  Digital medical images are always displayed scaled to fit particular view.\\nInterpolation is responsible for this scaling, and if not done properly, can\\nsignificantly degrade diagnostic image quality. However, theoretically-optimal\\ninterpolation algorithms may also be the most time-consuming and impractical.\\nWe propose a new approach, adapted to the needs of digital medical imaging, to\\ncombine high interpolation speed and superior L2-optimal image quality.\\n</summary>\\n    <author>\\n      <name>Oleg Pianykh</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1006.2368v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1006.2368v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1007.1016v1</id>\\n    <updated>2010-07-06T23:25:39Z</updated>\\n    <published>2010-07-06T23:25:39Z</published>\\n    <title>Bilateral filters: what they can and cannot do</title>\\n    <summary>  Nonlinear bilateral filters (BF) deliver a fine blend of computational\\nsimplicity and blur-free denoising. However, little is known about their\\nnature, noise-suppressing properties, and optimal choices of filter parameters.\\nOur study is meant to fill this gap-explaining the underlying mechanism of\\nbilateral filtering and providing the methodology for optimal filter selection.\\nPractical application to CT image denoising is discussed to illustrate our\\nresults.\\n</summary>\\n    <author>\\n      <name>Oleg S. Pianykh</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1007.1016v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1007.1016v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1101.5766v1</id>\\n    <updated>2011-01-30T12:05:12Z</updated>\\n    <published>2011-01-30T12:05:12Z</published>\\n    <title>Geometric Models with Co-occurrence Groups</title>\\n    <summary>  A geometric model of sparse signal representations is introduced for classes\\nof signals. It is computed by optimizing co-occurrence groups with a maximum\\nlikelihood estimate calculated with a Bernoulli mixture model. Applications to\\nface image compression and MNIST digit classification illustrate the\\napplicability of this model.\\n</summary>\\n    <author>\\n      <name>Joan Bruna</name>\\n    </author>\\n    <author>\\n      <name>St\\xc3\\xa9phane Mallat</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, ESANN 2010</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1101.5766v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1101.5766v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1104.0582v1</id>\\n    <updated>2011-04-04T14:18:51Z</updated>\\n    <published>2011-04-04T14:18:51Z</published>\\n    <title>Visual Concept Detection and Real Time Object Detection</title>\\n    <summary>  Bag-of-words model is implemented and tried on 10-class visual concept\\ndetection problem. The experimental results show that \"DURF+ERT+SVM\"\\noutperforms \"SIFT+ERT+SVM\" both in detection performance and computation\\nefficiency. Besides, combining DURF and SIFT results in even better detection\\nperformance. Real-time object detection using SIFT and RANSAC is also tried on\\nsimple objects, e.g. drink can, and good result is achieved.\\n</summary>\\n    <author>\\n      <name>Ran Tao</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1104.0582v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1104.0582v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1104.2059v1</id>\\n    <updated>2011-04-11T20:32:54Z</updated>\\n    <published>2011-04-11T20:32:54Z</published>\\n    <title>Template-based matching using weight maps</title>\\n    <summary>  Template matching is one of the most prevalent pattern recognition methods\\nworldwide. It has found uses in most visual concept detection fields. In this\\nwork, we investigate methods for improving template matching by adjusting the\\nweights of different regions of the template. We compare several weight maps\\nand test the methods using the FERET face test set in the context of human eye\\ndetection.\\n</summary>\\n    <author>\\n      <name>Kwie Min Wong</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1104.2059v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1104.2059v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1104.4989v6</id>\\n    <updated>2011-08-11T09:00:58Z</updated>\\n    <published>2011-04-26T18:38:01Z</published>\\n    <title>Preprocessing: A Step in Automating Early Detection of Cervical Cancer</title>\\n    <summary>  This paper has been withdrawn\\n</summary>\\n    <author>\\n      <name>Abhishek Das</name>\\n    </author>\\n    <author>\\n      <name>Avijit Kar</name>\\n    </author>\\n    <author>\\n      <name>Debasis Bhattacharyya</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">wrong conference name mentioned (This paper has been withdrawn)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1104.4989v6\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1104.4989v6\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1107.2807v1</id>\\n    <updated>2011-07-14T12:51:10Z</updated>\\n    <published>2011-07-14T12:51:10Z</published>\\n    <title>Modelling Distributed Shape Priors by Gibbs Random Fields of Second\\n  Order</title>\\n    <summary>  We analyse the potential of Gibbs Random Fields for shape prior modelling. We\\nshow that the expressive power of second order GRFs is already sufficient to\\nexpress simple shapes and spatial relations between them simultaneously. This\\nallows to model and recognise complex shapes as spatial compositions of simpler\\nparts.\\n</summary>\\n    <author>\\n      <name>Boris Flach</name>\\n    </author>\\n    <author>\\n      <name>Dmitrij Schlesinger</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">17 pages, 8 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Control Systems and Computers, (2) 2011, pp 14-24</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1107.2807v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1107.2807v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1111.1461v1</id>\\n    <updated>2011-11-07T00:28:37Z</updated>\\n    <published>2011-11-07T00:28:37Z</published>\\n    <title>Multimodal diff-hash</title>\\n    <summary>  Many applications require comparing multimodal data with different structure\\nand dimensionality that cannot be compared directly. Recently, there has been\\nincreasing interest in methods for learning and efficiently representing such\\nmultimodal similarity. In this paper, we present a simple algorithm for\\nmultimodal similarity-preserving hashing, trying to map multimodal data into\\nthe Hamming space while preserving the intra- and inter-modal similarities. We\\nshow that our method significantly outperforms the state-of-the-art method in\\nthe field.\\n</summary>\\n    <author>\\n      <name>Michael M. Bronstein</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1111.1461v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1111.1461v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1111.6030v2</id>\\n    <updated>2011-12-06T13:21:25Z</updated>\\n    <published>2011-11-25T15:46:37Z</published>\\n    <title>An image processing of a Raphael\\'s portrait of Leonardo</title>\\n    <summary>  In one of his paintings, the School of Athens, Raphael is depicting Leonardo\\nda Vinci as the philosopher Plato. Some image processing tools can help us in\\ncomparing this portrait with two Leonardo\\'s portraits, considered as\\nself-portraits.\\n</summary>\\n    <author>\\n      <name>Amelia Carolina Sparavigna</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Image processing. Portrait. Self-portrait. Leonardo da Vinci.\\n  Raphael. Raffaello Sanzio Images revised using a high-quality image of\\n  Raphael\\'s Plato</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1111.6030v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1111.6030v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1202.0216v1</id>\\n    <updated>2012-02-01T17:00:45Z</updated>\\n    <published>2012-02-01T17:00:45Z</published>\\n    <title>The watershed concept and its use in segmentation : a brief history</title>\\n    <summary>  The watershed is one of the most used tools in image segmentation. We present\\nhow its concept is born and developed over time. Its implementation as an\\nalgorithm or a hardwired device evolved together with the technology which\\nallowed it. We present also how it is used in practice, first together with\\nmarkers, and later introduced in a multiscale framework, in order to produce\\nnot a unique partition but a complete hierarchy.\\n</summary>\\n    <author>\\n      <name>Fernand Meyer</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1202.0216v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1202.0216v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68U10, 05C85\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1204.1634v1</id>\\n    <updated>2012-04-07T13:46:24Z</updated>\\n    <published>2012-04-07T13:46:24Z</published>\\n    <title>Automatic liver segmentation method in CT images</title>\\n    <summary>  The aim of this work is to develop a method for automatic segmentation of the\\nliver based on a priori knowledge of the image, such as location and shape of\\nthe liver.\\n</summary>\\n    <author>\\n      <name>Oussema zayane</name>\\n    </author>\\n    <author>\\n      <name>besma jouini</name>\\n    </author>\\n    <author>\\n      <name>Mohamed Ali Mahjoub</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Canadian Journal on Image Processing &amp; Computer Vision Vol. 2, No.\\n  8, 1923-1717 December 2011</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1204.1634v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1204.1634v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1204.2994v1</id>\\n    <updated>2012-04-13T13:48:27Z</updated>\\n    <published>2012-04-13T13:48:27Z</published>\\n    <title>Image Restoration with Signal-dependent Camera Noise</title>\\n    <summary>  This article describes a fast iterative algorithm for image denoising and\\ndeconvolution with signal-dependent observation noise. We use an optimization\\nstrategy based on variable splitting that adapts traditional Gaussian\\nnoise-based restoration algorithms to account for the observed image being\\ncorrupted by mixed Poisson-Gaussian noise and quantization errors.\\n</summary>\\n    <author>\\n      <name>Ayan Chakrabarti</name>\\n    </author>\\n    <author>\\n      <name>Todd Zickler</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 3 figures, 2 tables</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1204.2994v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1204.2994v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.AP\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1205.3766v1</id>\\n    <updated>2012-05-16T19:11:51Z</updated>\\n    <published>2012-05-16T19:11:51Z</published>\\n    <title>Efficient Topology-Controlled Sampling of Implicit Shapes</title>\\n    <summary>  Sampling from distributions of implicitly defined shapes enables analysis of\\nvarious energy functionals used for image segmentation. Recent work describes a\\ncomputationally efficient Metropolis-Hastings method for accomplishing this\\ntask. Here, we extend that framework so that samples are accepted at every\\niteration of the sampler, achieving an order of magnitude speed up in\\nconvergence. Additionally, we show how to incorporate topological constraints.\\n</summary>\\n    <author>\\n      <name>Jason Chang</name>\\n    </author>\\n    <author>\\n      <name>John W. Fisher III</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1205.3766v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1205.3766v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1207.7244v1</id>\\n    <updated>2012-06-29T15:07:26Z</updated>\\n    <published>2012-06-29T15:07:26Z</published>\\n    <title>Visual Vocabulary Learning and Its Application to 3D and Mobile Visual\\n  Search</title>\\n    <summary>  In this technical report, we review related works and recent trends in visual\\nvocabulary based web image search, object recognition, mobile visual search,\\nand 3D object retrieval. Especial focuses would be also given for the recent\\ntrends in supervised/unsupervised vocabulary optimization, compact descriptor\\nfor visual search, as well as in multi-view based 3D object representation.\\n</summary>\\n    <author>\\n      <name>Liujuan Cao</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1207.7244v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1207.7244v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1210.5653v1</id>\\n    <updated>2012-10-20T20:37:22Z</updated>\\n    <published>2012-10-20T20:37:22Z</published>\\n    <title>Identifications of concealed weapon in a Human Body</title>\\n    <summary>  The detection of weapons concealed underneath a person cloths is very much\\nimportant to the improvement of the security of the public as well as the\\nsafety of public assets like airports, buildings and railway stations etc.\\n</summary>\\n    <author>\\n      <name>Prof. Samir K. Bandyopadhyay</name>\\n    </author>\\n    <author>\\n      <name>Biswajita Datta</name>\\n    </author>\\n    <author>\\n      <name>Sudipta Roy</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, International Journal of Scientific &amp; Engineering Research\\n  (ISSN 2229-5518) 2012</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1210.5653v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1210.5653v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1211.1127v1</id>\\n    <updated>2012-11-06T07:26:49Z</updated>\\n    <published>2012-11-06T07:26:49Z</published>\\n    <title>Visual Transfer Learning: Informal Introduction and Literature Overview</title>\\n    <summary>  Transfer learning techniques are important to handle small training sets and\\nto allow for quick generalization even from only a few examples. The following\\npaper is the introduction as well as the literature overview part of my thesis\\nrelated to the topic of transfer learning for visual recognition problems.\\n</summary>\\n    <author>\\n      <name>Erik Rodner</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">part of my PhD thesis</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1211.1127v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1211.1127v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1211.5712v1</id>\\n    <updated>2012-11-24T23:08:15Z</updated>\\n    <published>2012-11-24T23:08:15Z</published>\\n    <title>Detection of elliptical shapes via cross-entropy clustering</title>\\n    <summary>  The problem of finding elliptical shapes in an image will be considered. We\\ndiscuss the solution which uses cross-entropy clustering. The proposed method\\nallows the search for ellipses with predefined sizes and position in the space.\\nMoreover, it works well for search of ellipsoids in higher dimensions.\\n</summary>\\n    <author>\\n      <name>Jacek Tabor</name>\\n    </author>\\n    <author>\\n      <name>Krzysztof Misztal</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1007/978-3-642-38628-2_78</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1007/978-3-642-38628-2_78\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/1211.5712v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1211.5712v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1212.4527v1</id>\\n    <updated>2012-12-18T22:30:23Z</updated>\\n    <published>2012-12-18T22:30:23Z</published>\\n    <title>GMM-Based Hidden Markov Random Field for Color Image and 3D Volume\\n  Segmentation</title>\\n    <summary>  In this project, we first study the Gaussian-based hidden Markov random field\\n(HMRF) model and its expectation-maximization (EM) algorithm. Then we\\ngeneralize it to Gaussian mixture model-based hidden Markov random field. The\\nalgorithm is implemented in MATLAB. We also apply this algorithm to color image\\nsegmentation problems and 3D volume segmentation problems.\\n</summary>\\n    <author>\\n      <name>Quan Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1212.4527v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1212.4527v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1302.2575v1</id>\\n    <updated>2013-02-04T22:52:13Z</updated>\\n    <published>2013-02-04T22:52:13Z</published>\\n    <title>Coded aperture compressive temporal imaging</title>\\n    <summary>  We use mechanical translation of a coded aperture for code division multiple\\naccess compression of video. We present experimental results for reconstruction\\nat 148 frames per coded snapshot.\\n</summary>\\n    <author>\\n      <name>Patrick Llull</name>\\n    </author>\\n    <author>\\n      <name>Xuejun Liao</name>\\n    </author>\\n    <author>\\n      <name>Xin Yuan</name>\\n    </author>\\n    <author>\\n      <name>Jianbo Yang</name>\\n    </author>\\n    <author>\\n      <name>David Kittle</name>\\n    </author>\\n    <author>\\n      <name>Lawrence Carin</name>\\n    </author>\\n    <author>\\n      <name>Guillermo Sapiro</name>\\n    </author>\\n    <author>\\n      <name>David J. Brady</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1364/OE.21.010526</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1364/OE.21.010526\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">19 pages (when compiled with Optics Express\\' TEX template), 15\\n  figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1302.2575v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1302.2575v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1302.5985v1</id>\\n    <updated>2013-02-25T03:12:12Z</updated>\\n    <published>2013-02-25T03:12:12Z</published>\\n    <title>A Meta-Theory of Boundary Detection Benchmarks</title>\\n    <summary>  Human labeled datasets, along with their corresponding evaluation algorithms,\\nplay an important role in boundary detection. We here present a psychophysical\\nexperiment that addresses the reliability of such benchmarks. To find better\\nremedies to evaluate the performance of any boundary detection algorithm, we\\npropose a computational framework to remove inappropriate human labels and\\nestimate the intrinsic properties of boundaries.\\n</summary>\\n    <author>\\n      <name>Xiaodi Hou</name>\\n    </author>\\n    <author>\\n      <name>Alan Yuille</name>\\n    </author>\\n    <author>\\n      <name>Christof Koch</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NIPS 2012 Workshop on Human Computation for Science and Computational\\n  Sustainability</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1302.5985v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1302.5985v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1303.2844v1</id>\\n    <updated>2013-03-12T11:23:47Z</updated>\\n    <published>2013-03-12T11:23:47Z</published>\\n    <title>A Stochastic Grammar for Natural Shapes</title>\\n    <summary>  We consider object detection using a generic model for natural shapes. A\\ncommon approach for object recognition involves matching object models directly\\nto images. Another approach involves building intermediate representations via\\na generic grouping processes. We argue that these two processes (model-based\\nrecognition and grouping) may use similar computational mechanisms. By defining\\na generic model for shapes we can use model-based techniques to implement a\\nmid-level vision grouping process.\\n</summary>\\n    <author>\\n      <name>Pedro F. Felzenszwalb</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1007/978-1-4471-5195-1_21</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1007/978-1-4471-5195-1_21\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/1303.2844v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1303.2844v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.0421v1</id>\\n    <updated>2013-04-01T19:14:27Z</updated>\\n    <published>2013-04-01T19:14:27Z</published>\\n    <title>Stroke-Based Cursive Character Recognition</title>\\n    <summary>  Human eye can see and read what is written or displayed either in natural\\nhandwriting or in printed format. The same work in case the machine does is\\ncalled handwriting recognition. Handwriting recognition can be broken down into\\ntwo categories: off-line and on-line. ...\\n</summary>\\n    <author>\\n      <name>K. C. Santosh</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LORIA</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>E. Iwata</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Advances in Character Recognition INTECH (Ed.) (2012) 175-192</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1304.0421v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.0421v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.1876v3</id>\\n    <updated>2013-05-28T05:24:25Z</updated>\\n    <published>2013-04-06T10:36:25Z</published>\\n    <title>Proceedings of the 37th Annual Workshop of the Austrian Association for\\n  Pattern Recognition (\\xc3\\x96AGM/AAPR), 2013</title>\\n    <summary>  This volume represents the proceedings of the 37th Annual Workshop of the\\nAustrian Association for Pattern Recognition (\\\\\"OAGM/AAPR), held May 23-24,\\n2013, in Innsbruck, Austria.\\n</summary>\\n    <author>\\n      <name>Justus Piater</name>\\n    </author>\\n    <author>\\n      <name>Antonio Rodr\\xc3\\xadguez-S\\xc3\\xa1nchez</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Contributed papers presented at \\\\\"OAGM/AAPR 2013</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1304.1876v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.1876v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4; I.5; I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.1972v1</id>\\n    <updated>2013-04-07T09:43:47Z</updated>\\n    <published>2013-04-07T09:43:47Z</published>\\n    <title>Facial transformations of ancient portraits: the face of Caesar</title>\\n    <summary>  Some software solutions used to obtain the facial transformations can help\\ninvestigating the artistic metamorphosis of the ancient portraits of the same\\nperson. An analysis with a freely available software of portraitures of Julius\\nCaesar is proposed, showing his several \"morphs\". The software helps enhancing\\nthe mood the artist added to a portrait.\\n</summary>\\n    <author>\\n      <name>Amelia Carolina Sparavigna</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Image processing, Facial transformation, Morphing, Portraits, Julius\\n  Caesar, Arles bust, Tusculum bust</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1304.1972v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.1972v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.2743v1</id>\\n    <updated>2013-03-27T19:48:54Z</updated>\\n    <published>2013-03-27T19:48:54Z</published>\\n    <title>Comparisons of Reasoning Mechanisms for Computer Vision</title>\\n    <summary>  An evidential reasoning mechanism based on the Dempster-Shafer theory of\\nevidence is introduced. Its performance in real-world image analysis is\\ncompared with other mechanisms based on the Bayesian formalism and a simple\\nweight combination method.\\n</summary>\\n    <author>\\n      <name>Ze-Nian Li</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Appears in Proceedings of the Third Conference on Uncertainty in\\n  Artificial Intelligence (UAI1987)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1304.2743v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.2743v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.2749v1</id>\\n    <updated>2013-03-27T19:49:25Z</updated>\\n    <published>2013-03-27T19:49:25Z</published>\\n    <title>Evidential Reasoning in Image Understanding</title>\\n    <summary>  In this paper, we present some results of evidential reasoning in\\nunderstanding multispectral images of remote sensing systems. The\\nDempster-Shafer approach of combination of evidences is pursued to yield\\ncontextual classification results, which are compared with previous results of\\nthe Bayesian context free classification, contextual classifications of dynamic\\nprogramming and stochastic relaxation approaches.\\n</summary>\\n    <author>\\n      <name>Minchuan Zhang</name>\\n    </author>\\n    <author>\\n      <name>Su-shing Chen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Appears in Proceedings of the Third Conference on Uncertainty in\\n  Artificial Intelligence (UAI1987)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1304.2749v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.2749v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1304.3447v1</id>\\n    <updated>2013-03-27T19:58:23Z</updated>\\n    <published>2013-03-27T19:58:23Z</published>\\n    <title>Developing and Analyzing Boundary Detection Operators Using\\n  Probabilistic Models</title>\\n    <summary>  Most feature detectors such as edge detectors or circle finders are\\nstatistical, in the sense that they decide at each point in an image about the\\npresence of a feature, this paper describes the use of Bayesian feature\\ndetectors.\\n</summary>\\n    <author>\\n      <name>David Sher</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Appears in Proceedings of the First Conference on Uncertainty in\\n  Artificial Intelligence (UAI1985)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1304.3447v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1304.3447v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1307.1303v1</id>\\n    <updated>2013-07-02T15:25:09Z</updated>\\n    <published>2013-07-02T15:25:09Z</published>\\n    <title>Submodularity of a Set Label Disagreement Function</title>\\n    <summary>  A set label disagreement function is defined over the number of variables\\nthat deviates from the dominant label. The dominant label is the value assumed\\nby the largest number of variables within a set of binary variables. The\\nsubmodularity of a certain family of set label disagreement function is\\ndiscussed in this manuscript. Such disagreement function could be utilized as a\\ncost function in combinatorial optimization approaches for problems defined\\nover hypergraphs.\\n</summary>\\n    <author>\\n      <name>Toufiq Parag</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Janelia Farm Research Campus-HHMI</arxiv:affiliation>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1307.1303v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1307.1303v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1307.3759v1</id>\\n    <updated>2013-07-14T17:37:36Z</updated>\\n    <published>2013-07-14T17:37:36Z</published>\\n    <title>A Minimal Six-Point Auto-Calibration Algorithm</title>\\n    <summary>  A non-iterative auto-calibration algorithm is presented. It deals with a\\nminimal set of six scene points in three views taken by a camera with fixed but\\nunknown intrinsic parameters. Calibration is based on the image correspondences\\nonly. The algorithm is implemented and validated on synthetic image data.\\n</summary>\\n    <author>\\n      <name>Evgeniy Martyushev</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 4 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings of the 23rd International Conference on Computer\\n  Graphics and Vision, September 16-20, 2013 Vladivostok, Russia</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1307.3759v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1307.3759v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1308.0890v1</id>\\n    <updated>2013-08-05T05:17:26Z</updated>\\n    <published>2013-08-05T05:17:26Z</published>\\n    <title>Head Gesture Recognition using Optical Flow based Classification with\\n  Reinforcement of GMM based Background Subtraction</title>\\n    <summary>  This paper describes a technique of real time head gesture recognition\\nsystem. The method includes Gaussian mixture model (GMM) accompanied by optical\\nflow algorithm which provided us the required information regarding head\\nmovement. The proposed model can be implemented in various control system. We\\nare also presenting the result and implementation of both mentioned method.\\n</summary>\\n    <author>\\n      <name>Parimita Saikia</name>\\n    </author>\\n    <author>\\n      <name>Karen Das</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1308.0890v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1308.0890v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1310.0319v3</id>\\n    <updated>2013-11-03T08:37:46Z</updated>\\n    <published>2013-10-01T14:26:29Z</published>\\n    <title>Second Croatian Computer Vision Workshop (CCVW 2013)</title>\\n    <summary>  Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,\\nhttp://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,\\nCroatia. Workshop was organized by the Center of Excellence for Computer Vision\\nof the University of Zagreb.\\n</summary>\\n    <author>\\n      <name>Sven Lon\\xc4\\x8dari\\xc4\\x87</name>\\n    </author>\\n    <author>\\n      <name>Sini\\xc5\\xa1a \\xc5\\xa0egvi\\xc4\\x87</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Papers presented at the Second Croatian Computer Vision Workshop CCVW\\n  2013</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1310.0319v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1310.0319v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1311.6500v1</id>\\n    <updated>2013-11-11T20:32:50Z</updated>\\n    <published>2013-11-11T20:32:50Z</published>\\n    <title>Stitched Panoramas from Toy Airborne Video Cameras</title>\\n    <summary>  Effective panoramic photographs are taken from vantage points that are high.\\nHigh vantage points have recently become easier to reach as the cost of\\nquadrotor helicopters has dropped to nearly disposable levels. Although cameras\\ncarried by such aircraft weigh only a few grams, their low-quality video can be\\nconverted into panoramas of high quality and high resolution. Also, the small\\nsize of these aircraft vastly reduces the risks inherent to flight.\\n</summary>\\n    <author>\\n      <name>Camille Goudeseune</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 9 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1311.6500v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1311.6500v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.3.3; I.4; J.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1312.3035v1</id>\\n    <updated>2013-12-11T04:59:49Z</updated>\\n    <published>2013-12-11T04:59:49Z</published>\\n    <title>Heat kernel coupling for multiple graph analysis</title>\\n    <summary>  In this paper, we introduce heat kernel coupling (HKC) as a method of\\nconstructing multimodal spectral geometry on weighted graphs of different size\\nwithout vertex-wise bijective correspondence. We show that Laplacian averaging\\ncan be derived as a limit case of HKC, and demonstrate its applications on\\nseveral problems from the manifold learning and pattern recognition domain.\\n</summary>\\n    <author>\\n      <name>Michael M. Bronstein</name>\\n    </author>\\n    <author>\\n      <name>Klaus Glashoff</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1312.3035v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1312.3035v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1312.3724v1</id>\\n    <updated>2013-12-13T07:54:22Z</updated>\\n    <published>2013-12-13T07:54:22Z</published>\\n    <title>ARIANNA: pAth Recognition for Indoor Assisted NavigatioN with Augmented\\n  perception</title>\\n    <summary>  ARIANNA stands for pAth Recognition for Indoor Assisted Navigation with\\nAugmented perception. It is a flexible and low cost navigation system for vi-\\nsually impaired people. Arianna permits to navigate colored paths painted or\\nsticked on the floor revealing their directions through vibrational feedback on\\ncommercial smartphones.\\n</summary>\\n    <author>\\n      <name>Pierluigi Gallo</name>\\n    </author>\\n    <author>\\n      <name>Ilenia Tinnirello</name>\\n    </author>\\n    <author>\\n      <name>Laura Giarr\\xc3\\xa9</name>\\n    </author>\\n    <author>\\n      <name>Domenico Garlisi</name>\\n    </author>\\n    <author>\\n      <name>Daniele Croce</name>\\n    </author>\\n    <author>\\n      <name>Adriano Fagiolini</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1312.3724v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1312.3724v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1403.2031v1</id>\\n    <updated>2014-03-09T06:53:13Z</updated>\\n    <published>2014-03-09T06:53:13Z</published>\\n    <title>Texture Defect Detection in Gradient Space</title>\\n    <summary>  In this paper, we propose a machine vision algorithm for automatically\\ndetecting defects in patterned textures with the help of gradient space and its\\nenergy. Experiments on real fabric images with defects show that the proposed\\nmethod can be used for automatic detection of fabric defects in textile\\nindustries.\\n</summary>\\n    <author>\\n      <name>V. Asha</name>\\n    </author>\\n    <author>\\n      <name>N. U. Bhajantri</name>\\n    </author>\\n    <author>\\n      <name>P. Nagabhushan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, ICFoCS-2011</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1403.2031v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1403.2031v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"11K70, 39A14, 39A70, 47A30, 62H30, 68M20\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1403.3964v1</id>\\n    <updated>2014-03-16T22:03:45Z</updated>\\n    <published>2014-03-16T22:03:45Z</published>\\n    <title>Image processing using miniKanren</title>\\n    <summary>  An integral image is one of the most efficient optimization technique for\\nimage processing. However an integral image is only a special case of delayed\\nstream or memoization. This research discusses generalizing concept of integral\\nimage optimization technique, and how to generate an integral image optimized\\nprogram code automatically from abstracted image processing algorithm. In oder\\nto abstruct algorithms, we forces to miniKanren.\\n</summary>\\n    <author>\\n      <name>Hirotaka Niitsuma</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1403.3964v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1403.3964v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.PL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1404.7748v1</id>\\n    <updated>2014-04-30T14:54:19Z</updated>\\n    <published>2014-04-30T14:54:19Z</published>\\n    <title>A graph-based mathematical morphology reader</title>\\n    <summary>  This survey paper aims at providing a \"literary\" anthology of mathematical\\nmorphology on graphs. It describes in the English language many ideas stemming\\nfrom a large number of different papers, hence providing a unified view of an\\nactive and diverse field of research.\\n</summary>\\n    <author>\\n      <name>Laurent Najman</name>\\n    </author>\\n    <author>\\n      <name>Jean Cousty</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.patrec.2014.05.007</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.patrec.2014.05.007\" rel=\"related\"/>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Pattern Recognition Letters 47 (2014) 3-17</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1404.7748v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1404.7748v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1405.1678v3</id>\\n    <updated>2015-03-12T12:38:13Z</updated>\\n    <published>2014-05-07T17:51:52Z</published>\\n    <title>RPCA-KFE: Key Frame Extraction for Consumer Video based Robust Principal\\n  Component Analysis</title>\\n    <summary>  Key frame extraction algorithms consider the problem of selecting a subset of\\nthe most informative frames from a video to summarize its content.\\n</summary>\\n    <author>\\n      <name>Chinh Dang</name>\\n    </author>\\n    <author>\\n      <name>Abdolreza Moghadam</name>\\n    </author>\\n    <author>\\n      <name>Hayder Radha</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/TIP.2015.2445572</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/TIP.2015.2445572\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been withdrawn by the author due to a crucial sign\\n  error in equation 1</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1405.1678v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1405.1678v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1405.6132v1</id>\\n    <updated>2014-02-05T00:46:18Z</updated>\\n    <published>2014-02-05T00:46:18Z</published>\\n    <title>Comparative analysis of common edge detection techniques in context of\\n  object extraction</title>\\n    <summary>  Edges characterize boundaries and are therefore a problem of practical\\nimportance in remote sensing.In this paper a comparative study of various edge\\ndetection techniques and band wise analysis of these algorithms in the context\\nof object extraction with regard to remote sensing satellite images from the\\nIndian Remote Sensing Satellite (IRS) sensors LISS 3, LISS 4 and Cartosat1 as\\nwell as Google Earth is presented.\\n</summary>\\n    <author>\\n      <name>S. K. Katiyar</name>\\n    </author>\\n    <author>\\n      <name>P. V. Arun</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1405.6132v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1405.6132v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1405.6133v1</id>\\n    <updated>2014-02-05T14:49:36Z</updated>\\n    <published>2014-02-05T14:49:36Z</published>\\n    <title>A review over the applicability of image entropy in analyses of remote\\n  sensing datasets</title>\\n    <summary>  Entropy is the measure of uncertainty in any data and is adopted for\\nmaximisation of mutual information in many remote sensing operations. The\\navailability of wide entropy variations motivated us for an investigation over\\nthe suitability preference of these versions to specific operations.\\n</summary>\\n    <author>\\n      <name>S. K. Katiyar</name>\\n    </author>\\n    <author>\\n      <name>P. V. Arun</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">arXiv admin note: substantial text overlap with arXiv:1303.6926</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1405.6133v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1405.6133v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1407.3673v2</id>\\n    <updated>2016-10-21T16:07:15Z</updated>\\n    <published>2014-07-03T10:55:52Z</published>\\n    <title>Enhanced EZW Technique for Compression of Image by Setting Detail\\n  Retaining Pass Number</title>\\n    <summary>  This submission has been withdrawn by arXiv administrators because it\\ncontains excessive and unattributed reuse of content from other authors.\\n</summary>\\n    <author>\\n      <name>Isha Tyagi</name>\\n    </author>\\n    <author>\\n      <name>Ashish Nautiyal</name>\\n    </author>\\n    <author>\\n      <name>Vishwanath Bijalwan</name>\\n    </author>\\n    <author>\\n      <name>Meenu Balodhi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This submission has been withdrawn by arXiv administrators because it\\n  contains excessive and unattributed reuse of content from other authors</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1407.3673v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1407.3673v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1407.6492v2</id>\\n    <updated>2014-08-14T11:28:48Z</updated>\\n    <published>2014-07-24T08:53:00Z</published>\\n    <title>Recognition of Handwritten Persian/Arabic Numerals Based on Robust\\n  Feature Set and K-NN Classifier</title>\\n    <summary>  This paper has been withdrawn by the author due to a crucial sign error in\\nequation 2 and some mistake in Table 1 information. please let me for changing\\nthis information and updating this paper.\\n</summary>\\n    <author>\\n      <name>Reza Azad</name>\\n    </author>\\n    <author>\\n      <name>Fatemeh Davami</name>\\n    </author>\\n    <author>\\n      <name>Hamid Reza Shayegh</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been withdrawn by the main author due to the Table 1\\n  and equation 2 errors</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1407.6492v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1407.6492v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1408.1986v1</id>\\n    <updated>2014-08-08T21:24:59Z</updated>\\n    <published>2014-08-08T21:24:59Z</published>\\n    <title>Gabor-like Image Filtering using a Neural Microcircuit</title>\\n    <summary>  In this letter, we present an implementation of a neural microcircuit for\\nimage processing employing Hebbian-adaptive learning. The neuronal circuit\\nutilizes only excitatory synapses to correlate action potentials, extracting\\nthe uncorrelated ones, which contain significant image information. This\\ncircuit is capable of approximating Gabor-like image filtering and other image\\nprocessing functions\\n</summary>\\n    <author>\\n      <name>C. Mayr</name>\\n    </author>\\n    <author>\\n      <name>A. Heittmann</name>\\n    </author>\\n    <author>\\n      <name>R. Sch\\xc3\\xbcffny</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/TNN.2007.891687</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/TNN.2007.891687\" rel=\"related\"/>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Transactions on Neural Networks, vol. 18, pages 955-959, 2007</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1408.1986v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1408.1986v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.ET\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"q-bio.NC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1410.2474v1</id>\\n    <updated>2014-10-09T14:08:46Z</updated>\\n    <published>2014-10-09T14:08:46Z</published>\\n    <title>Genetic Stereo Matching Algorithm with Fuzzy Fitness</title>\\n    <summary>  This paper presents a genetic stereo matching algorithm with fuzzy evaluation\\nfunction. The proposed algorithm presents a new encoding scheme in which a\\nchromosome is represented by a disparity matrix. Evolution is controlled by a\\nfuzzy fitness function able to deal with noise and uncertain camera\\nmeasurements, and uses classical evolutionary operators. The result of the\\nalgorithm is accurate dense disparity maps obtained in a reasonable\\ncomputational time suitable for real-time applications as shown in experimental\\nresults.\\n</summary>\\n    <author>\\n      <name>Haythem Ghazouani</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1410.2474v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1410.2474v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1410.2663v1</id>\\n    <updated>2014-10-10T02:48:08Z</updated>\\n    <published>2014-10-10T02:48:08Z</published>\\n    <title>Challenge IEEE-ISBI/TCB : Application of Covariance matrices and wavelet\\n  marginals</title>\\n    <summary>  This short memo aims at explaining our approach for the challenge IEEE-ISBI\\non Bone Texture Characterization. In this work, we focus on the use of\\ncovariance matrices and wavelet marginals in an SVM classifier.\\n</summary>\\n    <author>\\n      <name>Florian Yger</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 4 Figues, 2 Tables, Challenge IEEE-ISBI : Bone Texture\\n  Characterization</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1410.2663v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1410.2663v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1411.1442v1</id>\\n    <updated>2014-11-05T22:56:10Z</updated>\\n    <published>2014-11-05T22:56:10Z</published>\\n    <title>Optical Character Recognition, Using K-Nearest Neighbors</title>\\n    <summary>  The problem of optical character recognition, OCR, has been widely discussed\\nin the literature. Having a hand-written text, the program aims at recognizing\\nthe text. Even though there are several approaches to this issue, it is still\\nan open problem. In this paper we would like to propose an approach that uses\\nK-nearest neighbors algorithm, and has the accuracy of more than 90%. The\\ntraining and run time is also very short.\\n</summary>\\n    <author>\\n      <name>Wei Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1411.1442v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1411.1442v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1411.6850v1</id>\\n    <updated>2014-11-25T13:13:47Z</updated>\\n    <published>2014-11-25T13:13:47Z</published>\\n    <title>Similarity- based approach for outlier detection</title>\\n    <summary>  This paper presents a new approach for detecting outliers by introducing the\\nnotion of object\\'s proximity. The main idea is that normal point has similar\\ncharacteristics with several neighbors. So the point in not an outlier if it\\nhas a high degree of proximity and its neighbors are several. The performance\\nof this approach is illustrated through real datasets\\n</summary>\\n    <author>\\n      <name>Amina Dik</name>\\n    </author>\\n    <author>\\n      <name>Khalid Jebari</name>\\n    </author>\\n    <author>\\n      <name>Abdelaziz Bouroumi</name>\\n    </author>\\n    <author>\\n      <name>Aziz Ettouhami</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">International Journal of Computer Science Issues 2014</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1411.6850v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1411.6850v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1411.7855v1</id>\\n    <updated>2014-11-28T13:18:22Z</updated>\\n    <published>2014-11-28T13:18:22Z</published>\\n    <title>V-variable image compression</title>\\n    <summary>  V-variable fractals, where $V$ is a positive integer, are intuitively\\nfractals with at most $V$ different \"forms\" or \"shapes\" at all levels of\\nmagnification. In this paper we describe how V-variable fractals can be used\\nfor the purpose of image compression.\\n</summary>\\n    <author>\\n      <name>Franklin Mendivil</name>\\n    </author>\\n    <author>\\n      <name>\\xc3\\x96rjan Stenflo</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1142/S0218348X15500073</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1142/S0218348X15500073\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages, 22 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Fractals, 23, no 02, (2015)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1411.7855v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1411.7855v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"28A80, 68U10, 94A08\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1412.5334v1</id>\\n    <updated>2014-12-17T10:58:46Z</updated>\\n    <published>2014-12-17T10:58:46Z</published>\\n    <title>The Affine Transforms for Image Enhancement in the Context of\\n  Logarithmic Models</title>\\n    <summary>  The logarithmic model offers new tools for image processing. An efficient\\nmethod for image enhancement is to use an affine transformation with the\\nlogarithmic operations: addition and scalar multiplication. We define some\\ncriteria for automatically determining the parameters of the processing and\\nthis is done via mean and variance computed by logarithmic operations.\\n</summary>\\n    <author>\\n      <name>Vasile Patrascu</name>\\n    </author>\\n    <author>\\n      <name>Vasile Buzuloiu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">International Conference on Computer Vision and Graphics, ICCVG2002,\\n  25-29 September, 2002, Zakopane, Poland</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1412.5334v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1412.5334v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1412.5769v1</id>\\n    <updated>2014-12-18T09:19:50Z</updated>\\n    <published>2014-12-18T09:19:50Z</published>\\n    <title>Gray level image enhancement using the Bernstein polynomials</title>\\n    <summary>  This paper presents a method for enhancing the gray level images. This\\npresented method takes part from the category of point operations and it is\\nbased on piecewise linear functions. The interpolation nodes of these functions\\nare calculated using the Bernstein polynomials.\\n</summary>\\n    <author>\\n      <name>Vasile Patrascu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Scientific Bulletin of the Politechnica, University of\\n  Timisoara,Transactions on Electronics and Communications, Vol. 47 (61), No:\\n  2,pp.121-126, June 2002</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1412.5769v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1412.5769v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1412.6061v1</id>\\n    <updated>2014-12-15T06:55:28Z</updated>\\n    <published>2014-12-15T06:55:28Z</published>\\n    <title>CITlab ARGUS for Arabic Handwriting</title>\\n    <summary>  In the recent years it turned out that multidimensional recurrent neural\\nnetworks (MDRNN) perform very well for offline handwriting recognition tasks\\nlike the OpenHaRT 2013 evaluation DIR. With suitable writing preprocessing and\\ndictionary lookup, our ARGUS software completed this task with an error rate of\\n26.27% in its primary setup.\\n</summary>\\n    <author>\\n      <name>Gundram Leifert</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Rostock - CITlab</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Roger Labahn</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Rostock - CITlab</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Tobias Strau\\xc3\\x9f</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Rostock - CITlab</arxiv:affiliation>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">http://www.nist.gov/itl/iad/mig/upload/OpenHaRT2013_SysDesc_CITLAB.pdf</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1412.6061v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1412.6061v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68T10, 68T05\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1412.6154v1</id>\\n    <updated>2014-10-06T11:45:07Z</updated>\\n    <published>2014-10-06T11:45:07Z</published>\\n    <title>Effective persistent homology of digital images</title>\\n    <summary>  In this paper, three Computational Topology methods (namely effective\\nhomology, persistent homology and discrete vector fields) are mixed together to\\nproduce algorithms for homological digital image processing. The algorithms\\nhave been implemented as extensions of the Kenzo system and have shown a good\\nperformance when applied on some actual images extracted from a public dataset.\\n</summary>\\n    <author>\\n      <name>Ana Romero</name>\\n    </author>\\n    <author>\\n      <name>Julio Rubio</name>\\n    </author>\\n    <author>\\n      <name>Francis Sergeraert</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1412.6154v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1412.6154v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1501.07692v1</id>\\n    <updated>2015-01-30T08:12:48Z</updated>\\n    <published>2015-01-30T08:12:48Z</published>\\n    <title>Blob indentation identification via curvature measurement</title>\\n    <summary>  This paper presents a novel method for identifying indentations on the\\nboundary of solid 2D shape. It uses the signed curvature at a set of points\\nalong the boundary to identify indentations and provides one parameter for\\ntuning the selection mechanism for discriminating indentations from other\\nboundary irregularities. An efficient implementation is described based on the\\nFourier transform for calculating curvature from a sequence of points obtained\\nfrom the boundary of a binary blob.\\n</summary>\\n    <author>\\n      <name>Matthew Sottile</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1501.07692v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1501.07692v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1502.05565v1</id>\\n    <updated>2015-02-19T13:35:06Z</updated>\\n    <published>2015-02-19T13:35:06Z</published>\\n    <title>Multi-valued Color Representation Based on Frank t-norm Properties</title>\\n    <summary>  In this paper two knowledge representation models are proposed, FP4 and FP6.\\nBoth combine ideas from fuzzy sets and four-valued and hexa-valued logics. Both\\nrepresent imprecise properties whose accomplished degree is unknown or\\ncontradictory for some objects. A possible application in the color analysis\\nand color image processing is discussed.\\n</summary>\\n    <author>\\n      <name>Vasile Patrascu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12th International Conference Information Processing and Management\\n  of Uncertainty for Knowledge-Based Systems, IPMU\\'2008, pp. 1215-1222, June\\n  22-27, 2008, Malaga, Spain</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1502.05565v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1502.05565v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1502.06556v1</id>\\n    <updated>2015-02-23T19:11:12Z</updated>\\n    <published>2015-02-23T19:11:12Z</published>\\n    <title>Shannon, Tsallis and Kaniadakis entropies in bi-level image thresholding</title>\\n    <summary>  The maximum entropy principle is often used for bi-level or multi-level\\nthresholding of images. For this purpose, some methods are available based on\\nShannon and Tsallis entropies. In this paper, we discuss them and propose a\\nmethod based on Kaniadakis entropy.\\n</summary>\\n    <author>\\n      <name>Amelia Carolina Sparavigna</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.18483/ijSci.626</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.18483/ijSci.626\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Keywords: Kaniadakis Entropy, Image Processing, Image Segmentation,\\n  Image Thresholding, Texture Transitions</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">International Journal of Sciences 4(2), 35-43, 2015</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1502.06556v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1502.06556v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1503.01557v3</id>\\n    <updated>2015-04-19T02:42:16Z</updated>\\n    <published>2015-03-05T07:06:02Z</published>\\n    <title>Supervised Discrete Hashing</title>\\n    <summary>  This paper has been withdrawn by the authour.\\n</summary>\\n    <author>\\n      <name>Fumin Shen</name>\\n    </author>\\n    <author>\\n      <name>Chunhua Shen</name>\\n    </author>\\n    <author>\\n      <name>Wei Liu</name>\\n    </author>\\n    <author>\\n      <name>Heng Tao Shen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been withdrawn by the authour since the algorithm is\\n  being used for patent application</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1503.01557v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1503.01557v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1505.01065v1</id>\\n    <updated>2015-04-30T10:10:16Z</updated>\\n    <published>2015-04-30T10:10:16Z</published>\\n    <title>Proceedings of The 39th Annual Workshop of the Austrian Association for\\n  Pattern Recognition (OAGM), 2015</title>\\n    <summary>  The 39th annual workshop of the Austrian Association for Pattern Recognition\\n(OAGM/AAPR) provides a platform for presentation and discussion of research\\nprogress as well as research projects within the OAGM/AAPR community.\\n</summary>\\n    <author>\\n      <name>Sebastian Hegenbart</name>\\n    </author>\\n    <author>\\n      <name>Roland Kwitt</name>\\n    </author>\\n    <author>\\n      <name>Andreas Uhl</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Index submitted before individual papers</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1505.01065v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1505.01065v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1505.02890v2</id>\\n    <updated>2015-08-25T15:12:37Z</updated>\\n    <published>2015-05-12T07:30:22Z</published>\\n    <title>Sparse 3D convolutional neural networks</title>\\n    <summary>  We have implemented a convolutional neural network designed for processing\\nsparse three-dimensional input data. The world we live in is three dimensional\\nso there are a large number of potential applications including 3D object\\nrecognition and analysis of space-time objects. In the quest for efficiency, we\\nexperiment with CNNs on the 2D triangular-lattice and 3D tetrahedral-lattice.\\n</summary>\\n    <author>\\n      <name>Ben Graham</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">BMVC 2015</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1505.02890v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1505.02890v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1505.03795v1</id>\\n    <updated>2015-05-14T16:43:07Z</updated>\\n    <published>2015-05-14T16:43:07Z</published>\\n    <title>Fast and numerically stable circle fit</title>\\n    <summary>  We develop a new algorithm for fitting circles that does not have drawbacks\\ncommonly found in existing circle fits. Our fit achieves ultimate accuracy (to\\nmachine precision), avoids divergence, and is numerically stable even when\\nfitting circles get arbitrary large. Lastly, our algorithm takes less than 10\\niterations to converge, on average.\\n</summary>\\n    <author>\\n      <name>Houssam Abdul-Rahman</name>\\n    </author>\\n    <author>\\n      <name>Nikolai Chernov</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1007/s10851-013-0461-4</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1007/s10851-013-0461-4\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Journal of Mathematical Imaging and Vision June 2014, Volume 49,\\n  Issue 2, pp 289-295</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1505.03795v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1505.03795v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1505.05240v1</id>\\n    <updated>2015-05-20T04:09:47Z</updated>\\n    <published>2015-05-20T04:09:47Z</published>\\n    <title>Benchmarking KAZE and MCM for Multiclass Classification</title>\\n    <summary>  In this paper, we propose a novel approach for feature generation by\\nappropriately fusing KAZE and SIFT features. We then use this feature set along\\nwith Minimal Complexity Machine(MCM) for object classification. We show that\\nKAZE and SIFT features are complementary. Experimental results indicate that an\\nelementary integration of these techniques can outperform the state-of-the-art\\napproaches.\\n</summary>\\n    <author>\\n      <name>Siddharth Srivastava</name>\\n    </author>\\n    <author>\\n      <name>Prerana Mukherjee</name>\\n    </author>\\n    <author>\\n      <name>Brejesh Lall</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1505.05240v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1505.05240v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.7; I.5.4; I.4.8; I.4.9; I.5.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1505.06769v1</id>\\n    <updated>2015-05-25T22:18:36Z</updated>\\n    <published>2015-05-25T22:18:36Z</published>\\n    <title>VeinPLUS: A Transillumination and Reflection-based Hand Vein Database</title>\\n    <summary>  This paper gives a short summary of work related to the creation of a\\ndepartment-hosted hand vein database. After the introducing section, special\\nproperties of the hand vein acquisition are explained, followed by a comparison\\ntable, which shows key differences to existing well-known hand vein databases.\\nAt the end, the ROI extraction process is described and sample images and ROIs\\nare presented.\\n</summary>\\n    <author>\\n      <name>Alexander Gruschina</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Presented at OAGM Workshop, 2015 (arXiv:1505.01065)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1505.06769v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1505.06769v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1507.05053v1</id>\\n    <updated>2015-07-17T17:48:49Z</updated>\\n    <published>2015-07-17T17:48:49Z</published>\\n    <title>Massively Deep Artificial Neural Networks for Handwritten Digit\\n  Recognition</title>\\n    <summary>  Greedy Restrictive Boltzmann Machines yield an fairly low 0.72% error rate on\\nthe famous MNIST database of handwritten digits. All that was required to\\nachieve this result was a high number of hidden layers consisting of many\\nneurons, and a graphics card to greatly speed up the rate of learning.\\n</summary>\\n    <author>\\n      <name>Keiron O\\'Shea</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2 pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1507.05053v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1507.05053v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1507.05244v1</id>\\n    <updated>2015-07-19T03:14:56Z</updated>\\n    <published>2015-07-19T03:14:56Z</published>\\n    <title>Handwriting Recognition</title>\\n    <summary>  This paper describes the method to recognize offline handwritten characters.\\nA robust algorithm for handwriting segmentation is described here with the help\\nof which individual characters can be segmented from a selected word from a\\nparagraph of handwritten text image which is given as input.\\n</summary>\\n    <author>\\n      <name>Jayati Ghosh Dastidar</name>\\n    </author>\\n    <author>\\n      <name>Surabhi Sarkar</name>\\n    </author>\\n    <author>\\n      <name>Rick Punyadyuti Sinha</name>\\n    </author>\\n    <author>\\n      <name>Kasturi Basu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1507.05244v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1507.05244v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1508.02246v1</id>\\n    <updated>2015-08-10T13:51:35Z</updated>\\n    <published>2015-08-10T13:51:35Z</published>\\n    <title>Feature Learning for Interaction Activity Recognition in RGBD Videos</title>\\n    <summary>  This paper proposes a human activity recognition method which is based on\\nfeatures learned from 3D video data without incorporating domain knowledge. The\\nexperiments on data collected by RGBD cameras produce results outperforming\\nother techniques. Our feature encoding method follows the bag-of-visual-word\\nmodel, then we use a SVM classifier to recognise the activities. We do not use\\nskeleton or tracking information and the same technique is applied on color and\\ndepth data.\\n</summary>\\n    <author>\\n      <name>Ngu Nguyen</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1508.02246v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1508.02246v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1509.04232v1</id>\\n    <updated>2015-09-14T18:30:05Z</updated>\\n    <published>2015-09-14T18:30:05Z</published>\\n    <title>gSLICr: SLIC superpixels at over 250Hz</title>\\n    <summary>  We introduce a parallel GPU implementation of the Simple Linear Iterative\\nClustering (SLIC) superpixel segmentation. Using a single graphic card, our\\nimplementation achieves speedups of up to $83\\\\times$ from the standard\\nsequential implementation. Our implementation is fully compatible with the\\nstandard sequential implementation and the software is now available online and\\nis open source.\\n</summary>\\n    <author>\\n      <name>Carl Yuheng Ren</name>\\n    </author>\\n    <author>\\n      <name>Victor Adrian Prisacariu</name>\\n    </author>\\n    <author>\\n      <name>Ian D Reid</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1509.04232v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1509.04232v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1509.05054v1</id>\\n    <updated>2015-09-16T20:23:06Z</updated>\\n    <published>2015-09-16T20:23:06Z</published>\\n    <title>Overcomplete Dictionary Learning with Jacobi Atom Updates</title>\\n    <summary>  Dictionary learning for sparse representations is traditionally approached\\nwith sequential atom updates, in which an optimized atom is used immediately\\nfor the optimization of the next atoms. We propose instead a Jacobi version, in\\nwhich groups of atoms are updated independently, in parallel. Extensive\\nnumerical evidence for sparse image representation shows that the parallel\\nalgorithms, especially when all atoms are updated simultaneously, give better\\ndictionaries than their sequential counterparts.\\n</summary>\\n    <author>\\n      <name>Paul Irofti</name>\\n    </author>\\n    <author>\\n      <name>Bogdan Dumitrescu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1509.05054v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1509.05054v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1512.01533v1</id>\\n    <updated>2015-12-04T20:28:27Z</updated>\\n    <published>2015-12-04T20:28:27Z</published>\\n    <title>Motion trails from time-lapse video</title>\\n    <summary>  From an image sequence captured by a stationary camera, background\\nsubtraction can detect moving foreground objects in the scene. Distinguishing\\nforeground from background is further improved by various heuristics. Then each\\nobject\\'s motion can be emphasized by duplicating its positions as a motion\\ntrail. These trails clarify the objects\\' spatial relationships. Also, adding\\nmotion trails to a video before previewing it at high speed reduces the risk of\\noverlooking transient events.\\n</summary>\\n    <author>\\n      <name>Camille Goudeseune</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1512.01533v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1512.01533v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.3.3; I.4.6\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1512.02329v2</id>\\n    <updated>2015-12-15T06:18:35Z</updated>\\n    <published>2015-12-08T05:04:57Z</published>\\n    <title>Computational Models for Multiview Dense Depth Maps of Dynamic Scene</title>\\n    <summary>  This paper reviews the recent progresses of the depth map generation for\\ndynamic scene and its corresponding computational models. This paper mainly\\ncovers the homogeneous ambiguity models in depth sensing, resolution models in\\ndepth processing, and consistency models in depth optimization. We also\\nsummarize the future work in the depth map generation.\\n</summary>\\n    <author>\\n      <name>Qifei Wang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, IEEE COMSOC MMTC E-Letter 2015</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1512.02329v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1512.02329v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1512.02357v1</id>\\n    <updated>2015-12-08T07:25:29Z</updated>\\n    <published>2015-12-08T07:25:29Z</published>\\n    <title>Towards the Application of Linear Programming Methods For Multi-Camera\\n  Pose Estimation</title>\\n    <summary>  We presented a separation based optimization algorithm which, rather than\\noptimization the entire variables altogether, This would allow us to employ: 1)\\na class of nonlinear functions with three variables and 2) a convex quadratic\\nmultivariable polynomial, for minimization of reprojection error. Neglecting\\nthe inversion required to minimize the nonlinear functions, in this paper we\\ndemonstrate how separation allows eradication of matrix inversion.\\n</summary>\\n    <author>\\n      <name>Masoud Aghamohamadian-Sharbaf</name>\\n    </author>\\n    <author>\\n      <name>Ahmadreza Heravi</name>\\n    </author>\\n    <author>\\n      <name>Hamidreza Pourreza</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1512.02357v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1512.02357v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1512.06014v2</id>\\n    <updated>2016-12-04T20:42:48Z</updated>\\n    <published>2015-12-18T16:17:35Z</published>\\n    <title>Multiclass Classification of Cervical Cancer Tissues by Hidden Markov\\n  Model</title>\\n    <summary>  In this paper, we report a hidden Markov model based multiclass\\nclassification of cervical cancer tissues. This model has been validated\\ndirectly over time series generated by the medium refractive index fluctuations\\nextracted from differential interference contrast images of healthy and\\ndifferent stages of cancer tissues. The method shows promising results for\\nmulticlass classification with higher accuracy.\\n</summary>\\n    <author>\\n      <name>Sabyasachi Mukhopadhyay</name>\\n    </author>\\n    <author>\\n      <name>Sanket Nandan</name>\\n    </author>\\n    <author>\\n      <name>Indrajit Kurmi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1512.06014v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1512.06014v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1601.00396v1</id>\\n    <updated>2016-01-04T07:28:53Z</updated>\\n    <published>2016-01-04T07:28:53Z</published>\\n    <title>Automatic Detection and Decoding of Photogrammetric Coded Targets</title>\\n    <summary>  Close-range Photogrammetry is widely used in many industries because of the\\ncost effectiveness and efficiency of the technique. In this research, we\\nintroduce an automated coded target detection method which can be used to\\nenhance the efficiency of the Photogrammetry.\\n</summary>\\n    <author>\\n      <name>Udaya Wijenayake</name>\\n    </author>\\n    <author>\\n      <name>Sung-In Choi</name>\\n    </author>\\n    <author>\\n      <name>Soon-Yong Park</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/ELINFOCOM.2014.6914413</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/ELINFOCOM.2014.6914413\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 4 figures, Electronics, Information and Communications\\n  (ICEIC), 2014 International Conference on</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1601.00396v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1601.00396v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1601.04568v1</id>\\n    <updated>2016-01-18T15:22:48Z</updated>\\n    <published>2016-01-18T15:22:48Z</published>\\n    <title>Content Aware Neural Style Transfer</title>\\n    <summary>  This paper presents a content-aware style transfer algorithm for paintings\\nand photos of similar content using pre-trained neural network, obtaining\\nbetter results than the previous work. In addition, the numerical experiments\\nshow that the style pattern and the content information is not completely\\nseparated by neural network.\\n</summary>\\n    <author>\\n      <name>Rujie Yin</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1601.04568v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1601.04568v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68T10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.10; I.5.2; I.5.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1601.08003v1</id>\\n    <updated>2016-01-29T08:54:22Z</updated>\\n    <published>2016-01-29T08:54:22Z</published>\\n    <title>Efficient Robust Mean Value Calculation of 1D Features</title>\\n    <summary>  A robust mean value is often a good alternative to the standard mean value\\nwhen dealing with data containing many outliers. An efficient method for\\nsamples of one-dimensional features and the truncated quadratic error norm is\\npresented and compared to the method of channel averaging (soft histograms).\\n</summary>\\n    <author>\\n      <name>Erik Jonsson</name>\\n    </author>\\n    <author>\\n      <name>Michael Felsberg</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Presented at the SSBA Symposium 2005, Malm\\\\\"o, Sweden</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1601.08003v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1601.08003v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1603.01772v1</id>\\n    <updated>2016-03-06T00:30:34Z</updated>\\n    <published>2016-03-06T00:30:34Z</published>\\n    <title>Fast calculation of correlations in recognition systems</title>\\n    <summary>  Computationally efficient classification system architecture is proposed. It\\nutilizes fast tensor-vector multiplication algorithm to apply linear operators\\nupon input signals . The approach is applicable to wide variety of recognition\\nsystem architectures ranging from single stage matched filter bank classifiers\\nto complex neural networks with unlimited number of hidden layers.\\n</summary>\\n    <author>\\n      <name>Pavel Dourbal</name>\\n    </author>\\n    <author>\\n      <name>Mikhail Pekker</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1603.01772v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1603.01772v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"62H30, 65F05, 65F10, 65F30, 65F50, 68T05, 68T10, 94A11, 94A12,&#10;  94A13, 94A15\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"F.2.1; G.1.0; G.1.3; G.4; H.4.2; I.1.2; I.2.2; I.5.2; I.5.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1603.06433v1</id>\\n    <updated>2016-03-21T14:23:00Z</updated>\\n    <published>2016-03-21T14:23:00Z</published>\\n    <title>Illumination-invariant image mosaic calculation based on logarithmic\\n  search</title>\\n    <summary>  This technical report describes an improved image mosaicking algorithm. It is\\nbased on Jain\\'s logarithmic search algorithm [Jain 1981] which is coupled to\\nthe method of Kourogi (1999} for matching images in a video sequence.\\nLogarithmic search has a better invariance against illumination changes than\\nthe original optical-flow-based method of Kourogi.\\n</summary>\\n    <author>\\n      <name>Wolfgang Konen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1603.06433v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1603.06433v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1603.09037v1</id>\\n    <updated>2016-03-30T04:40:31Z</updated>\\n    <published>2016-03-30T04:40:31Z</published>\\n    <title>Vector Quantization for Machine Vision</title>\\n    <summary>  This paper shows how to reduce the computational cost for a variety of common\\nmachine vision tasks by operating directly in the compressed domain,\\nparticularly in the context of hardware acceleration. Pyramid Vector\\nQuantization (PVQ) is the compression technique of choice and its properties\\nare exploited to simplify Support Vector Machines (SVM), Convolutional Neural\\nNetworks(CNNs), Histogram of Oriented Gradients (HOG) features, interest points\\nmatching and other algorithms.\\n</summary>\\n    <author>\\n      <name>Vincenzo Liguori</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 7 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1603.09037v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1603.09037v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1603.09129v1</id>\\n    <updated>2016-03-30T11:11:29Z</updated>\\n    <published>2016-03-30T11:11:29Z</published>\\n    <title>Exploiting Facial Landmarks for Emotion Recognition in the Wild</title>\\n    <summary>  In this paper, we describe an entry to the third Emotion Recognition in the\\nWild Challenge, EmotiW2015. We detail the associated experiments and show that,\\nthrough more accurately locating the facial landmarks, and considering only the\\ndistances between them, we can achieve a surprising level of performance. The\\nresulting system is not only more accurate than the challenge baseline, but\\nalso much simpler.\\n</summary>\\n    <author>\\n      <name>Matthew Day</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, ICMI 2015</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1603.09129v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1603.09129v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1604.04926v1</id>\\n    <updated>2016-04-17T20:48:49Z</updated>\\n    <published>2016-04-17T20:48:49Z</published>\\n    <title>Some medical applications of example-based super-resolution</title>\\n    <summary>  Example-based super-resolution (EBSR) reconstructs a high-resolution image\\nfrom a low-resolution image, given a training set of high-resolution images. In\\nthis note I propose some applications of EBSR to medical imaging. A particular\\ninteresting application, which I call \"x-ray voxelization\", approximates the\\nresult of a CT scan from an x-ray image.\\n</summary>\\n    <author>\\n      <name>Ramin Zabih</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1604.04926v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1604.04926v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1605.04250v2</id>\\n    <updated>2016-08-01T13:25:06Z</updated>\\n    <published>2016-05-13T16:56:10Z</published>\\n    <title>Color Homography</title>\\n    <summary>  We show the surprising result that colors across a change in viewing\\ncondition (changing light color, shading and camera) are related by a\\nhomography. Our homography color correction application delivers improved color\\nfidelity compared with the linear least-square.\\n</summary>\\n    <author>\\n      <name>Graham D. Finlayson</name>\\n    </author>\\n    <author>\\n      <name>Han Gong</name>\\n    </author>\\n    <author>\\n      <name>Robert B. Fisher</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted by Progress in Colour Studies 2016</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1605.04250v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1605.04250v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1605.04785v1</id>\\n    <updated>2016-05-16T14:42:34Z</updated>\\n    <published>2016-05-16T14:42:34Z</published>\\n    <title>An Alternative Matting Laplacian</title>\\n    <summary>  Cutting out and object and estimate its transparency mask is a key task in\\nmany applications. We take on the work on closed-form matting by Levin et al.,\\nthat is used at the core of many matting techniques, and propose an alternative\\nformulation that offers more flexible controls over the matting priors. We also\\nshow that this new approach is efficient at upscaling transparency maps from\\ncoarse estimates.\\n</summary>\\n    <author>\\n      <name>Fran\\xc3\\xa7ois Piti\\xc3\\xa9</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ICIP 2016</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1605.04785v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1605.04785v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1606.03473v1</id>\\n    <updated>2016-06-10T20:34:39Z</updated>\\n    <published>2016-06-10T20:34:39Z</published>\\n    <title>Face Detection with the Faster R-CNN</title>\\n    <summary>  The Faster R-CNN has recently demonstrated impressive results on various\\nobject detection benchmarks. By training a Faster R-CNN model on the large\\nscale WIDER face dataset, we report state-of-the-art results on two widely used\\nface detection benchmarks, FDDB and the recently released IJB-A.\\n</summary>\\n    <author>\\n      <name>Huaizu Jiang</name>\\n    </author>\\n    <author>\\n      <name>Erik Learned-Miller</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">technical report</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1606.03473v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1606.03473v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1606.08315v1</id>\\n    <updated>2016-06-27T15:23:04Z</updated>\\n    <published>2016-06-27T15:23:04Z</published>\\n    <title>Depth Estimation from Single Image using Sparse Representations</title>\\n    <summary>  Monocular depth estimation is an interesting and challenging problem as there\\nis no analytic mapping known between an intensity image and its depth map.\\nRecently there has been a lot of data accumulated through depth-sensing\\ncameras, in parallel to that researchers started to tackle this task using\\nvarious learning algorithms. In this paper, a deep sparse coding method is\\nproposed for monocular depth estimation along with an approach for\\ndeterministic dictionary initialization.\\n</summary>\\n    <author>\\n      <name>Yigit Oktar</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.13140/RG.2.1.5059.0323</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.13140/RG.2.1.5059.0323\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/1606.08315v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1606.08315v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1608.03617v1</id>\\n    <updated>2016-08-11T20:53:48Z</updated>\\n    <published>2016-08-11T20:53:48Z</published>\\n    <title>Automatic detection of moving objects in video surveillance</title>\\n    <summary>  This work is in the field of video surveillance including motion detection.\\nThe video surveillance is one of essential techniques for automatic video\\nanalysis to extract crucial information or relevant scenes in video\\nsurveillance systems. The aim of our work is to propose solutions for the\\nautomatic detection of moving objects in real time with a surveillance camera.\\nThe detected objects are objects that have some geometric shape (circle,\\nellipse, square, and rectangle).\\n</summary>\\n    <author>\\n      <name>Larbi Guezouli</name>\\n    </author>\\n    <author>\\n      <name>Hanane Belhani</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1608.03617v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1608.03617v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1608.03832v1</id>\\n    <updated>2016-08-12T15:55:12Z</updated>\\n    <published>2016-08-12T15:55:12Z</published>\\n    <title>On Minimal Accuracy Algorithm Selection in Computer Vision and\\n  Intelligent Systems</title>\\n    <summary>  In this paper we discuss certain theoretical properties of algorithm\\nselection approach to image processing and to intelligent system in general. We\\nanalyze the theoretical limits of algorithm selection with respect to the\\nalgorithm selection accuracy. We show the theoretical formulation of a crisp\\nbound on the algorithm selector precision guaranteeing to always obtain better\\nthan the best available algorithm result.\\n</summary>\\n    <author>\\n      <name>Martin Lukac</name>\\n    </author>\\n    <author>\\n      <name>Kamila Abdiyeva</name>\\n    </author>\\n    <author>\\n      <name>Michitaka Kameyama</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1608.03832v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1608.03832v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1609.02271v2</id>\\n    <updated>2016-09-09T18:37:03Z</updated>\\n    <published>2016-09-08T04:49:31Z</published>\\n    <title>Ashwin: Plug-and-Play System for Machine-Human Image Annotation</title>\\n    <summary>  We present an end-to-end machine-human image annotation system where each\\ncomponent can be attached in a plug-and-play fashion. These components include\\nFeature Extraction, Machine Classifier, Task Sampling and Crowd Consensus.\\n</summary>\\n    <author>\\n      <name>Anand Sriraman</name>\\n    </author>\\n    <author>\\n      <name>Mandar Kulkarni</name>\\n    </author>\\n    <author>\\n      <name>Rahul Kumar</name>\\n    </author>\\n    <author>\\n      <name>Kanika Kalra</name>\\n    </author>\\n    <author>\\n      <name>Purushotam Radadia</name>\\n    </author>\\n    <author>\\n      <name>Shirish Karande</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">HCOMP 2016 Demonstrations Track</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1609.02271v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1609.02271v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1609.03529v1</id>\\n    <updated>2016-09-12T19:00:24Z</updated>\\n    <published>2016-09-12T19:00:24Z</published>\\n    <title>Examining Representational Similarity in ConvNets and the Primate Visual\\n  Cortex</title>\\n    <summary>  We compare several ConvNets with different depth and regularization\\ntechniques with multi-unit macaque IT cortex recordings and assess the impact\\nof the same on representational similarity with the primate visual cortex. We\\nfind that with increasing depth and validation performance, ConvNet features\\nare closer to cortical IT representations.\\n</summary>\\n    <author>\\n      <name>Abhimanyu Dubey</name>\\n    </author>\\n    <author>\\n      <name> Jayadeva</name>\\n    </author>\\n    <author>\\n      <name>Sumeet Agarwal</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, short abstract, Accepted to the Workshop on Biological and\\n  Artificial Vision, ECCV, 2016</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1609.03529v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1609.03529v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"q-bio.NC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1609.05001v1</id>\\n    <updated>2016-09-16T11:20:07Z</updated>\\n    <published>2016-09-16T11:20:07Z</published>\\n    <title>Stamp processing with examplar features</title>\\n    <summary>  Document digitization is becoming increasingly crucial. In this work, we\\npropose a shape based approach for automatic stamp verification/detection in\\ndocument images using an unsupervised feature learning. Given a small set of\\ntraining images, our algorithm learns an appropriate shape representation using\\nan unsupervised clustering. Experimental results demonstrate the effectiveness\\nof our framework in challenging scenarios.\\n</summary>\\n    <author>\\n      <name>Yash Bhalgat</name>\\n    </author>\\n    <author>\\n      <name>Mandar Kulkarni</name>\\n    </author>\\n    <author>\\n      <name>Shirish Karande</name>\\n    </author>\\n    <author>\\n      <name>Sachin Lodha</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1609.05001v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1609.05001v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1609.07597v1</id>\\n    <updated>2016-09-24T10:32:30Z</updated>\\n    <published>2016-09-24T10:32:30Z</published>\\n    <title>DimensionApp : android app to estimate object dimensions</title>\\n    <summary>  In this project, we develop an android app that uses on computer vision\\ntechniques to estimate an object dimension present in field of view. The app\\nwhile having compact size, is accurate upto +/- 5 mm and robust towards touch\\ninputs. We use single-view metrology to compute accurate measurement. Unlike\\nprevious approaches, our technique does not rely on line detection and can be\\ngeneralize to any object shape easily.\\n</summary>\\n    <author>\\n      <name>Suriya Singh</name>\\n    </author>\\n    <author>\\n      <name>Vijay Kumar</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Project Report 2014</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1609.07597v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1609.07597v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1610.04575v1</id>\\n    <updated>2016-04-19T03:16:14Z</updated>\\n    <published>2016-04-19T03:16:14Z</published>\\n    <title>Comparing Face Detection and Recognition Techniques</title>\\n    <summary>  This paper implements and compares different techniques for face detection\\nand recognition. One is find where the face is located in the images that is\\nface detection and second is face recognition that is identifying the person.\\nWe study three techniques in this paper: Face detection using self organizing\\nmap (SOM), Face recognition by projection and nearest neighbor and Face\\nrecognition using SVM.\\n</summary>\\n    <author>\\n      <name>Jyothi Korra</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1610.04575v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1610.04575v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1610.09520v1</id>\\n    <updated>2016-10-29T14:54:28Z</updated>\\n    <published>2016-10-29T14:54:28Z</published>\\n    <title>Multi-Camera Occlusion and Sudden-Appearance-Change Detection Using\\n  Hidden Markovian Chains</title>\\n    <summary>  This paper was originally submitted to Xinova as a response to a Request for\\nInvention (RFI) on new event monitoring methods. In this paper, a new object\\ntracking algorithm using multiple cameras for surveillance applications is\\nproposed. The proposed system can detect sudden-appearance-changes and\\nocclusions using a hidden Markovian statistical model. The experimental results\\nconfirm that our system detect the sudden-appearance changes and occlusions\\nreliably.\\n</summary>\\n    <author>\\n      <name>Xudong Ma</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1610.09520v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1610.09520v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1611.03873v1</id>\\n    <updated>2016-11-11T21:00:58Z</updated>\\n    <published>2016-11-11T21:00:58Z</published>\\n    <title>Effective sparse representation of X-Ray medical images</title>\\n    <summary>  Effective sparse representation of X-Ray medical images within the context of\\ndata reduction is considered. The proposed framework is shown to render an\\nenormous reduction in the cardinality of the data set required to represent\\nthis class of images at very good quality. The particularity of the approach is\\nthat it can be implemented at very competitive processing time and low memory\\nrequirements\\n</summary>\\n    <author>\\n      <name>Laura Rebollo-Neira</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Routines for implementing the approach are available on\\n  http://www.nonlinear-approx.info/examples/node06.html</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1611.03873v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1611.03873v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1701.01035v1</id>\\n    <updated>2017-01-04T14:53:07Z</updated>\\n    <published>2017-01-04T14:53:07Z</published>\\n    <title>Path-following based Point Matching using Similarity Transformation</title>\\n    <summary>  To address the problem of 3D point matching where the poses of two point sets\\nare unknown, we adapt a recently proposed path following based method to use\\nsimilarity transformation instead of the original affine transformation. The\\nreduced number of transformation parameters leads to more constrained and\\ndesirable matching results. Experimental results demonstrate better robustness\\nof the proposed method over state-of-the-art methods.\\n</summary>\\n    <author>\\n      <name>Wei Lian</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1701.01035v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1701.01035v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1701.01885v1</id>\\n    <updated>2017-01-07T21:12:24Z</updated>\\n    <published>2017-01-07T21:12:24Z</published>\\n    <title>Group Visual Sentiment Analysis</title>\\n    <summary>  In this paper, we introduce a framework for classifying images according to\\nhigh-level sentiment. We subdivide the task into three primary problems:\\nemotion classification on faces, human pose estimation, and 3D estimation and\\nclustering of groups of people. We introduce novel algorithms for matching body\\nparts to a common individual and clustering people in images based on physical\\nlocation and orientation. Our results outperform several baseline approaches.\\n</summary>\\n    <author>\\n      <name>Zeshan Hussain</name>\\n    </author>\\n    <author>\\n      <name>Tariq Patanam</name>\\n    </author>\\n    <author>\\n      <name>Hardie Cate</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1701.01885v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1701.01885v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1701.07354v1</id>\\n    <updated>2017-01-25T15:35:09Z</updated>\\n    <published>2017-01-25T15:35:09Z</published>\\n    <title>Photographic dataset: playing cards</title>\\n    <summary>  This is a photographic dataset collected for testing image processing\\nalgorithms. The idea is to have images that can exploit the properties of total\\nvariation, therefore a set of playing cards was distributed on the scene. The\\ndataset is made available at www.fips.fi/photographic_dataset2.php\\n</summary>\\n    <author>\\n      <name>David Villacis</name>\\n    </author>\\n    <author>\\n      <name>Santeri Kaupinm\\xc3\\xa4ki</name>\\n    </author>\\n    <author>\\n      <name>Samuli Siltanen</name>\\n    </author>\\n    <author>\\n      <name>Teemu Helenius</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 12 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1701.07354v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1701.07354v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"physics.data-an\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1702.00723v1</id>\\n    <updated>2017-02-01T18:32:12Z</updated>\\n    <published>2017-02-01T18:32:12Z</published>\\n    <title>Handwritten Recognition Using SVM, KNN and Neural Network</title>\\n    <summary>  Handwritten recognition (HWR) is the ability of a computer to receive and\\ninterpret intelligible handwritten input from source such as paper documents,\\nphotographs, touch-screens and other devices. In this paper we will using three\\n(3) classification t o re cognize the handwritten which is SVM, KNN and Neural\\nNetwork.\\n</summary>\\n    <author>\\n      <name>Norhidayu Abdul Hamid</name>\\n    </author>\\n    <author>\\n      <name>Nilam Nur Amir Sjarif</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages ; 22 Figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1702.00723v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1702.00723v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68Txx\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1702.07006v1</id>\\n    <updated>2017-02-22T21:03:49Z</updated>\\n    <published>2017-02-22T21:03:49Z</published>\\n    <title>Synthesising Dynamic Textures using Convolutional Neural Networks</title>\\n    <summary>  Here we present a parametric model for dynamic textures. The model is based\\non spatiotemporal summary statistics computed from the feature representations\\nof a Convolutional Neural Network (CNN) trained on object recognition. We\\ndemonstrate how the model can be used to synthesise new samples of dynamic\\ntextures and to predict motion in simple movies.\\n</summary>\\n    <author>\\n      <name>Christina M. Funke</name>\\n    </author>\\n    <author>\\n      <name>Leon A. Gatys</name>\\n    </author>\\n    <author>\\n      <name>Alexander S. Ecker</name>\\n    </author>\\n    <author>\\n      <name>Matthias Bethge</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1702.07006v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1702.07006v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1702.07963v1</id>\\n    <updated>2017-02-26T00:56:25Z</updated>\\n    <published>2017-02-26T00:56:25Z</published>\\n    <title>Spatially Aware Melanoma Segmentation Using Hybrid Deep Learning\\n  Techniques</title>\\n    <summary>  In this paper, we proposed using a hybrid method that utilises deep\\nconvolutional and recurrent neural networks for accurate delineation of skin\\nlesion of images supplied with ISBI 2017 lesion segmentation challenge. The\\nproposed method was trained using 1800 images and tested on 150 images from\\nISBI 2017 challenge.\\n</summary>\\n    <author>\\n      <name>M. Attia</name>\\n    </author>\\n    <author>\\n      <name>M. Hossny</name>\\n    </author>\\n    <author>\\n      <name>S. Nahavandi</name>\\n    </author>\\n    <author>\\n      <name>A. Yazdabadi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ISIC2017</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1702.07963v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1702.07963v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.01402v1</id>\\n    <updated>2017-03-04T06:32:15Z</updated>\\n    <published>2017-03-04T06:32:15Z</published>\\n    <title>Skin Lesion Classification Using Deep Multi-scale Convolutional Neural\\n  Networks</title>\\n    <summary>  We present a deep learning approach to the ISIC 2017 Skin Lesion\\nClassification Challenge using a multi-scale convolutional neural network. Our\\napproach utilizes an Inception-v3 network pre-trained on the ImageNet dataset,\\nwhich is fine-tuned for skin lesion classification using two different scales\\nof input images.\\n</summary>\\n    <author>\\n      <name>Terrance DeVries</name>\\n    </author>\\n    <author>\\n      <name>Dhanesh Ramachandram</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1703.01402v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.01402v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.03108v1</id>\\n    <updated>2017-03-09T02:35:59Z</updated>\\n    <published>2017-03-09T02:35:59Z</published>\\n    <title>Image Classification of Melanoma, Nevus and Seborrheic Keratosis by Deep\\n  Neural Network Ensemble</title>\\n    <summary>  This short paper reports the method and the evaluation results of Casio and\\nShinshu University joint team for the ISBI Challenge 2017 - Skin Lesion\\nAnalysis Towards Melanoma Detection - Part 3: Lesion Classification hosted by\\nISIC. Our online validation score was 0.958 with melanoma classifier AUC 0.924\\nand seborrheic keratosis classifier AUC 0.993.\\n</summary>\\n    <author>\\n      <name>Kazuhisa Matsunaga</name>\\n    </author>\\n    <author>\\n      <name>Akira Hamada</name>\\n    </author>\\n    <author>\\n      <name>Akane Minagawa</name>\\n    </author>\\n    <author>\\n      <name>Hiroshi Koga</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages. 3 figures. ISIC2017</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1703.03108v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.03108v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.03186v1</id>\\n    <updated>2017-03-09T09:14:40Z</updated>\\n    <published>2017-03-09T09:14:40Z</published>\\n    <title>Segmenting Dermoscopic Images</title>\\n    <summary>  We propose an automatic algorithm, named SDI, for the segmentation of skin\\nlesions in dermoscopic images, articulated into three main steps: selection of\\nthe image ROI, selection of the segmentation band, and segmentation. We present\\nextensive experimental results achieved by the SDI algorithm on the lesion\\nsegmentation dataset made available for the ISIC 2017 challenge on Skin Lesion\\nAnalysis Towards Melanoma Detection, highlighting its advantages and\\ndisadvantages.\\n</summary>\\n    <author>\\n      <name>Mario Rosario Guarracino</name>\\n    </author>\\n    <author>\\n      <name>Lucia Maddalena</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1703.03186v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.03186v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.03888v1</id>\\n    <updated>2017-03-11T01:18:14Z</updated>\\n    <published>2017-03-11T01:18:14Z</published>\\n    <title>Segmentation of skin lesions based on fuzzy classification of pixels and\\n  histogram thresholding</title>\\n    <summary>  This paper proposes an innovative method for segmentation of skin lesions in\\ndermoscopy images developed by the authors, based on fuzzy classification of\\npixels and histogram thresholding.\\n</summary>\\n    <author>\\n      <name>Jose Luis Garcia-Arroyo</name>\\n    </author>\\n    <author>\\n      <name>Begonya Garcia-Zapirain</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1703.03888v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.03888v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1703.08366v1</id>\\n    <updated>2017-03-24T11:39:26Z</updated>\\n    <published>2017-03-24T11:39:26Z</published>\\n    <title>A Hybrid Deep Learning Approach for Texture Analysis</title>\\n    <summary>  Texture classification is a problem that has various applications such as\\nremote sensing and forest species recognition. Solutions tend to be custom fit\\nto the dataset used but fails to generalize. The Convolutional Neural Network\\n(CNN) in combination with Support Vector Machine (SVM) form a robust selection\\nbetween powerful invariant feature extractor and accurate classifier. The\\nfusion of experts provides stability in classification rates among different\\ndatasets.\\n</summary>\\n    <author>\\n      <name>Hussein Adly</name>\\n    </author>\\n    <author>\\n      <name>Mohamed Moustafa</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1703.08366v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1703.08366v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1704.02956v1</id>\\n    <updated>2017-04-10T17:13:00Z</updated>\\n    <published>2017-04-10T17:13:00Z</published>\\n    <title>Surface Normals in the Wild</title>\\n    <summary>  We study the problem of single-image depth estimation for images in the wild.\\nWe collect human annotated surface normals and use them to train a neural\\nnetwork that directly predicts pixel-wise depth. We propose two novel loss\\nfunctions for training with surface normal annotations. Experiments on NYU\\nDepth and our own dataset demonstrate that our approach can significantly\\nimprove the quality of depth estimation in the wild.\\n</summary>\\n    <author>\\n      <name>Weifeng Chen</name>\\n    </author>\\n    <author>\\n      <name>Donglai Xiang</name>\\n    </author>\\n    <author>\\n      <name>Jia Deng</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1704.02956v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1704.02956v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1704.03966v1</id>\\n    <updated>2017-04-13T01:41:30Z</updated>\\n    <published>2017-04-13T01:41:30Z</published>\\n    <title>Collaborative Low-Rank Subspace Clustering</title>\\n    <summary>  In this paper we present Collaborative Low-Rank Subspace Clustering. Given\\nmultiple observations of a phenomenon we learn a unified representation matrix.\\nThis unified matrix incorporates the features from all the observations, thus\\nincreasing the discriminative power compared with learning the representation\\nmatrix on each observation separately. Experimental evaluation shows that our\\nmethod outperforms subspace clustering on separate observations and the state\\nof the art collaborative learning algorithm.\\n</summary>\\n    <author>\\n      <name>Stephen Tierney</name>\\n    </author>\\n    <author>\\n      <name>Yi Guo</name>\\n    </author>\\n    <author>\\n      <name>Junbin Gao</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1704.03966v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1704.03966v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1705.01148v1</id>\\n    <updated>2017-05-02T19:21:51Z</updated>\\n    <published>2017-05-02T19:21:51Z</published>\\n    <title>Recovery of structure of looped jointed objects from multiframes</title>\\n    <summary>  A method to recover structural parameters of looped jointed objects from\\nmultiframes is being developed. Each rigid part of the jointed body needs only\\nto be traced at two (that is at junction) points.\\n  This method has been linearized for 4-part loops, with recovery from at least\\n19 frames.\\n</summary>\\n    <author>\\n      <name>Mieczys\\xc5\\x82aw K\\xc5\\x82opotek</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">a preliminary version for Machine Graphics and Vision, Vol. 3 No.\\n  4, pp. 645-656, 1995</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1705.01148v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1705.01148v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1705.01809v1</id>\\n    <updated>2017-05-04T12:20:56Z</updated>\\n    <published>2017-05-04T12:20:56Z</published>\\n    <title>Pixel Normalization from Numeric Data as Input to Neural Networks</title>\\n    <summary>  Text to image transformation for input to neural networks requires\\nintermediate steps. This paper attempts to present a new approach to pixel\\nnormalization so as to convert textual data into image, suitable as input for\\nneural networks. This method can be further improved by its Graphics Processing\\nUnit (GPU) implementation to provide significant speedup in computational time.\\n</summary>\\n    <author>\\n      <name>Parth Sane</name>\\n    </author>\\n    <author>\\n      <name>Ravindra Agrawal</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE WiSPNET 2017 conference in Chennai</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1705.01809v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1705.01809v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1705.04272v1</id>\\n    <updated>2017-04-29T11:14:16Z</updated>\\n    <published>2017-04-29T11:14:16Z</published>\\n    <title>Improved underwater image enhancement algorithms based on partial\\n  differential equations (PDEs)</title>\\n    <summary>  The experimental results of improved underwater image enhancement algorithms\\nbased on partial differential equations (PDEs) are presented in this report.\\nThis second work extends the study of previous work and incorporating several\\nimprovements into the revised algorithm. Experiments show the evidence of the\\nimprovements when compared to previously proposed approaches and other\\nconventional algorithms found in the literature.\\n</summary>\\n    <author>\\n      <name>U. A. Nnolim</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1705.04272v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1705.04272v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1706.00083v1</id>\\n    <updated>2017-05-31T20:44:55Z</updated>\\n    <published>2017-05-31T20:44:55Z</published>\\n    <title>Blood capillaries and vessels segmentation in optical coherence\\n  tomography angiogram using fuzzy C-means and Curvelet transform</title>\\n    <summary>  This paper has been removed from arXiv as the submitter did not have\\nownership of the data presented in this work.\\n</summary>\\n    <author>\\n      <name>Fariborz Taherkhani</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">arXiv admin note: This paper has been removed from arXiv as the\\n  submitter did not have ownership of the data presented in this work</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1706.00083v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.00083v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1706.03497v1</id>\\n    <updated>2017-06-12T08:04:42Z</updated>\\n    <published>2017-06-12T08:04:42Z</published>\\n    <title>A filter based approach for inbetweening</title>\\n    <summary>  We present a filter based approach for inbetweening. We train a convolutional\\nneural network to generate intermediate frames. This network aim to generate\\nsmooth animation of line drawings. Our method can process scanned images\\ndirectly. Our method does not need to compute correspondence of lines and\\ntopological changes explicitly. We experiment our method with real animation\\nproduction data. The results show that our method can generate intermediate\\nframes partially.\\n</summary>\\n    <author>\\n      <name>Yuichi Yagi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, in Japanese</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1706.03497v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.03497v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1706.05534v1</id>\\n    <updated>2017-06-17T13:33:29Z</updated>\\n    <published>2017-06-17T13:33:29Z</published>\\n    <title>Rotation Invariance Neural Network</title>\\n    <summary>  Rotation invariance and translation invariance have great values in image\\nrecognition tasks. In this paper, we bring a new architecture in convolutional\\nneural network (CNN) named cyclic convolutional layer to achieve rotation\\ninvariance in 2-D symbol recognition. We can also get the position and\\norientation of the 2-D symbol by the network to achieve detection purpose for\\nmultiple non-overlap target. Last but not least, this architecture can achieve\\none-shot learning in some cases using those invariance.\\n</summary>\\n    <author>\\n      <name>Shiyuan Li</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 4 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1706.05534v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.05534v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1706.06230v1</id>\\n    <updated>2017-06-20T00:43:22Z</updated>\\n    <published>2017-06-20T00:43:22Z</published>\\n    <title>A Bayesian algorithm for detecting identity matches and fraud in image\\n  databases</title>\\n    <summary>  A statistical algorithm for categorizing different types of matches and fraud\\nin image databases is presented. The approach is based on a generative model of\\na graph representing images and connections between pairs of identities,\\ntrained using properties of a matching algorithm between images.\\n</summary>\\n    <author>\\n      <name>Gaurav Thakur</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1706.06230v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.06230v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1706.07757v1</id>\\n    <updated>2017-04-14T14:54:14Z</updated>\\n    <published>2017-04-14T14:54:14Z</published>\\n    <title>Improved Human Emotion Recognition Using Symmetry of Facial Key Points\\n  with Dihedral Group</title>\\n    <summary>  This article describes how to deploy dihedral group theory to detect Facial\\nKey Points (FKP) symmetry to recognize emotions. The method can be applied in\\nmany other areas which those have the same data texture.\\n</summary>\\n    <author>\\n      <name>Mehdi Ghayoumi</name>\\n    </author>\\n    <author>\\n      <name>Arvind Bansal</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IJASCSE Volume 6 Issue 01 2017</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1706.07757v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.07757v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.01159v1</id>\\n    <updated>2017-07-04T21:34:08Z</updated>\\n    <published>2017-07-04T21:34:08Z</published>\\n    <title>UPSET and ANGRI : Breaking High Performance Image Classifiers</title>\\n    <summary>  In this paper, targeted fooling of high performance image classifiers is\\nachieved by developing two novel attack methods. The first method generates\\nuniversal perturbations for target classes and the second generates image\\nspecific perturbations. Extensive experiments are conducted on MNIST and\\nCIFAR10 datasets to provide insights about the proposed algorithms and show\\ntheir effectiveness.\\n</summary>\\n    <author>\\n      <name>Sayantan Sarkar</name>\\n    </author>\\n    <author>\\n      <name>Ankan Bansal</name>\\n    </author>\\n    <author>\\n      <name>Upal Mahbub</name>\\n    </author>\\n    <author>\\n      <name>Rama Chellappa</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1707.01159v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.01159v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.02051v1</id>\\n    <updated>2017-07-07T06:27:54Z</updated>\\n    <published>2017-07-07T06:27:54Z</published>\\n    <title>Image Segmentation Algorithms Overview</title>\\n    <summary>  The technology of image segmentation is widely used in medical image\\nprocessing, face recognition pedestrian detection, etc. The current image\\nsegmentation techniques include region-based segmentation, edge detection\\nsegmentation, segmentation based on clustering, segmentation based on\\nweakly-supervised learning in CNN, etc. This paper analyzes and summarizes\\nthese algorithms of image segmentation, and compares the advantages and\\ndisadvantages of different algorithms. Finally, we make a prediction of the\\ndevelopment trend of image segmentation with the combination of these\\nalgorithms.\\n</summary>\\n    <author>\\n      <name>Song Yuheng</name>\\n    </author>\\n    <author>\\n      <name>Yan Hao</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1707.02051v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.02051v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.06825v1</id>\\n    <updated>2017-07-21T10:17:33Z</updated>\\n    <published>2017-07-21T10:17:33Z</published>\\n    <title>Evaluation of Hashing Methods Performance on Binary Feature Descriptors</title>\\n    <summary>  In this paper we evaluate performance of data-dependent hashing methods on\\nbinary data. The goal is to find a hashing method that can effectively produce\\nlower dimensional binary representation of 512-bit FREAK descriptors. A\\nrepresentative sample of recent unsupervised, semi-supervised and supervised\\nhashing methods was experimentally evaluated on large datasets of labelled\\nbinary FREAK feature descriptors.\\n</summary>\\n    <author>\\n      <name>Jacek Komorowski</name>\\n    </author>\\n    <author>\\n      <name>Tomasz Trzcinski</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1707.06825v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.06825v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.08722v1</id>\\n    <updated>2017-07-27T07:00:02Z</updated>\\n    <published>2017-07-27T07:00:02Z</published>\\n    <title>Algebraic Relations and Triangulation of Unlabeled Image Points</title>\\n    <summary>  In multiview geometry when correspondences among multiple views are unknown\\nthe image points can be understood as being unlabeled. This is a common problem\\nin computer vision. We give a novel approach to handle such a situation by\\nregarding unlabeled point configurations as points on the Chow variety\\n$\\\\text{Sym}_m(\\\\mathbb{P}^2)$. For two unlabeled points we design an algorithm\\nthat solves the triangulation problem with unknown correspondences. Further the\\nunlabeled multiview variety $\\\\text{Sym}_m(V_A)$ is studied.\\n</summary>\\n    <author>\\n      <name>Andr\\xc3\\xa9 Wagner</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">17 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1707.08722v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.08722v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1707.09869v1</id>\\n    <updated>2017-07-23T01:35:55Z</updated>\\n    <published>2017-07-23T01:35:55Z</published>\\n    <title>A comment on the paper Prediction of Kidney Function from Biopsy Images\\n  using Convolutional Neural Networks</title>\\n    <summary>  This letter presente a comment on the paper Prediction of Kidney Function\\nfrom Biopsy Images using Convolutional Neural Networks by Ledbetter et al.\\n(2017)\\n</summary>\\n    <author>\\n      <name>Washington LC dos-Santos</name>\\n    </author>\\n    <author>\\n      <name>Angelo A Duarte</name>\\n    </author>\\n    <author>\\n      <name>Luiz AR de Freitas</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2 pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1707.09869v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1707.09869v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1709.05867v1</id>\\n    <updated>2017-09-18T11:28:15Z</updated>\\n    <published>2017-09-18T11:28:15Z</published>\\n    <title>Combinational neural network using Gabor filters for the classification\\n  of handwritten digits</title>\\n    <summary>  A classification algorithm that combines the components of k-nearest\\nneighbours and multilayer neural networks has been designed and tested. With\\nthis method the computational time required for training the dataset has been\\nreduced substancially. Gabor filters were used for the feature extraction to\\nensure a better performance. This algorithm is tested with MNIST dataset and it\\nwill be integrated as a module in the object recognition software which is\\ncurrently under development.\\n</summary>\\n    <author>\\n      <name>N. Joshi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1709.05867v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1709.05867v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1710.01462v1</id>\\n    <updated>2017-10-04T05:20:41Z</updated>\\n    <published>2017-10-04T05:20:41Z</published>\\n    <title>Secrets in Computing Optical Flow by Convolutional Networks</title>\\n    <summary>  Convolutional neural networks (CNNs) have been widely used over many areas in\\ncompute vision. Especially in classification. Recently, FlowNet and several\\nworks on opti- cal estimation using CNNs shows the potential ability of CNNs in\\ndoing per-pixel regression. We proposed several CNNs network architectures that\\ncan estimate optical flow, and fully unveiled the intrinsic different between\\nthese structures.\\n</summary>\\n    <author>\\n      <name>Junxuan Li</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1710.01462v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1710.01462v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1710.08011v1</id>\\n    <updated>2017-10-22T20:48:49Z</updated>\\n    <published>2017-10-22T20:48:49Z</published>\\n    <title>ActivityNet Challenge 2017 Summary</title>\\n    <summary>  The ActivityNet Large Scale Activity Recognition Challenge 2017 Summary:\\nresults and challenge participants papers.\\n</summary>\\n    <author>\\n      <name>Bernard Ghanem</name>\\n    </author>\\n    <author>\\n      <name>Juan Carlos Niebles</name>\\n    </author>\\n    <author>\\n      <name>Cees Snoek</name>\\n    </author>\\n    <author>\\n      <name>Fabian Caba Heilbron</name>\\n    </author>\\n    <author>\\n      <name>Humam Alwassel</name>\\n    </author>\\n    <author>\\n      <name>Ranjay Khrisna</name>\\n    </author>\\n    <author>\\n      <name>Victor Escorcia</name>\\n    </author>\\n    <author>\\n      <name>Kenji Hata</name>\\n    </author>\\n    <author>\\n      <name>Shyamal Buch</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">76 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1710.08011v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1710.08011v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1712.07286v4</id>\\n    <updated>2018-11-19T02:16:17Z</updated>\\n    <published>2017-12-20T01:38:53Z</published>\\n    <title>LVreID: Person Re-Identification with Long Sequence Videos</title>\\n    <summary>  This paper mainly establishes a large-scale Long sequence Video database for\\nperson re-IDentification (LVreID).\\n</summary>\\n    <author>\\n      <name>Jianing Li</name>\\n    </author>\\n    <author>\\n      <name>Shiliang Zhang</name>\\n    </author>\\n    <author>\\n      <name>Jingdong Wang</name>\\n    </author>\\n    <author>\\n      <name>Wen Gao</name>\\n    </author>\\n    <author>\\n      <name>Qi Tian</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">There is experimental error in secction 5.7</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1712.07286v4\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1712.07286v4\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1801.06104v2</id>\\n    <updated>2018-05-09T12:18:09Z</updated>\\n    <published>2018-01-18T15:53:00Z</published>\\n    <title>Invariants of multidimensional time series based on their\\n  iterated-integral signature</title>\\n    <summary>  We introduce a novel class of features for multidimensional time series, that\\nare invariant with respect to transformations of the ambient space. The general\\nlinear group, the group of rotations and the group of permutations of the axes\\nare considered. The starting point for their construction is Chen\\'s\\niterated-integral signature.\\n</summary>\\n    <author>\\n      <name>Joscha Diehl</name>\\n    </author>\\n    <author>\\n      <name>Jeremy Reizenstein</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">complete rewrite of Section 3.3</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1801.06104v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1801.06104v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.RT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1801.06504v2</id>\\n    <updated>2018-01-24T16:04:15Z</updated>\\n    <published>2018-01-19T17:41:12Z</published>\\n    <title>Detecting and counting tiny faces</title>\\n    <summary>  Finding Tiny Faces (by Hu and Ramanan) proposes a novel approach to find\\nsmall objects in an image. Our contribution consists in deeply understanding\\nthe choices of the paper together with applying and extending a similar method\\nto a real world subject which is the counting of people in a public\\ndemonstration.\\n</summary>\\n    <author>\\n      <name>Alexandre Attia</name>\\n    </author>\\n    <author>\\n      <name>Sharone Dayan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 10 figures, 2 appendix page</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1801.06504v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1801.06504v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1801.06694v1</id>\\n    <updated>2018-01-20T16:08:12Z</updated>\\n    <published>2018-01-20T16:08:12Z</published>\\n    <title>Determination of Digital Straight Segments Using the Slope</title>\\n    <summary>  We present a new method for the recognition of digital straight lines based\\non the slope. This method combines the Freeman\\'s chain coding scheme and new\\ndiscovered properties of the digital slope introduced in this paper. We also\\npresent the efficiency of our method from a testbed.\\n</summary>\\n    <author>\\n      <name>Alejandro Cartas</name>\\n    </author>\\n    <author>\\n      <name>Mar\\xc3\\xada Elena Algorri</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1801.06694v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1801.06694v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1803.05779v1</id>\\n    <updated>2018-01-19T06:30:59Z</updated>\\n    <published>2018-01-19T06:30:59Z</published>\\n    <title>A predictor-corrector method for the training of deep neural networks</title>\\n    <summary>  The training of deep neural nets is expensive. We present a predictor-\\ncorrector method for the training of deep neural nets. It alternates a\\npredictor pass with a corrector pass using stochastic gradient descent with\\nbackpropagation such that there is no loss in validation accuracy. No special\\nmodifications to SGD with backpropagation is required by this methodology. Our\\nexperiments showed a time improvement of 9% on the CIFAR-10 dataset.\\n</summary>\\n    <author>\\n      <name>Yatin Saraiya</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 2 figures, 2 tables</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1803.05779v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1803.05779v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1803.05785v1</id>\\n    <updated>2018-03-15T14:48:47Z</updated>\\n    <published>2018-03-15T14:48:47Z</published>\\n    <title>Aggregated Sparse Attention for Steering Angle Prediction</title>\\n    <summary>  In this paper, we apply the attention mechanism to autonomous driving for\\nsteering angle prediction. We propose the first model, applying the recently\\nintroduced sparse attention mechanism to visual domain, as well as the\\naggregated extension for this model. We show the improvement of the proposed\\nmethod, comparing to no attention as well as to different types of attention.\\n</summary>\\n    <author>\\n      <name>Sen He</name>\\n    </author>\\n    <author>\\n      <name>Dmitry Kangin</name>\\n    </author>\\n    <author>\\n      <name>Yang Mi</name>\\n    </author>\\n    <author>\\n      <name>Nicolas Pugeault</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1803.05785v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1803.05785v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1803.07608v1</id>\\n    <updated>2018-03-20T19:12:05Z</updated>\\n    <published>2018-03-20T19:12:05Z</published>\\n    <title>A Survey of Deep Learning Techniques for Mobile Robot Applications</title>\\n    <summary>  Advancements in deep learning over the years have attracted research into how\\ndeep artificial neural networks can be used in robotic systems. This research\\nsurvey will present a summarization of the current research with a specific\\nfocus on the gains and obstacles for deep learning to be applied to mobile\\nrobotics.\\n</summary>\\n    <author>\\n      <name>Jahanzaib Shabbir</name>\\n    </author>\\n    <author>\\n      <name>Tarique Anwer</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1803.07608v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1803.07608v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1804.02543v1</id>\\n    <updated>2018-04-07T10:24:04Z</updated>\\n    <published>2018-04-07T10:24:04Z</published>\\n    <title>Not quite unreasonable effectiveness of machine learning algorithms</title>\\n    <summary>  State-of-the-art machine learning algorithms demonstrate close to absolute\\nperformance in selected challenges. We provide arguments that the reason can be\\nin low variability of the samples and high effectiveness in learning typical\\npatterns. Due to this fact, standard performance metrics do not reveal model\\ncapacity and new metrics are required for the better understanding of\\nstate-of-the-art.\\n</summary>\\n    <author>\\n      <name>Egor Illarionov</name>\\n    </author>\\n    <author>\\n      <name>Roman Khudorozhkov</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1804.02543v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1804.02543v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1804.03286v1</id>\\n    <updated>2018-04-10T04:54:29Z</updated>\\n    <published>2018-04-10T04:54:29Z</published>\\n    <title>On the Robustness of the CVPR 2018 White-Box Adversarial Example\\n  Defenses</title>\\n    <summary>  Neural networks are known to be vulnerable to adversarial examples. In this\\nnote, we evaluate the two white-box defenses that appeared at CVPR 2018 and\\nfind they are ineffective: when applying existing techniques, we can reduce the\\naccuracy of the defended models to 0%.\\n</summary>\\n    <author>\\n      <name>Anish Athalye</name>\\n    </author>\\n    <author>\\n      <name>Nicholas Carlini</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1804.03286v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1804.03286v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1806.05233v1</id>\\n    <updated>2018-06-13T19:23:51Z</updated>\\n    <published>2018-06-13T19:23:51Z</published>\\n    <title>End-to-End Parkinson Disease Diagnosis using Brain MR-Images by 3D-CNN</title>\\n    <summary>  In this work, we use a deep learning framework for simultaneous\\nclassification and regression of Parkinson disease diagnosis based on MR-Images\\nand personal information (i.e. age, gender). We intend to facilitate and\\nincrease the confidence in Parkinson disease diagnosis through our deep\\nlearning framework.\\n</summary>\\n    <author>\\n      <name>Soheil Esmaeilzadeh</name>\\n    </author>\\n    <author>\\n      <name>Yao Yang</name>\\n    </author>\\n    <author>\\n      <name>Ehsan Adeli</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1806.05233v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1806.05233v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.00273v1</id>\\n    <updated>2018-07-01T05:28:27Z</updated>\\n    <published>2018-07-01T05:28:27Z</published>\\n    <title>Photorealistic Style Transfer for Videos</title>\\n    <summary>  Photorealistic style transfer is a technique which transfers colour from one\\nreference domain to another domain by using deep learning and optimization\\ntechniques. Here, we present a technique which we use to transfer style and\\ncolour from a reference image to a video.\\n</summary>\\n    <author>\\n      <name>Michael Honke</name>\\n    </author>\\n    <author>\\n      <name>Rahul Iyer</name>\\n    </author>\\n    <author>\\n      <name>Dishant Mittal</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.00273v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.00273v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.00686v1</id>\\n    <updated>2018-06-29T07:49:08Z</updated>\\n    <published>2018-06-29T07:49:08Z</published>\\n    <title>YH Technologies at ActivityNet Challenge 2018</title>\\n    <summary>  This notebook paper presents an overview and comparative analysis of our\\nsystems designed for the following five tasks in ActivityNet Challenge 2018:\\ntemporal action proposals, temporal action localization, dense-captioning\\nevents in videos, trimmed action recognition, and spatio-temporal action\\nlocalization.\\n</summary>\\n    <author>\\n      <name>Ting Yao</name>\\n    </author>\\n    <author>\\n      <name>Xue Li</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Rank 2 in both Temporal Activity Detection Task &amp; Kinetics Task @\\n  ActivityNet 2018. arXiv admin note: substantial text overlap with\\n  arXiv:1710.08011 by other authors</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1807.00686v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.00686v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.06644v1</id>\\n    <updated>2018-07-17T20:03:19Z</updated>\\n    <published>2018-07-17T20:03:19Z</published>\\n    <title>A Framework for Moment Invariants</title>\\n    <summary>  For more than half a century, moments have attracted lot ot interest in the\\npattern recognition community.The moments of a distribution (an object) provide\\nseveral of its characteristics as center of gravity, orientation, disparity,\\nvolume. Moments can be used to define invariant characteristics to some\\ntransformations that an object can undergo, commonly called moment invariants.\\nThis work provides a simple and systematic formalism to compute geometric\\nmoment invariants in n-dimensional space.\\n</summary>\\n    <author>\\n      <name>Omar Tahri</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.06644v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.06644v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.08332v1</id>\\n    <updated>2018-07-22T18:07:50Z</updated>\\n    <published>2018-07-22T18:07:50Z</published>\\n    <title>Skin Lesion Analysis Towards Melanoma Detection via End-to-end Deep\\n  Learning of Convolutional Neural Networks</title>\\n    <summary>  This article presents the design, experiments and results of our solution\\nsubmitted to the 2018 ISIC challenge: Skin Lesion Analysis Towards Melanoma\\nDetection. We design a pipeline using state-of-the-art Convolutional Neural\\nNetwork (CNN) models for a Lesion Boundary Segmentation task and a Lesion\\nDiagnosis task.\\n</summary>\\n    <author>\\n      <name>Katherine M. Li</name>\\n    </author>\\n    <author>\\n      <name>Evelyn C. Li</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.08332v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.08332v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.08471v2</id>\\n    <updated>2018-07-25T09:31:46Z</updated>\\n    <published>2018-07-23T08:14:36Z</published>\\n    <title>Deep attention-guided fusion network for lesion segmentation</title>\\n    <summary>  We participated the Task 1: Lesion Segmentation. The paper describes our\\nalgorithm and the final result of validation set for the ISIC Challenge 2018 -\\nSkin Lesion Analysis Towards Melanoma Detection.\\n</summary>\\n    <author>\\n      <name>Hengliang Zhu</name>\\n    </author>\\n    <author>\\n      <name>Yangyang Hao</name>\\n    </author>\\n    <author>\\n      <name>Lizhuang Ma</name>\\n    </author>\\n    <author>\\n      <name>Ruixing Li</name>\\n    </author>\\n    <author>\\n      <name>Hua Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.08471v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.08471v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.09083v1</id>\\n    <updated>2018-07-24T13:17:55Z</updated>\\n    <published>2018-07-24T13:17:55Z</published>\\n    <title>ISIC 2017 Skin Lesion Segmentation Using Deep Encoder-Decoder Network</title>\\n    <summary>  This paper summarizes our method and validation results for part 1 of the\\nISBI Challenge 2018. Our algorithm makes use of deep encoder-decoder network\\nand novel skin lesion data augmentation to segment the challenge objective.\\nBesides, we also propose an effective testing strategy by applying multi-model\\ncomparison.\\n</summary>\\n    <author>\\n      <name>Ngoc-Quang Nguyen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ISIC 2018</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1807.09083v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.09083v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.09163v1</id>\\n    <updated>2018-07-24T14:48:57Z</updated>\\n    <published>2018-07-24T14:48:57Z</published>\\n    <title>Skin disease identification from dermoscopy images using deep\\n  convolutional neural network</title>\\n    <summary>  In this paper, a deep neural network based ensemble method is experimented\\nfor automatic identification of skin disease from dermoscopic images. The\\ndeveloped algorithm is applied on the task3 of the ISIC 2018 challenge dataset\\n(Skin Lesion Analysis Towards Melanoma Detection).\\n</summary>\\n    <author>\\n      <name>Anabik Pal</name>\\n    </author>\\n    <author>\\n      <name>Sounak Ray</name>\\n    </author>\\n    <author>\\n      <name>Utpal Garain</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Challenge Participation in ISIC 2018: Skin Lesion Analysis Towards\\n  Melanoma Detection</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1807.09163v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.09163v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1807.09312v1</id>\\n    <updated>2018-07-24T19:14:29Z</updated>\\n    <published>2018-07-24T19:14:29Z</published>\\n    <title>A Simple Probabilistic Model for Uncertainty Estimation</title>\\n    <summary>  The article focuses on determining the predictive uncertainty of a model on\\nthe example of atrial fibrillation detection problem by a single-lead ECG\\nsignal. To this end, the model predicts parameters of the beta distribution\\nover class probabilities instead of these probabilities themselves. It was\\nshown that the described approach allows to detect atypical recordings and\\nsignificantly improve the quality of the algorithm on confident predictions.\\n</summary>\\n    <author>\\n      <name>Alexander Kuvaev</name>\\n    </author>\\n    <author>\\n      <name>Roman Khudorozhkov</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1807.09312v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1807.09312v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1808.02373v2</id>\\n    <updated>2018-08-14T01:59:29Z</updated>\\n    <published>2018-08-04T11:57:27Z</published>\\n    <title>Troy: Give Attention to Saliency and for Saliency</title>\\n    <summary>  In addition, our work has text overlap with arXiv:1804.06242,\\narXiv:1705.00938 by other authors. We want to rewrite this paper for avoiding\\nthis fact.\\n</summary>\\n    <author>\\n      <name>Pingping Zhang</name>\\n    </author>\\n    <author>\\n      <name>Huchuan Lu</name>\\n    </author>\\n    <author>\\n      <name>Chunhua Shen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">All of authors agree to withdrawal this paper because we have noticed\\n  several important errors</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1808.02373v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1808.02373v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1809.05076v1</id>\\n    <updated>2018-09-13T17:33:18Z</updated>\\n    <published>2018-09-13T17:33:18Z</published>\\n    <title>Computer Vision-aided Atom Tracking in STEM Imaging</title>\\n    <summary>  To address the SMC\\'17 data challenge -- \"Data mining atomically resolved\\nimages for material properties\", we first used the classic \"blob detection\"\\nalgorithms developed in computer vision to identify all atom centers in each\\nSTEM image frame. With the help of nearest neighbor analysis, we then found and\\nlabeled every atom center common to all the STEM frames and tracked their\\nmovements through the given time interval for both Molybdenum or Selenium\\natoms.\\n</summary>\\n    <author>\\n      <name>Yawei Hui</name>\\n    </author>\\n    <author>\\n      <name>Yaohua Liu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1809.05076v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1809.05076v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1809.06079v1</id>\\n    <updated>2018-09-17T08:59:22Z</updated>\\n    <published>2018-09-17T08:59:22Z</published>\\n    <title>An Integral Pose Regression System for the ECCV2018 PoseTrack Challenge</title>\\n    <summary>  For the ECCV 2018 PoseTrack Challenge, we present a 3D human pose estimation\\nsystem based mainly on the integral human pose regression method. We show a\\ncomprehensive ablation study to examine the key performance factors of the\\nproposed system. Our system obtains 47mm MPJPE on the CHALL_H80K test dataset,\\nplacing second in the ECCV2018 3D human pose estimation challenge. Code will be\\nreleased to facilitate future work.\\n</summary>\\n    <author>\\n      <name>Xiao Sun</name>\\n    </author>\\n    <author>\\n      <name>Chuankang Li</name>\\n    </author>\\n    <author>\\n      <name>Stephen Lin</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1809.06079v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1809.06079v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1809.11066v1</id>\\n    <updated>2018-09-28T14:42:29Z</updated>\\n    <published>2018-09-28T14:42:29Z</published>\\n    <title>Camera Pose Estimation from Sequence of Calibrated Images</title>\\n    <summary>  In this paper a method for camera pose estimation from a sequence of images\\nis presented. The method assumes camera is calibrated (intrinsic parameters are\\nknown) which allows to decrease a number of required pairs of corresponding\\npoints compared to uncalibrated case. Our algorithm can be used as a first\\nstage in a structure from motion stereo reconstruction system.\\n</summary>\\n    <author>\\n      <name>Jacek Komorowski</name>\\n    </author>\\n    <author>\\n      <name>Przemyslaw Rokita</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1809.11066v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1809.11066v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1810.00965v1</id>\\n    <updated>2018-10-01T20:37:07Z</updated>\\n    <published>2018-10-01T20:37:07Z</published>\\n    <title>Natural measures of alignment</title>\\n    <summary>  Natural coordinate system will be proposed. In this coordinate system\\nalignment procedure of a device and a detector can be easily performed. This\\napproach is generalization of previous specific formulas in the field of\\ncalibration and provide top level description of the procedure. A basic example\\napplication to linac therapy plan is also provided.\\n</summary>\\n    <author>\\n      <name>R. A. Kycia</name>\\n    </author>\\n    <author>\\n      <name>Z. Tabor</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1810.00965v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1810.00965v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1811.06287v1</id>\\n    <updated>2018-11-15T10:44:35Z</updated>\\n    <published>2018-11-15T10:44:35Z</published>\\n    <title>Sketch based Reduced Memory Hough Transform</title>\\n    <summary>  This paper proposes using sketch algorithms to represent the votes in Hough\\ntransforms. Replacing the accumulator array with a sketch (Sketch Hough\\nTransform - SHT) significantly reduces the memory needed to compute a Hough\\ntransform. We also present a new sketch, Count Median Update, which works\\nbetter than known sketch methods for replacing the accumulator array in the\\nHough Transform.\\n</summary>\\n    <author>\\n      <name>Levi Offen</name>\\n    </author>\\n    <author>\\n      <name>Michael Werman</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2018 25th IEEE International Conference on Image Processing (ICIP)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1811.06287v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1811.06287v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"1\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1811.10355v1</id>\\n    <updated>2018-11-26T13:22:17Z</updated>\\n    <published>2018-11-26T13:22:17Z</published>\\n    <title>Unsupervised learning with sparse space-and-time autoencoders</title>\\n    <summary>  We use spatially-sparse two, three and four dimensional convolutional\\nautoencoder networks to model sparse structures in 2D space, 3D space, and\\n3+1=4 dimensional space-time. We evaluate the resulting latent spaces by\\ntesting their usefulness for downstream tasks. Applications are to handwriting\\nrecognition in 2D, segmentation for parts in 3D objects, segmentation for\\nobjects in 3D scenes, and body-part segmentation for 4D wire-frame models\\ngenerated from motion capture data.\\n</summary>\\n    <author>\\n      <name>Benjamin Graham</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1811.10355v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1811.10355v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1811.11314v1</id>\\n    <updated>2018-11-27T23:45:58Z</updated>\\n    <published>2018-11-27T23:45:58Z</published>\\n    <title>Skin lesion segmentation using U-Net and good training strategies</title>\\n    <summary>  In this paper we approach the problem of skin lesion segmentation using a\\nconvolutional neural network based on the U-Net architecture. We present a set\\nof training strategies that had a significant impact on the performance of this\\nmodel. We evaluated this method on the ISIC Challenge 2018 - Skin Lesion\\nAnalysis Towards Melanoma Detection, obtaining threshold Jaccard index of\\n77.5%.\\n</summary>\\n    <author>\\n      <name>Fred Guth</name>\\n    </author>\\n    <author>\\n      <name>Teofilo E. deCampos</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1811.11314v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1811.11314v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68T45\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.03706v5</id>\\n    <updated>2019-05-17T06:39:19Z</updated>\\n    <published>2019-01-13T12:42:42Z</published>\\n    <title>Generating Adversarial Perturbation with Root Mean Square Gradient</title>\\n    <summary>  We focus our attention on the problem of generating adversarial perturbations\\nbased on the gradient in image classification domain\\n</summary>\\n    <author>\\n      <name>Yatie Xiao</name>\\n    </author>\\n    <author>\\n      <name>Chi-Man Pun</name>\\n    </author>\\n    <author>\\n      <name>Jizhe Zhou</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The formula in Algorithm 1 lacks important representations</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1901.03706v5\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.03706v5\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.05259v1</id>\\n    <updated>2019-01-16T12:31:08Z</updated>\\n    <published>2019-01-16T12:31:08Z</published>\\n    <title>MRI to CT Translation with GANs</title>\\n    <summary>  We present a detailed description and reference implementation of\\npreprocessing steps necessary to prepare the public Retrospective Image\\nRegistration Evaluation (RIRE) dataset for the task of magnetic resonance\\nimaging (MRI) to X-ray computed tomography (CT) translation. Furthermore we\\ndescribe and implement three state of the art convolutional neural network\\n(CNN) and generative adversarial network (GAN) models where we report\\nstatistics and visual results of two of them.\\n</summary>\\n    <author>\\n      <name>Bodo Kaiser</name>\\n    </author>\\n    <author>\\n      <name>Shadi Albarqouni</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 12 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1901.05259v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.05259v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.05531v1</id>\\n    <updated>2019-01-16T21:27:57Z</updated>\\n    <published>2019-01-16T21:27:57Z</published>\\n    <title>Response to \"Visual Dialogue without Vision or Dialogue\" (Massiceti et\\n  al., 2018)</title>\\n    <summary>  In a recent workshop paper, Massiceti et al. presented a baseline model and\\nsubsequent critique of Visual Dialog (Das et al., CVPR 2017) that raises what\\nwe believe to be unfounded concerns about the dataset and evaluation. This\\narticle intends to rebut the critique and clarify potential confusions for\\npractitioners and future participants in the Visual Dialog challenge.\\n</summary>\\n    <author>\\n      <name>Abhishek Das</name>\\n    </author>\\n    <author>\\n      <name>Devi Parikh</name>\\n    </author>\\n    <author>\\n      <name>Dhruv Batra</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1901.05531v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.05531v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.09156v1</id>\\n    <updated>2019-01-26T04:22:30Z</updated>\\n    <published>2019-01-26T04:22:30Z</published>\\n    <title>Human Pose Estimation using Motion Priors and Ensemble Models</title>\\n    <summary>  Human pose estimation in images and videos is one of key technologies for\\nrealizing a variety of human activity recognition tasks (e.g., human-computer\\ninteraction, gesture recognition, surveillance, and video summarization). This\\npaper presents two types of human pose estimation methodologies; 1) 3D human\\npose tracking using motion priors and 2) 2D human pose estimation with ensemble\\nmodeling.\\n</summary>\\n    <author>\\n      <name>Norimichi Ukita</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Presented at the 2017 International Conference on Advanced\\n  Computer Science and Information Systems (ICACSIS)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1901.09156v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.09156v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1902.02831v1</id>\\n    <updated>2019-02-07T20:22:15Z</updated>\\n    <published>2019-02-07T20:22:15Z</published>\\n    <title>Evaluating Crowd Density Estimators via Their Uncertainty Bounds</title>\\n    <summary>  In this work, we use the Belief Function Theory which extends the\\nprobabilistic framework in order to provide uncertainty bounds to different\\ncategories of crowd density estimators. Our method allows us to compare the\\nmulti-scale performance of the estimators, and also to characterize their\\nreliability for crowd monitoring applications requiring varying degrees of\\nprudence.\\n</summary>\\n    <author>\\n      <name>Jennifer Vandoni</name>\\n    </author>\\n    <author>\\n      <name>Emanuel Aldea</name>\\n    </author>\\n    <author>\\n      <name>Sylvie Le H\\xc3\\xa9garat-Mascle</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1902.02831v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1902.02831v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1902.03091v1</id>\\n    <updated>2019-02-08T14:24:36Z</updated>\\n    <published>2019-02-08T14:24:36Z</published>\\n    <title>FocusNet: An attention-based Fully Convolutional Network for Medical\\n  Image Segmentation</title>\\n    <summary>  We propose a novel technique to incorporate attention within convolutional\\nneural networks using feature maps generated by a separate convolutional\\nautoencoder. Our attention architecture is well suited for incorporation with\\ndeep convolutional networks. We evaluate our model on benchmark segmentation\\ndatasets in skin cancer segmentation and lung lesion segmentation. Results show\\nhighly competitive performance when compared with U-Net and it\\'s residual\\nvariant.\\n</summary>\\n    <author>\\n      <name>Chaitanya Kaul</name>\\n    </author>\\n    <author>\\n      <name>Suresh Manandhar</name>\\n    </author>\\n    <author>\\n      <name>Nick Pears</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1902.03091v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1902.03091v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1902.03601v1</id>\\n    <updated>2019-02-10T13:51:47Z</updated>\\n    <published>2019-02-10T13:51:47Z</published>\\n    <title>Vulnerable road user detection: state-of-the-art and open challenges</title>\\n    <summary>  Correctly identifying vulnerable road users (VRUs), e.g. cyclists and\\npedestrians, remains one of the most challenging environment perception tasks\\nfor autonomous vehicles (AVs). This work surveys the current state-of-the-art\\nin VRU detection, covering topics such as benchmarks and datasets, object\\ndetection techniques and relevant machine learning algorithms. The article\\nconcludes with a discussion of remaining open challenges and promising future\\nresearch directions for this domain.\\n</summary>\\n    <author>\\n      <name>Patrick Mannion</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1902.03601v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1902.03601v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1902.05429v1</id>\\n    <updated>2019-02-13T09:09:52Z</updated>\\n    <published>2019-02-13T09:09:52Z</published>\\n    <title>Structured Bayesian Compression for Deep models in mobile enabled\\n  devices for connected healthcare</title>\\n    <summary>  Deep Models, typically Deep neural networks, have millions of parameters,\\nanalyze medical data accurately, yet in a time-consuming method. However,\\nenergy cost effectiveness and computational efficiency are important for\\nprerequisites developing and deploying mobile-enabled devices, the mainstream\\ntrend in connected healthcare.\\n</summary>\\n    <author>\\n      <name>Sijia Chen</name>\\n    </author>\\n    <author>\\n      <name>Bin Song</name>\\n    </author>\\n    <author>\\n      <name>Xiaojiang Du</name>\\n    </author>\\n    <author>\\n      <name>Nadra Guizani</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1902.05429v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1902.05429v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1904.06577v2</id>\\n    <updated>2020-05-30T11:18:01Z</updated>\\n    <published>2019-04-13T17:50:28Z</published>\\n    <title>Direct Sparse Mapping</title>\\n    <summary>  Photometric bundle adjustment, PBA, accurately estimates geometry from video.\\nHowever, current PBA systems have a temporary map that cannot manage scene\\nreobservations. We present, DSM, a full monocular visual SLAM based on PBA. Its\\npersistent map handles reobservations, yielding the most accurate results up to\\ndate on EuRoC for a direct method.\\n</summary>\\n    <author>\\n      <name>Jon Zubizarreta</name>\\n    </author>\\n    <author>\\n      <name>Iker Aguinaga</name>\\n    </author>\\n    <author>\\n      <name>J. M. M. Montiel</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/TRO.2020.2991614</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/TRO.2020.2991614\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted for publication in IEEE Transactions on Robotics</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1904.06577v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1904.06577v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1905.04093v1</id>\\n    <updated>2019-05-10T11:58:10Z</updated>\\n    <published>2019-05-10T11:58:10Z</published>\\n    <title>Towards Unsupervised Familiar Scene Recognition in Egocentric Videos</title>\\n    <summary>  Nowadays, there is an upsurge of interest in using lifelogging devices. Such\\ndevices generate huge amounts of image data; consequently, the need for\\nautomatic methods for analyzing and summarizing these data is drastically\\nincreasing. We present a new method for familiar scene recognition in\\negocentric videos, based on background pattern detection through automatically\\nconfigurable COSFIRE filters. We present some experiments over egocentric data\\nacquired with the Narrative Clip.\\n</summary>\\n    <author>\\n      <name>Estefania Talavera</name>\\n    </author>\\n    <author>\\n      <name>Nicolai Petkov</name>\\n    </author>\\n    <author>\\n      <name>Petia Radeva</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1905.04093v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1905.04093v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1905.04740v1</id>\\n    <updated>2019-05-12T16:38:19Z</updated>\\n    <published>2019-05-12T16:38:19Z</published>\\n    <title>Object Detection in Specific Traffic Scenes using YOLOv2</title>\\n    <summary>  object detection framework plays crucial role in autonomous driving. In this\\npaper, we introduce the real-time object detection framework called You Only\\nLook Once (YOLOv1) and the related improvements of YOLOv2. We further explore\\nthe capability of YOLOv2 by implementing its pre-trained model to do the object\\ndetecting tasks in some specific traffic scenes. The four artificially designed\\ntraffic scenes include single-car, single-person, frontperson-rearcar and\\nfrontcar-rearperson.\\n</summary>\\n    <author>\\n      <name>Shouyu Wang</name>\\n    </author>\\n    <author>\\n      <name>Weitao Tang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1905.04740v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1905.04740v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1905.06540v2</id>\\n    <updated>2019-05-27T07:11:10Z</updated>\\n    <published>2019-05-16T05:55:38Z</published>\\n    <title>Title Redacted</title>\\n    <summary>  arXiv admin note: This version removed by arXiv administrators as the\\nsubmitter did not have the right to agree to the license at the time of\\nsubmission\\n</summary>\\n    <author>\\n      <name>Shivang Bharadwaj</name>\\n    </author>\\n    <author>\\n      <name>Bhupendra Niranjan</name>\\n    </author>\\n    <author>\\n      <name>Anant Kumar</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been withdrawn as it is the proprietary property of an\\n  organization. A revision might or might not be uploaded in the future after\\n  further internal reviews and revisions. arXiv admin note: Title redacted</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1905.06540v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1905.06540v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1905.13302v1</id>\\n    <updated>2019-05-26T15:47:28Z</updated>\\n    <published>2019-05-26T15:47:28Z</published>\\n    <title>A Survey on Biomedical Image Captioning</title>\\n    <summary>  Image captioning applied to biomedical images can assist and accelerate the\\ndiagnosis process followed by clinicians. This article is the first survey of\\nbiomedical image captioning, discussing datasets, evaluation measures, and\\nstate of the art methods. Additionally, we suggest two baselines, a weak and a\\nstronger one; the latter outperforms all current state of the art systems on\\none of the datasets.\\n</summary>\\n    <author>\\n      <name>Vasiliki Kougia</name>\\n    </author>\\n    <author>\\n      <name>John Pavlopoulos</name>\\n    </author>\\n    <author>\\n      <name>Ion Androutsopoulos</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">SiVL 2019</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1905.13302v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1905.13302v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1906.05893v1</id>\\n    <updated>2019-06-13T18:59:29Z</updated>\\n    <published>2019-06-13T18:59:29Z</published>\\n    <title>IntrinSeqNet: Learning to Estimate the Reflectance from Varying\\n  Illumination</title>\\n    <summary>  This article has been removed by arXiv administrators because the submitter\\ndid not have the rights to agree to the license at the time of submission\\n</summary>\\n    <author>\\n      <name>Gr\\xc3\\xa9goire Nieto</name>\\n    </author>\\n    <author>\\n      <name>Mohammad Rouhani</name>\\n    </author>\\n    <author>\\n      <name>Philippe Robert</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This article has been removed by arXiv administrators because the\\n  submitter did not have the rights to agree to the license at the time of\\n  submission</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1906.05893v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1906.05893v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1906.07016v1</id>\\n    <updated>2019-06-14T08:39:52Z</updated>\\n    <published>2019-06-14T08:39:52Z</published>\\n    <title>Trimmed Action Recognition, Dense-Captioning Events in Videos, and\\n  Spatio-temporal Action Localization with Focus on ActivityNet Challenge 2019</title>\\n    <summary>  This notebook paper presents an overview and comparative analysis of our\\nsystems designed for the following three tasks in ActivityNet Challenge 2019:\\ntrimmed action recognition, dense-captioning events in videos, and\\nspatio-temporal action localization.\\n</summary>\\n    <author>\\n      <name>Zhaofan Qiu</name>\\n    </author>\\n    <author>\\n      <name>Dong Li</name>\\n    </author>\\n    <author>\\n      <name>Yehao Li</name>\\n    </author>\\n    <author>\\n      <name>Qi Cai</name>\\n    </author>\\n    <author>\\n      <name>Yingwei Pan</name>\\n    </author>\\n    <author>\\n      <name>Ting Yao</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">arXiv admin note: substantial text overlap with arXiv:1807.00686,\\n  arXiv:1710.08011</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1906.07016v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1906.07016v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1909.08866v1</id>\\n    <updated>2019-09-19T08:54:51Z</updated>\\n    <published>2019-09-19T08:54:51Z</published>\\n    <title>Challenging deep image descriptors for retrieval in heterogeneous\\n  iconographic collections</title>\\n    <summary>  This article proposes to study the behavior of recent and efficient\\nstate-of-the-art deep-learning based image descriptors for content-based image\\nretrieval, facing a panel of complex variations appearing in heterogeneous\\nimage datasets, in particular in cultural collections that may involve\\nmulti-source, multi-date and multi-view Permission to make digital\\n</summary>\\n    <author>\\n      <name>Dimitri Gominski</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LaSTIG</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Martyna Poreba</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LaSTIG</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Val\\xc3\\xa9rie Gouet-Brunet</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LaSTIG</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Liming Chen</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LaSTIG</arxiv:affiliation>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1145/3347317.3357246</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1145/3347317.3357246\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">SUMAC \\'19, 2019</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1909.08866v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1909.08866v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1910.03903v1</id>\\n    <updated>2019-10-09T11:22:59Z</updated>\\n    <published>2019-10-09T11:22:59Z</published>\\n    <title>MixMatch Domain Adaptaion: Prize-winning solution for both tracks of\\n  VisDA 2019 challenge</title>\\n    <summary>  We present a domain adaptation (DA) system that can be used in multi-source\\nand semi-supervised settings. Using the proposed method we achieved 2nd place\\non multi-source track and 3rd place on semi-supervised track of the VisDA 2019\\nchallenge (http://ai.bu.edu/visda-2019/). The source code of the method is\\navailable at https://github.com/filaPro/visda2019.\\n</summary>\\n    <author>\\n      <name>Danila Rukhovich</name>\\n    </author>\\n    <author>\\n      <name>Danil Galeev</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">accepted at TASK-CV 2019 at ICCV</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1910.03903v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1910.03903v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1910.11100v1</id>\\n    <updated>2019-10-18T08:09:23Z</updated>\\n    <published>2019-10-18T08:09:23Z</published>\\n    <title>Development of a hand pose recognition system on an embedded computer\\n  using CNNs</title>\\n    <summary>  Demand of hand pose recognition systems are growing in the last years in\\ntechnologies like human-machine interfaces. This work suggests an approach for\\nhand pose recognition in embedded computers using hand tracking and CNNs.\\nResults show a fast time response with an accuracy of 94.50% and low power\\nconsumption.\\n</summary>\\n    <author>\\n      <name>Dennis N\\xc3\\xba\\xc3\\xb1ez Fern\\xc3\\xa1ndez</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LatinX in AI Research at NeurIPS 2019</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1910.11100v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1910.11100v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1910.11534v1</id>\\n    <updated>2019-10-25T05:28:36Z</updated>\\n    <published>2019-10-25T05:28:36Z</published>\\n    <title>Team PFDet\\'s Methods for Open Images Challenge 2019</title>\\n    <summary>  We present the instance segmentation and the object detection method used by\\nteam PFDet for Open Images Challenge 2019. We tackle a massive dataset size,\\nhuge class imbalance and federated annotations. Using this method, the team\\nPFDet achieved 3rd and 4th place in the instance segmentation and the object\\ndetection track, respectively.\\n</summary>\\n    <author>\\n      <name>Yusuke Niitani</name>\\n    </author>\\n    <author>\\n      <name>Toru Ogawa</name>\\n    </author>\\n    <author>\\n      <name>Shuji Suzuki</name>\\n    </author>\\n    <author>\\n      <name>Takuya Akiba</name>\\n    </author>\\n    <author>\\n      <name>Tommi Kerola</name>\\n    </author>\\n    <author>\\n      <name>Kohei Ozaki</name>\\n    </author>\\n    <author>\\n      <name>Shotaro Sano</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1910.11534v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1910.11534v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1911.07938v1</id>\\n    <updated>2019-10-28T03:00:28Z</updated>\\n    <published>2019-10-28T03:00:28Z</published>\\n    <title>Towards Good Practices for Multi-Person Pose Estimation</title>\\n    <summary>  Multi-Person Pose Estimation is an interesting yet challenging task in\\ncomputer vision. In this paper, we conduct a series of refinements with the\\nMSPN and PoseFix Networks, and empirically evaluate their impact on the final\\nmodel performance through ablation studies. By taking all the refinements, we\\nachieve 78.7 on the COCO test-dev dataset and 76.3 on the COCO test-challenge\\ndataset.\\n</summary>\\n    <author>\\n      <name>Dongdong Yu</name>\\n    </author>\\n    <author>\\n      <name>Kai Su</name>\\n    </author>\\n    <author>\\n      <name>Changhu Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1911.07938v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.07938v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1911.07939v1</id>\\n    <updated>2019-10-28T03:03:48Z</updated>\\n    <published>2019-10-28T03:03:48Z</published>\\n    <title>Towards Good Practices for Instance Segmentation</title>\\n    <summary>  Instance Segmentation is an interesting yet challenging task in computer\\nvision. In this paper, we conduct a series of refinements with the Hybrid Task\\nCascade (HTC) Network, and empirically evaluate their impact on the final model\\nperformance through ablation studies. By taking all the refinements, we achieve\\n0.47 on the COCO test-dev dataset and 0.47 on the COCO test-challenge dataset.\\n</summary>\\n    <author>\\n      <name>Dongdong Yu</name>\\n    </author>\\n    <author>\\n      <name>Zehuan Yuan</name>\\n    </author>\\n    <author>\\n      <name>Jinlai Liu</name>\\n    </author>\\n    <author>\\n      <name>Kun Yuan</name>\\n    </author>\\n    <author>\\n      <name>Changhu Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1911.07939v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.07939v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1911.08169v1</id>\\n    <updated>2019-11-19T09:25:59Z</updated>\\n    <published>2019-11-19T09:25:59Z</published>\\n    <title>Dense Fusion Classmate Network for Land Cover Classification</title>\\n    <summary>  Recently, FCNs based methods have made great progress in semantic\\nsegmentation. Different with ordinary scenes, satellite image owns specific\\ncharacteristics, which elements always extend to large scope and no regular or\\nclear boundaries. Therefore, effective mid-level structure information\\nextremely missing, precise pixel-level classification becomes tough issues. In\\nthis paper, a Dense Fusion Classmate Network (DFCNet) is proposed to adopt in\\nland cover classification.\\n</summary>\\n    <author>\\n      <name>Chao Tian</name>\\n    </author>\\n    <author>\\n      <name>Cong Li</name>\\n    </author>\\n    <author>\\n      <name>Jianping Shi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1911.08169v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.08169v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1911.10636v1</id>\\n    <updated>2019-11-24T23:03:19Z</updated>\\n    <published>2019-11-24T23:03:19Z</published>\\n    <title>Pyramid Vector Quantization and Bit Level Sparsity in Weights for\\n  Efficient Neural Networks Inference</title>\\n    <summary>  This paper discusses three basic blocks for the inference of convolutional\\nneural networks (CNNs). Pyramid Vector Quantization (PVQ) is discussed as an\\neffective quantizer for CNNs weights resulting in highly sparse and\\ncompressible networks. Properties of PVQ are exploited for the elimination of\\nmultipliers during inference while maintaining high performance. The result is\\nthen extended to any other quantized weights. The Tiny Yolo v3 CNN is used to\\ncompare such basic blocks.\\n</summary>\\n    <author>\\n      <name>Vincenzo Liguori</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1911.10636v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.10636v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1911.12249v1</id>\\n    <updated>2019-11-27T16:14:14Z</updated>\\n    <published>2019-11-27T16:14:14Z</published>\\n    <title>Literature Review of Action Recognition in the Wild</title>\\n    <summary>  The literature review presented below on Action Recognition in the wild is\\nthe in-depth study of Research Papers. Action Recognition problem in the\\nuntrimmed videos is a challenging task and most of the papers have tackled this\\nproblem using hand-crafted features with shallow learning techniques and\\nsophisticated end-to-end deep learning techniques.\\n</summary>\\n    <author>\\n      <name>Asket Kaur</name>\\n    </author>\\n    <author>\\n      <name>Navya Rao</name>\\n    </author>\\n    <author>\\n      <name>Tanya Joon</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1911.12249v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.12249v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1911.12706v1</id>\\n    <updated>2019-11-28T13:40:06Z</updated>\\n    <published>2019-11-28T13:40:06Z</published>\\n    <title>Cameras Viewing Cameras Geometry</title>\\n    <summary>  A basic problem in computer vision is to understand the structure of a\\nreal-world scene given several images of it. Here we study several theoretical\\naspects of the intra multi-view geometry of calibrated cameras when all that\\nthey can reliably recognize is each other. With the proliferation of wearable\\ncameras, autonomous vehicles and drones, the geometry of these multiple cameras\\nis a timely and relevant problem to study.\\n</summary>\\n    <author>\\n      <name>Danail Brezov</name>\\n    </author>\\n    <author>\\n      <name>Michael Werman</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1911.12706v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.12706v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1912.02202v1</id>\\n    <updated>2019-12-04T19:00:15Z</updated>\\n    <published>2019-12-04T19:00:15Z</published>\\n    <title>MORPHOLO C++ Library for glasses-free multi-view stereo vision and\\n  streaming of live 3D video</title>\\n    <summary>  The MORPHOLO C++ extended Library allows to convert a specific stereoscopic\\nsnapshot into a Native multi-view image through morphing algorithms taking into\\naccount display calibration data for specific slanted lenticular 3D monitors.\\nMORPHOLO can also be implemented for glasses-free live applicatons of 3D video\\nstreaming, and for diverse innovative scientific, engineering and 3D video game\\napplications -see http://www.morpholo.it\\n</summary>\\n    <author>\\n      <name>Enrique Canessa</name>\\n    </author>\\n    <author>\\n      <name>Livio Tenze</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">28 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1912.02202v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1912.02202v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1912.04376v1</id>\\n    <updated>2019-12-09T21:06:15Z</updated>\\n    <published>2019-12-09T21:06:15Z</published>\\n    <title>Modular Multimodal Architecture for Document Classification</title>\\n    <summary>  Page classification is a crucial component to any document analysis system,\\nallowing for complex branching control flows for different components of a\\ngiven document. Utilizing both the visual and textual content of a page, the\\nproposed method exceeds the current state-of-the-art performance on the\\nRVL-CDIP benchmark at 93.03% test accuracy.\\n</summary>\\n    <author>\\n      <name>Tyler Dauphinee</name>\\n    </author>\\n    <author>\\n      <name>Nikunj Patel</name>\\n    </author>\\n    <author>\\n      <name>Mohammad Rashidi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1912.04376v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1912.04376v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1912.12167v1</id>\\n    <updated>2019-12-18T19:23:29Z</updated>\\n    <published>2019-12-18T19:23:29Z</published>\\n    <title>Design Considerations for Efficient Deep Neural Networks on\\n  Processing-in-Memory Accelerators</title>\\n    <summary>  This paper describes various design considerations for deep neural networks\\nthat enable them to operate efficiently and accurately on processing-in-memory\\naccelerators. We highlight important properties of these accelerators and the\\nresulting design considerations using experiments conducted on various\\nstate-of-the-art deep neural networks with the large-scale ImageNet dataset.\\n</summary>\\n    <author>\\n      <name>Tien-Ju Yang</name>\\n    </author>\\n    <author>\\n      <name>Vivienne Sze</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted by IEDM 2019</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1912.12167v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1912.12167v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.ET\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2001.05841v1</id>\\n    <updated>2020-01-13T08:36:10Z</updated>\\n    <published>2020-01-13T08:36:10Z</published>\\n    <title>Predicting population neural activity in the Algonauts challenge using\\n  end-to-end trained Siamese networks and group convolutions</title>\\n    <summary>  The Algonauts challenge is about predicting the object representations in the\\nform of Representational Dissimilarity Matrices (RDMS) derived from visual\\nbrain regions. We used a customized deep learning model using the concept of\\nSiamese networks and group convolutions to predict neural distances\\ncorresponding to a pair of images. Training data was best explained by\\ndistances computed over the last layer.\\n</summary>\\n    <author>\\n      <name>Georgin Jacob</name>\\n    </author>\\n    <author>\\n      <name>Harish Katti</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2001.05841v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2001.05841v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2001.05865v1</id>\\n    <updated>2020-01-15T08:20:54Z</updated>\\n    <published>2020-01-15T08:20:54Z</published>\\n    <title>Ensemble based discriminative models for Visual Dialog Challenge 2018</title>\\n    <summary>  This manuscript describes our approach for the Visual Dialog Challenge 2018.\\nWe use an ensemble of three discriminative models with different encoders and\\ndecoders for our final submission. Our best performing model on \\'test-std\\'\\nsplit achieves the NDCG score of 55.46 and the MRR value of 63.77, securing\\nthird position in the challenge.\\n</summary>\\n    <author>\\n      <name>Shubham Agarwal</name>\\n    </author>\\n    <author>\\n      <name>Raghav Goyal</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Rankings: https://visualdialog.org/challenge/2018#winners</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2001.05865v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2001.05865v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2002.05107v3</id>\\n    <updated>2020-08-16T13:29:19Z</updated>\\n    <published>2020-02-12T17:32:18Z</published>\\n    <title>Analysis of Dutch Master Paintings with Convolutional Neural Networks</title>\\n    <summary>  Trained on the works of an artist under study and visually comparable works\\nof other artists, convolutional neural networks can identify forgeries and\\nprovide attributions. They can also assign classification probabilities within\\na painting, revealing mixed authorship and identifying regions painted by\\ndifferent hands.\\n</summary>\\n    <author>\\n      <name>Steven J. Frank</name>\\n    </author>\\n    <author>\\n      <name>Andrea M. Frank</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2002.05107v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2002.05107v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2002.05447v1</id>\\n    <updated>2020-02-13T11:29:46Z</updated>\\n    <published>2020-02-13T11:29:46Z</published>\\n    <title>Emotion Recognition for In-the-wild Videos</title>\\n    <summary>  This paper is a brief introduction to our submission to the seven basic\\nexpression classification track of Affective Behavior Analysis in-the-wild\\nCompetition held in conjunction with the IEEE International Conference on\\nAutomatic Face and Gesture Recognition (FG) 2020. Our method combines Deep\\nResidual Network (ResNet) and Bidirectional Long Short-Term Memory Network\\n(BLSTM), achieving 64.3% accuracy and 43.4% final metric on the validation set.\\n</summary>\\n    <author>\\n      <name>Hanyu Liu</name>\\n    </author>\\n    <author>\\n      <name>Jiabei Zeng</name>\\n    </author>\\n    <author>\\n      <name>Shiguang Shan</name>\\n    </author>\\n    <author>\\n      <name>Xilin Chen</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2002.05447v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2002.05447v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2002.10363v1</id>\\n    <updated>2020-02-24T16:48:30Z</updated>\\n    <published>2020-02-24T16:48:30Z</published>\\n    <title>Joint Learning of Assignment and Representation for Biometric Group\\n  Membership</title>\\n    <summary>  This paper proposes a framework for group membership protocols preventing the\\ncurious but honest server from reconstructing the enrolled biometric signatures\\nand inferring the identity of querying clients. This framework learns the\\nembedding parameters, group representations and assignments simultaneously.\\nExperiments show the trade-off between security/privacy and\\nverification/identification performances.\\n</summary>\\n    <author>\\n      <name>Marzieh Gheisari</name>\\n    </author>\\n    <author>\\n      <name>Teddy Furon</name>\\n    </author>\\n    <author>\\n      <name>Laurent Amsaleg</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2002.10363v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2002.10363v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2004.03339v1</id>\\n    <updated>2020-03-27T23:34:01Z</updated>\\n    <published>2020-03-27T23:34:01Z</published>\\n    <title>Automatic Generation of Chinese Handwriting via Fonts Style\\n  Representation Learning</title>\\n    <summary>  In this paper, we propose and end-to-end deep Chinese font generation system.\\nThis system can generate new style fonts by interpolation of latent\\nstyle-related embeding variables that could achieve smooth transition between\\ndifferent style. Our method is simpler and more effective than other methods,\\nwhich will help to improve the font design efficiency\\n</summary>\\n    <author>\\n      <name>Fenxi Xiao</name>\\n    </author>\\n    <author>\\n      <name>Bo Huang</name>\\n    </author>\\n    <author>\\n      <name>Xia Wu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2004.03339v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2004.03339v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2004.09430v1</id>\\n    <updated>2020-04-20T16:36:01Z</updated>\\n    <published>2020-04-20T16:36:01Z</published>\\n    <title>Improving correlation method with convolutional neural networks</title>\\n    <summary>  We present a convolutional neural network for the classification of\\ncorrelation responses obtained by correlation filters. The proposed approach\\ncan improve the accuracy of classification, as well as achieve invariance to\\nthe image classes and parameters.\\n</summary>\\n    <author>\\n      <name>Dmitriy Goncharov</name>\\n    </author>\\n    <author>\\n      <name>Rostislav Starikov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 3 figures, 2 tables, 1 formula</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2004.09430v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2004.09430v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2005.08645v1</id>\\n    <updated>2020-05-09T12:13:43Z</updated>\\n    <published>2020-05-09T12:13:43Z</published>\\n    <title>Multi-Task Learning in Histo-pathology for Widely Generalizable Model</title>\\n    <summary>  In this work we show preliminary results of deep multi-task learning in the\\narea of computational pathology. We combine 11 tasks ranging from patch-wise\\noral cancer classification, one of the most prevalent cancers in the developing\\nworld, to multi-tissue nuclei instance segmentation and classification.\\n</summary>\\n    <author>\\n      <name>Jevgenij Gamper</name>\\n    </author>\\n    <author>\\n      <name>Navid Alemi Kooohbanani</name>\\n    </author>\\n    <author>\\n      <name>Nasir Rajpoot</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">AI4CC ICLR 2020 workshop</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2005.08645v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2005.08645v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2007.08170v1</id>\\n    <updated>2020-07-16T08:10:42Z</updated>\\n    <published>2020-07-16T08:10:42Z</published>\\n    <title>VIPriors Object Detection Challenge</title>\\n    <summary>  This paper is a brief report to our submission to the VIPriors Object\\nDetection Challenge. Object Detection has attracted many researchers\\' attention\\nfor its full application, but it is still a challenging task. In this paper, we\\nstudy analysis the characteristics of the data, and an effective data\\nenhancement method is proposed. We carefully choose the model which is more\\nsuitable for training from scratch. We benefit a lot from using softnms and\\nmodel fusion skillfully.\\n</summary>\\n    <author>\\n      <name>Zhipeng Luo</name>\\n    </author>\\n    <author>\\n      <name>Lixuan Che</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2007.08170v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2007.08170v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2007.10232v1</id>\\n    <updated>2020-07-17T09:09:41Z</updated>\\n    <published>2020-07-17T09:09:41Z</published>\\n    <title>The Effect of Top-Down Attention in Occluded Object Recognition</title>\\n    <summary>  This study is concerned with the top-down visual processing benefit in the\\ntask of occluded object recognition. To this end, a psychophysical experiment\\nis designed and carried out which aimed at investigating the effect of\\nconsistency of contextual information on the recognition of objects which are\\npartially occluded. The results demonstrate the facilitative impact of\\nconsistent contextual clues on the task of object recognition in presence of\\nocclusion.\\n</summary>\\n    <author>\\n      <name>Zahra Sadeghi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 2 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2007.10232v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2007.10232v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2010.05131v1</id>\\n    <updated>2020-10-11T01:20:55Z</updated>\\n    <published>2020-10-11T01:20:55Z</published>\\n    <title>Segmenting Epipolar Line</title>\\n    <summary>  Identifying feature correspondence between two images is a fundamental\\nprocedure in three-dimensional computer vision. Usually the feature search\\nspace is confined by the epipolar line. Using the cheirality constraint, this\\npaper finds that the feature search space can be restrained to one of two or\\nthree segments of the epipolar line that are defined by the epipole and a\\nso-called virtual infinity point.\\n</summary>\\n    <author>\\n      <name>Shengjie Li</name>\\n    </author>\\n    <author>\\n      <name>Qi Cai</name>\\n    </author>\\n    <author>\\n      <name>Yuanxin Wu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2010.05131v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2010.05131v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2010.06454v2</id>\\n    <updated>2020-11-05T05:52:08Z</updated>\\n    <published>2020-09-21T04:19:27Z</published>\\n    <title>The DongNiao International Birds 10000 Dataset</title>\\n    <summary>  DongNiao International Birds 10000 (DIB-10K) is a challenging image dataset\\nwhich has more than 10 thousand different types of birds. It was created to\\nenable the study of machine learning and also ornithology research. DIB-10K\\ndoes not own the copyright of these images. It only provides thumbnails of\\nimages, in a way similar to ImageNet.\\n</summary>\\n    <author>\\n      <name>Jian Mei</name>\\n    </author>\\n    <author>\\n      <name>Hao Dong</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2010.06454v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2010.06454v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2010.11339v1</id>\\n    <updated>2020-10-21T22:42:19Z</updated>\\n    <published>2020-10-21T22:42:19Z</published>\\n    <title>Voronoi Convolutional Neural Networks</title>\\n    <summary>  In this technical report, we investigate extending convolutional neural\\nnetworks to the setting where functions are not sampled in a grid pattern. We\\nshow that by treating the samples as the average of a function within a cell,\\nwe can find a natural equivalent of most layers used in CNN. We also present an\\nalgorithm for running inference for these models exactly using standard convex\\ngeometry algorithms.\\n</summary>\\n    <author>\\n      <name>Soroosh Yazdani</name>\\n    </author>\\n    <author>\\n      <name>Andrea Tagliasacchi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Technical report</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2010.11339v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2010.11339v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.0\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2010.15250v1</id>\\n    <updated>2020-10-28T21:42:16Z</updated>\\n    <published>2020-10-28T21:42:16Z</published>\\n    <title>Semantic video segmentation for autonomous driving</title>\\n    <summary>  We aim to solve semantic video segmentation in autonomous driving, namely\\nroad detection in real time video, using techniques discussed in (Shelhamer et\\nal., 2016a). While fully convolutional network gives good result, we show that\\nthe speed can be halved while preserving the accuracy. The test dataset being\\nused is KITTI, which consists of real footage from Germany\\'s streets.\\n</summary>\\n    <author>\\n      <name>Minh Triet Chau</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This work was done around 2017. Some minor changes were added</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2010.15250v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2010.15250v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2011.07230v1</id>\\n    <updated>2020-11-14T06:55:31Z</updated>\\n    <published>2020-11-14T06:55:31Z</published>\\n    <title>TDAsweep: A Novel Dimensionality Reduction Method for Image\\n  Classification Tasks</title>\\n    <summary>  One of the most celebrated achievements of modern machine learning technology\\nis automatic classification of images. However, success is typically achieved\\nonly with major computational costs. Here we introduce TDAsweep, a machine\\nlearning tool aimed at improving the efficiency of automatic classification of\\nimages.\\n</summary>\\n    <author>\\n      <name>Yu-Shih Chen</name>\\n    </author>\\n    <author>\\n      <name>Melissa Goh</name>\\n    </author>\\n    <author>\\n      <name>Norm Matloff</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2011.07230v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2011.07230v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2011.10759v1</id>\\n    <updated>2020-11-21T10:27:21Z</updated>\\n    <published>2020-11-21T10:27:21Z</published>\\n    <title>Visual Recognition of Great Ape Behaviours in the Wild</title>\\n    <summary>  We propose a first great ape-specific visual behaviour recognition system\\nutilising deep learning that is capable of detecting nine core ape behaviours.\\n</summary>\\n    <author>\\n      <name>Faizaan Sakib</name>\\n    </author>\\n    <author>\\n      <name>Tilo Burghardt</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 4 figures, to be published in the proceedings of ICPR 2020\\n  at the Visual observation and analysis of Vertebrate And Insect Behaviour\\n  (VAIB) workshop</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2011.10759v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2011.10759v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2011.13698v1</id>\\n    <updated>2020-11-27T12:25:24Z</updated>\\n    <published>2020-11-27T12:25:24Z</published>\\n    <title>Lightweight U-Net for High-Resolution Breast Imaging</title>\\n    <summary>  We study the fully convolutional neural networks in the context of malignancy\\ndetection for breast cancer screening. We work on a supervised segmentation\\ntask looking for an acceptable compromise between the precision of the network\\nand the computational complexity.\\n</summary>\\n    <author>\\n      <name>Mickael Tardy</name>\\n    </author>\\n    <author>\\n      <name>Diana Mateus</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">in Proceedings of iTWIST\\'20, Paper-ID: 30, Nantes, France, December,\\n  2-4, 2020</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2011.13698v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2011.13698v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2011.14761v1</id>\\n    <updated>2020-11-30T13:15:51Z</updated>\\n    <published>2020-11-30T13:15:51Z</published>\\n    <title>How Good MVSNets Are at Depth Fusion</title>\\n    <summary>  We study the effects of the additional input to deep multi-view stereo\\nmethods in the form of low-quality sensor depth. We modify two state-of-the-art\\ndeep multi-view stereo methods for using with the input depth. We show that the\\nadditional input depth may improve the quality of deep multi-view stereo.\\n</summary>\\n    <author>\\n      <name>Oleg Voynov</name>\\n    </author>\\n    <author>\\n      <name>Aleksandr Safin</name>\\n    </author>\\n    <author>\\n      <name>Savva Ignatyev</name>\\n    </author>\\n    <author>\\n      <name>Evgeny Burnaev</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 6 figures, 1 table. Accepted to ICMV 2020</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2011.14761v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2011.14761v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2101.00350v1</id>\\n    <updated>2021-01-02T01:51:38Z</updated>\\n    <published>2021-01-02T01:51:38Z</published>\\n    <title>Multi-Image Steganography Using Deep Neural Networks</title>\\n    <summary>  Steganography is the science of hiding a secret message within an ordinary\\npublic message. Over the years, steganography has been used to encode a lower\\nresolution image into a higher resolution image by simple methods like LSB\\nmanipulation. We aim to utilize deep neural networks for the encoding and\\ndecoding of multiple secret images inside a single cover image of the same\\nresolution.\\n</summary>\\n    <author>\\n      <name>Abhishek Das</name>\\n    </author>\\n    <author>\\n      <name>Japsimar Singh Wahi</name>\\n    </author>\\n    <author>\\n      <name>Mansi Anand</name>\\n    </author>\\n    <author>\\n      <name>Yugant Rana</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2101.00350v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2101.00350v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2101.06022v1</id>\\n    <updated>2021-01-15T09:14:10Z</updated>\\n    <published>2021-01-15T09:14:10Z</published>\\n    <title>Motion-Based Handwriting Recognition</title>\\n    <summary>  We attempt to overcome the restriction of requiring a writing surface for\\nhandwriting recognition. In this study, we design a prototype of a stylus\\nequipped with motion sensor, and utilizes gyroscopic and acceleration sensor\\nreading to perform written letter classification using various deep learning\\ntechniques such as CNN and RNNs. We also explore various data augmentation\\ntechniques and their effects, reaching up to 86% accuracy.\\n</summary>\\n    <author>\\n      <name>Junshen Kevin Chen</name>\\n    </author>\\n    <author>\\n      <name>Wanze Xie</name>\\n    </author>\\n    <author>\\n      <name>Yutong He</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2101.06022v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2101.06022v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2101.06025v1</id>\\n    <updated>2021-01-15T09:24:04Z</updated>\\n    <published>2021-01-15T09:24:04Z</published>\\n    <title>Motion-Based Handwriting Recognition and Word Reconstruction</title>\\n    <summary>  In this project, we leverage a trained single-letter classifier to predict\\nthe written word from a continuously written word sequence, by designing a word\\nreconstruction pipeline consisting of a dynamic-programming algorithm and an\\nauto-correction model. We conduct experiments to optimize models in this\\npipeline, then employ domain adaptation to explore using this pipeline on\\nunseen data distributions.\\n</summary>\\n    <author>\\n      <name>Junshen Kevin Chen</name>\\n    </author>\\n    <author>\\n      <name>Wanze Xie</name>\\n    </author>\\n    <author>\\n      <name>Yutong He</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2101.06025v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2101.06025v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2102.06793v1</id>\\n    <updated>2021-01-25T17:56:15Z</updated>\\n    <published>2021-01-25T17:56:15Z</published>\\n    <title>Unanswerable Questions about Images and Texts</title>\\n    <summary>  Questions about a text or an image that cannot be answered raise distinctive\\nissues for an AI. This note discusses the problem of unanswerable questions in\\nVQA (visual question answering), in QA (visual question answering), and in AI\\ngenerally.\\n</summary>\\n    <author>\\n      <name>Ernest Davis</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.3389/frai.2020.00051</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.3389/frai.2020.00051\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages, 4 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Frontiers in Artificial Intelligence: Language and Computation.\\n  July 2020</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2102.06793v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2102.06793v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2102.07455v1</id>\\n    <updated>2021-02-15T11:06:46Z</updated>\\n    <published>2021-02-15T11:06:46Z</published>\\n    <title>Video Analytics on IoT devices</title>\\n    <summary>  Deep Learning (DL) combined with advanced model optimization methods such as\\nRC-NN and Edge2Train has enabled offline execution of large networks on the IoT\\ndevices. In this paper, we compare the modern Deep Learning (DL) based video\\nanalytics approaches with the standard Computer Vision (CV) based approaches\\nand finally, discuss the best-suited approach for video analytics on IoT\\ndevices.\\n</summary>\\n    <author>\\n      <name>Sree Premkumar</name>\\n    </author>\\n    <author>\\n      <name>Vimal Premkumar</name>\\n    </author>\\n    <author>\\n      <name>Rakesh Dhakshinamurthy</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2102.07455v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2102.07455v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2103.09475v1</id>\\n    <updated>2021-03-17T07:11:38Z</updated>\\n    <published>2021-03-17T07:11:38Z</published>\\n    <title>Virtual Dress Swap Using Landmark Detection</title>\\n    <summary>  Online shopping has gained popularity recently. This paper addresses one\\ncrucial problem of buying dress online, which has not been solved yet. This\\nresearch tries to implement the idea of clothes swapping with the help of\\nDeepFashion dataset where 6,223 images with eight landmarks each used. Deep\\nConvolutional Neural Network has been built for Landmark detection.\\n</summary>\\n    <author>\\n      <name>Odar Zeynal</name>\\n    </author>\\n    <author>\\n      <name>Saber Malekzadeh</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2103.09475v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2103.09475v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2105.02964v1</id>\\n    <updated>2021-05-02T00:05:17Z</updated>\\n    <published>2021-05-02T00:05:17Z</published>\\n    <title>Object detection for crabs in top-view seabed imagery</title>\\n    <summary>  This report presents the application of object detection on a database of\\nunderwater images of different species of crabs, as well as aerial images of\\nsea lions and finally the Pascal VOC dataset. The model is an end-to-end object\\ndetection neural network based on a convolutional network base and a Long\\nShort-Term Memory detector.\\n</summary>\\n    <author>\\n      <name>Vlad Velici</name>\\n    </author>\\n    <author>\\n      <name>Adam Pr\\xc3\\xbcgel-Bennett</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2105.02964v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2105.02964v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2105.04093v1</id>\\n    <updated>2021-05-10T03:48:55Z</updated>\\n    <published>2021-05-10T03:48:55Z</published>\\n    <title>Elastic Weight Consolidation (EWC): Nuts and Bolts</title>\\n    <summary>  In this report, we present a theoretical support of the continual learning\\nmethod \\\\textbf{Elastic Weight Consolidation}, introduced in paper titled\\n`Overcoming catastrophic forgetting in neural networks\\'. Being one of the most\\ncited paper in regularized methods for continual learning, this report\\ndisentangles the underlying concept of the proposed objective function. We\\nassume that the reader is aware of the basic terminologies of continual\\nlearning.\\n</summary>\\n    <author>\\n      <name>Abhishek Aich</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2105.04093v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2105.04093v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2105.08796v1</id>\\n    <updated>2021-05-18T19:33:17Z</updated>\\n    <published>2021-05-18T19:33:17Z</published>\\n    <title>Analyzing the effectiveness of image augmentations for face recognition\\n  from limited data</title>\\n    <summary>  This work presents an analysis of the efficiency of image augmentations for\\nthe face recognition problem from limited data. We considered basic\\nmanipulations, generative methods, and their combinations for augmentations.\\nOur results show that augmentations, in general, can considerably improve the\\nquality of face recognition systems and the combination of generative and basic\\napproaches performs better than the other tested techniques.\\n</summary>\\n    <author>\\n      <name>Aleksei Zhuchkov</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2105.08796v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2105.08796v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.9\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2105.10063v1</id>\\n    <updated>2021-05-20T23:11:36Z</updated>\\n    <published>2021-05-20T23:11:36Z</published>\\n    <title>Uma implementa\\xc3\\xa7\\xc3\\xa3o do jogo Pedra, Papel e Tesoura utilizando Visao\\n  Computacional</title>\\n    <summary>  This paper presents a game, controlled by computer vision, in identification\\nof hand gestures (hand-tracking). The proposed work is based on image\\nsegmentation and construction of a convex hull with Jarvis Algorithm , and\\ndetermination of the pattern based on the extraction of area characteristics in\\nthe convex hull.\\n</summary>\\n    <author>\\n      <name>Ezequiel Fran\\xc3\\xa7a dos Santos</name>\\n    </author>\\n    <author>\\n      <name>Gabriel Fontenelle</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">14 pages, in Portuguese</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2105.10063v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2105.10063v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2105.13264v1</id>\\n    <updated>2021-05-27T16:02:40Z</updated>\\n    <published>2021-05-27T16:02:40Z</published>\\n    <title>How saccadic vision might help with theinterpretability of deep networks</title>\\n    <summary>  We describe how some problems (interpretability,lack of object-orientedness)\\nof modern deep networks potentiallycould be solved by adapting a biologically\\nplausible saccadicmechanism of perception. A sketch of such a saccadic\\nvisionmodel is proposed. Proof of concept experimental results areprovided to\\nsupport the proposed approach.\\n</summary>\\n    <author>\\n      <name>Iana Sereda</name>\\n    </author>\\n    <author>\\n      <name>Grigory Osipov</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2105.13264v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2105.13264v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2107.05186v1</id>\\n    <updated>2021-07-12T04:02:57Z</updated>\\n    <published>2021-07-12T04:02:57Z</published>\\n    <title>Early warning of pedestrians and cyclists</title>\\n    <summary>  State-of-the-art motor vehicles are able to break for pedestrians in an\\nemergency. We investigate what it would take to issue an early warning to the\\ndriver so he/she has time to react. We have identified that predicting the\\nintention of a pedestrian reliably by position is a particularly hard\\nchallenge. This paper describes an early pedestrian warning demonstration\\nsystem.\\n</summary>\\n    <author>\\n      <name>Joerg Christian Wolf</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2107.05186v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2107.05186v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2107.06780v1</id>\\n    <updated>2021-07-03T09:41:53Z</updated>\\n    <published>2021-07-03T09:41:53Z</published>\\n    <title>Person-MinkUNet: 3D Person Detection with LiDAR Point Cloud</title>\\n    <summary>  In this preliminary work we attempt to apply submanifold sparse convolution\\nto the task of 3D person detection. In particular, we present Person-MinkUNet,\\na single-stage 3D person detection network based on Minkowski Engine with U-Net\\narchitecture. The network achieves a 76.4% average precision (AP) on the JRDB\\n3D detection benchmark.\\n</summary>\\n    <author>\\n      <name>Dan Jia</name>\\n    </author>\\n    <author>\\n      <name>Bastian Leibe</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">accepted as an extended abstract in JRDB-ACT Workshop at CVPR21</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2107.06780v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2107.06780v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2112.02297v1</id>\\n    <updated>2021-12-04T09:59:01Z</updated>\\n    <published>2021-12-04T09:59:01Z</published>\\n    <title>Ablation study of self-supervised learning for image classification</title>\\n    <summary>  This project focuses on the self-supervised training of convolutional neural\\nnetworks (CNNs) and transformer networks for the task of image recognition. A\\nsimple siamese network with different backbones is used in order to maximize\\nthe similarity of two augmented transformed images from the same source image.\\nIn this way, the backbone is able to learn visual information without\\nsupervision. Finally, the method is evaluated on three image recognition\\ndatasets.\\n</summary>\\n    <author>\\n      <name>Ilias Papastratis</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2112.02297v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2112.02297v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2112.05576v1</id>\\n    <updated>2021-12-10T14:43:24Z</updated>\\n    <published>2021-12-10T14:43:24Z</published>\\n    <title>GPU-accelerated image alignment for object detection in industrial\\n  applications</title>\\n    <summary>  This research proposes a practical method for detecting featureless objects\\nby using image alignment approach with a robust similarity measure in\\nindustrial applications. This similarity measure is robust against occlusion,\\nillumination changes and background clutter. The performance of the proposed\\nGPU (Graphics Processing Unit) accelerated algorithm is deemed successful in\\nexperiments of comparison between both CPU and GPU implementations\\n</summary>\\n    <author>\\n      <name>Trung-Son Le</name>\\n    </author>\\n    <author>\\n      <name>Chyi-Yeu Lin</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/ARIS.2017.8297173</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/ARIS.2017.8297173\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/2112.05576v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2112.05576v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2112.13707v1</id>\\n    <updated>2021-12-27T14:31:24Z</updated>\\n    <published>2021-12-27T14:31:24Z</published>\\n    <title>Visual Place Representation and Recognition from Depth Images</title>\\n    <summary>  This work proposes a new method for place recognition based on the scene\\narchitecture. From depth video, we compute the 3D model and we derive and\\ndescribe geometrically the 2D map from which the scene descriptor is deduced to\\nconstitute the core of the proposed algorithm. The obtained results show the\\nefficiency and the robustness of the propounded descriptor to scene appearance\\nchanges and light variations.\\n</summary>\\n    <author>\\n      <name>Farah Ibelaiden</name>\\n    </author>\\n    <author>\\n      <name>Slimane Larabi</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.ijleo.2022.169109</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.ijleo.2022.169109\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/2112.13707v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2112.13707v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2206.02002v1</id>\\n    <updated>2022-06-04T14:55:24Z</updated>\\n    <published>2022-06-04T14:55:24Z</published>\\n    <title>CVNets: High Performance Library for Computer Vision</title>\\n    <summary>  We introduce CVNets, a high-performance open-source library for training deep\\nneural networks for visual recognition tasks, including classification,\\ndetection, and segmentation. CVNets supports image and video understanding\\ntools, including data loading, data transformations, novel data sampling\\nmethods, and implementations of several standard networks with similar or\\nbetter performance than previous studies.\\n  Our source code is available at: \\\\url{https://github.com/apple/ml-cvnets}.\\n</summary>\\n    <author>\\n      <name>Sachin Mehta</name>\\n    </author>\\n    <author>\\n      <name>Farzad Abdolhosseini</name>\\n    </author>\\n    <author>\\n      <name>Mohammad Rastegari</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Technical report</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2206.02002v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2206.02002v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2208.08863v1</id>\\n    <updated>2022-08-03T01:42:49Z</updated>\\n    <published>2022-08-03T01:42:49Z</published>\\n    <title>Compressive Self-localization Using Relative Attribute Embedding</title>\\n    <summary>  The use of relative attribute (e.g., beautiful, safe, convenient) -based\\nimage embeddings in visual place recognition, as a domain-adaptive compact\\nimage descriptor that is orthogonal to the typical approach of absolute\\nattribute (e.g., color, shape, texture) -based image embeddings, is explored in\\nthis paper.\\n</summary>\\n    <author>\\n      <name>Ryogo Yamamoto</name>\\n    </author>\\n    <author>\\n      <name>Kanji Tanaka</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 4 figures, An extended abstract version of a manuscript\\n  submitted to an international conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2208.08863v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2208.08863v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2209.10497v2</id>\\n    <updated>2023-01-26T07:26:02Z</updated>\\n    <published>2022-09-21T16:53:04Z</published>\\n    <title>Animating Still Images</title>\\n    <summary>  We present a method for imparting motion to a still 2D image. Our method uses\\ndeep learning to segment a section of the image denoted as subject, then uses\\nin-painting to complete the background, and finally adds animation to the\\nsubject by embedding the image in a triangle mesh, while preserving the rest of\\nthe image.\\n</summary>\\n    <author>\\n      <name>Kushagr Batra</name>\\n    </author>\\n    <author>\\n      <name>Mridul Kavidayal</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2209.10497v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2209.10497v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2209.12330v1</id>\\n    <updated>2022-09-25T22:03:39Z</updated>\\n    <published>2022-09-25T22:03:39Z</published>\\n    <title>Personalizing Text-to-Image Generation via Aesthetic Gradients</title>\\n    <summary>  This work proposes aesthetic gradients, a method to personalize a\\nCLIP-conditioned diffusion model by guiding the generative process towards\\ncustom aesthetics defined by the user from a set of images. The approach is\\nvalidated with qualitative and quantitative experiments, using the recent\\nstable diffusion model and several aesthetically-filtered datasets. Code is\\nreleased at https://github.com/vicgalle/stable-diffusion-aesthetic-gradients\\n</summary>\\n    <author>\\n      <name>Victor Gallego</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Submitted to NeurIPS 2022 Machine Learning for Creativity and Design\\n  Workshop</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2209.12330v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2209.12330v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0809.3352v1</id>\\n    <updated>2008-09-19T11:02:39Z</updated>\\n    <published>2008-09-19T11:02:39Z</published>\\n    <title>Generalized Prediction Intervals for Arbitrary Distributed\\n  High-Dimensional Data</title>\\n    <summary>  This paper generalizes the traditional statistical concept of prediction\\nintervals for arbitrary probability density functions in high-dimensional\\nfeature spaces by introducing significance level distributions, which provides\\ninterval-independent probabilities for continuous random variables. The\\nadvantage of the transformation of a probability density function into a\\nsignificance level distribution is that it enables one-class classification or\\noutlier detection in a direct manner.\\n</summary>\\n    <author>\\n      <name>Steffen Kuehn</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">13 pages, 3 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0809.3352v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0809.3352v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0809.4501v1</id>\\n    <updated>2008-09-25T20:54:29Z</updated>\\n    <published>2008-09-25T20:54:29Z</published>\\n    <title>Audio Classification from Time-Frequency Texture</title>\\n    <summary>  Time-frequency representations of audio signals often resemble texture\\nimages. This paper derives a simple audio classification algorithm based on\\ntreating sound spectrograms as texture images. The algorithm is inspired by an\\nearlier visual classification scheme particularly efficient at classifying\\ntextures. While solely based on time-frequency texture features, the algorithm\\nachieves surprisingly good performance in musical instrument classification\\nexperiments.\\n</summary>\\n    <author>\\n      <name>Guoshen Yu</name>\\n    </author>\\n    <author>\\n      <name>Jean-Jacques Slotine</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0809.4501v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0809.4501v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1506.06274v1</id>\\n    <updated>2015-06-20T17:55:49Z</updated>\\n    <published>2015-06-20T17:55:49Z</published>\\n    <title>Pose Estimation Based on 3D Models</title>\\n    <summary>  In this paper, we proposed a pose estimation system based on rendered image\\ntraining set, which predicts the pose of objects in real image, with knowledge\\nof object category and tight bounding box. We developed a patch-based\\nmulti-class classification algorithm, and an iterative approach to improve the\\naccuracy. We achieved state-of-the-art performance on pose estimation task.\\n</summary>\\n    <author>\\n      <name>Chuiwen Ma</name>\\n    </author>\\n    <author>\\n      <name>Hao Su</name>\\n    </author>\\n    <author>\\n      <name>Liang Shi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1506.06274v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1506.06274v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1506.08959v2</id>\\n    <updated>2015-09-24T09:04:24Z</updated>\\n    <published>2015-06-30T06:47:50Z</published>\\n    <title>A Large-Scale Car Dataset for Fine-Grained Categorization and\\n  Verification</title>\\n    <summary>  Updated on 24/09/2015: This update provides preliminary experiment results\\nfor fine-grained classification on the surveillance data of CompCars. The\\ntrain/test splits are provided in the updated dataset. See details in Section\\n6.\\n</summary>\\n    <author>\\n      <name>Linjie Yang</name>\\n    </author>\\n    <author>\\n      <name>Ping Luo</name>\\n    </author>\\n    <author>\\n      <name>Chen Change Loy</name>\\n    </author>\\n    <author>\\n      <name>Xiaoou Tang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">An extension to our conference paper in CVPR 2015</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1506.08959v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1506.08959v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1511.03650v3</id>\\n    <updated>2015-12-07T14:20:01Z</updated>\\n    <published>2015-11-11T20:54:28Z</published>\\n    <title>Piecewise Linear Activation Functions For More Efficient Deep Networks</title>\\n    <summary>  This submission has been withdrawn by arXiv administrators because it is\\nintentionally incomplete, which is in violation of our policies.\\n</summary>\\n    <author>\\n      <name>Cheng-Yang Fu</name>\\n    </author>\\n    <author>\\n      <name>Alexander C. Berg</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Withdrawn by arXiv admins</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1511.03650v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1511.03650v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1511.06489v2</id>\\n    <updated>2018-10-23T22:04:42Z</updated>\\n    <published>2015-11-20T04:56:47Z</published>\\n    <title>A Simple Hierarchical Pooling Data Structure for Loop Closure</title>\\n    <summary>  We propose a data structure obtained by hierarchically averaging bag-of-word\\ndescriptors during a sequence of views that achieves average speedups in\\nlarge-scale loop closure applications ranging from 4 to 20 times on benchmark\\ndatasets. Although simple, the method works as well as sophisticated\\nagglomerative schemes at a fraction of the cost with minimal loss of\\nperformance.\\n</summary>\\n    <author>\\n      <name>Xiaohan Fei</name>\\n    </author>\\n    <author>\\n      <name>Konstantine Tsotsos</name>\\n    </author>\\n    <author>\\n      <name>Stefano Soatto</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1511.06489v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1511.06489v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1511.07347v1</id>\\n    <updated>2015-11-23T18:15:13Z</updated>\\n    <published>2015-11-23T18:15:13Z</published>\\n    <title>Node Specificity in Convolutional Deep Nets Depends on Receptive Field\\n  Position and Size</title>\\n    <summary>  In convolutional deep neural networks, receptive field (RF) size increases\\nwith hierarchical depth. When RF size approaches full coverage of the input\\nimage, different RF positions result in RFs with different specificity, as\\nportions of the RF fall out of the input space. This leads to a departure from\\nthe convolutional concept of positional invariance and opens the possibility\\nfor complex forms of context specificity.\\n</summary>\\n    <author>\\n      <name>Karl Zipser</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1511.07347v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1511.07347v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1805.08416v1</id>\\n    <updated>2018-05-22T06:11:00Z</updated>\\n    <published>2018-05-22T06:11:00Z</published>\\n    <title>Training Convolutional Networks with Web Images</title>\\n    <summary>  In this thesis we investigate the effect of using web images to build a large\\nscale database to be used along a deep learning method for a classification\\ntask. We replicate the ImageNet large scale database (ILSVRC-2012) from images\\ncollected from the web using 4 different download strategies varying: the\\nsearch engine, the query and the image resolution. As a deep learning method,\\nwe will choose the Convolutional Neural Network that was very successful with\\nrecognition tasks; the AlexNet.\\n</summary>\\n    <author>\\n      <name>Nizar Massouh</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1805.08416v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1805.08416v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1805.09421v1</id>\\n    <updated>2018-05-23T20:57:31Z</updated>\\n    <published>2018-05-23T20:57:31Z</published>\\n    <title>Use of symmetric kernels for convolutional neural networks</title>\\n    <summary>  At this work we introduce horizontally symmetric convolutional kernels for\\nCNNs which make the network output invariant to horizontal flips of the image.\\nWe also study other types of symmetric kernels which lead to vertical flip\\ninvariance, and approximate rotational invariance. We show that usage of such\\nkernels acts as regularizer, and improves generalization of the convolutional\\nneural networks at the cost of more complicated training process.\\n</summary>\\n    <author>\\n      <name>Viacheslav Dudar</name>\\n    </author>\\n    <author>\\n      <name>Vladimir Semenov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ICDSIAI 2018</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1805.09421v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1805.09421v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1812.00877v1</id>\\n    <updated>2018-11-23T22:36:36Z</updated>\\n    <published>2018-11-23T22:36:36Z</published>\\n    <title>Automatic lesion boundary detection in dermoscopy</title>\\n    <summary>  This manuscript addresses the problem of the automatic lesion boundary\\ndetection in dermoscopy, using deep neural networks. An approach is based on\\nthe adaptation of the U-net convolutional neural network with skip connections\\nfor lesion boundary segmentation task. I hope this paper could serve, to some\\nextent, as an experiment of using deep convolutional networks in biomedical\\nsegmentation task and as a guideline of the boundary detection benchmark,\\ninspiring further attempts and researches.\\n</summary>\\n    <author>\\n      <name>Glib Kechyn</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1812.00877v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1812.00877v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1812.02542v1</id>\\n    <updated>2018-12-06T14:16:56Z</updated>\\n    <published>2018-12-06T14:16:56Z</published>\\n    <title>Computer Vision for Autonomous Vehicles</title>\\n    <summary>  In this work, we try to implement Image Processing techniques in the area of\\nautonomous vehicles, both indoor and outdoor. The challenges for both are\\ndifferent and the ways to tackle them vary too. We also showed deep learning\\nmakes things easier and precise. We also made base models for all the problems\\nwe tackle while building an autonomous car for Indian Institute of Space\\nscience and Technology.\\n</summary>\\n    <author>\\n      <name>Rohit Gandikota</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1812.02542v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1812.02542v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1812.10915v1</id>\\n    <updated>2018-12-28T07:51:08Z</updated>\\n    <published>2018-12-28T07:51:08Z</published>\\n    <title>Spatiotemporal Data Fusion for Precipitation Nowcasting</title>\\n    <summary>  Precipitation nowcasting using neural networks and ground-based radars has\\nbecome one of the key components of modern weather prediction services, but it\\nis limited to the regions covered by ground-based radars. Truly global\\nprecipitation nowcasting requires fusion of radar and satellite observations.\\nWe propose the data fusion pipeline based on computer vision techniques,\\nincluding novel inpainting algorithm with soft masking.\\n</summary>\\n    <author>\\n      <name>Vladimir Ivashkin</name>\\n    </author>\\n    <author>\\n      <name>Vadim Lebedev</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1812.10915v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1812.10915v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1903.00117v2</id>\\n    <updated>2019-03-13T14:07:45Z</updated>\\n    <published>2019-03-01T01:13:30Z</published>\\n    <title>A Sketch Based 3D Shape Retrieval Approach Based on Efficient Deep\\n  Point-to-Subspace Metric Learning</title>\\n    <summary>  A sketch based 3D shape retrieval\\n</summary>\\n    <author>\\n      <name>Yinjie Lei</name>\\n    </author>\\n    <author>\\n      <name>Ziqin Zhou</name>\\n    </author>\\n    <author>\\n      <name>Pingping Zhang</name>\\n    </author>\\n    <author>\\n      <name>Yulan Guo</name>\\n    </author>\\n    <author>\\n      <name>Zijun Ma</name>\\n    </author>\\n    <author>\\n      <name>Lingqiao Liu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The first author wants to withdraw this paper. He has noticed several\\n  setting errors in experiment parts</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1903.00117v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1903.00117v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1903.01814v1</id>\\n    <updated>2019-03-05T13:32:03Z</updated>\\n    <published>2019-03-05T13:32:03Z</published>\\n    <title>HexagDLy - Processing hexagonally sampled data with CNNs in PyTorch</title>\\n    <summary>  HexagDLy is a Python-library extending the PyTorch deep learning framework\\nwith convolution and pooling operations on hexagonal grids. It aims to ease the\\naccess to convolutional neural networks for applications that rely on\\nhexagonally sampled data as, for example, commonly found in ground-based\\nastroparticle physics experiments.\\n</summary>\\n    <author>\\n      <name>Constantin Steppa</name>\\n    </author>\\n    <author>\\n      <name>Tim Lukas Holch</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.softx.2019.02.010</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.softx.2019.02.010\" rel=\"related\"/>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">SoftwareX, 9, 193-198, 2019</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1903.01814v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1903.01814v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"astro-ph.IM\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1903.11421v1</id>\\n    <updated>2019-03-27T13:41:17Z</updated>\\n    <published>2019-03-27T13:41:17Z</published>\\n    <title>Social Behavioral Phenotyping of Drosophila with a2D-3D Hybrid CNN\\n  Framework</title>\\n    <summary>  Behavioural phenotyping of Drosophila is an important means in biological and\\nmedical research to identify genetic, pathologic or psychologic impact on\\nanimal behaviour.\\n</summary>\\n    <author>\\n      <name>Ziping Jiang</name>\\n    </author>\\n    <author>\\n      <name>Paul L. Chazot</name>\\n    </author>\\n    <author>\\n      <name>M. Emre Celebi</name>\\n    </author>\\n    <author>\\n      <name>Danny Crookes</name>\\n    </author>\\n    <author>\\n      <name>Richard Jiang</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Access 2019</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/1903.11421v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1903.11421v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.ET\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1907.09233v1</id>\\n    <updated>2019-07-22T11:12:35Z</updated>\\n    <published>2019-07-22T11:12:35Z</published>\\n    <title>Adapting Computer Vision Algorithms for Omnidirectional Video</title>\\n    <summary>  Omnidirectional (360{\\\\deg}) video has got quite popular because it provides a\\nhighly immersive viewing experience. For computer vision algorithms, it poses\\nseveral challenges, like the special (equirectangular) projection commonly\\nemployed and the huge image size. In this work, we give a high-level overview\\nof these challenges and outline strategies how to adapt computer vision\\nalgorithm for the specifics of omnidirectional video.\\n</summary>\\n    <author>\\n      <name>Hannes Fassold</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted for 27th ACM International Conference on Multimedia (ACMM MM\\n  2019, Nice, France)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1907.09233v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1907.09233v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1908.04386v1</id>\\n    <updated>2019-08-04T11:31:26Z</updated>\\n    <published>2019-08-04T11:31:26Z</published>\\n    <title>Detection of the Group of Traffic Signs with Central Slice Theorem</title>\\n    <summary>  Our sensor system consists of a combination of Photonic Mixer Device - PMD\\nand Mono optical cameras. Some traffic signs have stripes at 45{deg}. These\\ntraffic signs cancel different restrictions on the road. We detect this class\\nof signs with Radon transformation. Here the Radon transformation is calculated\\nusing Central Slice Theorem. We approximate the slice of spectrum by the\\nDiscrete Cosine Transformation (DCT).\\n</summary>\\n    <author>\\n      <name>Koba Natroshvili</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1908.04386v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1908.04386v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1908.10585v1</id>\\n    <updated>2019-08-28T07:41:53Z</updated>\\n    <published>2019-08-28T07:41:53Z</published>\\n    <title>Attention-based Fusion for Outfit Recommendation</title>\\n    <summary>  This paper describes an attention-based fusion method for outfit\\nrecommendation which fuses the information in the product image and description\\nto capture the most important, fine-grained product features into the item\\nrepresentation. We experiment with different kinds of attention mechanisms and\\ndemonstrate that the attention-based fusion improves item understanding. We\\noutperform state-of-the-art outfit recommendation results on three benchmark\\ndatasets.\\n</summary>\\n    <author>\\n      <name>Katrien Laenen</name>\\n    </author>\\n    <author>\\n      <name>Marie-Francine Moens</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1908.10585v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1908.10585v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2003.08756v1</id>\\n    <updated>2020-03-04T15:02:05Z</updated>\\n    <published>2020-03-04T15:02:05Z</published>\\n    <title>Deep Neural Network Perception Models and Robust Autonomous Driving\\n  Systems</title>\\n    <summary>  This paper analyzes the robustness of deep learning models in autonomous\\ndriving applications and discusses the practical solutions to address that.\\n</summary>\\n    <author>\\n      <name>Mohammad Javad Shafiee</name>\\n    </author>\\n    <author>\\n      <name>Ahmadreza Jeddi</name>\\n    </author>\\n    <author>\\n      <name>Amir Nazemi</name>\\n    </author>\\n    <author>\\n      <name>Paul Fieguth</name>\\n    </author>\\n    <author>\\n      <name>Alexander Wong</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2003.08756v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2003.08756v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2003.09234v1</id>\\n    <updated>2020-03-11T13:20:42Z</updated>\\n    <published>2020-03-11T13:20:42Z</published>\\n    <title>DeepFake Detection: Current Challenges and Next Steps</title>\\n    <summary>  High quality fake videos and audios generated by AI-algorithms (the deep\\nfakes) have started to challenge the status of videos and audios as definitive\\nevidence of events. In this paper, we highlight a few of these challenges and\\ndiscuss the research opportunities in this direction.\\n</summary>\\n    <author>\\n      <name>Siwei Lyu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">arXiv admin note: text overlap with arXiv:1909.12962</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2003.09234v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2003.09234v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2003.09971v2</id>\\n    <updated>2020-05-10T21:59:36Z</updated>\\n    <published>2020-03-22T19:04:25Z</published>\\n    <title>A Better Variant of Self-Critical Sequence Training</title>\\n    <summary>  In this work, we present a simple yet better variant of Self-Critical\\nSequence Training. We make a simple change in the choice of baseline function\\nin REINFORCE algorithm. The new baseline can bring better performance with no\\nextra cost, compared to the greedy decoding baseline.\\n</summary>\\n    <author>\\n      <name>Ruotian Luo</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2003.09971v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2003.09971v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2006.02536v1</id>\\n    <updated>2020-06-03T21:13:05Z</updated>\\n    <published>2020-06-03T21:13:05Z</published>\\n    <title>Phasic dopamine release identification using ensemble of AlexNet</title>\\n    <summary>  Dopamine (DA) is an organic chemical that influences several parts of\\nbehaviour and physical functions. Fast-scan cyclic voltammetry (FSCV) is a\\ntechnique used for in vivo phasic dopamine release measurements. The analysis\\nof such measurements, though, requires notable effort. In this paper, we\\npresent the use of convolutional neural networks (CNNs) for the identification\\nof phasic dopamine releases.\\n</summary>\\n    <author>\\n      <name>Luca Patarnello</name>\\n    </author>\\n    <author>\\n      <name>Marco Celin</name>\\n    </author>\\n    <author>\\n      <name>Loris Nanni</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2006.02536v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2006.02536v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2006.02692v2</id>\\n    <updated>2020-06-05T07:51:53Z</updated>\\n    <published>2020-06-04T08:20:30Z</published>\\n    <title>Problems of dataset creation for light source estimation</title>\\n    <summary>  The paper describes our experience collecting a new dataset for the light\\nsource estimation problem in a single image. The analysis of existing color\\ntargets is presented along with various technical and scientific aspects\\nessential for data collection. The paper also contains an announcement of an\\nupcoming 2-nd International Illumination Estimation Challenge (IEC 2020).\\n</summary>\\n    <author>\\n      <name>E. I. Ershov</name>\\n    </author>\\n    <author>\\n      <name>A. V. Belokopytov</name>\\n    </author>\\n    <author>\\n      <name>A. V. Savchik</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2006.02692v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2006.02692v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2006.05927v1</id>\\n    <updated>2020-06-10T16:25:28Z</updated>\\n    <published>2020-06-10T16:25:28Z</published>\\n    <title>Recent Advances in 3D Object and Hand Pose Estimation</title>\\n    <summary>  3D object and hand pose estimation have huge potentials for Augmented\\nReality, to enable tangible interfaces, natural interfaces, and blurring the\\nboundaries between the real and virtual worlds. In this chapter, we present the\\nrecent developments for 3D object and hand pose estimation using cameras, and\\ndiscuss their abilities and limitations and the possible future development of\\nthe field.\\n</summary>\\n    <author>\\n      <name>Vincent Lepetit</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2006.05927v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2006.05927v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2006.10923v1</id>\\n    <updated>2020-06-19T01:49:37Z</updated>\\n    <published>2020-06-19T01:49:37Z</published>\\n    <title>Hyperparameter Analysis for Image Captioning</title>\\n    <summary>  In this paper, we perform a thorough sensitivity analysis on state-of-the-art\\nimage captioning approaches using two different architectures: CNN+LSTM and\\nCNN+Transformer. Experiments were carried out using the Flickr8k dataset. The\\nbiggest takeaway from the experiments is that fine-tuning the CNN encoder\\noutperforms the baseline and all other experiments carried out for both\\narchitectures.\\n</summary>\\n    <author>\\n      <name>Amish Patel</name>\\n    </author>\\n    <author>\\n      <name>Aravind Varier</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, 9 figures, and 7 tables</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2006.10923v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2006.10923v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2006.14319v1</id>\\n    <updated>2020-06-25T11:50:35Z</updated>\\n    <published>2020-06-25T11:50:35Z</published>\\n    <title>Deep Learning for Cornea Microscopy Blind Deblurring</title>\\n    <summary>  The goal of this project is to build a deep-learning solution that deblurs\\ncornea scans, used for medical examination. The spherical shape of the eye\\nprevents ophtamologist from having completely sharp image. Provided with a\\nstack of corneas from confocal images, our approach is to build a model that\\nperforms an upscaling of the images using an SR (Super Resolution) Network.\\n</summary>\\n    <author>\\n      <name>Toussain Cardot</name>\\n    </author>\\n    <author>\\n      <name>Pilar Marxer</name>\\n    </author>\\n    <author>\\n      <name>Ivan Snozzi</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2006.14319v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2006.14319v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2008.00168v2</id>\\n    <updated>2020-10-21T11:10:31Z</updated>\\n    <published>2020-08-01T04:31:11Z</published>\\n    <title>Land Cover Classification from Remote Sensing Images Based on\\n  Multi-Scale Fully Convolutional Network</title>\\n    <summary>  In this paper, a Multi-Scale Fully Convolutional Network (MSFCN) with\\nmulti-scale convolutional kernel is proposed to exploit discriminative\\nrepresentations from two-dimensional (2D) satellite images.\\n</summary>\\n    <author>\\n      <name>Rui Li</name>\\n    </author>\\n    <author>\\n      <name>Shunyi Zheng</name>\\n    </author>\\n    <author>\\n      <name>Chenxi Duan</name>\\n    </author>\\n    <author>\\n      <name>Ce Zhang</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1080/10095020.2021.2017237</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1080/10095020.2021.2017237\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/2008.00168v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2008.00168v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2008.05336v1</id>\\n    <updated>2020-08-12T14:13:53Z</updated>\\n    <published>2020-08-12T14:13:53Z</published>\\n    <title>Image-based Portrait Engraving</title>\\n    <summary>  This paper describes a simple image-based method that applies engraving\\nstylisation to portraits using ordered dithering. Face detection is used to\\nestimate a rough proxy geometry of the head consisting of a cylinder, which is\\nused to warp the dither matrix, causing the engraving lines to curve around the\\nface for better stylisation. Finally, an application of the approach to colour\\nengraving is demonstrated.\\n</summary>\\n    <author>\\n      <name>Paul L. Rosin</name>\\n    </author>\\n    <author>\\n      <name>Yu-Kun Lai</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 8 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2008.05336v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2008.05336v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2008.10236v1</id>\\n    <updated>2020-08-24T07:37:12Z</updated>\\n    <published>2020-08-24T07:37:12Z</published>\\n    <title>Strawberry Detection using Mixed Training on Simulated and Real Data</title>\\n    <summary>  This paper demonstrates how simulated images can be useful for object\\ndetection tasks in the agricultural sector, where labeled data can be scarce\\nand costly to collect. We consider training on mixed datasets with real and\\nsimulated data for strawberry detection in real images. Our results show that\\nusing the real dataset augmented by the simulated dataset resulted in slightly\\nhigher accuracy.\\n</summary>\\n    <author>\\n      <name>Sunny Goondram</name>\\n    </author>\\n    <author>\\n      <name>Akansel Cosgun</name>\\n    </author>\\n    <author>\\n      <name>Dana Kulic</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">DICTA 2020 Short Paper Track</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2008.10236v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2008.10236v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2009.05132v1</id>\\n    <updated>2020-08-24T05:45:20Z</updated>\\n    <published>2020-08-24T05:45:20Z</published>\\n    <title>1st Place Solution to Google Landmark Retrieval 2020</title>\\n    <summary>  This paper presents the 1st place solution to the Google Landmark Retrieval\\n2020 Competition on Kaggle. The solution is based on metric learning to\\nclassify numerous landmark classes, and uses transfer learning with two train\\ndatasets, fine-tuning on bigger images, adjusting loss weight for cleaner\\nsamples, and esemble to enhance the model\\'s performance further. Finally, it\\nscored 0.38677 mAP@100 on the private leaderboard.\\n</summary>\\n    <author>\\n      <name>SeungKee Jeon</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2009.05132v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2009.05132v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2009.09703v1</id>\\n    <updated>2020-09-21T09:18:19Z</updated>\\n    <published>2020-09-21T09:18:19Z</published>\\n    <title>The High-Quality Wide Multi-Channel Attack (HQ-WMCA) database</title>\\n    <summary>  The High-Quality Wide Multi-Channel Attack database (HQ-WMCA) database\\nextends the previous Wide Multi-Channel Attack database(WMCA), with more\\nchannels including color, depth, thermal, infrared (spectra), and short-wave\\ninfrared (spectra), and also a wide variety of attacks.\\n</summary>\\n    <author>\\n      <name>Zohreh Mostaani</name>\\n    </author>\\n    <author>\\n      <name>Anjith George</name>\\n    </author>\\n    <author>\\n      <name>Guillaume Heusch</name>\\n    </author>\\n    <author>\\n      <name>David Geissbuhler</name>\\n    </author>\\n    <author>\\n      <name>Sebastien Marcel</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2009.09703v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2009.09703v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2009.10115v1</id>\\n    <updated>2020-09-21T18:19:23Z</updated>\\n    <published>2020-09-21T18:19:23Z</published>\\n    <title>Extreme compression of grayscale images</title>\\n    <summary>  Given an grayscale digital image, and a positive integer $n$, how well can we\\nstore the image at a compression ratio of $n:1$?\\n  In this paper we address the above question in extreme cases when $n&gt;&gt;50$\\nusing \"$\\\\mathbf{V}$-variable image compression\".\\n</summary>\\n    <author>\\n      <name>Franklin Mendivil</name>\\n    </author>\\n    <author>\\n      <name>\\xc3\\x96rjan Stenflo</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.cnsns.2020.105546</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.cnsns.2020.105546\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 pages, 12 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2009.10115v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2009.10115v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"28A80, 68U10, 94A08\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2009.13793v1</id>\\n    <updated>2020-09-29T05:58:31Z</updated>\\n    <published>2020-09-29T05:58:31Z</published>\\n    <title>A comparison of classical and variational autoencoders for anomaly\\n  detection</title>\\n    <summary>  This paper analyzes and compares a classical and a variational autoencoder in\\nthe context of anomaly detection. To better understand their architecture and\\nfunctioning, describe their properties and compare their performance, it\\nexplores how they address a simple problem: reconstructing a line with a slope.\\n</summary>\\n    <author>\\n      <name>Fabrizio Patuzzo</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2009.13793v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2009.13793v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2104.01622v1</id>\\n    <updated>2021-04-04T15:02:32Z</updated>\\n    <published>2021-04-04T15:02:32Z</published>\\n    <title>OnTarget: An Electronic Archery Scoring</title>\\n    <summary>  There are several challenges in creating an electronic archery scoring system\\nusing computer vision techniques. Variability of light, reconstruction of the\\ntarget from several images, variability of target configuration, and filtering\\nnoise were significant challenges during the creation of this scoring system.\\nThis paper discusses the approach used to determine where an arrow hits a\\ntarget, for any possible single or set of targets and provides an algorithm\\nthat balances the difficulty of robust arrow detection while retaining the\\nrequired accuracy.\\n</summary>\\n    <author>\\n      <name>Andreea Danielescu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2104.01622v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2104.01622v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.02222v1</id>\\n    <updated>2021-06-04T02:55:46Z</updated>\\n    <published>2021-06-04T02:55:46Z</published>\\n    <title>History Encoding Representation Design for Human Intention Inference</title>\\n    <summary>  In this extended abstract, we investigate the design of learning\\nrepresentation for human intention inference. In our designed human intention\\nprediction task, we propose a history encoding representation that is both\\ninterpretable and effective for prediction. Through extensive experiments, we\\nshow our prediction framework with a history encoding representation design is\\nsuccessful on the human intention prediction problem.\\n</summary>\\n    <author>\\n      <name>Zhuo Xu</name>\\n    </author>\\n    <author>\\n      <name>Masayoshi Tomizuka</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2106.02222v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.02222v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.04104v1</id>\\n    <updated>2021-06-08T05:06:51Z</updated>\\n    <published>2021-06-08T05:06:51Z</published>\\n    <title>Design of Low-Artifact Interpolation Kernels by Means of Computer\\n  Algebra</title>\\n    <summary>  We present a number of new piecewise-polynomial kernels for image\\ninterpolation. The kernels are constructed by optimizing a measure of\\ninterpolation quality based on the magnitude of anisotropic artifacts. The\\nkernel design process is performed symbolically using Mathematica computer\\nalgebra system. Experimental evaluation involving 14 image quality assessment\\nmethods demonstrates that our results compare favorably with the existing\\nlinear interpolators.\\n</summary>\\n    <author>\\n      <name>Peter Karpov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2106.04104v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.04104v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.SC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.08042v1</id>\\n    <updated>2021-06-15T10:52:07Z</updated>\\n    <published>2021-06-15T10:52:07Z</published>\\n    <title>Hotel Recognition via Latent Image Embedding</title>\\n    <summary>  We approach the problem of hotel recognition with deep metric learning. We\\noverview the existing approaches and propose a modification to Contrastive loss\\ncalled Contrastive-Triplet loss. We construct a robust pipeline for\\nbenchmarking metric learning models and perform experiments on Hotels-50K and\\nCUB200 datasets. Contrastive-Triplet loss is shown to achieve better retrieval\\non Hotels-50k. We open-source our code.\\n</summary>\\n    <author>\\n      <name>Boris Tseytlin</name>\\n    </author>\\n    <author>\\n      <name>Ilya Makarov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IWANN 2021</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2106.08042v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.08042v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.08366v1</id>\\n    <updated>2021-06-15T18:36:54Z</updated>\\n    <published>2021-06-15T18:36:54Z</published>\\n    <title>Explaining decision of model from its prediction</title>\\n    <summary>  This document summarizes different visual explanations methods such as CAM,\\nGrad-CAM, Localization using Multiple Instance Learning - Saliency-based\\nmethods, Saliency-driven Class-Impressions, Muting pixels in input image -\\nAdversarial methods and Activation visualization, Convolution filter\\nvisualization - Feature-based methods. We have also shown the results produced\\nby different methods and a comparison between CAM, GradCAM, and Guided\\nBackpropagation.\\n</summary>\\n    <author>\\n      <name>Dipesh Tamboli</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Literature review</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2106.08366v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.08366v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.11467v1</id>\\n    <updated>2021-06-22T01:02:52Z</updated>\\n    <published>2021-06-22T01:02:52Z</published>\\n    <title>Multimodal trajectory forecasting based on discrete heat map</title>\\n    <summary>  In Argoverse motion forecasting competition, the task is to predict the\\nprobabilistic future trajectory distribution for the interested targets in the\\ntraffic scene. We use vectorized lane map and 2 s targets\\' history trajectories\\nas input. Then the model outputs 6 forecasted trajectories with probability for\\neach target.\\n</summary>\\n    <author>\\n      <name>Jingni Yuan</name>\\n    </author>\\n    <author>\\n      <name>Jianyun Xu</name>\\n    </author>\\n    <author>\\n      <name>Yushi Zhu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2106.11467v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.11467v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.12016v1</id>\\n    <updated>2021-06-22T18:42:44Z</updated>\\n    <published>2021-06-22T18:42:44Z</published>\\n    <title>On Matrix Factorizations in Subspace Clustering</title>\\n    <summary>  This article explores subspace clustering algorithms using CUR\\ndecompositions, and examines the effect of various hyperparameters in these\\nalgorithms on clustering performance on two real-world benchmark datasets, the\\nHopkins155 motion segmentation dataset and the Yale face dataset. Extensive\\nexperiments are done for a variety of sampling methods and oversampling\\nparameters for these datasets, and some guidelines for parameter choices are\\ngiven for practical applications.\\n</summary>\\n    <author>\\n      <name>Reeshad Arian</name>\\n    </author>\\n    <author>\\n      <name>Keaton Hamm</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">13 pages plus 4 pages of tables</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2106.12016v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.12016v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68P99, 68T10, 62H30\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.15179v1</id>\\n    <updated>2021-06-29T08:51:23Z</updated>\\n    <published>2021-06-29T08:51:23Z</published>\\n    <title>Wrong Colored Vermeer: Color-Symmetric Image Distortion</title>\\n    <summary>  Color symmetry implies that the colors of geometrical objects are assigned\\naccording to their symmetry properties. It is defined by associating the\\nelements of the symmetry group with a color permutation. I use this concept for\\ngenerative art and apply symmetry-consistent color distortions to images of\\npaintings by Johannes Vermeer. The color permutations are realized as mappings\\nof the HSV color space onto itself.\\n</summary>\\n    <author>\\n      <name>Hendrik Richter</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2106.15179v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.15179v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2106.15306v1</id>\\n    <updated>2021-06-08T14:57:25Z</updated>\\n    <published>2021-06-08T14:57:25Z</published>\\n    <title>Artificial Intelligence in Minimally Invasive Interventional Treatment</title>\\n    <summary>  Minimally invasive image guided treatment procedures often employ advanced\\nimage processing algorithms. The recent developments of artificial intelligence\\nalgorithms harbor potential to further enhance this domain. In this article we\\nexplore several application areas within the minimally invasive treatment space\\nand discuss the deployment of artificial intelligence within these areas.\\n</summary>\\n    <author>\\n      <name>Daniel Ruijters</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2106.15306v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2106.15306v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.1; I.2.10; I.4.9\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2108.04453v2</id>\\n    <updated>2021-08-11T02:36:26Z</updated>\\n    <published>2021-08-10T05:25:59Z</published>\\n    <title>Method Towards CVPR 2021 Image Matching Challenge</title>\\n    <summary>  This report describes Megvii-3D team\\'s approach towards CVPR 2021 Image\\nMatching Workshop.\\n</summary>\\n    <author>\\n      <name>Xiaopeng Bi</name>\\n    </author>\\n    <author>\\n      <name>Yu Chen</name>\\n    </author>\\n    <author>\\n      <name>Xinyang Liu</name>\\n    </author>\\n    <author>\\n      <name>Dehao Zhang</name>\\n    </author>\\n    <author>\\n      <name>Ran Yan</name>\\n    </author>\\n    <author>\\n      <name>Zheng Chai</name>\\n    </author>\\n    <author>\\n      <name>Haotian Zhang</name>\\n    </author>\\n    <author>\\n      <name>Xiao Liu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2108.04453v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2108.04453v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2109.00816v1</id>\\n    <updated>2021-09-02T09:47:43Z</updated>\\n    <published>2021-09-02T09:47:43Z</published>\\n    <title>Deep Learning-based mitosis detection in breast cancer histologic\\n  samples</title>\\n    <summary>  This is the submission for mitosis detection in the context of the MIDOG 2021\\nchallenge. It is based on the two-stage objection model Faster RCNN as well as\\nDenseNet as a backbone for the neural network architecture. It achieves a\\nF1-score of 0.6645 on the Preliminary Test Phase Leaderboard.\\n</summary>\\n    <author>\\n      <name>Michel Halmes</name>\\n    </author>\\n    <author>\\n      <name>Hippolyte Heuberger</name>\\n    </author>\\n    <author>\\n      <name>Sylvain Berlemont</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2109.00816v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2109.00816v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2109.13126v1</id>\\n    <updated>2021-09-27T15:39:27Z</updated>\\n    <published>2021-09-27T15:39:27Z</published>\\n    <title>GANiry: Bald-to-Hairy Translation Using CycleGAN</title>\\n    <summary>  This work presents our computer vision course project called bald\\nmen-to-hairy men translation using CycleGAN. On top of CycleGAN architecture,\\nwe utilize perceptual loss in order to achieve more realistic results. We also\\nintegrate conditional constrains to obtain different stylized and colored hairs\\non bald men. We conducted extensive experiments and present qualitative results\\nin this paper. Our code and models are available at\\nhttps://github.com/fidansamet/GANiry.\\n</summary>\\n    <author>\\n      <name>Fidan Samet</name>\\n    </author>\\n    <author>\\n      <name>Oguz Bakir</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2109.13126v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2109.13126v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2110.07201v1</id>\\n    <updated>2021-10-14T07:54:36Z</updated>\\n    <published>2021-10-14T07:54:36Z</published>\\n    <title>Coarse to Fine: Video Retrieval before Moment Localization</title>\\n    <summary>  The current state-of-the-art methods for video corpus moment retrieval (VCMR)\\noften use similarity-based feature alignment approach for the sake of\\nconvenience and speed. However, late fusion methods like cosine similarity\\nalignment are unable to make full use of the information from both query texts\\nand videos. In this paper, we combine feature alignment with feature fusion to\\npromote the performance on VCMR.\\n</summary>\\n    <author>\\n      <name>Zijian Gao</name>\\n    </author>\\n    <author>\\n      <name>Huanyu Liu</name>\\n    </author>\\n    <author>\\n      <name>Jingyu Liu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2110.07201v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2110.07201v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2110.14830v1</id>\\n    <updated>2021-10-28T00:35:32Z</updated>\\n    <published>2021-10-28T00:35:32Z</published>\\n    <title>ODMTCNet: An Interpretable Multi-view Deep Neural Network Architecture\\n  for Image Feature Representation</title>\\n    <summary>  This work proposes an interpretable multi-view deep neural network\\narchitecture, namely optimal discriminant multi-view tensor convolutional\\nnetwork (ODMTCNet), by integrating statistical machine learning (SML)\\nprinciples with the deep neural network (DNN) architecture.\\n</summary>\\n    <author>\\n      <name>Lei Gao</name>\\n    </author>\\n    <author>\\n      <name>Zheng Guo</name>\\n    </author>\\n    <author>\\n      <name>Ling Guan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Submitted to IEEE TPAMI</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2110.14830v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2110.14830v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2111.04839v1</id>\\n    <updated>2021-11-08T21:23:37Z</updated>\\n    <published>2021-11-08T21:23:37Z</published>\\n    <title>Evolving Evocative 2D Views of Generated 3D Objects</title>\\n    <summary>  We present a method for jointly generating 3D models of objects and 2D\\nrenders at different viewing angles, with the process guided by ImageNet and\\nCLIP -based models. Our results indicate that it can generate anamorphic\\nobjects, with renders that both evoke the target caption and look visually\\nappealing.\\n</summary>\\n    <author>\\n      <name>Eric Chu</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NeurIPS 2021 Workshop on Machine Learning for Creativity and\\n  Design</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2111.04839v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2111.04839v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2111.05471v1</id>\\n    <updated>2021-11-10T00:56:45Z</updated>\\n    <published>2021-11-10T00:56:45Z</published>\\n    <title>Analysis of PDE-based binarization model for degraded document images</title>\\n    <summary>  This report presents the results of a PDE-based binarization model for\\ndegraded document images. The model utilizes an edge and binary source term in\\nits formulation. Results indicate effectiveness for document images with\\nbleed-through and faded text and stains to a lesser extent.\\n</summary>\\n    <author>\\n      <name>Uche A. Nnolim</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2111.05471v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2111.05471v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2111.06662v1</id>\\n    <updated>2021-11-12T11:08:15Z</updated>\\n    <published>2021-11-12T11:08:15Z</published>\\n    <title>A comprehensive study of clustering a class of 2D shapes</title>\\n    <summary>  The paper concerns clustering with respect to the shape and size of 2D\\ncontours that are boundaries of cross-sections of 3D objects of revolution. We\\npropose a number of similarity measures based on combined disparate Procrustes\\nanalysis (PA) and Dynamic Time Warping (DTW) distances. Motivation and the main\\napplication for this study comes from archaeology. The performed computational\\nexperiments refer to the clustering of archaeological pottery.\\n</summary>\\n    <author>\\n      <name>Agnieszka Kaliszewska</name>\\n    </author>\\n    <author>\\n      <name>Monika Syga</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2111.06662v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2111.06662v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2111.09113v1</id>\\n    <updated>2021-11-15T11:51:36Z</updated>\\n    <published>2021-11-15T11:51:36Z</published>\\n    <title>2nd Place Solution to Facebook AI Image Similarity Challenge Matching\\n  Track</title>\\n    <summary>  This paper presents the 2nd place solution to the Facebook AI Image\\nSimilarity Challenge : Matching Track on DrivenData. The solution is based on\\nself-supervised learning, and Vision Transformer(ViT). The main breaktrough\\ncomes from concatenating query and reference image to form as one image and\\nasking ViT to directly predict from the image if query image used reference\\nimage. The solution scored 0.8291 Micro-average Precision on the private\\nleaderboard.\\n</summary>\\n    <author>\\n      <name>SeungKee Jeon</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2111.09113v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2111.09113v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2201.08122v1</id>\\n    <updated>2022-01-20T12:01:06Z</updated>\\n    <published>2022-01-20T12:01:06Z</published>\\n    <title>A Computational Model for Machine Thinking</title>\\n    <summary>  A machine thinking model is proposed in this report based on recent advances\\nof computer vision and the recent results of neuroscience devoted to brain\\nunderstanding. We deliver the result of machine thinking in the form of\\nsentences of natural-language or drawn sketches either informative or\\ndecisional. This result is obtained from a reasoning performed on new acquired\\ndata and memorized data.\\n</summary>\\n    <author>\\n      <name>Slimane Larabi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Internal report, RIIMA Laboratory</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2201.08122v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2201.08122v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2201.10522v1</id>\\n    <updated>2022-01-22T08:21:12Z</updated>\\n    <published>2022-01-22T08:21:12Z</published>\\n    <title>Blind Image Deblurring: a Review</title>\\n    <summary>  This is a review on blind image deblurring. First, we formulate the blind\\nimage deblurring problem and explain why it is challenging. Next, we bring some\\npsychological and cognitive studies on the way our human vision system deblurs.\\nThen, relying on several previous reviews, we discuss the topic of metrics and\\ndatasets, which is non-trivial to blind deblurring. Finally, we introduce some\\ntypical optimization-based methods and learning-based methods.\\n</summary>\\n    <author>\\n      <name>Zhengrong Xue</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2201.10522v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2201.10522v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2202.07437v3</id>\\n    <updated>2023-03-19T13:11:59Z</updated>\\n    <published>2022-02-09T01:24:36Z</published>\\n    <title>Mathematical Cookbook for Snapshot Compressive Imaging</title>\\n    <summary>  The author intends to provide you with a beautiful, elegant, user-friendly\\ncookbook for mathematics in Snapshot Compressive Imaging (SCI). Currently, the\\ncookbook is composed of introduction, conventional optimization, and deep\\nequilibrium models. The latest releases are strongly recommended! For any other\\nquestions, suggestions, or comments, feel free to email the author.\\n</summary>\\n    <author>\\n      <name>Yaping Zhao</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2202.07437v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2202.07437v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2202.07572v3</id>\\n    <updated>2025-08-10T15:24:18Z</updated>\\n    <published>2022-02-15T16:58:49Z</published>\\n    <title>On Representation Learning with Feedback</title>\\n    <summary>  This note complements the author\\'s recent paper \"Robust representation\\nlearning with feedback for single image deraining\" by providing heuristically\\ntheoretical explanations on the mechanism of representation learning with\\nfeedback, namely an essential merit of the works presented in this recent\\narticle. This note facilitates understanding of key points in the mechanism of\\nrepresentation learning with feedback.\\n</summary>\\n    <author>\\n      <name>Hao Li</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2202.07572v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2202.07572v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2202.13837v1</id>\\n    <updated>2022-02-28T14:48:51Z</updated>\\n    <published>2022-02-28T14:48:51Z</published>\\n    <title>Fuse Local and Global Semantics in Representation Learning</title>\\n    <summary>  We propose Fuse Local and Global Semantics in Representation Learning (FLAGS)\\nto generate richer representations. FLAGS aims at extract both global and local\\nsemantics from images to benefit various downstream tasks. It shows promising\\nresults under common linear evaluation protocol. We also conduct detection and\\nsegmentation on PASCAL VOC and COCO to show the representations extracted by\\nFLAGS are transferable.\\n</summary>\\n    <author>\\n      <name>Yuchi Zhao</name>\\n    </author>\\n    <author>\\n      <name>Yuhao Zhou</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2202.13837v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2202.13837v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2203.06890v2</id>\\n    <updated>2022-03-21T15:34:03Z</updated>\\n    <published>2022-03-14T07:11:20Z</published>\\n    <title>Attention based Memory video portrait matting</title>\\n    <summary>  We proposed a novel trimap free video matting method based on the attention\\nmechanism. By the nature of the problem, most existing approaches use either\\nmultiple computational expansive modules or complex algorithms to exploit\\ntemporal information fully. We designed a temporal aggregation module to\\ncompute the temporal coherence between the current frame and its two previous\\nframes.\\n</summary>\\n    <author>\\n      <name>Shufeng Song</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2203.06890v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2203.06890v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2203.13185v1</id>\\n    <updated>2022-03-24T17:02:43Z</updated>\\n    <published>2022-03-24T17:02:43Z</published>\\n    <title>Quantum Motion Segmentation</title>\\n    <summary>  Motion segmentation is a challenging problem that seeks to identify\\nindependent motions in two or several input images. This paper introduces the\\nfirst algorithm for motion segmentation that relies on adiabatic quantum\\noptimization of the objective function. The proposed method achieves on-par\\nperformance with the state of the art on problem instances which can be mapped\\nto modern quantum annealers.\\n</summary>\\n    <author>\\n      <name>Federica Arrigoni</name>\\n    </author>\\n    <author>\\n      <name>Willi Menapace</name>\\n    </author>\\n    <author>\\n      <name>Marcel Seelbach Benkner</name>\\n    </author>\\n    <author>\\n      <name>Elisa Ricci</name>\\n    </author>\\n    <author>\\n      <name>Vladislav Golyanik</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2203.13185v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2203.13185v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2204.01081v1</id>\\n    <updated>2022-04-03T14:28:16Z</updated>\\n    <published>2022-04-03T14:28:16Z</published>\\n    <title>Faces: AI Blitz XIII Solutions</title>\\n    <summary>  AI Blitz XIII Faces challenge hosted on www.aicrowd.com platform consisted of\\nfive problems: Sentiment Classification, Age Prediction, Mask Prediction, Face\\nRecognition, and Face De-Blurring. Our team GLaDOS took second place. Here we\\npresent our solutions and results. Code implementation:\\nhttps://github.com/ndrwmlnk/ai-blitz-xiii\\n</summary>\\n    <author>\\n      <name>Andrew Melnik</name>\\n    </author>\\n    <author>\\n      <name>Eren Akbulut</name>\\n    </author>\\n    <author>\\n      <name>Jannik Sheikh</name>\\n    </author>\\n    <author>\\n      <name>Kira Loos</name>\\n    </author>\\n    <author>\\n      <name>Michael Buettner</name>\\n    </author>\\n    <author>\\n      <name>Tobias Lenze</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2204.01081v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2204.01081v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2204.06120v1</id>\\n    <updated>2022-04-13T00:11:45Z</updated>\\n    <published>2022-04-13T00:11:45Z</published>\\n    <title>Baseline Computation for Attribution Methods Based on Interpolated\\n  Inputs</title>\\n    <summary>  We discuss a way to find a well behaved baseline for attribution methods that\\nwork by feeding a neural network with a sequence of interpolated inputs between\\ntwo given inputs. Then, we test it with our novel Riemann-Stieltjes Integrated\\nGradient-weighted Class Activation Mapping (RSI-Grad-CAM) attribution method.\\n</summary>\\n    <author>\\n      <name>Miguel Lerma</name>\\n    </author>\\n    <author>\\n      <name>Mirtha Lucas</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 3 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2204.06120v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2204.06120v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68T07\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"K.3.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2205.00934v1</id>\\n    <updated>2022-05-02T14:32:59Z</updated>\\n    <published>2022-05-02T14:32:59Z</published>\\n    <title>Assessing unconstrained surgical cuttings in VR using CNNs</title>\\n    <summary>  We present a Convolutional Neural Network (CNN) suitable to assess\\nunconstrained surgical cuttings, trained on a dataset created with a data\\naugmentation technique.\\n</summary>\\n    <author>\\n      <name>Ilias Chrysovergis</name>\\n    </author>\\n    <author>\\n      <name>Manos Kamarianakis</name>\\n    </author>\\n    <author>\\n      <name>Mike Kentros</name>\\n    </author>\\n    <author>\\n      <name>Dimitris Angelis</name>\\n    </author>\\n    <author>\\n      <name>Antonis Protopsaltis</name>\\n    </author>\\n    <author>\\n      <name>George Papagiannakis</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2 pages, 2 figures, Submitted to the Siggraph \\'22 Poster Session\\n  (Vancouver, 8-11 Aug 2022)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2205.00934v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2205.00934v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2205.06873v1</id>\\n    <updated>2022-05-13T20:12:12Z</updated>\\n    <published>2022-05-13T20:12:12Z</published>\\n    <title>Using Augmented Face Images to Improve Facial Recognition Tasks</title>\\n    <summary>  We present a framework that uses GAN-augmented images to complement certain\\nspecific attributes, usually underrepresented, for machine learning model\\ntraining. This allows us to improve inference quality over those attributes for\\nthe facial recognition tasks.\\n</summary>\\n    <author>\\n      <name>Shuo Cheng</name>\\n    </author>\\n    <author>\\n      <name>Guoxian Song</name>\\n    </author>\\n    <author>\\n      <name>Wan-Chun Ma</name>\\n    </author>\\n    <author>\\n      <name>Chao Wang</name>\\n    </author>\\n    <author>\\n      <name>Linjie Luo</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CHI 2022 Workshop: AI-Generated Characters: Putting Deepfakes to Good\\n  Use</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2205.06873v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2205.06873v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2207.03843v1</id>\\n    <updated>2022-07-08T11:54:37Z</updated>\\n    <published>2022-07-08T11:54:37Z</published>\\n    <title>Continuous Methods : Hamiltonian Domain Translation</title>\\n    <summary>  This paper proposes a novel approach to domain translation. Leveraging\\nestablished parallels between generative models and dynamical systems, we\\npropose a reformulation of the Cycle-GAN architecture. By embedding our model\\nwith a Hamiltonian structure, we obtain a continuous, expressive and most\\nimportantly invertible generative model for domain translation.\\n</summary>\\n    <author>\\n      <name>Emmanuel Menier</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LISN, Inria, IRT SystemX</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Michele Alessandro Bucci</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Inria</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Mouadh Yagoubi</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IRT SystemX</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Lionel Mathelin</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LISN</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Marc Schoenauer</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Inria, LISN</arxiv:affiliation>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2207.03843v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.03843v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2207.06553v1</id>\\n    <updated>2022-07-13T23:25:30Z</updated>\\n    <published>2022-07-13T23:25:30Z</published>\\n    <title>QML for Argoverse 2 Motion Forecasting Challenge</title>\\n    <summary>  To safely navigate in various complex traffic scenarios, autonomous driving\\nsystems are generally equipped with a motion forecasting module to provide\\nvital information for the downstream planning module. For the real-world\\nonboard applications, both accuracy and latency of a motion forecasting model\\nare essential. In this report, we present an effective and efficient solution,\\nwhich ranks the 3rd place in the Argoverse 2 Motion Forecasting Challenge 2022.\\n</summary>\\n    <author>\\n      <name>Tong Su</name>\\n    </author>\\n    <author>\\n      <name>Xishun Wang</name>\\n    </author>\\n    <author>\\n      <name>Xiaodong Yang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2207.06553v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.06553v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2207.10201v1</id>\\n    <updated>2022-07-20T21:38:47Z</updated>\\n    <published>2022-07-20T21:38:47Z</published>\\n    <title>Hybrid CNN-Transformer Model For Facial Affect Recognition In the ABAW4\\n  Challenge</title>\\n    <summary>  This paper describes our submission to the fourth Affective Behavior Analysis\\n(ABAW) competition. We proposed a hybrid CNN-Transformer model for the\\nMulti-Task-Learning (MTL) and Learning from Synthetic Data (LSD) task.\\nExperimental results on validation dataset shows that our method achieves\\nbetter performance than baseline model, which verifies that the effectiveness\\nof proposed network.\\n</summary>\\n    <author>\\n      <name>Lingfeng Wang</name>\\n    </author>\\n    <author>\\n      <name>Haocheng Li</name>\\n    </author>\\n    <author>\\n      <name>Chunyin Liu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2207.10201v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.10201v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2207.11329v1</id>\\n    <updated>2022-07-22T20:45:05Z</updated>\\n    <published>2022-07-22T20:45:05Z</published>\\n    <title>Video Swin Transformers for Egocentric Video Understanding @ Ego4D\\n  Challenges 2022</title>\\n    <summary>  We implemented Video Swin Transformer as a base architecture for the tasks of\\nPoint-of-No-Return temporal localization and Object State Change\\nClassification. Our method achieved competitive performance on both challenges.\\n</summary>\\n    <author>\\n      <name>Maria Escobar</name>\\n    </author>\\n    <author>\\n      <name>Laura Daza</name>\\n    </author>\\n    <author>\\n      <name>Cristina Gonz\\xc3\\xa1lez</name>\\n    </author>\\n    <author>\\n      <name>Jordi Pont-Tuset</name>\\n    </author>\\n    <author>\\n      <name>Pablo Arbel\\xc3\\xa1ez</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2207.11329v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.11329v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2210.09296v1</id>\\n    <updated>2022-10-14T12:26:13Z</updated>\\n    <published>2022-10-14T12:26:13Z</published>\\n    <title>3rd Place Solution for Google Universal Image Embedding</title>\\n    <summary>  This paper presents the 3rd place solution to the Google Universal Image\\nEmbedding Competition on Kaggle. We use ViT-H/14 from OpenCLIP for the backbone\\nof ArcFace, and trained in 2 stage. 1st stage is done with freezed backbone,\\nand 2nd stage is whole model training. We achieve 0.692 mean Precision @5 on\\nprivate leaderboard. Code available at\\nhttps://github.com/YasumasaNamba/google-universal-image-embedding\\n</summary>\\n    <author>\\n      <name>Nobuaki Aoki</name>\\n    </author>\\n    <author>\\n      <name>Yasumasa Namba</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 5 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2210.09296v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2210.09296v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2210.10594v1</id>\\n    <updated>2022-10-16T06:36:10Z</updated>\\n    <published>2022-10-16T06:36:10Z</published>\\n    <title>Motion-Based Weak Supervision for Video Parsing with Application to\\n  Colonoscopy</title>\\n    <summary>  We propose a two-stage unsupervised approach for parsing videos into phases.\\nWe use motion cues to divide the video into coarse segments. Noisy segment\\nlabels are then used to weakly supervise an appearance-based classifier. We\\nshow the effectiveness of the method for phase detection in colonoscopy videos.\\n</summary>\\n    <author>\\n      <name>Ori Kelner</name>\\n    </author>\\n    <author>\\n      <name>Or Weinstein</name>\\n    </author>\\n    <author>\\n      <name>Ehud Rivlin</name>\\n    </author>\\n    <author>\\n      <name>Roman Goldenberg</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2210.10594v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2210.10594v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2210.12417v2</id>\\n    <updated>2022-11-10T09:06:27Z</updated>\\n    <published>2022-10-22T11:17:30Z</published>\\n    <title>SLAMs: Semantic Learning based Activation Map for Weakly Supervised\\n  Semantic Segmentation</title>\\n    <summary>  Recent mainstream weakly-supervised semantic segmentation (WSSS) approaches\\nmainly relies on image-level classification learning, which has limited\\nrepresentation capacity. In this paper, we propose a novel semantic learning\\nbased framework, named SLAMs (Semantic Learning based Activation Map), for\\nWSSS.\\n</summary>\\n    <author>\\n      <name>Junliang Chen</name>\\n    </author>\\n    <author>\\n      <name>Xiaodong Zhao</name>\\n    </author>\\n    <author>\\n      <name>Minmin Liu</name>\\n    </author>\\n    <author>\\n      <name>Linlin Shen</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2210.12417v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2210.12417v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2211.15286v1</id>\\n    <updated>2022-11-18T16:05:15Z</updated>\\n    <published>2022-11-18T16:05:15Z</published>\\n    <title>Masked Autoencoders for Egocentric Video Understanding @ Ego4D Challenge\\n  2022</title>\\n    <summary>  In this report, we present our approach and empirical results of applying\\nmasked autoencoders in two egocentric video understanding tasks, namely, Object\\nState Change Classification and PNR Temporal Localization, of Ego4D Challenge\\n2022. As team TheSSVL, we ranked 2nd place in both tasks. Our code will be made\\navailable.\\n</summary>\\n    <author>\\n      <name>Jiachen Lei</name>\\n    </author>\\n    <author>\\n      <name>Shuang Ma</name>\\n    </author>\\n    <author>\\n      <name>Zhongjie Ba</name>\\n    </author>\\n    <author>\\n      <name>Sai Vemprala</name>\\n    </author>\\n    <author>\\n      <name>Ashish Kapoor</name>\\n    </author>\\n    <author>\\n      <name>Kui Ren</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2211.15286v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2211.15286v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2212.09027v1</id>\\n    <updated>2022-12-18T07:36:32Z</updated>\\n    <published>2022-12-18T07:36:32Z</published>\\n    <title>2D Pose Estimation based Child Action Recognition</title>\\n    <summary>  We present a graph convolutional network with 2D pose estimation for the\\nfirst time on child action recognition task achieving on par results with an\\nRGB modality based model on a novel benchmark dataset containing unconstrained\\nenvironment based videos.\\n</summary>\\n    <author>\\n      <name>Sanka Mohottala</name>\\n    </author>\\n    <author>\\n      <name>Sandun Abeygunawardana</name>\\n    </author>\\n    <author>\\n      <name>Pradeepa Samarasinghe</name>\\n    </author>\\n    <author>\\n      <name>Dharshana Kasthurirathna</name>\\n    </author>\\n    <author>\\n      <name>Charith Abhayaratne</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Paper Accepted for the IEEE TENCON Conference (2022). 7 pages, 5\\n  figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2212.09027v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2212.09027v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2212.13810v1</id>\\n    <updated>2022-12-28T13:06:30Z</updated>\\n    <published>2022-12-28T13:06:30Z</published>\\n    <title>All\\'s well that FID\\'s well? Result quality and metric scores in GAN\\n  models for lip-sychronization tasks</title>\\n    <summary>  We test the performance of GAN models for lip-synchronization. For this, we\\nreimplement LipGAN in Pytorch, train it on the dataset GRID and compare it to\\nour own variation, L1WGAN-GP, adapted to the LipGAN architecture and also\\ntrained on GRID.\\n</summary>\\n    <author>\\n      <name>Carina Geldhauser</name>\\n    </author>\\n    <author>\\n      <name>Johan Liljegren</name>\\n    </author>\\n    <author>\\n      <name>Pontus Nordqvist</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2212.13810v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2212.13810v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68T07\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2301.06936v1</id>\\n    <updated>2022-12-12T21:24:03Z</updated>\\n    <published>2022-12-12T21:24:03Z</published>\\n    <title>The use of Octree in point cloud analysis with application to cultural\\n  heritage</title>\\n    <summary>  In this article we present the effects of our work on the subject of the\\ntechnical approach to the 3D point cloud data analysis through the use of the\\nOctree method to compress, analyse and compute the initial data.\\n</summary>\\n    <author>\\n      <name>Rafa\\xc5\\x82 Bie\\xc5\\x84kowski</name>\\n    </author>\\n    <author>\\n      <name>Krzysztof E. Rutkowski</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 12 figures, 7 citations</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2301.06936v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2301.06936v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"E.1; E.2; J.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2301.07947v1</id>\\n    <updated>2023-01-19T08:47:31Z</updated>\\n    <published>2023-01-19T08:47:31Z</published>\\n    <title>Point Cloud Data Simulation and Modelling with Aize Workspace</title>\\n    <summary>  This work takes a look at data models often used in digital twins and\\npresents preliminary results specifically from surface reconstruction and\\nsemantic segmentation models trained using simulated data. This work is\\nexpected to serve as a ground work for future endeavours in data\\ncontextualisation inside a digital twin.\\n</summary>\\n    <author>\\n      <name>Boris Mocialov</name>\\n    </author>\\n    <author>\\n      <name>Eirik Eythorsson</name>\\n    </author>\\n    <author>\\n      <name>Reza Parseh</name>\\n    </author>\\n    <author>\\n      <name>Hoang Tran</name>\\n    </author>\\n    <author>\\n      <name>Vegard Flovik</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Extended abstract, Northern Lights Deep Learning Conference, 2023</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2301.07947v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2301.07947v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2302.12185v1</id>\\n    <updated>2023-02-02T19:19:10Z</updated>\\n    <published>2023-02-02T19:19:10Z</published>\\n    <title>Scaling Up Computer Vision Neural Networks Using Fast Fourier Transform</title>\\n    <summary>  Deep Learning-based Computer Vision field has recently been trying to explore\\nlarger kernels for convolution to effectively scale up Convolutional Neural\\nNetworks. Simultaneously, new paradigm of models such as Vision Transformers\\nfind it difficult to scale up to larger higher resolution images due to their\\nquadratic complexity in terms of input sequence. In this report, Fast Fourier\\nTransform is utilised in various ways to provide some solutions to these\\nissues.\\n</summary>\\n    <author>\\n      <name>Siddharth Agrawal</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2302.12185v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2302.12185v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2303.04208v1</id>\\n    <updated>2023-03-07T19:58:57Z</updated>\\n    <published>2023-03-07T19:58:57Z</published>\\n    <title>EscherNet 101</title>\\n    <summary>  A deep learning model, EscherNet 101, is constructed to categorize images of\\n2D periodic patterns into their respective 17 wallpaper groups. Beyond\\nevaluating EscherNet 101 performance by classification rates, at a micro-level\\nwe investigate the filters learned at different layers in the network, capable\\nof capturing second-order invariants beyond edge and curvature.\\n</summary>\\n    <author>\\n      <name>Christopher Funk</name>\\n    </author>\\n    <author>\\n      <name>Yanxi Liu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 page, 12 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2303.04208v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2303.04208v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"20-08 Computational methods for problems pertaining to group theory\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2303.12727v1</id>\\n    <updated>2023-03-13T11:31:35Z</updated>\\n    <published>2023-03-13T11:31:35Z</published>\\n    <title>A XGBoost Algorithm-based Fatigue Recognition Model Using Face Detection</title>\\n    <summary>  As fatigue is normally revealed in the eyes and mouth of a person\\'s face,\\nthis paper tried to construct a XGBoost Algorithm-Based fatigue recognition\\nmodel using the two indicators, EAR (Eye Aspect Ratio) and MAR(Mouth Aspect\\nRatio). With an accuracy rate of 87.37% and sensitivity rate of 89.14%, the\\nmodel was proved to be efficient and valid for further applications.\\n</summary>\\n    <author>\\n      <name>Xinrui Chen</name>\\n    </author>\\n    <author>\\n      <name>Bingquan Zhang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages;2 fiqures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2303.12727v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2303.12727v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2303.12946v1</id>\\n    <updated>2023-03-01T22:36:54Z</updated>\\n    <published>2023-03-01T22:36:54Z</published>\\n    <title>Underwater Camouflage Object Detection Dataset</title>\\n    <summary>  We have made a dataset of camouflage object detection mainly for complex\\nseabed scenes, and named it UnderWater RGB&amp;Sonar,or UW-RS for short. The UW-RS\\ndataset contains a total of 1972 image data. The dataset mainly consists of two\\nparts, namely underwater optical data part (UW-R dataset) and underwater sonar\\ndata part (UW-S dataset).\\n</summary>\\n    <author>\\n      <name>Feng Dong</name>\\n    </author>\\n    <author>\\n      <name>Jinchao Zhu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2303.12946v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2303.12946v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2304.02766v1</id>\\n    <updated>2023-04-05T22:14:53Z</updated>\\n    <published>2023-04-05T22:14:53Z</published>\\n    <title>Shape complexity estimation using VAE</title>\\n    <summary>  In this paper, we compare methods for estimating the complexity of\\ntwo-dimensional shapes and introduce a method that exploits reconstruction loss\\nof Variational Autoencoders with different sizes of latent vectors. Although\\ncomplexity of a shape is not a well defined attribute, different aspects of it\\ncan be estimated. We demonstrate that our methods captures some aspects of\\nshape complexity. Code and training details will be publicly available.\\n</summary>\\n    <author>\\n      <name>Markus Rothgaenger</name>\\n    </author>\\n    <author>\\n      <name>Andrew Melnik</name>\\n    </author>\\n    <author>\\n      <name>Helge Ritter</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2304.02766v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2304.02766v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2304.11923v2</id>\\n    <updated>2023-09-18T12:30:10Z</updated>\\n    <published>2023-04-24T09:06:06Z</published>\\n    <title>Improving Knowledge Distillation via Transferring Learning Ability</title>\\n    <summary>  Existing knowledge distillation methods generally use a teacher-student\\napproach, where the student network solely learns from a well-trained teacher.\\nHowever, this approach overlooks the inherent differences in learning abilities\\nbetween the teacher and student networks, thus causing the capacity-gap\\nproblem. To address this limitation, we propose a novel method called SLKD.\\n</summary>\\n    <author>\\n      <name>Long Liu</name>\\n    </author>\\n    <author>\\n      <name>Tong Li</name>\\n    </author>\\n    <author>\\n      <name>Hui Cheng</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2304.11923v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2304.11923v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2304.14485v1</id>\\n    <updated>2023-03-10T12:58:16Z</updated>\\n    <published>2023-03-10T12:58:16Z</published>\\n    <title>Inter-sphere consistency-based method for camera-projector pair\\n  calibration</title>\\n    <summary>  We construct constraints from consistency between estimated parameters from\\ndifferent spheres, termed inter-sphere consistency. It facilitates more\\nflexible calibration using only two spheres, which has been considered a\\nchallenging and not well addressed ill-posed problem.\\n</summary>\\n    <author>\\n      <name>Zhaoshuai Qi</name>\\n    </author>\\n    <author>\\n      <name>Jingqi Pang</name>\\n    </author>\\n    <author>\\n      <name>Yifeng Hao</name>\\n    </author>\\n    <author>\\n      <name>Yanning Zhang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages,1 figure</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2304.14485v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2304.14485v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2305.00204v1</id>\\n    <updated>2023-04-29T09:10:32Z</updated>\\n    <published>2023-04-29T09:10:32Z</published>\\n    <title>CARLA-BSP: a simulated dataset with pedestrians</title>\\n    <summary>  We present a sample dataset featuring pedestrians generated using the ARCANE\\nframework, a new framework for generating datasets in CARLA (0.9.13). We\\nprovide use cases for pedestrian detection, autoencoding, pose estimation, and\\npose lifting. We also showcase baseline results. For more information, visit\\nhttps://project-arcane.eu/.\\n</summary>\\n    <author>\\n      <name>Maciej Wielgosz</name>\\n    </author>\\n    <author>\\n      <name>Antonio M. L\\xc3\\xb3pez</name>\\n    </author>\\n    <author>\\n      <name>Muhammad Naveed Riaz</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2305.00204v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2305.00204v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2305.17786v1</id>\\n    <updated>2023-05-28T18:17:31Z</updated>\\n    <published>2023-05-28T18:17:31Z</published>\\n    <title>Real-time Object Detection: YOLOv1 Re-Implementation in PyTorch</title>\\n    <summary>  Real-time object detection is a crucial problem to solve when in comes to\\ncomputer vision systems that needs to make appropriate decision based on\\ndetection in a timely manner. I have chosen the YOLO v1 architecture to\\nimplement it using PyTorch framework, with goal to familiarize with entire\\nobject detection pipeline I attempted different techniques to modify the\\noriginal architecture to improve the results. Finally, I compare the metrics of\\nmy implementation to the original.\\n</summary>\\n    <author>\\n      <name>Michael Shenoda</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2305.17786v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2305.17786v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2306.00360v2</id>\\n    <updated>2023-07-22T23:32:49Z</updated>\\n    <published>2023-06-01T05:40:58Z</published>\\n    <title>How Do ConvNets Understand Image Intensity?</title>\\n    <summary>  Convolutional Neural Networks (ConvNets) usually rely on edge/shape\\ninformation to classify images. Visualization methods developed over the last\\ndecade confirm that ConvNets rely on edge information. We investigate\\nsituations where the ConvNet needs to rely on image intensity in addition to\\nshape. We show that the ConvNet relies on image intensity information using\\nvisualization.\\n</summary>\\n    <author>\\n      <name>Jackson Kaunismaa</name>\\n    </author>\\n    <author>\\n      <name>Michael Guerzhoy</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ICLR Tiny Papers 2023</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2306.00360v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2306.00360v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2306.15445v2</id>\\n    <updated>2023-07-16T13:49:21Z</updated>\\n    <published>2023-06-27T13:02:24Z</published>\\n    <title>UniUD Submission to the EPIC-Kitchens-100 Multi-Instance Retrieval\\n  Challenge 2023</title>\\n    <summary>  In this report, we present the technical details of our submission to the\\nEPIC-Kitchens-100 Multi-Instance Retrieval Challenge 2023. To participate in\\nthe challenge, we ensembled two models trained with two different loss\\nfunctions on 25% of the training data. Our submission, visible on the public\\nleaderboard, obtains an average score of 56.81% nDCG and 42.63% mAP.\\n</summary>\\n    <author>\\n      <name>Alex Falcon</name>\\n    </author>\\n    <author>\\n      <name>Giuseppe Serra</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2306.15445v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2306.15445v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2307.00083v1</id>\\n    <updated>2023-06-30T18:39:57Z</updated>\\n    <published>2023-06-30T18:39:57Z</published>\\n    <title>A Parts Based Registration Loss for Detecting Knee Joint Areas</title>\\n    <summary>  In this paper, a parts based loss is considered for finetune registering knee\\njoint areas. Here the parts are defined as abstract feature vectors with\\nlocation and they are automatically selected from a reference image. For a test\\nimage the detected parts are encouraged to have a similar spatial configuration\\nthan the corresponding parts in the reference image.\\n</summary>\\n    <author>\\n      <name>Juha Tiirola</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2307.00083v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.00083v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2307.00411v1</id>\\n    <updated>2023-07-01T19:04:11Z</updated>\\n    <published>2023-07-01T19:04:11Z</published>\\n    <title>Applications of Binary Similarity and Distance Measures</title>\\n    <summary>  In the recent past, binary similarity measures have been applied in solving\\nbiometric identification problems, including fingerprint, handwritten character\\ndetection, and in iris image recognition. The application of the relevant\\nmeasurements has also resulted in more accurate data analysis. This paper\\nsurveys the applicability of binary similarity and distance measures in various\\nfields.\\n</summary>\\n    <author>\\n      <name>Manoj Muniswamaiah</name>\\n    </author>\\n    <author>\\n      <name>Tilak Agerwala</name>\\n    </author>\\n    <author>\\n      <name>Charles C. Tappert</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2307.00411v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.00411v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2307.05601v1</id>\\n    <updated>2023-07-10T20:28:58Z</updated>\\n    <published>2023-07-10T20:28:58Z</published>\\n    <title>Unsupervised Domain Adaptation with Deep Neural-Network</title>\\n    <summary>  This report contributes to the field of unsupervised domain adaptation by\\nproviding an analysis of existing methods, introducing a new approach, and\\ndemonstrating the potential for improving visual recognition tasks across\\ndifferent domains. The results of this study open up opportunities for further\\nstudy and development of advanced methods in the field of domain adaptation.\\n</summary>\\n    <author>\\n      <name>Artem Bituitskii</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Master\\'s thesis, 34 pages, 13 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2307.05601v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.05601v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2307.13215v1</id>\\n    <updated>2023-07-25T02:56:20Z</updated>\\n    <published>2023-07-25T02:56:20Z</published>\\n    <title>Image Segmentation Keras : Implementation of Segnet, FCN, UNet, PSPNet\\n  and other models in Keras</title>\\n    <summary>  Semantic segmentation plays a vital role in computer vision tasks, enabling\\nprecise pixel-level understanding of images. In this paper, we present a\\ncomprehensive library for semantic segmentation, which contains implementations\\nof popular segmentation models like SegNet, FCN, UNet, and PSPNet. We also\\nevaluate and compare these models on several datasets, offering researchers and\\npractitioners a powerful toolset for tackling diverse segmentation challenges.\\n</summary>\\n    <author>\\n      <name>Divam Gupta</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2307.13215v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.13215v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2309.15097v1</id>\\n    <updated>2023-09-26T17:43:58Z</updated>\\n    <published>2023-09-26T17:43:58Z</published>\\n    <title>Case Study: Ensemble Decision-Based Annotation of Unconstrained Real\\n  Estate Images</title>\\n    <summary>  We describe a proof-of-concept for annotating real estate images using simple\\niterative rule-based semi-supervised learning. In this study, we have gained\\nimportant insights into the content characteristics and uniqueness of\\nindividual image classes as well as essential requirements for a practical\\nimplementation.\\n</summary>\\n    <author>\\n      <name>Miroslav Despotovic</name>\\n    </author>\\n    <author>\\n      <name>Zedong Zhang</name>\\n    </author>\\n    <author>\\n      <name>Eric Stumpe</name>\\n    </author>\\n    <author>\\n      <name>Matthias Zeppelzauer</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2 pages, 3 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2309.15097v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2309.15097v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"68\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2310.10517v1</id>\\n    <updated>2023-10-16T15:33:58Z</updated>\\n    <published>2023-10-16T15:33:58Z</published>\\n    <title>Distribution prediction for image compression: An experimental\\n  re-compressor for JPEG images</title>\\n    <summary>  We propose a new scheme to re-compress JPEG images in a lossless way. Using a\\nJPEG image as an input the algorithm partially decodes the signal to obtain\\nquantized DCT coefficients and then re-compress them in a more effective way.\\n</summary>\\n    <author>\\n      <name>Maxim Koroteev</name>\\n    </author>\\n    <author>\\n      <name>Yaroslav Borisov</name>\\n    </author>\\n    <author>\\n      <name>Pavel Frolov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 5 figures, 2 tables</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2310.10517v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2310.10517v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2312.07357v1</id>\\n    <updated>2023-12-12T15:26:06Z</updated>\\n    <published>2023-12-12T15:26:06Z</published>\\n    <title>Automatic coral reef fish identification and 3D measurement in the wild</title>\\n    <summary>  In this paper we present a pipeline using stereo images in order to\\nautomatically identify, track in 3D fish, and measure fish population.\\n</summary>\\n    <author>\\n      <name>Cyril Barrelet</name>\\n    </author>\\n    <author>\\n      <name>Marc Chaumont</name>\\n    </author>\\n    <author>\\n      <name>G\\xc3\\xa9rard Subsol</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper is in its draft version and should be improved in order to\\n  be published. This paper is issued from one Year of Engineering work</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2312.07357v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2312.07357v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2312.09876v1</id>\\n    <updated>2023-12-15T15:24:49Z</updated>\\n    <published>2023-12-15T15:24:49Z</published>\\n    <title>Automatic Image Colourizer</title>\\n    <summary>  In this project we have designed and described a model which colourize a\\ngray-scale image, with no human intervention. We propose a fully automatic\\nprocess of colouring and re-colouring faded or gray-scale image with vibrant\\nand pragmatic colours. We have used Convolutional Neural Network to hallucinate\\ninput images and feed-forwarded by training thousands of images. This approach\\nresults in trailblazing results.\\n</summary>\\n    <author>\\n      <name>Aditya Parikh</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2312.09876v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2312.09876v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2312.16987v1</id>\\n    <updated>2023-12-28T12:15:58Z</updated>\\n    <published>2023-12-28T12:15:58Z</published>\\n    <title>Image Quality, Uniformity and Computation Improvement of Compressive\\n  Light Field Displays with U-Net</title>\\n    <summary>  We apply the U-Net model for compressive light field synthesis. Compared to\\nmethods based on stacked CNN and iterative algorithms, this method offers\\nbetter image quality, uniformity and less computation.\\n</summary>\\n    <author>\\n      <name>Chen Gao</name>\\n    </author>\\n    <author>\\n      <name>Haifeng Li</name>\\n    </author>\\n    <author>\\n      <name>Xu Liu</name>\\n    </author>\\n    <author>\\n      <name>Xiaodi Tan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 6 figures, conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2312.16987v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2312.16987v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"78-06\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.3.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2401.06167v1</id>\\n    <updated>2024-01-02T03:49:41Z</updated>\\n    <published>2024-01-02T03:49:41Z</published>\\n    <title>Enhancing Multimodal Understanding with CLIP-Based Image-to-Text\\n  Transformation</title>\\n    <summary>  The process of transforming input images into corresponding textual\\nexplanations stands as a crucial and complex endeavor within the domains of\\ncomputer vision and natural language processing. In this paper, we propose an\\ninnovative ensemble approach that harnesses the capabilities of Contrastive\\nLanguage-Image Pretraining models.\\n</summary>\\n    <author>\\n      <name>Chang Che</name>\\n    </author>\\n    <author>\\n      <name>Qunwei Lin</name>\\n    </author>\\n    <author>\\n      <name>Xinyu Zhao</name>\\n    </author>\\n    <author>\\n      <name>Jiaxin Huang</name>\\n    </author>\\n    <author>\\n      <name>Liqiang Yu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2401.06167v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2401.06167v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2401.14675v1</id>\\n    <updated>2024-01-26T06:40:00Z</updated>\\n    <published>2024-01-26T06:40:00Z</published>\\n    <title>Multi-model learning by sequential reading of untrimmed videos for\\n  action recognition</title>\\n    <summary>  We propose a new method for learning videos by aggregating multiple models by\\nsequentially extracting video clips from untrimmed video. The proposed method\\nreduces the correlation between clips by feeding clips to multiple models in\\nturn and synchronizes these models through federated learning. Experimental\\nresults show that the proposed method improves the performance compared to the\\nno synchronization.\\n</summary>\\n    <author>\\n      <name>Kodai Kamiya</name>\\n    </author>\\n    <author>\\n      <name>Toru Tamaki</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The International Workshop on Frontiers of Computer Vision\\n  (IW-FCV2024)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2401.14675v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2401.14675v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2402.04953v1</id>\\n    <updated>2024-02-07T15:37:17Z</updated>\\n    <published>2024-02-07T15:37:17Z</published>\\n    <title>4-Dimensional deformation part model for pose estimation using Kalman\\n  filter constraints</title>\\n    <summary>  The main goal of this article is to analyze the effect on pose estimation\\naccuracy when using a Kalman filter added to 4-dimensional deformation part\\nmodel partial solutions. The experiments run with two data sets showing that\\nthis method improves pose estimation accuracy compared with state-of-the-art\\nmethods and that a Kalman filter helps to increase this accuracy.\\n</summary>\\n    <author>\\n      <name>Enrique Martinez-Berti</name>\\n    </author>\\n    <author>\\n      <name>Antonio-Jose Sanchez-Salmeron</name>\\n    </author>\\n    <author>\\n      <name>Carlos Ricolfe-Viala</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2402.04953v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2402.04953v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2402.06212v1</id>\\n    <updated>2024-02-09T06:44:21Z</updated>\\n    <published>2024-02-09T06:44:21Z</published>\\n    <title>Halo Reduction in Display Systems through Smoothed Local Histogram\\n  Equalization and Human Visual System Modeling</title>\\n    <summary>  Halo artifacts significantly impact display quality. We propose a method to\\nreduce halos in Local Histogram Equalization (LHE) algorithms by separately\\naddressing dark and light variants. This approach results in visually natural\\nimages by exploring the relationship between lateral inhibition and halo\\nartifacts in the human visual system.\\n</summary>\\n    <author>\\n      <name>Prasoon Ambalathankandy</name>\\n    </author>\\n    <author>\\n      <name>Yafei Ou</name>\\n    </author>\\n    <author>\\n      <name>Masayuki Ikebe</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.36463/idw.2023.1488</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.36463/idw.2023.1488\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/2402.06212v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2402.06212v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2403.15990v1</id>\\n    <updated>2024-03-24T02:55:45Z</updated>\\n    <published>2024-03-24T02:55:45Z</published>\\n    <title>Mars Spectrometry 2: Gas Chromatography -- Second place solution</title>\\n    <summary>  The Mars Spectrometry 2: Gas Chromatography challenge was sponsored by NASA\\nand run on the DrivenData competition platform in 2022. This report describes\\nthe solution which achieved the second-best score on the competition\\'s test\\ndataset. The solution utilized two-dimensional, image-like representations of\\nthe competition\\'s chromatography data samples. A number of different\\nConvolutional Neural Network models were trained and ensembled for the final\\nsubmission.\\n</summary>\\n    <author>\\n      <name>Dmitry A. Konovalov</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2403.15990v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2403.15990v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2404.00597v1</id>\\n    <updated>2024-03-31T08:08:05Z</updated>\\n    <published>2024-03-31T08:08:05Z</published>\\n    <title>Parameter and Data-Efficient Spectral StyleDCGAN</title>\\n    <summary>  We present a simple, highly parameter, and data-efficient adversarial network\\nfor unconditional face generation. Our method: Spectral Style-DCGAN or SSD\\nutilizes only 6.574 million parameters and 4739 dog faces from the Animal Faces\\nHQ (AFHQ) dataset as training samples while preserving fidelity at low\\nresolutions up to 64x64. Code available at\\nhttps://github.com/Aryan-Garg/StyleDCGAN.\\n</summary>\\n    <author>\\n      <name>Aryan Garg</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Notable ICLR Tiny Paper 2024</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2404.00597v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2404.00597v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2404.10319v1</id>\\n    <updated>2024-04-16T06:59:26Z</updated>\\n    <published>2024-04-16T06:59:26Z</published>\\n    <title>Application of Deep Learning Methods to Processing of Noisy Medical\\n  Video Data</title>\\n    <summary>  Cells count become a challenging problem when the cells move in a continuous\\nstream, and their boundaries are difficult for visual detection. To resolve\\nthis problem we modified the training and decision making processes using\\ncurriculum learning and multi-view predictions techniques, respectively.\\n</summary>\\n    <author>\\n      <name>Danil Afonchikov</name>\\n    </author>\\n    <author>\\n      <name>Elena Kornaeva</name>\\n    </author>\\n    <author>\\n      <name>Irina Makovik</name>\\n    </author>\\n    <author>\\n      <name>Alexey Kornaev</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2404.10319v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2404.10319v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2405.00196v1</id>\\n    <updated>2024-04-30T20:59:53Z</updated>\\n    <published>2024-04-30T20:59:53Z</published>\\n    <title>Synthetic Image Verification in the Era of Generative AI: What Works and\\n  What Isn\\'t There Yet</title>\\n    <summary>  In this work we present an overview of approaches for the detection and\\nattribution of synthetic images and highlight their strengths and weaknesses.\\nWe also point out and discuss hot topics in this field and outline promising\\ndirections for future research.\\n</summary>\\n    <author>\\n      <name>Diangarti Tariang</name>\\n    </author>\\n    <author>\\n      <name>Riccardo Corvi</name>\\n    </author>\\n    <author>\\n      <name>Davide Cozzolino</name>\\n    </author>\\n    <author>\\n      <name>Giovanni Poggi</name>\\n    </author>\\n    <author>\\n      <name>Koki Nagano</name>\\n    </author>\\n    <author>\\n      <name>Luisa Verdoliva</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2405.00196v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2405.00196v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2405.05260v1</id>\\n    <updated>2024-03-18T20:46:35Z</updated>\\n    <published>2024-03-18T20:46:35Z</published>\\n    <title>Financial Table Extraction in Image Documents</title>\\n    <summary>  Table extraction has long been a pervasive problem in financial services.\\nThis is more challenging in the image domain, where content is locked behind\\ncumbersome pixel format. Luckily, advances in deep learning for image\\nsegmentation, OCR, and sequence modeling provides the necessary heavy lifting\\nto achieve impressive results. This paper presents an end-to-end pipeline for\\nidentifying, extracting and transcribing tabular content in image documents,\\nwhile retaining the original spatial relations with high fidelity.\\n</summary>\\n    <author>\\n      <name>William Watson</name>\\n    </author>\\n    <author>\\n      <name>Bo Liu</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1145/3383455.3422520</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1145/3383455.3422520\" rel=\"related\"/>\\n    <link href=\"http://arxiv.org/abs/2405.05260v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2405.05260v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2405.11351v1</id>\\n    <updated>2024-05-18T17:43:50Z</updated>\\n    <published>2024-05-18T17:43:50Z</published>\\n    <title>PlantTracing: Tracing Arabidopsis Thaliana Apex with CenterTrack</title>\\n    <summary>  This work applies an encoder-decoder-based machine learning network to detect\\nand track the motion and growth of the flowering stem apex of Arabidopsis\\nThaliana. Based on the CenterTrack, a machine learning back-end network, we\\ntrained a model based on ten time-lapsed labeled videos and tested against\\nthree videos.\\n</summary>\\n    <author>\\n      <name>Yuanzhe Liu</name>\\n    </author>\\n    <author>\\n      <name>Yixiang Mao</name>\\n    </author>\\n    <author>\\n      <name>Yao Wang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 13 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2405.11351v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2405.11351v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2406.18587v1</id>\\n    <updated>2024-06-06T21:02:51Z</updated>\\n    <published>2024-06-06T21:02:51Z</published>\\n    <title>Nomic Embed Vision: Expanding the Latent Space</title>\\n    <summary>  This technical report describes the training of nomic-embed-vision, a highly\\nperformant, open-code, open-weights image embedding model that shares the same\\nlatent space as nomic-embed-text. Together, nomic-embed-vision and\\nnomic-embed-text form the first unified latent space to achieve high\\nperformance across vision, language, and multimodal tasks.\\n</summary>\\n    <author>\\n      <name>Zach Nussbaum</name>\\n    </author>\\n    <author>\\n      <name>Brandon Duderstadt</name>\\n    </author>\\n    <author>\\n      <name>Andriy Mulyar</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2406.18587v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2406.18587v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2407.04265v1</id>\\n    <updated>2024-07-05T05:38:20Z</updated>\\n    <published>2024-07-05T05:38:20Z</published>\\n    <title>Parametric Curve Segment Extraction by Support Regions</title>\\n    <summary>  We introduce a method to extract curve segments in parametric form from the\\nimage directly using the Laplacian of Gaussian (LoG) filter response. Our\\nsegmentation gives convex and concave curves. To do so, we form curve support\\nregions by grouping pixels of the thresholded filter response. Then, we model\\neach support region boundary by Fourier series and extract the corresponding\\nparametric curve segment.\\n</summary>\\n    <author>\\n      <name>Cem \\xc3\\x9cnsalan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, 5 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2407.04265v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.04265v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2407.04592v1</id>\\n    <updated>2024-07-05T15:40:39Z</updated>\\n    <published>2024-07-05T15:40:39Z</published>\\n    <title>Smell and Emotion: Recognising emotions in smell-related artworks</title>\\n    <summary>  Emotions and smell are underrepresented in digital art history. In this\\nexploratory work, we show that recognising emotions from smell-related artworks\\nis technically feasible but has room for improvement. Using style transfer and\\nhyperparameter optimization we achieve a minor performance boost and open up\\nthe field for future extensions.\\n</summary>\\n    <author>\\n      <name>Vishal Patoliya</name>\\n    </author>\\n    <author>\\n      <name>Mathias Zinnen</name>\\n    </author>\\n    <author>\\n      <name>Andreas Maier</name>\\n    </author>\\n    <author>\\n      <name>Vincent Christlein</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 3 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2407.04592v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.04592v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2407.05312v1</id>\\n    <updated>2024-07-07T09:52:04Z</updated>\\n    <published>2024-07-07T09:52:04Z</published>\\n    <title>An Improved Method for Personalizing Diffusion Models</title>\\n    <summary>  Diffusion models have demonstrated impressive image generation capabilities.\\nPersonalized approaches, such as textual inversion and Dreambooth, enhance\\nmodel individualization using specific images. These methods enable generating\\nimages of specific objects based on diverse textual contexts. Our proposed\\napproach aims to retain the model\\'s original knowledge during new information\\nintegration, resulting in superior outcomes while necessitating less training\\ntime compared to Dreambooth and textual inversion.\\n</summary>\\n    <author>\\n      <name>Yan Zeng</name>\\n    </author>\\n    <author>\\n      <name>Masanori Suganuma</name>\\n    </author>\\n    <author>\\n      <name>Takayuki Okatani</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2407.05312v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.05312v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2407.18290v1</id>\\n    <updated>2024-07-11T02:49:13Z</updated>\\n    <published>2024-07-11T02:49:13Z</published>\\n    <title>Several questions of visual generation in 2024</title>\\n    <summary>  This paper does not propose any new algorithms but instead outlines various\\nproblems in the field of visual generation based on the author\\'s personal\\nunderstanding. The core of these problems lies in how to decompose visual\\nsignals, with all other issues being closely related to this central problem\\nand stemming from unsuitable approaches to signal decomposition. This paper\\naims to draw researchers\\' attention to the significance of Visual Signal\\nDecomposition.\\n</summary>\\n    <author>\\n      <name>Shuyang Gu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 3 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2407.18290v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.18290v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2408.07225v1</id>\\n    <updated>2024-08-01T19:40:55Z</updated>\\n    <published>2024-08-01T19:40:55Z</published>\\n    <title>Longitudinal Evaluation of Child Face Recognition and the Impact of\\n  Underlying Age</title>\\n    <summary>  The need for reliable identification of children in various emerging\\napplications has sparked interest in leveraging child face recognition\\ntechnology. This study introduces a longitudinal approach to enrollment and\\nverification accuracy for child face recognition, focusing on the YFA database\\ncollected by Clarkson University CITeR research group over an 8 year period, at\\n6 month intervals.\\n</summary>\\n    <author>\\n      <name>Surendra Singh</name>\\n    </author>\\n    <author>\\n      <name>Keivan Bahmani</name>\\n    </author>\\n    <author>\\n      <name>Stephanie Schuckers</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2408.07225v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2408.07225v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2408.08529v1</id>\\n    <updated>2024-08-16T04:57:21Z</updated>\\n    <published>2024-08-16T04:57:21Z</published>\\n    <title>Privacy-Preserving Vision Transformer Using Images Encrypted with\\n  Restricted Random Permutation Matrices</title>\\n    <summary>  We propose a novel method for privacy-preserving fine-tuning vision\\ntransformers (ViTs) with encrypted images. Conventional methods using encrypted\\nimages degrade model performance compared with that of using plain images due\\nto the influence of image encryption. In contrast, the proposed encryption\\nmethod using restricted random permutation matrices can provide a higher\\nperformance than the conventional ones.\\n</summary>\\n    <author>\\n      <name>Kouki Horio</name>\\n    </author>\\n    <author>\\n      <name>Kiyoshi Nishikawa</name>\\n    </author>\\n    <author>\\n      <name>Hitoshi Kiya</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 9 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2408.08529v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2408.08529v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2408.15374v2</id>\\n    <updated>2024-11-21T23:51:29Z</updated>\\n    <published>2024-08-27T19:22:06Z</published>\\n    <title>CycleGAN with Better Cycles</title>\\n    <summary>  CycleGAN provides a framework to train image-to-image translation with\\nunpaired datasets using cycle consistency loss [4]. While results are great in\\nmany applications, the pixel level cycle consistency can potentially be\\nproblematic and causes unrealistic images in certain cases. In this project, we\\npropose three simple modifications to cycle consistency, and show that such an\\napproach achieves better results with fewer artifacts.\\n</summary>\\n    <author>\\n      <name>Tongzhou Wang</name>\\n    </author>\\n    <author>\\n      <name>Yihan Lin</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Technical Report 2018</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2408.15374v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2408.15374v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2409.02448v1</id>\\n    <updated>2024-09-04T05:06:34Z</updated>\\n    <published>2024-09-04T05:06:34Z</published>\\n    <title>Detecting Korean Food Using Image using Hierarchical Model</title>\\n    <summary>  A solution was made available for Korean Food lovers who have dietary\\nrestrictions to identify the Korean food before consuming. Just by uploading a\\nclear photo of the dish, people can get to know what they are eating. Image\\nprocessing techniques together with machine learning helped to come up with\\nthis solution.\\n</summary>\\n    <author>\\n      <name>Hoang Khanh Lam</name>\\n    </author>\\n    <author>\\n      <name>Kahandakanaththage Maduni Pramuditha Perera</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2409.02448v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2409.02448v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2409.15028v1</id>\\n    <updated>2024-09-23T13:55:16Z</updated>\\n    <published>2024-09-23T13:55:16Z</published>\\n    <title>Region Mixup</title>\\n    <summary>  This paper introduces a simple extension of mixup (Zhang et al., 2018) data\\naugmentation to enhance generalization in visual recognition tasks. Unlike the\\nvanilla mixup method, which blends entire images, our approach focuses on\\ncombining regions from multiple images.\\n</summary>\\n    <author>\\n      <name>Saptarshi Saha</name>\\n    </author>\\n    <author>\\n      <name>Utpal Garain</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Published as a Tiny Paper at ICLR 2024</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The Second Tiny Papers Track at ICLR 2024</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2409.15028v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2409.15028v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2409.15997v2</id>\\n    <updated>2024-09-26T21:56:01Z</updated>\\n    <published>2024-09-24T11:57:12Z</published>\\n    <title>Improvements to SDXL in NovelAI Diffusion V3</title>\\n    <summary>  In this technical report, we document the changes we made to SDXL in the\\nprocess of training NovelAI Diffusion V3, our state of the art anime image\\ngeneration model.\\n</summary>\\n    <author>\\n      <name>Juan Ossa</name>\\n    </author>\\n    <author>\\n      <name>Eren Do\\xc4\\x9fan</name>\\n    </author>\\n    <author>\\n      <name>Alex Birch</name>\\n    </author>\\n    <author>\\n      <name>F. Johnson</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">14 pages, 8 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2409.15997v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2409.15997v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2410.05680v1</id>\\n    <updated>2024-10-08T04:40:16Z</updated>\\n    <published>2024-10-08T04:40:16Z</published>\\n    <title>Convolutional neural networks applied to modification of images</title>\\n    <summary>  The reader will learn how digital images are edited using linear algebra and\\ncalculus. Starting from the concept of filter towards machine learning\\ntechniques such as convolutional neural networks.\\n</summary>\\n    <author>\\n      <name>Carlos I. Aguirre-Velez</name>\\n    </author>\\n    <author>\\n      <name>Jose Antonio Arciniega-Nevarez</name>\\n    </author>\\n    <author>\\n      <name>Eric Dolores-Cuenca</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1007/978-3-030-93954-0_5-1</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1007/978-3-030-93954-0_5-1\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">23 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">In: Sriraman, B. (eds) Handbook of Visual, Experimental and\\n  Computational Mathematics . Springer, Cham. (2023)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2410.05680v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2410.05680v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"A.1; G.m\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2410.07125v1</id>\\n    <updated>2024-09-20T21:41:57Z</updated>\\n    <published>2024-09-20T21:41:57Z</published>\\n    <title>A Simplified Positional Cell Type Visualization using Spatially\\n  Aggregated Clusters</title>\\n    <summary>  We introduce a novel method for overlaying cell type proportion data onto\\ntissue images. This approach preserves spatial context while avoiding visual\\nclutter or excessively obscuring the underlying slide. Our proposed technique\\ninvolves clustering the data and aggregating neighboring points of the same\\ncluster into polygons.\\n</summary>\\n    <author>\\n      <name>Lee Mason</name>\\n    </author>\\n    <author>\\n      <name>Jonas Almeida</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">For the Bio+MedVis 2024 redesign challenge</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2410.07125v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2410.07125v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2410.13871v2</id>\\n    <updated>2024-11-05T09:07:14Z</updated>\\n    <published>2024-10-02T12:14:31Z</published>\\n    <title>Explaining an image classifier with a generative model conditioned by\\n  uncertainty</title>\\n    <summary>  We propose to condition a generative model by a given image classifier\\nuncertainty in order to analyze and explain its behavior. Preliminary\\nexperiments on synthetic data and a corrupted version of MNIST dataset\\nillustrate the idea.\\n</summary>\\n    <author>\\n      <name>Adrien LeCoz</name>\\n    </author>\\n    <author>\\n      <name>St\\xc3\\xa9phane Herbin</name>\\n    </author>\\n    <author>\\n      <name>Faouzi Adjed</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Uncertainty meets Explainability | Workshop and Tutorial @\\n  ECML-PKDD 2023, Sep 2023, Torino, Italy</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/2410.13871v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2410.13871v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2410.14958v1</id>\\n    <updated>2024-10-19T03:17:29Z</updated>\\n    <published>2024-10-19T03:17:29Z</published>\\n    <title>Neural Radiance Field Image Refinement through End-to-End Sampling Point\\n  Optimization</title>\\n    <summary>  Neural Radiance Field (NeRF), capable of synthesizing high-quality novel\\nviewpoint images, suffers from issues like artifact occurrence due to its fixed\\nsampling points during rendering. This study proposes a method that optimizes\\nsampling points to reduce artifacts and produce more detailed images.\\n</summary>\\n    <author>\\n      <name>Kazuhiro Ohta</name>\\n    </author>\\n    <author>\\n      <name>Satoshi Ono</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2410.14958v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2410.14958v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2410.18051v1</id>\\n    <updated>2024-10-23T17:25:26Z</updated>\\n    <published>2024-10-23T17:25:26Z</published>\\n    <title>Real time anomalies detection on video</title>\\n    <summary>  Nowadays, many places use security cameras. Unfortunately, when an incident\\noccurs, these technologies are used to show past events. So it can be\\nconsidered as a deterrence tool than a detection tool. In this article, we will\\npropose a deep learning approach trying to solve this problematic. This\\napproach uses convolutional models (CNN) to extract relevant characteristics\\nlinked to the video images, theses characteristics will form times series to be\\nanalyzed by LSTM / GRU models.\\n</summary>\\n    <author>\\n      <name>Fabien Poirier</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2410.18051v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2410.18051v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2410.22777v1</id>\\n    <updated>2024-10-30T07:46:06Z</updated>\\n    <published>2024-10-30T07:46:06Z</published>\\n    <title>Bregman implementation of Meyer\\'s $G-$norm for cartoon + textures\\n  decomposition</title>\\n    <summary>  In this paper, we design a very simple algorithm based on Split Bregman\\niterations to numerically solve the cartoon + textures decomposition model of\\nMeyer. This results in a significant gain in speed compared to Chambolle\\'s\\nnonlinear projectors.\\n</summary>\\n    <author>\\n      <name>Jerome Gilles</name>\\n    </author>\\n    <author>\\n      <name>Stanley Osher</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2410.22777v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2410.22777v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.FA\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2411.05603v1</id>\\n    <updated>2024-11-08T14:47:28Z</updated>\\n    <published>2024-11-08T14:47:28Z</published>\\n    <title>Efficient Audio-Visual Fusion for Video Classification</title>\\n    <summary>  We present Attend-Fusion, a novel and efficient approach for audio-visual\\nfusion in video classification tasks. Our method addresses the challenge of\\nexploiting both audio and visual modalities while maintaining a compact model\\narchitecture. Through extensive experiments on the YouTube-8M dataset, we\\ndemonstrate that our Attend-Fusion achieves competitive performance with\\nsignificantly reduced model complexity compared to larger baseline models.\\n</summary>\\n    <author>\\n      <name>Mahrukh Awan</name>\\n    </author>\\n    <author>\\n      <name>Asmar Nadeem</name>\\n    </author>\\n    <author>\\n      <name>Armin Mustafa</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CVMP Short Paper</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2411.05603v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2411.05603v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2411.08878v1</id>\\n    <updated>2024-11-13T18:55:10Z</updated>\\n    <published>2024-11-13T18:55:10Z</published>\\n    <title>A Short Note on Evaluating RepNet for Temporal Repetition Counting in\\n  Videos</title>\\n    <summary>  We discuss some consistent issues on how RepNet has been evaluated in various\\npapers. As a way to mitigate these issues, we report RepNet performance results\\non different datasets, and release evaluation code and the RepNet checkpoint to\\nobtain these results. Code URL:\\nhttps://github.com/google-research/google-research/blob/master/repnet/\\n</summary>\\n    <author>\\n      <name>Debidatta Dwibedi</name>\\n    </author>\\n    <author>\\n      <name>Yusuf Aytar</name>\\n    </author>\\n    <author>\\n      <name>Jonathan Tompson</name>\\n    </author>\\n    <author>\\n      <name>Pierre Sermanet</name>\\n    </author>\\n    <author>\\n      <name>Andrew Zisserman</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2411.08878v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2411.08878v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2411.10705v1</id>\\n    <updated>2024-11-16T05:17:27Z</updated>\\n    <published>2024-11-16T05:17:27Z</published>\\n    <title>Poster: Reliable 3D Reconstruction for Ad-hoc Edge Implementations</title>\\n    <summary>  Ad-hoc edge deployments to support real-time complex video processing\\napplications such as, multi-view 3D reconstruction often suffer from\\nspatio-temporal system disruptions that greatly impact reconstruction quality.\\nIn this poster paper, we present a novel portfolio theory-inspired edge\\nresource management strategy to ensure reliable multi-view 3D reconstruction by\\naccounting for possible system disruptions.\\n</summary>\\n    <author>\\n      <name>Md Nurul Absur</name>\\n    </author>\\n    <author>\\n      <name>Swastik Brahma</name>\\n    </author>\\n    <author>\\n      <name>Saptarshi Debroy</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 Pages, 2 figures, IEEE SEC 2024</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2411.10705v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2411.10705v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2411.12331v1</id>\\n    <updated>2024-11-19T08:32:17Z</updated>\\n    <published>2024-11-19T08:32:17Z</published>\\n    <title>Accelerating UMAP for Large-Scale Datasets Through Spectral Coarsening</title>\\n    <summary>  This paper introduces an innovative approach to dramatically accelerate UMAP\\nusing spectral data compression.The proposed method significantly reduces the\\nsize of the dataset, preserving its essential manifold structure through an\\nadvanced spectral compression technique. This allows UMAP to perform much\\nfaster while maintaining the quality of its embeddings. Experiments on\\nreal-world datasets, such as USPS, demonstrate the method\\'s ability to achieve\\nsubstantial data reduction without compromising embedding fidelity.\\n</summary>\\n    <author>\\n      <name>Yongyu Wang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2411.12331v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2411.12331v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2411.18314v1</id>\\n    <updated>2024-11-27T13:10:18Z</updated>\\n    <published>2024-11-27T13:10:18Z</published>\\n    <title>Real-time Video Target Tracking Algorithm Utilizing Convolutional Neural\\n  Networks (CNN)</title>\\n    <summary>  Thispaperaimstoresearchandimplementa\\nreal-timevideotargettrackingalgorithmbasedon\\nConvolutionalNeuralNetworks(CNN),enhancingthe\\naccuracyandrobustnessoftargettrackingincomplex\\nscenarios.Addressingthelimitationsoftraditionaltracking\\nalgorithmsinhandlingissuessuchastargetocclusion,morphologicalchanges,andbackgroundinterference,our\\napproachintegratestargetdetectionandtrackingstrategies.It\\ncontinuouslyupdatesthetargetmodelthroughanonline\\nlearningmechanismtoadapttochangesinthetarget\\'s\\nappearance.Experimentalresultsdemonstratethat,when\\ndealingwithsituationsinvolvingrapidmotion,partial\\nocclusion,andcomplexbackgrounds,theproposedalgorithm\\nexhibitshighertrackingsuccessratesandlowerfailurerates\\ncomparedtoseveralmainstreamtrackingalgorithms.This\\nstudysuccessfullyappliesCNNtoreal-timevideotarget\\ntracking,improvingtheaccuracyandstabilityofthetracking\\nalgorithmwhilemaintaininghighprocessingspeeds,thus\\nmeetingthedemandsofreal-timeapplications.Thisalgorithm\\nisexpectedtoprovidenewsolutionsfortargettrackingtasksin\\nvideosurveillanceandintelligenttransportationdomains.\\n</summary>\\n    <author>\\n      <name>Chaoyi Tan</name>\\n    </author>\\n    <author>\\n      <name>Xiangtian Li</name>\\n    </author>\\n    <author>\\n      <name>Xiaobo Wang</name>\\n    </author>\\n    <author>\\n      <name>Zhen Qi</name>\\n    </author>\\n    <author>\\n      <name>Ao Xiang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2411.18314v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2411.18314v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2412.17517v1</id>\\n    <updated>2024-12-23T12:30:28Z</updated>\\n    <published>2024-12-23T12:30:28Z</published>\\n    <title>Dataset for Real-World Human Action Detection Using FMCW mmWave Radar</title>\\n    <summary>  Human action detection using privacy-preserving mmWave radar sensors is\\nstudied for its applications in healthcare and home automation. Unlike existing\\nresearch, limited to simulations in controlled environments, we present a\\nreal-world mmWave radar dataset with baseline results for human action\\ndetection.\\n</summary>\\n    <author>\\n      <name>Dylan jayabahu</name>\\n    </author>\\n    <author>\\n      <name>Parthipan Siva</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">To be published in JCVIS (proceedings of 10th Annual Conference on\\n  Vision and Intelligent Systems)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2412.17517v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.17517v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2503.00400v1</id>\\n    <updated>2025-03-01T08:29:31Z</updated>\\n    <published>2025-03-01T08:29:31Z</published>\\n    <title>Inteval Analysis for two spherical functions arising from robust\\n  Perspective-n-Lines problem</title>\\n    <summary>  This report presents a comprehensive interval analysis of two spherical\\nfunctions derived from the robust Perspective-n-Lines (PnL) problem. The study\\nis motivated by the application of a dimension-reduction technique to achieve\\nglobal solutions for the robust PnL problem. We establish rigorous theoretical\\nresults, supported by detailed proofs, and validate our findings through\\nextensive numerical simulations.\\n</summary>\\n    <author>\\n      <name>Xiang Zheng</name>\\n    </author>\\n    <author>\\n      <name>Haodong Jiang</name>\\n    </author>\\n    <author>\\n      <name>Junfeng Wu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2503.00400v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2503.00400v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2504.06099v1</id>\\n    <updated>2025-04-08T14:41:42Z</updated>\\n    <published>2025-04-08T14:41:42Z</published>\\n    <title>Towards Varroa destructor mite detection using a narrow spectra\\n  illumination</title>\\n    <summary>  This paper focuses on the development and modification of a beehive\\nmonitoring device and Varroa destructor detection on the bees with the help of\\nhyperspectral imagery while utilizing a U-net, semantic segmentation\\narchitecture, and conventional computer vision methods. The main objectives\\nwere to collect a dataset of bees and mites, and propose the computer vision\\nmodel which can achieve the detection between bees and mites.\\n</summary>\\n    <author>\\n      <name>Samuel Bielik</name>\\n    </author>\\n    <author>\\n      <name>Simon Bilik</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2504.06099v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2504.06099v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2504.17619v1</id>\\n    <updated>2025-04-24T14:43:55Z</updated>\\n    <published>2025-04-24T14:43:55Z</published>\\n    <title>Enhancing CNNs robustness to occlusions with bioinspired filters for\\n  border completion</title>\\n    <summary>  We exploit the mathematical modeling of the visual cortex mechanism for\\nborder completion to define custom filters for CNNs. We see a consistent\\nimprovement in performance, particularly in accuracy, when our modified LeNet 5\\nis tested with occluded MNIST images.\\n</summary>\\n    <author>\\n      <name>Catarina P. Coutinho</name>\\n    </author>\\n    <author>\\n      <name>Aneeqa Merhab</name>\\n    </author>\\n    <author>\\n      <name>Janko Petkovic</name>\\n    </author>\\n    <author>\\n      <name>Ferdinando Zanchetta</name>\\n    </author>\\n    <author>\\n      <name>Rita Fioresi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Submitted to the 7th International Conference on Geometric Science of\\n  Information</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2504.17619v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2504.17619v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2505.03204v2</id>\\n    <updated>2025-05-07T04:09:12Z</updated>\\n    <published>2025-05-06T05:38:17Z</published>\\n    <title>DCS-ST for Classification of Breast Cancer Histopathology Images with\\n  Limited Annotations</title>\\n    <summary>  Deep learning methods have shown promise in classifying breast cancer\\nhistopathology images, but their performance often declines with limited\\nannotated data, a critical challenge in medical imaging due to the high cost\\nand expertise required for annotations.\\n</summary>\\n    <author>\\n      <name>Liu Suxing</name>\\n    </author>\\n    <author>\\n      <name>Byungwon Min</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2505.03204v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2505.03204v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2505.06389v1</id>\\n    <updated>2025-05-09T19:33:35Z</updated>\\n    <published>2025-05-09T19:33:35Z</published>\\n    <title>Deep Learning-Based Robust Optical Guidance for Hypersonic Platforms</title>\\n    <summary>  Sensor-based guidance is required for long-range platforms. To bypass the\\nstructural limitation of classical registration on reference image framework,\\nwe offer in this paper to encode a stack of images of the scene into a deep\\nnetwork. Relying on a stack is showed to be relevant on bimodal scene (e.g.\\nwhen the scene can or can not be snowy).\\n</summary>\\n    <author>\\n      <name>Adrien Chan-Hon-Tong</name>\\n    </author>\\n    <author>\\n      <name>Aur\\xc3\\xa9lien Plyer</name>\\n    </author>\\n    <author>\\n      <name>Baptiste Cadalen</name>\\n    </author>\\n    <author>\\n      <name>Laurent Serre</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2505.06389v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2505.06389v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2505.17808v1</id>\\n    <updated>2025-05-23T12:25:13Z</updated>\\n    <published>2025-05-23T12:25:13Z</published>\\n    <title>An Attention Infused Deep Learning System with Grad-CAM Visualization\\n  for Early Screening of Glaucoma</title>\\n    <summary>  This research work reveals the eye opening wisdom of the hybrid labyrinthine\\ndeep learning models synergy born out of combining a trailblazing convolutional\\nneural network with a disruptive Vision Transformer, both intertwined together\\nwith a radical Cross Attention module. Here, two high yielding datasets for\\nartificial intelligence models in detecting glaucoma, namely ACRIMA and\\nDrishti, are utilized.\\n</summary>\\n    <author>\\n      <name>Ramanathan Swaminathan</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages in general IEEE format, 8 figures, 4 tables, pdflatex</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2505.17808v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2505.17808v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2506.06748v1</id>\\n    <updated>2025-06-07T10:33:16Z</updated>\\n    <published>2025-06-07T10:33:16Z</published>\\n    <title>THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised\\n  Video Object Segmentation</title>\\n    <summary>  In this report, we describe our approach to egocentric video object\\nsegmentation. Our method combines large-scale visual pretraining from SAM2 with\\ndepth-based geometric cues to handle complex scenes and long-term tracking. By\\nintegrating these signals in a unified framework, we achieve strong\\nsegmentation performance. On the VISOR test set, our method reaches a J&amp;F score\\nof 90.1%.\\n</summary>\\n    <author>\\n      <name>Mingqi Gao</name>\\n    </author>\\n    <author>\\n      <name>Haoran Duan</name>\\n    </author>\\n    <author>\\n      <name>Tianlu Zhang</name>\\n    </author>\\n    <author>\\n      <name>Jungong Han</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2506.06748v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2506.06748v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2506.13043v1</id>\\n    <updated>2025-06-16T02:16:17Z</updated>\\n    <published>2025-06-16T02:16:17Z</published>\\n    <title>ViewPCL: a point cloud based active learning method for multi-view\\n  segmentation</title>\\n    <summary>  We propose a novel active learning framework for multi-view semantic\\nsegmentation. This framework relies on a new score that measures the\\ndiscrepancy between point cloud distributions generated from the extra\\ngeometrical information derived from the model\\'s prediction across different\\nviews. Our approach results in a data efficient and explainable active learning\\nmethod. The source code is available at https://github.com/chilai235/viewpclAL.\\n</summary>\\n    <author>\\n      <name>Christian Hilaire</name>\\n    </author>\\n    <author>\\n      <name>Sima Didari</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2506.13043v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2506.13043v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2506.13458v1</id>\\n    <updated>2025-06-16T13:15:02Z</updated>\\n    <published>2025-06-16T13:15:02Z</published>\\n    <title>Leveraging Vision-Language Pre-training for Human Activity Recognition\\n  in Still Images</title>\\n    <summary>  Recognising human activity in a single photo enables indexing, safety and\\nassistive applications, yet lacks motion cues. Using 285 MSCOCO images labelled\\nas walking, running, sitting, and standing, scratch CNNs scored 41% accuracy.\\nFine-tuning multimodal CLIP raised this to 76%, demonstrating that contrastive\\nvision-language pre-training decisively improves still-image action recognition\\nin real-world deployments.\\n</summary>\\n    <author>\\n      <name>Cristina Mahanta</name>\\n    </author>\\n    <author>\\n      <name>Gagan Bhatia</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2506.13458v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2506.13458v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2508.06537v1</id>\\n    <updated>2025-08-04T10:03:40Z</updated>\\n    <published>2025-08-04T10:03:40Z</published>\\n    <title>Benchmarking Deep Learning-Based Object Detection Models on Feature\\n  Deficient Astrophotography Imagery Dataset</title>\\n    <summary>  Object detection models are typically trained on datasets like ImageNet,\\nCOCO, and PASCAL VOC, which focus on everyday objects. However, these lack\\nsignal sparsity found in non-commercial domains. MobilTelesco, a\\nsmartphone-based astrophotography dataset, addresses this by providing sparse\\nnight-sky images. We benchmark several detection models on it, highlighting\\nchallenges under feature-deficient conditions.\\n</summary>\\n    <author>\\n      <name>Shantanusinh Parmar</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2508.06537v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2508.06537v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"astro-ph.IM\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2508.17472v1</id>\\n    <updated>2025-08-24T17:59:38Z</updated>\\n    <published>2025-08-24T17:59:38Z</published>\\n    <title>T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image\\n  Generation</title>\\n    <summary>  We propose T2I-ReasonBench, a benchmark evaluating reasoning capabilities of\\ntext-to-image (T2I) models. It consists of four dimensions: Idiom\\nInterpretation, Textual Image Design, Entity-Reasoning and\\nScientific-Reasoning. We propose a two-stage evaluation protocol to assess the\\nreasoning accuracy and image quality. We benchmark various T2I generation\\nmodels, and provide comprehensive analysis on their performances.\\n</summary>\\n    <author>\\n      <name>Kaiyue Sun</name>\\n    </author>\\n    <author>\\n      <name>Rongyao Fang</name>\\n    </author>\\n    <author>\\n      <name>Chengqi Duan</name>\\n    </author>\\n    <author>\\n      <name>Xian Liu</name>\\n    </author>\\n    <author>\\n      <name>Xihui Liu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Code: https://github.com/KaiyueSun98/T2I-ReasonBench</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2508.17472v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2508.17472v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0001025v1</id>\\n    <updated>2000-01-28T14:23:18Z</updated>\\n    <published>2000-01-28T14:23:18Z</published>\\n    <title>Computational Geometry Column 38</title>\\n    <summary>  Recent results on curve reconstruction are described.\\n</summary>\\n    <author>\\n      <name>Joseph O\\'Rourke</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 1 figure, 18 refs</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0001025v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0001025v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"F.2.2; I.5.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1301.3590v1</id>\\n    <updated>2013-01-16T05:20:01Z</updated>\\n    <published>2013-01-16T05:20:01Z</published>\\n    <title>Tree structured sparse coding on cubes</title>\\n    <summary>  A brief description of tree structured sparse coding on the binary cube.\\n</summary>\\n    <author>\\n      <name>Arthur Szlam</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1301.3590v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1301.3590v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1607.04311v1</id>\\n    <updated>2016-07-14T20:44:27Z</updated>\\n    <published>2016-07-14T20:44:27Z</published>\\n    <title>Defensive Distillation is Not Robust to Adversarial Examples</title>\\n    <summary>  We show that defensive distillation is not secure: it is no more resistant to\\ntargeted misclassification attacks than unprotected neural networks.\\n</summary>\\n    <author>\\n      <name>Nicholas Carlini</name>\\n    </author>\\n    <author>\\n      <name>David Wagner</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1607.04311v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1607.04311v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1701.05549v1</id>\\n    <updated>2017-01-19T18:43:56Z</updated>\\n    <published>2017-01-19T18:43:56Z</published>\\n    <title>Deep Neural Networks - A Brief History</title>\\n    <summary>  Introduction to deep neural networks and their history.\\n</summary>\\n    <author>\\n      <name>Krzysztof J. Cios</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">14 pages, 14 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1701.05549v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1701.05549v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2309.15477v1</id>\\n    <updated>2023-09-27T08:18:04Z</updated>\\n    <published>2023-09-27T08:18:04Z</published>\\n    <title>A Tutorial on Uniform B-Spline</title>\\n    <summary>  This document facilitates understanding of core concepts about uniform\\nB-spline and its matrix representation.\\n</summary>\\n    <author>\\n      <name>Yi Zhou</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2309.15477v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2309.15477v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0004012v1</id>\\n    <updated>2000-04-21T17:32:29Z</updated>\\n    <published>2000-04-21T17:32:29Z</published>\\n    <title>Assisted Video Sequences Indexing : Motion Analysis Based on Interest\\n  Points</title>\\n    <summary>  This work deals with content-based video indexing. Our viewpoint is\\nsemi-automatic analysis of compressed video. We consider the possible\\napplications of motion analysis and moving object detection : assisting moving\\nobject indexing, summarising videos, and allowing image and motion queries. We\\npropose an approach based on interest points. As first results, we test and\\ncompare the stability of different types of interest point detectors in\\ncompressed sequences.\\n</summary>\\n    <author>\\n      <name>Emmanuel Etievent</name>\\n    </author>\\n    <author>\\n      <name>Frank Lebourgeois</name>\\n    </author>\\n    <author>\\n      <name>Jean-Michel Jolion</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">HTML, 8 pages, 6 figures, http://rfv.insa-lyon.fr/~etievent/</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Iciap 99, Venezia, 27-29 sept., 1059-1062</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0004012v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0004012v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8; I.4.9\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0006047v1</id>\\n    <updated>2000-06-30T22:17:42Z</updated>\\n    <published>2000-06-30T22:17:42Z</published>\\n    <title>Geometric Morphology of Granular Materials</title>\\n    <summary>  We present a new method to transform the spectral pixel information of a\\nmicrograph into an affine geometric description, which allows us to analyze the\\nmorphology of granular materials. We use spectral and pulse-coupled neural\\nnetwork based segmentation techniques to generate blobs, and a newly developed\\nalgorithm to extract dilated contours. A constrained Delaunay tesselation of\\nthe contour points results in a triangular mesh. This mesh is the basic\\ningredient of the Chodal Axis Transform, which provides a morphological\\ndecomposition of shapes. Such decomposition allows for grain separation and the\\nefficient computation of the statistical features of granular materials.\\n</summary>\\n    <author>\\n      <name>B. R. Schlei</name>\\n    </author>\\n    <author>\\n      <name>L. Prasad</name>\\n    </author>\\n    <author>\\n      <name>A. N. Skourikhine</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1117/12.404821</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1117/12.404821\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 9 figures. For more information visit\\n  http://www.nis.lanl.gov/~bschlei/labvis/index.html</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0006047v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0006047v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10;I.4.6;I.4.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0109116v1</id>\\n    <updated>2001-09-26T22:14:40Z</updated>\\n    <published>2001-09-26T22:14:40Z</published>\\n    <title>Digital Color Imaging</title>\\n    <summary>  This paper surveys current technology and research in the area of digital\\ncolor imaging. In order to establish the background and lay down terminology,\\nfundamental concepts of color perception and measurement are first presented\\nus-ing vector-space notation and terminology. Present-day color recording and\\nreproduction systems are reviewed along with the common mathematical models\\nused for representing these devices. Algorithms for processing color images for\\ndisplay and communication are surveyed, and a forecast of research trends is\\nattempted. An extensive bibliography is provided.\\n</summary>\\n    <author>\\n      <name>Gaurav Sharma</name>\\n    </author>\\n    <author>\\n      <name>H. Joel Trussell</name>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/83.597268</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/83.597268\" rel=\"related\"/>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Trans. Image Proc., vol. 6, no. 7, pp. 901-932, Jul. 1997</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0109116v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0109116v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"A.1;I.4,I.3.3,I.2.10;I.3.7;B.4.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0201019v1</id>\\n    <updated>2002-01-22T21:00:35Z</updated>\\n    <published>2002-01-22T21:00:35Z</published>\\n    <title>Structure from Motion: Theoretical Foundations of a Novel Approach Using\\n  Custom Built Invariants</title>\\n    <summary>  We rephrase the problem of 3D reconstruction from images in terms of\\nintersections of projections of orbits of custom built Lie groups actions. We\\nthen use an algorithmic method based on moving frames \"a la Fels-Olver\" to\\nobtain a fundamental set of invariants of these groups actions. The invariants\\nare used to define a set of equations to be solved by the points of the 3D\\nobject, providing a new technique for recovering 3D structure from motion.\\n</summary>\\n    <author>\\n      <name>Pierre-Louis Bazin</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Brown University</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Mireille Boutin</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Brown University</arxiv:affiliation>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0201019v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0201019v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"math.DG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8;I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0303015v1</id>\\n    <updated>2003-03-18T21:30:36Z</updated>\\n    <published>2003-03-18T21:30:36Z</published>\\n    <title>Statistical efficiency of curve fitting algorithms</title>\\n    <summary>  We study the problem of fitting parametrized curves to noisy data. Under\\ncertain assumptions (known as Cartesian and radial functional models), we\\nderive asymptotic expressions for the bias and the covariance matrix of the\\nparameter estimates. We also extend Kanatani\\'s version of the Cramer-Rao lower\\nbound, which he proved for unbiased estimates only, to more general estimates\\nthat include many popular algorithms (most notably, the orthogonal least\\nsquares and algebraic fits). We then show that the gradient-weighted algebraic\\nfit is statistically efficient and describe all other statistically efficient\\nalgebraic fits.\\n</summary>\\n    <author>\\n      <name>N. Chernov</name>\\n    </author>\\n    <author>\\n      <name>C. Lesort</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">17 pages, 3 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0303015v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0303015v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8;I.5.1;I.2.10;G.3;G.1.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0303024v1</id>\\n    <updated>2003-03-24T02:36:21Z</updated>\\n    <published>2003-03-24T02:36:21Z</published>\\n    <title>Differential Methods in Catadioptric Sensor Design with Applications to\\n  Panoramic Imaging</title>\\n    <summary>  We discuss design techniques for catadioptric sensors that realize given\\nprojections. In general, these problems do not have solutions, but approximate\\nsolutions may often be found that are visually acceptable. There are several\\nmethods to approach this problem, but here we focus on what we call the\\n``vector field approach\\'\\'. An application is given where a true panoramic\\nmirror is derived, i.e. a mirror that yields a cylindrical projection to the\\nviewer without any digital unwarping.\\n</summary>\\n    <author>\\n      <name>R. Andrew Hicks</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 7 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0303024v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0303024v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.9\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0307046v1</id>\\n    <updated>2003-07-20T05:18:59Z</updated>\\n    <published>2003-07-20T05:18:59Z</published>\\n    <title>A New Analytical Radial Distortion Model for Camera Calibration</title>\\n    <summary>  Common approach to radial distortion is by the means of polynomial\\napproximation, which introduces distortion-specific parameters into the camera\\nmodel and requires estimation of these distortion parameters. The task of\\nestimating radial distortion is to find a radial distortion model that allows\\neasy undistortion as well as satisfactory accuracy. This paper presents a new\\nradial distortion model with an easy analytical undistortion formula, which\\nalso belongs to the polynomial approximation category. Experimental results are\\npresented to show that with this radial distortion model, satisfactory accuracy\\nis achieved.\\n</summary>\\n    <author>\\n      <name>Lili Ma</name>\\n    </author>\\n    <author>\\n      <name>YangQuan Chen</name>\\n    </author>\\n    <author>\\n      <name>Kevin L. Moore</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2 Postscript figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0307046v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307046v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0307047v1</id>\\n    <updated>2003-07-20T05:54:42Z</updated>\\n    <published>2003-07-20T05:54:42Z</published>\\n    <title>Rational Radial Distortion Models with Analytical Undistortion Formulae</title>\\n    <summary>  The common approach to radial distortion is by the means of polynomial\\napproximation, which introduces distortion-specific parameters into the camera\\nmodel and requires estimation of these distortion parameters. The task of\\nestimating radial distortion is to find a radial distortion model that allows\\neasy undistortion as well as satisfactory accuracy. This paper presents a new\\nclass of rational radial distortion models with easy analytical undistortion\\nformulae. Experimental results are presented to show that with this class of\\nrational radial distortion models, satisfactory and comparable accuracy is\\nachieved.\\n</summary>\\n    <author>\\n      <name>Lili Ma</name>\\n    </author>\\n    <author>\\n      <name>YangQuan Chen</name>\\n    </author>\\n    <author>\\n      <name>Kevin L. Moore</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0307047v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307047v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0307072v1</id>\\n    <updated>2003-07-31T19:33:48Z</updated>\\n    <published>2003-07-31T19:33:48Z</published>\\n    <title>Camera Calibration: a USU Implementation</title>\\n    <summary>  The task of camera calibration is to estimate the intrinsic and extrinsic\\nparameters of a camera model. Though there are some restricted techniques to\\ninfer the 3-D information about the scene from uncalibrated cameras, effective\\ncamera calibration procedures will open up the possibility of using a wide\\nrange of existing algorithms for 3-D reconstruction and recognition.\\n  The applications of camera calibration include vision-based metrology, robust\\nvisual platooning and visual docking of mobile robots where the depth\\ninformation is important.\\n</summary>\\n    <author>\\n      <name>Lili Ma</name>\\n    </author>\\n    <author>\\n      <name>YangQuan Chen</name>\\n    </author>\\n    <author>\\n      <name>Kevin L. Moore</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">39 pages, 19 eps figures, source codes are in the codes.m and\\n  corners.dat</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0307072v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307072v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0308037v1</id>\\n    <updated>2003-08-22T10:31:53Z</updated>\\n    <published>2003-08-22T10:31:53Z</published>\\n    <title>Distributed and Parallel Net Imaging</title>\\n    <summary>  A very complex vision system is developed to detect luminosity variations\\nconnected with the discovery of new planets in the Universe. The traditional\\nimaging system can not manage a so large load. A private net is implemented to\\nperform an automatic vision and decision architecture. It lets to carry out an\\non-line discrimination of interesting events by using two levels of triggers.\\nThis system can even manage many Tbytes of data per day. The architecture\\navails itself of a distributed parallel network system based on a maximum of\\n256 standard workstations with Microsoft Window as OS.\\n</summary>\\n    <author>\\n      <name>G. Iovane</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 8 figures, Procedding of NIDays 2003 (sponsored by National\\n  Instruments), Rome 2003. Winner (2nd classified) of the price \"Best\\n  Application of Measurement and Automation</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0308037v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0308037v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"astro-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4,I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0308038v1</id>\\n    <updated>2003-08-22T18:47:33Z</updated>\\n    <published>2003-08-22T18:47:33Z</published>\\n    <title>Image Analysis in Astronomy for very large vision machine</title>\\n    <summary>  It is developed a very complex system (hardware/software) to detect\\nluminosity variations connected with the discovery of new planets outside the\\nSolar System. Traditional imaging approaches are very demanding in terms of\\ncomputing time; then, the implementation of an automatic vision and decision\\nsoftware architecture is presented. It allows to perform an on-line\\ndiscrimination of interesting events by using two levels of triggers. A\\nfundamental challenge was to work with very large CCD camera (even 16k*16k\\npixels) in line with very large telescopes. Then, the architecture can use a\\ndistributed parallel network system based on a maximum of 256 standard\\nworkstations.\\n</summary>\\n    <author>\\n      <name>G. Iovane</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 9 figures, Proceeding of NIWEEK 2002 (sponsored by National\\n  Instruments), Austin (Usa), 2002</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0308038v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0308038v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"astro-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4,I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0311012v1</id>\\n    <updated>2003-11-12T19:15:41Z</updated>\\n    <published>2003-11-12T19:15:41Z</published>\\n    <title>A rigorous definition of axial lines: ridges on isovist fields</title>\\n    <summary>  We suggest that \\'axial lines\\' defined by (Hillier and Hanson, 1984) as lines\\nof uninterrupted movement within urban streetscapes or buildings, appear as\\nridges in isovist fields (Benedikt, 1979). These are formed from the maximum\\ndiametric lengths of the individual isovists, sometimes called viewsheds, that\\nmake up these fields (Batty and Rana, 2004). We present an image processing\\ntechnique for the identification of lines from ridges, discuss current\\nstrengths and weaknesses of the method, and show how it can be implemented\\neasily and effectively.\\n</summary>\\n    <author>\\n      <name>Rui Carvalho</name>\\n    </author>\\n    <author>\\n      <name>Michael Batty</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">18 pages, 5 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0311012v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0311012v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I2.10; I.4.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0402020v1</id>\\n    <updated>2004-02-11T16:34:16Z</updated>\\n    <published>2004-02-11T16:34:16Z</published>\\n    <title>Geometrical Complexity of Classification Problems</title>\\n    <summary>  Despite encouraging recent progresses in ensemble approaches, classification\\nmethods seem to have reached a plateau in development. Further advances depend\\non a better understanding of geometrical and topological characteristics of\\npoint sets in high-dimensional spaces, the preservation of such characteristics\\nunder feature transformations and sampling processes, and their interaction\\nwith geometrical models used in classifiers. We discuss an attempt to measure\\nsuch properties from data sets and relate them to classifier accuracies.\\n</summary>\\n    <author>\\n      <name>Tin Kam Ho</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings of the 7th Course on Ensemble Methods for Learning\\n  Machines at the International School on Neural Nets ``E.R. Caianiello\\'\\'</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0402020v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0402020v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.5.0\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0404046v1</id>\\n    <updated>2004-04-22T13:42:48Z</updated>\\n    <published>2004-04-22T13:42:48Z</published>\\n    <title>Visualising the structure of architectural open spaces based on shape\\n  analysis</title>\\n    <summary>  This paper proposes the application of some well known two-dimensional\\ngeometrical shape descriptors for the visualisation of the structure of\\narchitectural open spaces. The paper demonstrates the use of visibility\\nmeasures such as distance to obstacles and amount of visible space to calculate\\nshape descriptors such as convexity and skeleton of the open space. The aim of\\nthe paper is to indicate a simple, objective and quantifiable approach to\\nunderstand the structure of open spaces otherwise impossible due to the complex\\nconstruction of built structures.\\n</summary>\\n    <author>\\n      <name>Sanjay Rana</name>\\n    </author>\\n    <author>\\n      <name>Mike Batty</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, 9 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">International Journal of Architectural Computing, 2(1), 2004</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0404046v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0404046v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.3.5;I.4.8;I.5.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0405093v2</id>\\n    <updated>2004-10-20T10:07:43Z</updated>\\n    <published>2004-05-25T11:36:34Z</published>\\n    <title>Computerized Face Detection and Recognition</title>\\n    <summary>  This publication presents methods for face detection, analysis and\\nrecognition: fast normalized cross-correlation (fast correlation coefficient)\\nbetween multiple templates based face pre-detection method, method for\\ndetection of exact face contour based on snakes and Generalized Gradient Vector\\nFlow field, method for combining recognition algorithms based on Cumulative\\nMatch Characteristics in order to increase recognition speed and accuracy, and\\nface recognition method based on Principal Component Analysis of the Wavelet\\nPacket Decomposition allowing to use PCA - based recognition method with large\\nnumber of training images. For all the methods are presented experimental\\nresults and comparisons of speed and accuracy with large face databases.\\n</summary>\\n    <author>\\n      <name>Vytautas Perlibakas</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">PhD dissertation summary. 35 pages, 12 figures, 7 tables</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0405093v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0405093v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8; I.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0405095v1</id>\\n    <updated>2004-05-25T22:40:42Z</updated>\\n    <published>2004-05-25T22:40:42Z</published>\\n    <title>Blind Detection and Compensation of Camera Lens Geometric Distortions</title>\\n    <summary>  This paper presents a blind detection and compensation technique for camera\\nlens geometric distortions. The lens distortion introduces higher-order\\ncorrelations in the frequency domain and in turn it can be detected using\\nhigher-order spectral analysis tools without assuming any specific calibration\\ntarget. The existing blind lens distortion removal method only considered a\\nsingle-coefficient radial distortion model. In this paper, two coefficients are\\nconsidered to model approximately the geometric distortion. All the models\\nconsidered have analytical closed-form inverse formulae.\\n</summary>\\n    <author>\\n      <name>Lili Ma</name>\\n    </author>\\n    <author>\\n      <name>YangQuan Chen</name>\\n    </author>\\n    <author>\\n      <name>Kevin L. Moore</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 4 figures, 2 tables</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">SIAM Imaging Science, 2004</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0405095v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0405095v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I 4.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0503001v1</id>\\n    <updated>2005-03-01T05:17:33Z</updated>\\n    <published>2005-03-01T05:17:33Z</published>\\n    <title>Top-Down Unsupervised Image Segmentation (it sounds like oxymoron, but\\n  actually it is not)</title>\\n    <summary>  Pattern recognition is generally assumed as an interaction of two inversely\\ndirected image-processing streams: the bottom-up information details gathering\\nand localization (segmentation) stream, and the top-down information features\\naggregation, association and interpretation (recognition) stream. Inspired by\\nrecent evidence from biological vision research and by the insights of\\nKolmogorov Complexity theory, we propose a new, just top-down evolving,\\nprocedure of initial image segmentation. We claim that traditional top-down\\ncognitive reasoning, which is supposed to guide the segmentation process to its\\nfinal result, is not at all a part of the image information content evaluation.\\nAnd that initial image segmentation is certainly an unsupervised process. We\\npresent some illustrative examples, which support our claims.\\n</summary>\\n    <author>\\n      <name>Emanuel Diamant</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/cs/0503001v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0503001v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0504037v2</id>\\n    <updated>2006-10-31T14:34:47Z</updated>\\n    <published>2005-04-11T12:41:19Z</published>\\n    <title>Bayesian Restoration of Digital Images Employing Markov Chain Monte\\n  Carlo a Review</title>\\n    <summary>  A review of Bayesian restoration of digital images based on Monte Carlo\\ntechniques is presented. The topics covered include Likelihood, Prior and\\nPosterior distributions, Poisson, Binay symmetric channel, and Gaussian channel\\nmodels of Likelihood distribution,Ising and Potts spin models of Prior\\ndistribution, restoration of an image through Posterior maximization,\\nstatistical estimation of a true image from Posterior ensembles, Markov Chain\\nMonte Carlo methods and cluster algorithms.\\n</summary>\\n    <author>\\n      <name>K. P. N. Murthy</name>\\n    </author>\\n    <author>\\n      <name>M. Janani</name>\\n    </author>\\n    <author>\\n      <name>B. Shenbga Priya</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">42 pages; 16 figures; revised version with several typos removed and\\n  mistakes in equations corrected</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0504037v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0504037v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cond-mat.stat-mech\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"physics.comp-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0604062v1</id>\\n    <updated>2006-04-14T04:40:29Z</updated>\\n    <published>2006-04-14T04:40:29Z</published>\\n    <title>Biologically Inspired Hierarchical Model for Feature Extraction and\\n  Localization</title>\\n    <summary>  Feature extraction and matching are among central problems of computer\\nvision. It is inefficent to search features over all locations and scales.\\nNeurophysiological evidence shows that to locate objects in a digital image the\\nhuman visual system employs visual attention to a specific object while\\nignoring others. The brain also has a mechanism to search from coarse to fine.\\nIn this paper, we present a feature extractor and an associated hierarchical\\nsearching model to simulate such processes. With the hierarchical\\nrepresentation of the object, coarse scanning is done through the matching of\\nthe larger scale and precise localization is conducted through the matching of\\nthe smaller scale. Experimental results justify the proposed model in its\\neffectiveness and efficiency to localize features.\\n</summary>\\n    <author>\\n      <name>Liang Wu</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 4 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0604062v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0604062v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0606060v1</id>\\n    <updated>2006-06-13T12:53:45Z</updated>\\n    <published>2006-06-13T12:53:45Z</published>\\n    <title>Complex Networks: New Concepts and Tools for Real-Time Imaging and\\n  Vision</title>\\n    <summary>  This article discusses how concepts and methods of complex networks can be\\napplied to real-time imaging and computer vision. After a brief introduction of\\ncomplex networks basic concepts, their use as means to represent and\\ncharacterize images, as well as for modeling visual saliency, are briefly\\ndescribed. The possibility to apply complex networks in order to model and\\nsimulate the performance of parallel and distributed computing systems for\\nperformance of visual methods is also proposed.\\n</summary>\\n    <author>\\n      <name>Luciano da Fontoura Costa</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0606060v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0606060v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"physics.soc-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0608115v1</id>\\n    <updated>2006-08-29T13:24:37Z</updated>\\n    <published>2006-08-29T13:24:37Z</published>\\n    <title>Neural Network Clustering Based on Distances Between Objects</title>\\n    <summary>  We present an algorithm of clustering of many-dimensional objects, where only\\nthe distances between objects are used. Centers of classes are found with the\\naid of neuron-like procedure with lateral inhibition. The result of clustering\\ndoes not depend on starting conditions. Our algorithm makes it possible to give\\nan idea about classes that really exist in the empirical data. The results of\\ncomputer simulations are presented.\\n</summary>\\n    <author>\\n      <name>Leonid B. Litinskii</name>\\n    </author>\\n    <author>\\n      <name>Dmitry E. Romanov</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages,4 figures, presentation on ICANN (Athens, Greece, 2006)</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0608115v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0608115v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0610002v1</id>\\n    <updated>2006-09-30T08:05:02Z</updated>\\n    <published>2006-09-30T08:05:02Z</published>\\n    <title>Conditional Expressions for Blind Deconvolution: Derivative form</title>\\n    <summary>  We developed novel conditional expressions (CEs) for Lane and Bates\\' blind\\ndeconvolution. The CEs are given in term of the derivatives of the zero-values\\nof the z-transform of given images. The CEs make it possible to automatically\\ndetect multiple blur convolved in the given images all at once without\\nperforming any analysis of the zero-sheets of the given images. We illustrate\\nthe multiple blur-detection by the CEs for a model image\\n</summary>\\n    <author>\\n      <name>S. Aogaki</name>\\n    </author>\\n    <author>\\n      <name>I. Moritani</name>\\n    </author>\\n    <author>\\n      <name>T. Sugai</name>\\n    </author>\\n    <author>\\n      <name>F. Takeutchi</name>\\n    </author>\\n    <author>\\n      <name>F. M. Toyama</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 page, 3 figures, conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0610002v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0610002v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0701127v3</id>\\n    <updated>2007-12-28T15:30:19Z</updated>\\n    <published>2007-01-20T15:45:03Z</published>\\n    <title>A novel set of rotationally and translationally invariant features for\\n  images based on the non-commutative bispectrum</title>\\n    <summary>  We propose a new set of rotationally and translationally invariant features\\nfor image or pattern recognition and classification. The new features are cubic\\npolynomials in the pixel intensities and provide a richer representation of the\\noriginal image than most existing systems of invariants. Our construction is\\nbased on the generalization of the concept of bispectrum to the\\nthree-dimensional rotation group SO(3), and a projection of the image onto the\\nsphere.\\n</summary>\\n    <author>\\n      <name>Risi Kondor</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The claim that the invariants uniquely determine the original image\\n  had to be dropped</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/cs/0701127v3\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0701127v3\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.7; I.2.10; I.5.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0701150v1</id>\\n    <updated>2007-01-24T15:13:06Z</updated>\\n    <published>2007-01-24T15:13:06Z</published>\\n    <title>Contains and Inside relationships within combinatorial Pyramids</title>\\n    <summary>  Irregular pyramids are made of a stack of successively reduced graphs\\nembedded in the plane. Such pyramids are used within the segmentation framework\\nto encode a hierarchy of partitions. The different graph models used within the\\nirregular pyramid framework encode different types of relationships between\\nregions. This paper compares different graph models used within the irregular\\npyramid framework according to a set of relationships between regions. We also\\ndefine a new algorithm based on a pyramid of combinatorial maps which allows to\\ndetermine if one region contains the other using only local calculus.\\n</summary>\\n    <author>\\n      <name>Luc Brun</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">GREYC</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Walter G. Kropatsch</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">PRIP</arxiv:affiliation>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">35 pages</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Pattern Recognition 39 (01/04/2006) 515-526</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0701150v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0701150v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/cs/0703088v1</id>\\n    <updated>2007-03-16T00:18:11Z</updated>\\n    <published>2007-03-16T00:18:11Z</published>\\n    <title>Plot 94 in ambiance X-Window</title>\\n    <summary>  &lt;PLOT &gt; is a collection of routines to draw surfaces, contours and so on. In\\nthis work we are presenting a version, that functions over work stations with\\nthe operative system UNIX, that count with the graphic ambiance X-WINDOW with\\nthe tools XLIB and OSF/MOTIF. This implant was realized for the work stations\\nDEC 5000-200, DEC IPX, and DEC ALFA of the CINVESTAV (Center of Investigation\\nand Advanced Studies). Also implanted in SILICON GRAPHICS of the CENAC\\n(National Center of Calculation of the Polytechnic National Institute\\n</summary>\\n    <author>\\n      <name>Ignacio Vega-Paez</name>\\n    </author>\\n    <author>\\n      <name>Carlos Alberto Hernandez-Hernandez</name>\\n    </author>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings in Information Systems Analysis and Synthesis ISAS\\n  1995, 5th, International Symposium on Systems Research, Informatics and\\n  Cybernetics, pp. 135-139, August 16-20, 95, Baden-Baden, Germany</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cs/0703088v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0703088v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0704.3635v1</id>\\n    <updated>2007-04-26T22:22:45Z</updated>\\n    <published>2007-04-26T22:22:45Z</published>\\n    <title>Rough Sets Computations to Impute Missing Data</title>\\n    <summary>  Many techniques for handling missing data have been proposed in the\\nliterature. Most of these techniques are overly complex. This paper explores an\\nimputation technique based on rough set computations. In this paper,\\ncharacteristic relations are introduced to describe incompletely specified\\ndecision tables.It is shown that the basic rough set idea of lower and upper\\napproximations for incompletely specified decision tables may be defined in a\\nvariety of different ways. Empirical results obtained using real data are given\\nand they provide a valuable and promising insight to the problem of missing\\ndata. Missing data were predicted with an accuracy of up to 99%.\\n</summary>\\n    <author>\\n      <name>Fulufhelo Vincent Nelwamondo</name>\\n    </author>\\n    <author>\\n      <name>Tshilidzi Marwala</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">19 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0704.3635v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0704.3635v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0705.0449v1</id>\\n    <updated>2007-05-03T12:47:31Z</updated>\\n    <published>2007-05-03T12:47:31Z</published>\\n    <title>Multiresolution Approximation of Polygonal Curves in Linear Complexity</title>\\n    <summary>  We propose a new algorithm to the problem of polygonal curve approximation\\nbased on a multiresolution approach. This algorithm is suboptimal but still\\nmaintains some optimality between successive levels of resolution using dynamic\\nprogramming. We show theoretically and experimentally that this algorithm has a\\nlinear complexity in time and space. We experimentally compare the outcomes of\\nour algorithm to the optimal \"full search\" dynamic programming solution and\\nfinally to classical merge and split approaches. The experimental evaluations\\nconfirm the theoretical derivations and show that the proposed approach\\nevaluated on 2D coastal maps either show a lower time complexity or provide\\npolygonal approximations closer to the input discrete curves.\\n</summary>\\n    <author>\\n      <name>Pierre-Fran\\xc3\\xa7ois Marteau</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">VALORIA</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Gilbas M\\xc3\\xa9nier</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">VALORIA</arxiv:affiliation>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0705.0449v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0705.0449v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0705.0781v1</id>\\n    <updated>2007-05-06T06:02:46Z</updated>\\n    <published>2007-05-06T06:02:46Z</published>\\n    <title>Medical Image Segmentation and Localization using Deformable Templates</title>\\n    <summary>  This paper presents deformable templates as a tool for segmentation and\\nlocalization of biological structures in medical images. Structures are\\nrepresented by a prototype template, combined with a parametric warp mapping\\nused to deform the original shape. The localization procedure is achieved using\\na multi-stage, multi-resolution algorithm de-signed to reduce computational\\ncomplexity and time. The algorithm initially identifies regions in the image\\nmost likely to contain the desired objects and then examines these regions at\\nprogressively increasing resolutions. The final stage of the algorithm involves\\nwarping the prototype template to match the localized objects. The algorithm is\\npresented along with the results of four example applications using MRI, x-ray\\nand ultrasound images.\\n</summary>\\n    <author>\\n      <name>Jonathan M. Spiller</name>\\n    </author>\\n    <author>\\n      <name>T. Marwala</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0705.0781v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0705.0781v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0705.0952v1</id>\\n    <updated>2007-05-07T19:19:55Z</updated>\\n    <published>2007-05-07T19:19:55Z</published>\\n    <title>An Independent Evaluation of Subspace Face Recognition Algorithms</title>\\n    <summary>  This paper explores a comparative study of both the linear and kernel\\nimplementations of three of the most popular Appearance-based Face Recognition\\nprojection classes, these being the methodologies of Principal Component\\nAnalysis, Linear Discriminant Analysis and Independent Component Analysis. The\\nexperimental procedure provides a platform of equal working conditions and\\nexamines the ten algorithms in the categories of expression, illumination,\\nocclusion and temporal delay. The results are then evaluated based on a\\nsequential combination of assessment tools that facilitate both intuitive and\\nstatistical decisiveness among the intra and interclass comparisons. The best\\ncategorical algorithms are then incorporated into a hybrid methodology, where\\nthe advantageous effects of fusion strategies are considered.\\n</summary>\\n    <author>\\n      <name>Dhiresh R. Surajpal</name>\\n    </author>\\n    <author>\\n      <name>Tshilidzi Marwala</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0705.0952v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0705.0952v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0705.3593v2</id>\\n    <updated>2007-06-19T12:14:51Z</updated>\\n    <published>2007-05-24T14:41:11Z</published>\\n    <title>MI image registration using prior knowledge</title>\\n    <summary>  Subtraction of aligned images is a means to assess changes in a wide variety\\nof clinical applications. In this paper we explore the information theoretical\\norigin of Mutual Information (MI), which is based on Shannon\\'s entropy.However,\\nthe interpretation of standard MI registration as a communication channel\\nsuggests that MI is too restrictive a criterion. In this paper the concept of\\nMutual Information (MI) is extended to (Normalized) Focussed Mutual Information\\n(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We\\nuse this to develop new methodologies to successfully address specific\\nregistration problems, the follow-up of dental restorations, cephalometry, and\\nthe monitoring of implants.\\n</summary>\\n    <author>\\n      <name>W. Jacquet</name>\\n    </author>\\n    <author>\\n      <name>P. de Groen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0705.3593v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0705.3593v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0706.1926v1</id>\\n    <updated>2007-06-13T15:15:00Z</updated>\\n    <published>2007-06-13T15:15:00Z</published>\\n    <title>Towards understanding and modelling office daily life</title>\\n    <summary>  Measuring and modeling human behavior is a very complex task. In this paper\\nwe present our initial thoughts on modeling and automatic recognition of some\\nhuman activities in an office. We argue that to successfully model human\\nactivities, we need to consider both individual behavior and group dynamics. To\\ndemonstrate these theoretical approaches, we introduce an experimental system\\nfor analyzing everyday activity in our office.\\n</summary>\\n    <author>\\n      <name>Michele Bezzi</name>\\n    </author>\\n    <author>\\n      <name>Robin Groenevelt</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, ECHISE 2006 - 2nd International Workshop on Exploiting\\n  Context Histories in Smart Environments - Infrastructures and Design, 8th\\n  International Conference of Ubiquitous Computing (Ubicomp 2006), Orange\\n  County, CA, 17-21 September 2006</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0706.1926v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0706.1926v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.8; I.5.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0708.2432v1</id>\\n    <updated>2007-08-18T14:36:28Z</updated>\\n    <published>2007-08-18T14:36:28Z</published>\\n    <title>A structure from motion inequality</title>\\n    <summary>  We state an elementary inequality for the structure from motion problem for m\\ncameras and n points. This structure from motion inequality relates space\\ndimension, camera parameter dimension, the number of cameras and number points\\nand global symmetry properties and provides a rigorous criterion for which\\nreconstruction is not possible with probability 1. Mathematically the\\ninequality is based on Frobenius theorem which is a geometric incarnation of\\nthe fundamental theorem of linear algebra. The paper also provides a general\\nmathematical formalism for the structure from motion problem. It includes the\\nsituation the points can move while the camera takes the pictures.\\n</summary>\\n    <author>\\n      <name>Oliver Knill</name>\\n    </author>\\n    <author>\\n      <name>Jose Ramirez-Herran</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages, 22 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0708.2432v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0708.2432v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0708.2438v1</id>\\n    <updated>2007-08-17T21:36:08Z</updated>\\n    <published>2007-08-17T21:36:08Z</published>\\n    <title>On Ullman\\'s theorem in computer vision</title>\\n    <summary>  Both in the plane and in space, we invert the nonlinear Ullman transformation\\nfor 3 points and 3 orthographic cameras. While Ullman\\'s theorem assures a\\nunique reconstruction modulo a reflection for 3 cameras and 4 points, we find a\\nlocally unique reconstruction for 3 cameras and 3 points. Explicit\\nreconstruction formulas allow to decide whether picture data of three cameras\\nseeing three points can be realized as a point-camera configuration.\\n</summary>\\n    <author>\\n      <name>Oliver Knill</name>\\n    </author>\\n    <author>\\n      <name>Jose Ramirez-Herran</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 pages, 13 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0708.2438v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0708.2438v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0708.2974v1</id>\\n    <updated>2007-08-22T08:28:02Z</updated>\\n    <published>2007-08-22T08:28:02Z</published>\\n    <title>The Fuzzy Vault for fingerprints is Vulnerable to Brute Force Attack</title>\\n    <summary>  The \\\\textit{fuzzy vault} approach is one of the best studied and well\\naccepted ideas for binding cryptographic security into biometric\\nauthentication. The vault has been implemented in connection with fingerprint\\ndata by Uludag and Jain. We show that this instance of the vault is vulnerable\\nto brute force attack. An interceptor of the vault data can recover both secret\\nand template data using only generally affordable computational resources. Some\\npossible alternatives are then discussed and it is suggested that cryptographic\\nsecurity may be preferable to the one - way function approach to biometric\\nsecurity.\\n</summary>\\n    <author>\\n      <name>Preda Mihailescu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0708.2974v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0708.2974v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"D.4.6\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0709.1771v1</id>\\n    <updated>2007-09-12T08:41:36Z</updated>\\n    <published>2007-09-12T08:41:36Z</published>\\n    <title>Variational local structure estimation for image super-resolution</title>\\n    <summary>  Super-resolution is an important but difficult problem in image/video\\nprocessing. If a video sequence or some training set other than the given\\nlow-resolution image is available, this kind of extra information can greatly\\naid in the reconstruction of the high-resolution image. The problem is\\nsubstantially more difficult with only a single low-resolution image on hand.\\nThe image reconstruction methods designed primarily for denoising is\\ninsufficient for super-resolution problem in the sense that it tends to\\noversmooth images with essentially no noise. We propose a new adaptive linear\\ninterpolation method based on variational method and inspired by local linear\\nembedding (LLE). The experimental result shows that our method avoids the\\nproblem of oversmoothing and preserves image structures well.\\n</summary>\\n    <author>\\n      <name>Heng Lian</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0709.1771v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0709.1771v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0710.0243v1</id>\\n    <updated>2007-10-01T09:18:36Z</updated>\\n    <published>2007-10-01T09:18:36Z</published>\\n    <title>High-Order Nonparametric Belief-Propagation for Fast Image Inpainting</title>\\n    <summary>  In this paper, we use belief-propagation techniques to develop fast\\nalgorithms for image inpainting. Unlike traditional gradient-based approaches,\\nwhich may require many iterations to converge, our techniques achieve\\ncompetitive results after only a few iterations. On the other hand, while\\nbelief-propagation techniques are often unable to deal with high-order models\\ndue to the explosion in the size of messages, we avoid this problem by\\napproximating our high-order prior model using a Gaussian mixture. By using\\nsuch an approximation, we are able to inpaint images quickly while at the same\\ntime retaining good visual results.\\n</summary>\\n    <author>\\n      <name>Julian John McAuley</name>\\n    </author>\\n    <author>\\n      <name>Tiberio S. Caetano</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 6 figures</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0710.0243v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0710.0243v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0710.0736v1</id>\\n    <updated>2007-10-03T08:51:44Z</updated>\\n    <published>2007-10-03T08:51:44Z</published>\\n    <title>Colour image segmentation by the vector-valued Allen-Cahn phase-field\\n  model: a multigrid solution</title>\\n    <summary>  We propose a new method for the numerical solution of a PDE-driven model for\\ncolour image segmentation and give numerical examples of the results. The\\nmethod combines the vector-valued Allen-Cahn phase field equation with initial\\ndata fitting terms. This method is known to be closely related to the\\nMumford-Shah problem and the level set segmentation by Chan and Vese. Our\\nnumerical solution is performed using a multigrid splitting of a finite element\\nspace, thereby producing an efficient and robust method for the segmentation of\\nlarge images.\\n</summary>\\n    <author>\\n      <name>David A Kay</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Oxford University Computational Laboratory</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Alessandro Tomasi</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Sussex</arxiv:affiliation>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/TIP.2009.2026678</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/TIP.2009.2026678\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">17 pages, 9 figures</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Trans. Im. Proc. 18.10 (2009)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/0710.0736v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0710.0736v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"I.4.6; G.1.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0710.2037v2</id>\\n    <updated>2007-10-11T11:32:25Z</updated>\\n    <published>2007-10-10T15:12:20Z</published>\\n    <title>An Affinity Propagation Based method for Vector Quantization Codebook\\n  Design</title>\\n    <summary>  In this paper, we firstly modify a parameter in affinity propagation (AP) to\\nimprove its convergence ability, and then, we apply it to vector quantization\\n(VQ) codebook design problem. In order to improve the quality of the resulted\\ncodebook, we combine the improved AP (IAP) with the conventional LBG algorithm\\nto generate an effective algorithm call IAP-LBG. According to the experimental\\nresults, the proposed method not only enhances the convergence abilities but\\nalso is capable of providing higher-quality codebooks than conventional LBG\\nmethod.\\n</summary>\\n    <author>\\n      <name>Wu Jiang</name>\\n    </author>\\n    <author>\\n      <name>Fei Ding</name>\\n    </author>\\n    <author>\\n      <name>Qiao-liang Xiang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">In this version we make some explaination about the network-support\\n  similarity</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0710.2037v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0710.2037v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0712.4015v1</id>\\n    <updated>2007-12-24T17:11:56Z</updated>\\n    <published>2007-12-24T17:11:56Z</published>\\n    <title>A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased\\n  Estimators</title>\\n    <summary>  This paper proposes a novel method for segmentation of images by hierarchical\\nmultilevel thresholding. The method is global, agglomerative in nature and\\ndisregards pixel locations. It involves the optimization of the ratio of the\\nunbiased estimators of within class to between class variances. We obtain a\\nrecursive relation at each step for the variances which expedites the process.\\nThe efficacy of the method is shown in a comparison with some well-known\\nmethods.\\n</summary>\\n    <author>\\n      <name>Sreechakra Goparaju</name>\\n    </author>\\n    <author>\\n      <name>Jayadev Acharya</name>\\n    </author>\\n    <author>\\n      <name>Ajoy K. Ray</name>\\n    </author>\\n    <author>\\n      <name>Jaideva C. Goswami</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, 5 figures, submitted to \"IEEE Transactions on Pattern\\n  Analysis and Machine Intelligence\"</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0712.4015v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0712.4015v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0802.3285v1</id>\\n    <updated>2008-02-22T10:48:44Z</updated>\\n    <published>2008-02-22T10:48:44Z</published>\\n    <title>Some Aspects of Testing Process for Transport Streams in Digital Video\\n  Broadcasting</title>\\n    <summary>  This paper presents some aspects related to the DVB (Digital Video\\nBroadcasting) investigation. The basic aspects of DVB are presented, with an\\nemphasis on DVB-T version of standard. The main purpose of this research is to\\nanalyze the way that the transmission of the transport streams is realized in\\ncase of the Terrestrial Digital Video Broadcasting (DVB-T). To accomplish this,\\nfirst, Digital Video Broadcasting standard is presented, and then the main\\naspects of DVB testing and analysis of the transport streams are investigated.\\nThe paper presents also the results obtained using two programs designed for\\nDVB analysis: Mosalina and TSA.\\n</summary>\\n    <author>\\n      <name>Radu Arsinte</name>\\n    </author>\\n    <author>\\n      <name>Ciprian Ilioaei</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 3 figures, 3 tables</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Acta Technica Napocensis, Electronics and Telecommunications,\\n  nr.1/2004 pp.59-74</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/0802.3285v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0802.3285v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.MM\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0803.1586v1</id>\\n    <updated>2008-03-11T13:40:42Z</updated>\\n    <published>2008-03-11T13:40:42Z</published>\\n    <title>Spatio-activity based object detection</title>\\n    <summary>  We present the SAMMI lightweight object detection method which has a high\\nlevel of accuracy and robustness, and which is able to operate in an\\nenvironment with a large number of cameras. Background modeling is based on DCT\\ncoefficients provided by cameras. Foreground detection uses similarity in\\ntemporal characteristics of adjacent blocks of pixels, which is a\\ncomputationally inexpensive way to make use of object coherence. Scene model\\nupdating uses the approximated median method for improved performance.\\nEvaluation at pixel level and application level shows that SAMMI object\\ndetection performs better and faster than the conventional Mixture of Gaussians\\nmethod.\\n</summary>\\n    <author>\\n      <name>Jarrad Springett</name>\\n    </author>\\n    <author>\\n      <name>Jeroen Vendrig</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">To be submitted to: AVSS 2008 conference</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/0803.1586v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0803.1586v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/0804.1046v1</id>\\n    <updated>2008-04-07T14:47:03Z</updated>\\n    <published>2008-04-07T14:47:03Z</published>\\n    <title>Discrete schemes for Gaussian curvature and their convergence</title>\\n    <summary>  In this paper, several discrete schemes for Gaussian curvature are surveyed.\\nThe convergence property of a modified discrete scheme for the Gaussian\\ncurvature is considered. Furthermore, a new discrete scheme for Gaussian\\ncurvature is resented. We prove that the new scheme converges at the regular\\nvertex with valence not less than 5. By constructing a counterexample, we also\\nshow that it is impossible for building a discrete scheme for Gaussian\\ncurvature which converges over the regular vertex with valence 4. Finally,\\nasymptotic errors of several discrete scheme for Gaussian curvature are\\ncompared.\\n</summary>\\n    <author>\\n      <name>Zhiqiang Xu</name>\\n    </author>\\n    <author>\\n      <name>Guoliang Xu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/0804.1046v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/0804.1046v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка уникальности заголовков"
      ],
      "metadata": {
        "id": "t6gfvM_9pcJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unique titles\n",
        "\n",
        "docs = feedparser.parse(r)\n",
        "titles = [d[\"title\"] for d in docs[\"entries\"]]\n",
        "len(set(titles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ45CPNAH7vI",
        "outputId": "703e0e70-b156-471f-a8e5-f449596581e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Извлечение ключевых слов (Transformers)\n",
        "\n",
        "Модель: `ilsilfverskiold/tech-keywords-extractor`.\n",
        "Это тяжёлая операция. Рекомендации:\n",
        "- Сначала протестируй на 5–10 абстрактах.\n",
        "- Запускай на GPU.\n",
        "- Кешируй результаты в CSV, чтобы не вызывать модель повторно.\n"
      ],
      "metadata": {
        "id": "USko2qW9JZjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# keywords extraction\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text2text-generation\", model=\"ilsilfverskiold/tech-keywords-extractor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            "9cd208713a744d34ab10be32ffc31de4",
            "08d34110ead94febbf0915ef74e4fad1",
            "6c24cc611f9a46008b87541425931fe9",
            "dc0ec7587fc5481795addd4ff7500f6d",
            "90faa2c852f749c28e2708369a7558be",
            "17f66b4a559d40cd9f77e1132ac534d3",
            "582b2c5af7b844bd91292e5113970ba3",
            "2fe17ff134734cc2b82626ac76b4f731",
            "928b1987f8a24b05a95cedbf9dd86ead",
            "c0668d36dcd741ab9c2b82506a46c545",
            "4145f0e5ef41467793bfd429948524cc",
            "4753824af4254fa8ac86c785f5204286",
            "f8c08d042854411ba5368ad2ff6b3b11",
            "1367b7e8346f4251a1f4988125511e58",
            "0323f0b6e2e54f97bc1303b1f9bee77b",
            "e48b410fea744c20a9a2304f67c2d1c9",
            "231075132b0548d185777aa4cdd145c5",
            "315c8439af614fd28d09be398e213003",
            "644cb1bd592f42279c540798e7876b81",
            "821fa5d0c02f4d1cb3ded788fd985eb8",
            "9bfdd05560474d878178cd6c124ac48a",
            "f8a63d8b2b9a4200ae50ee265e33ddaa",
            "f179ad4ae948481484499434afeaaa75",
            "45e8b59247a84991bdcf60f34c589932",
            "bce058ea9de44192a5adc241ba6cdd93",
            "0d4012fe2e714488b57a8dc255d3664d",
            "8b58a25937d9465aa594c18c4b649a36",
            "ef439dbac29e4da59c101e04fcf0f338",
            "f408c0ba29b84c1b8d0709b456478918",
            "f42b0eac383a46b69e1e5d69fe300e9c",
            "edb1100414a24a15909275a6e1127274",
            "40b7fdc74d6347d386ee0733340559d3",
            "5d2e6d49782744b58c0849c8ba827634",
            "ce4a4c38756342958d83dd4e04e700ad",
            "0397b48b919d4ac393fc1f23cbd69c78",
            "318d510babc84c43926144b09d8d15e6",
            "6c0fecca17b542d7852458fb0bab2fc2",
            "38e44eedc5134049acf156a1a13ff13e",
            "fa2abba2917447be8981457564d2b05f",
            "fca947425a364c7e806e09088e315b19",
            "099cdfb398014299bb1b098af008117d",
            "6011f15b358242a6849d007e13f88cb4",
            "59a74c7e743d45a5942da2c5624ba83d",
            "dab11a2befdb4f18970d6632b600a975",
            "6e5d2057cdb0406284c1203ff5d655a9",
            "e86691730d264f9e8fa7ccee82eb91dc",
            "d1741e5b36af481795c789a8c8331fbc",
            "84ec6f0884c34b2fa5b115e726e118fa",
            "a0e289884bd3464d811924bde3ca3ed3",
            "6050bb7b8dc244e4a2f6b36c5296639f",
            "7dd07c961daa4d5a87bae39d8119bc61",
            "c37568c0198c42d0926a28bc66a90700",
            "c364f7077e3d42a785f116d8f0fbee28",
            "027ee9c3e7d843f699f612b3d105acdb",
            "346334c81ecd4b9c94ccc19455cf29f4",
            "6c079ca15456450a866b22d8c777e808",
            "6cf6f72aea2d47d5a77db38da32bc931",
            "e1c3e0c520b44231a8a0918a3a15bfac",
            "3de84ae2ec6c4ff98b2a633fcba095b0",
            "0724410e8ade4f7e8dfb2eeb76f383ee",
            "92c117b4bcf54932be0c1902e2d3f1b1",
            "07dc5ba139fa4edd973987bc8332fc87",
            "2fb35f2cf0f74ab1bb6852c9be8088f7",
            "06d072840039401ea674b0e3c1bdc8ca",
            "1c36b147f77c4f6db3ccb57b67e41b1f",
            "8dfb96135df342d986ab40118369788d",
            "201085b3d1c349109664088c6e0047d2",
            "ce020eb3100243f991bdb64e5b66645d",
            "6d2b9a6e1a304f99acb4ce3522867dff",
            "c8933ad6030d4daaaac7f87851c91dfc",
            "c3d8ccff78bd48dfbd6c50f1e550f9db",
            "4b73f48d43be44e5821efd1ce09b0e24",
            "60988f288d4f4634a02fb46039ac16b9",
            "07142a04bd36461286f7b1f2fa06a6de",
            "d6f9955843664d6d8d0b03a5cf954185",
            "68b27f76c6134e65b694f3e546e89112",
            "b2d87cfa44644e6f8ae03517b58ebd3f",
            "599716614d404edea6d474ca8930842c",
            "2b191b5529244fc6beed41de59d156ec",
            "8f404437390d42189757efac328d04fb",
            "a6ffb62637144bd28a06d790c48510f1",
            "0efc2dcbf9cd4cc08136a3a8a3268feb",
            "241e0fed153549d29e4d0e0e48fa5ac7",
            "2d0f25caa42f411a814d040e65a14090",
            "20febd182f26473aa33774634fcd088f",
            "5ec4174bac394b519397da34f50328aa",
            "69b90074efbc434c9bdb34cde12a45c9",
            "da07fe6d6c4a48c2b4f09d2f68c9c828"
          ]
        },
        "id": "Lgmfzge1H7qR",
        "outputId": "3f516c06-ed99-425b-eb7d-001a58557411"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cd208713a744d34ab10be32ffc31de4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4753824af4254fa8ac86c785f5204286"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f179ad4ae948481484499434afeaaa75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce4a4c38756342958d83dd4e04e700ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e5d2057cdb0406284c1203ff5d655a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c079ca15456450a866b22d8c777e808"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "201085b3d1c349109664088c6e0047d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "599716614d404edea6d474ca8930842c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25.1 s, sys: 8.64 s, total: 33.7 s\n",
            "Wall time: 1min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "# data extraction example\n",
        "\n",
        "doc = feedparser.parse(r)\n",
        "title = doc['entries'][0]['title']\n",
        "abstract = doc['entries'][0]['summary']\n",
        "authors = [author['name'] for author in doc['entries'][0]['authors']]\n",
        "tags = [tag['term'] for tag in doc['entries'][0]['tags']]\n",
        "\n",
        "keywords = pipe(abstract)[0][\"generated_text\"].split(\", \")\n",
        "\n",
        "\n",
        "print(f\"Title: {title}\\n\\nAuthors: {authors}\\n\\nAbstract: {abstract}\\n\\nTags: {tags}\\n\\nKeywords: {keywords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4qZTtW5H7nq",
        "outputId": "58a87cfb-e187-4a54-de2b-0f4fa68a4388"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.96 µs\n",
            "Title: Recognition of Regular Shapes in Satelite Images\n",
            "\n",
            "Authors: ['Ahmad Reza Eskandari', 'Ali Pourmohammad']\n",
            "\n",
            "Abstract: This paper has been withdrawn by the author ali pourmohammad.\n",
            "\n",
            "Tags: ['cs.CV']\n",
            "\n",
            "Keywords: ['Paper', 'Ali Pourmohammad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "\n",
        "pubs = []\n",
        "for entry in docs[\"entries\"]:\n",
        "  data = {\"title\": entry['title'],\n",
        "          \"abstract\": entry['summary'],\n",
        "          \"authors\": [author['name'] for author in entry['authors']],\n",
        "          \"tags\": [tag['term'] for tag in entry['tags']]}\n",
        "  pubs.append(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dhYVDKJH7lG",
        "outputId": "a409f4f4-f5cb-4137-b695-8f490e69b617"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 4.05 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Формирование DataFrame"
      ],
      "metadata": {
        "id": "ROyZ4y-QpxA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pubs)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "VsZ76w5jJwSH",
        "outputId": "5c1a4278-0231-407b-ac6f-40cca20b9987"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0     Recognition of Regular Shapes in Satelite Images   \n",
              "1    Convolutional Matching Pursuit and Dictionary ...   \n",
              "2    Template Matching based Object Detection Using...   \n",
              "3    Exploration of object recognition from 3D poin...   \n",
              "4    Brain MRI Image Super Resolution using Phase S...   \n",
              "..                                                 ...   \n",
              "495  An Affinity Propagation Based method for Vecto...   \n",
              "496  A Fast Hierarchical Multilevel Image Segmentat...   \n",
              "497  Some Aspects of Testing Process for Transport ...   \n",
              "498             Spatio-activity based object detection   \n",
              "499  Discrete schemes for Gaussian curvature and th...   \n",
              "\n",
              "                                              abstract  \\\n",
              "0    This paper has been withdrawn by the author al...   \n",
              "1    Matching pursuit and K-SVD is demonstrated in ...   \n",
              "2    This article provides a step by step developme...   \n",
              "3    We present our latest experiment results of ob...   \n",
              "4    A hallucination-free and computationally effic...   \n",
              "..                                                 ...   \n",
              "495  In this paper, we firstly modify a parameter i...   \n",
              "496  This paper proposes a novel method for segment...   \n",
              "497  This paper presents some aspects related to th...   \n",
              "498  We present the SAMMI lightweight object detect...   \n",
              "499  In this paper, several discrete schemes for Ga...   \n",
              "\n",
              "                                               authors  \\\n",
              "0             [Ahmad Reza Eskandari, Ali Pourmohammad]   \n",
              "1        [Arthur Szlam, Koray Kavukcuoglu, Yann LeCun]   \n",
              "2                                      [Anish Acharya]   \n",
              "3                                           [Lin Duan]   \n",
              "4                           [Sifeng He, Bahram Jalali]   \n",
              "..                                                 ...   \n",
              "495             [Wu Jiang, Fei Ding, Qiao-liang Xiang]   \n",
              "496  [Sreechakra Goparaju, Jayadev Acharya, Ajoy K....   \n",
              "497                    [Radu Arsinte, Ciprian Ilioaei]   \n",
              "498                 [Jarrad Springett, Jeroen Vendrig]   \n",
              "499                         [Zhiqiang Xu, Guoliang Xu]   \n",
              "\n",
              "                             tags  \n",
              "0                         [cs.CV]  \n",
              "1                         [cs.CV]  \n",
              "2                         [cs.CV]  \n",
              "3                         [cs.CV]  \n",
              "4                         [cs.CV]  \n",
              "..                            ...  \n",
              "495                       [cs.CV]  \n",
              "496                       [cs.CV]  \n",
              "497                [cs.CV, cs.MM]  \n",
              "498                       [cs.CV]  \n",
              "499  [cs.CV, cs.CG, cs.GR, cs.NA]  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7e36a88-95eb-40df-a2d0-0491e3f492ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Recognition of Regular Shapes in Satelite Images</td>\n",
              "      <td>This paper has been withdrawn by the author al...</td>\n",
              "      <td>[Ahmad Reza Eskandari, Ali Pourmohammad]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Convolutional Matching Pursuit and Dictionary ...</td>\n",
              "      <td>Matching pursuit and K-SVD is demonstrated in ...</td>\n",
              "      <td>[Arthur Szlam, Koray Kavukcuoglu, Yann LeCun]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Template Matching based Object Detection Using...</td>\n",
              "      <td>This article provides a step by step developme...</td>\n",
              "      <td>[Anish Acharya]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Exploration of object recognition from 3D poin...</td>\n",
              "      <td>We present our latest experiment results of ob...</td>\n",
              "      <td>[Lin Duan]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brain MRI Image Super Resolution using Phase S...</td>\n",
              "      <td>A hallucination-free and computationally effic...</td>\n",
              "      <td>[Sifeng He, Bahram Jalali]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>An Affinity Propagation Based method for Vecto...</td>\n",
              "      <td>In this paper, we firstly modify a parameter i...</td>\n",
              "      <td>[Wu Jiang, Fei Ding, Qiao-liang Xiang]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>A Fast Hierarchical Multilevel Image Segmentat...</td>\n",
              "      <td>This paper proposes a novel method for segment...</td>\n",
              "      <td>[Sreechakra Goparaju, Jayadev Acharya, Ajoy K....</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Some Aspects of Testing Process for Transport ...</td>\n",
              "      <td>This paper presents some aspects related to th...</td>\n",
              "      <td>[Radu Arsinte, Ciprian Ilioaei]</td>\n",
              "      <td>[cs.CV, cs.MM]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Spatio-activity based object detection</td>\n",
              "      <td>We present the SAMMI lightweight object detect...</td>\n",
              "      <td>[Jarrad Springett, Jeroen Vendrig]</td>\n",
              "      <td>[cs.CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Discrete schemes for Gaussian curvature and th...</td>\n",
              "      <td>In this paper, several discrete schemes for Ga...</td>\n",
              "      <td>[Zhiqiang Xu, Guoliang Xu]</td>\n",
              "      <td>[cs.CV, cs.CG, cs.GR, cs.NA]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7e36a88-95eb-40df-a2d0-0491e3f492ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7e36a88-95eb-40df-a2d0-0491e3f492ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7e36a88-95eb-40df-a2d0-0491e3f492ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-071ee021-623f-45d0-beba-4faa11e8b1d4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-071ee021-623f-45d0-beba-4faa11e8b1d4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-071ee021-623f-45d0-beba-4faa11e8b1d4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6bb1daa6-66ab-460c-9220-d5768bf5bee4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6bb1daa6-66ab-460c-9220-d5768bf5bee4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"ODMTCNet: An Interpretable Multi-view Deep Neural Network Architecture\\n  for Image Feature Representation\",\n          \"General Theory of Image Normalization\",\n          \"Baseline Computation for Attribution Methods Based on Interpolated\\n  Inputs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"We rephrase the problem of 3D reconstruction from images in terms of\\nintersections of projections of orbits of custom built Lie groups actions. We\\nthen use an algorithmic method based on moving frames \\\"a la Fels-Olver\\\" to\\nobtain a fundamental set of invariants of these groups actions. The invariants\\nare used to define a set of equations to be solved by the points of the 3D\\nobject, providing a new technique for recovering 3D structure from motion.\",\n          \"This paper presents an invariant under scaling and linear brightness change.\\nThe invariant is based on differentials and therefore is a local feature.\\nRotationally invariant 2-d differential Gaussian operators up to third order\\nare proposed for the implementation of the invariant. The performance is\\nanalyzed by simulating a camera zoom-out.\",\n          \"In this work, we use a deep learning framework for simultaneous\\nclassification and regression of Parkinson disease diagnosis based on MR-Images\\nand personal information (i.e. age, gender). We intend to facilitate and\\nincrease the confidence in Parkinson disease diagnosis through our deep\\nlearning framework.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация ключевых слов для всех абстрактов"
      ],
      "metadata": {
        "id": "CvXrp9edqTzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df[\"keywords\"] = df[\"abstract\"].apply(lambda x: pipe(x)[0][\"generated_text\"].split(\", \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1uOPhVPH7id",
        "outputId": "23cdf359-7b01-41b9-a964-6cebaca3a64d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 18s, sys: 53 ms, total: 2min 19s\n",
            "Wall time: 2min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"authors\"] = df[\"authors\"].apply(lambda x: \", \".join(x))\n",
        "df[\"tags\"] = df[\"tags\"].apply(lambda x: \", \".join(x))\n",
        "df[\"keywords\"] = df[\"keywords\"].apply(lambda x: \", \".join(x))\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "sGt_qGDbH7fs",
        "outputId": "c931a391-5c8f-468f-8044-c3a239a0e566"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0     Recognition of Regular Shapes in Satelite Images   \n",
              "1    Convolutional Matching Pursuit and Dictionary ...   \n",
              "2    Template Matching based Object Detection Using...   \n",
              "3    Exploration of object recognition from 3D poin...   \n",
              "4    Brain MRI Image Super Resolution using Phase S...   \n",
              "..                                                 ...   \n",
              "495  An Affinity Propagation Based method for Vecto...   \n",
              "496  A Fast Hierarchical Multilevel Image Segmentat...   \n",
              "497  Some Aspects of Testing Process for Transport ...   \n",
              "498             Spatio-activity based object detection   \n",
              "499  Discrete schemes for Gaussian curvature and th...   \n",
              "\n",
              "                                              abstract  \\\n",
              "0    This paper has been withdrawn by the author al...   \n",
              "1    Matching pursuit and K-SVD is demonstrated in ...   \n",
              "2    This article provides a step by step developme...   \n",
              "3    We present our latest experiment results of ob...   \n",
              "4    A hallucination-free and computationally effic...   \n",
              "..                                                 ...   \n",
              "495  In this paper, we firstly modify a parameter i...   \n",
              "496  This paper proposes a novel method for segment...   \n",
              "497  This paper presents some aspects related to th...   \n",
              "498  We present the SAMMI lightweight object detect...   \n",
              "499  In this paper, several discrete schemes for Ga...   \n",
              "\n",
              "                                               authors  \\\n",
              "0               Ahmad Reza Eskandari, Ali Pourmohammad   \n",
              "1          Arthur Szlam, Koray Kavukcuoglu, Yann LeCun   \n",
              "2                                        Anish Acharya   \n",
              "3                                             Lin Duan   \n",
              "4                             Sifeng He, Bahram Jalali   \n",
              "..                                                 ...   \n",
              "495               Wu Jiang, Fei Ding, Qiao-liang Xiang   \n",
              "496  Sreechakra Goparaju, Jayadev Acharya, Ajoy K. ...   \n",
              "497                      Radu Arsinte, Ciprian Ilioaei   \n",
              "498                   Jarrad Springett, Jeroen Vendrig   \n",
              "499                           Zhiqiang Xu, Guoliang Xu   \n",
              "\n",
              "                           tags  \\\n",
              "0                         cs.CV   \n",
              "1                         cs.CV   \n",
              "2                         cs.CV   \n",
              "3                         cs.CV   \n",
              "4                         cs.CV   \n",
              "..                          ...   \n",
              "495                       cs.CV   \n",
              "496                       cs.CV   \n",
              "497                cs.CV, cs.MM   \n",
              "498                       cs.CV   \n",
              "499  cs.CV, cs.CG, cs.GR, cs.NA   \n",
              "\n",
              "                                              keywords  \n",
              "0                              Paper, Ali Pourmohammad  \n",
              "1       Matching Pursuit, K-SVD, Translation invariant  \n",
              "2    ObjectDetection, HOG, Feature Pyramid, Templat...  \n",
              "3       Object Recognition, 3D Point Cloud, Moving Car  \n",
              "4         Brain MRI, Algorithm, Resolution Enhancement  \n",
              "..                                                 ...  \n",
              "495             AIAP, IAP-LBG, Vector Quantization, VQ  \n",
              "496  Hierarchical Multilevel Thresholding, Image Se...  \n",
              "497  DVB-T, Terrestrial Digital Video Broadcasting,...  \n",
              "498  SAMMI, Object Detection, DCT, Mixture of Gauss...  \n",
              "499  Gaussian Curvature, Dense Schemes, Valence Con...  \n",
              "\n",
              "[500 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e235a4bb-6a59-4ede-a6cd-8391473bdacb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>tags</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Recognition of Regular Shapes in Satelite Images</td>\n",
              "      <td>This paper has been withdrawn by the author al...</td>\n",
              "      <td>Ahmad Reza Eskandari, Ali Pourmohammad</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>Paper, Ali Pourmohammad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Convolutional Matching Pursuit and Dictionary ...</td>\n",
              "      <td>Matching pursuit and K-SVD is demonstrated in ...</td>\n",
              "      <td>Arthur Szlam, Koray Kavukcuoglu, Yann LeCun</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>Matching Pursuit, K-SVD, Translation invariant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Template Matching based Object Detection Using...</td>\n",
              "      <td>This article provides a step by step developme...</td>\n",
              "      <td>Anish Acharya</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>ObjectDetection, HOG, Feature Pyramid, Templat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Exploration of object recognition from 3D poin...</td>\n",
              "      <td>We present our latest experiment results of ob...</td>\n",
              "      <td>Lin Duan</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>Object Recognition, 3D Point Cloud, Moving Car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brain MRI Image Super Resolution using Phase S...</td>\n",
              "      <td>A hallucination-free and computationally effic...</td>\n",
              "      <td>Sifeng He, Bahram Jalali</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>Brain MRI, Algorithm, Resolution Enhancement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>An Affinity Propagation Based method for Vecto...</td>\n",
              "      <td>In this paper, we firstly modify a parameter i...</td>\n",
              "      <td>Wu Jiang, Fei Ding, Qiao-liang Xiang</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>AIAP, IAP-LBG, Vector Quantization, VQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>A Fast Hierarchical Multilevel Image Segmentat...</td>\n",
              "      <td>This paper proposes a novel method for segment...</td>\n",
              "      <td>Sreechakra Goparaju, Jayadev Acharya, Ajoy K. ...</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>Hierarchical Multilevel Thresholding, Image Se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Some Aspects of Testing Process for Transport ...</td>\n",
              "      <td>This paper presents some aspects related to th...</td>\n",
              "      <td>Radu Arsinte, Ciprian Ilioaei</td>\n",
              "      <td>cs.CV, cs.MM</td>\n",
              "      <td>DVB-T, Terrestrial Digital Video Broadcasting,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Spatio-activity based object detection</td>\n",
              "      <td>We present the SAMMI lightweight object detect...</td>\n",
              "      <td>Jarrad Springett, Jeroen Vendrig</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>SAMMI, Object Detection, DCT, Mixture of Gauss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Discrete schemes for Gaussian curvature and th...</td>\n",
              "      <td>In this paper, several discrete schemes for Ga...</td>\n",
              "      <td>Zhiqiang Xu, Guoliang Xu</td>\n",
              "      <td>cs.CV, cs.CG, cs.GR, cs.NA</td>\n",
              "      <td>Gaussian Curvature, Dense Schemes, Valence Con...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e235a4bb-6a59-4ede-a6cd-8391473bdacb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e235a4bb-6a59-4ede-a6cd-8391473bdacb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e235a4bb-6a59-4ede-a6cd-8391473bdacb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df9c18cf-e0c4-4451-9a18-1b9915684ee3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df9c18cf-e0c4-4451-9a18-1b9915684ee3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df9c18cf-e0c4-4451-9a18-1b9915684ee3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_973b5dcc-e9b3-4983-bfd4-a47483658c3f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_973b5dcc-e9b3-4983-bfd4-a47483658c3f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"ODMTCNet: An Interpretable Multi-view Deep Neural Network Architecture\\n  for Image Feature Representation\",\n          \"General Theory of Image Normalization\",\n          \"Baseline Computation for Attribution Methods Based on Interpolated\\n  Inputs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"We rephrase the problem of 3D reconstruction from images in terms of\\nintersections of projections of orbits of custom built Lie groups actions. We\\nthen use an algorithmic method based on moving frames \\\"a la Fels-Olver\\\" to\\nobtain a fundamental set of invariants of these groups actions. The invariants\\nare used to define a set of equations to be solved by the points of the 3D\\nobject, providing a new technique for recovering 3D structure from motion.\",\n          \"This paper presents an invariant under scaling and linear brightness change.\\nThe invariant is based on differentials and therefore is a local feature.\\nRotationally invariant 2-d differential Gaussian operators up to third order\\nare proposed for the implementation of the invariant. The performance is\\nanalyzed by simulating a camera zoom-out.\",\n          \"In this work, we use a deep learning framework for simultaneous\\nclassification and regression of Parkinson disease diagnosis based on MR-Images\\nand personal information (i.e. age, gender). We intend to facilitate and\\nincrease the confidence in Parkinson disease diagnosis through our deep\\nlearning framework.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 472,\n        \"samples\": [\n          \"Jiang Yu Zheng\",\n          \"B. R. Schlei, L. Prasad\",\n          \"Douglas Summers-Stay\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"cs.CV, cs.LG, 20-08 Computational methods for problems pertaining to group theory\",\n          \"cs.CV, I.4.8; I.5.1\",\n          \"cs.CV, 28A80, 68U10, 94A08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"Movement Inequality, Frobenius Theorem, Linear Algebra\",\n          \"Rotationally Invariant, Gaussian Operators, Scaling, Linear Brightness\",\n          \"Deep Learning, Parkinson Disease, MR-Images, Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Кол-во публикаций:\", len(df))\n",
        "print(\"Средняя длина аннотации:\", df[\"abstract\"].apply(lambda x: len(x.split())).mean())\n",
        "all_keywords = [kw for kws in df[\"keywords\"].str.split(\",\") for kw in kws]\n",
        "print(\"Уникальных ключевых слов:\", len(set(all_keywords)))\n",
        "pd.Series(all_keywords).value_counts().head(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "m4Kl-yZsTnvr",
        "outputId": "50846d76-10f2-45ce-cf99-5cf26966a72e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во публикаций: 500\n",
            "Средняя длина аннотации: 50.628\n",
            "Уникальных ключевых слов: 1580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Computer Vision                  19\n",
              " Algorithms                       14\n",
              " CNN                              14\n",
              "Deep Learning                     11\n",
              " Image Processing                  9\n",
              " Machine Learning                  7\n",
              " Deep Learning                     7\n",
              " MNIST                             6\n",
              " Melanoma Detection                6\n",
              " Object Detection                  6\n",
              " Convolutional Neural Networks     6\n",
              " CNNs                              6\n",
              " Convolutional Neural Network      6\n",
              " SVM                               6\n",
              " Neural Networks                   6\n",
              " Algorithm                         5\n",
              " Image Segmentation                5\n",
              "Convolutional Neural Network       5\n",
              "ArXiv                              5\n",
              "Convolutional Neural Networks      5\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Computer Vision</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Algorithms</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNN</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Deep Learning</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image Processing</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Machine Learning</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Deep Learning</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MNIST</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Melanoma Detection</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Object Detection</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Convolutional Neural Networks</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNNs</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Convolutional Neural Network</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Networks</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Algorithm</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image Segmentation</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Convolutional Neural Network</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ArXiv</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Convolutional Neural Networks</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сохранение результата"
      ],
      "metadata": {
        "id": "PUyD3L04qXrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=\"title\", inplace=True)\n",
        "print(\"Уникальных публикаций:\", len(df))\n",
        "\n",
        "df.to_csv(\"multimedia_250.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_hGURplH7dK",
        "outputId": "d6af2ea9-686b-42ab-b831-e503dd0a8843"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уникальных публикаций: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Построение графа ключевых слов\n",
        "\n",
        "Граф: узлы = ключевые слова, ребро между двумя словами если они встречаются в одной статье.\n",
        "Вес ребра = количество совместных появлений.\n",
        "\n",
        "Далее строим взвешенный граф и выполняем кластеризацию.\n"
      ],
      "metadata": {
        "id": "j_NTlLkHJ7uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from itertools import combinations, chain\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from operator import itemgetter\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "JJRByA7KH7al"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"multimedia_250.csv\")\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "01WONuBDH7YC",
        "outputId": "60f488fa-776f-4bd7-f633-de31d2fcad70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "260                                     Title Redacted   \n",
              "164  Massively Deep Artificial Neural Networks for ...   \n",
              "317                 Pose Estimation Based on 3D Models   \n",
              "15       Kunchenko's Polynomials for Template Matching   \n",
              "297  Motion-Based Handwriting Recognition and Word ...   \n",
              "\n",
              "                                              abstract  \\\n",
              "260  arXiv admin note: This version removed by arXi...   \n",
              "164  Greedy Restrictive Boltzmann Machines yield an...   \n",
              "317  In this paper, we proposed a pose estimation s...   \n",
              "15   This paper reviews Kunchenko's polynomials usi...   \n",
              "297  In this project, we leverage a trained single-...   \n",
              "\n",
              "                                               authors                 tags  \\\n",
              "260  Shivang Bharadwaj, Bhupendra Niranjan, Anant K...                cs.CV   \n",
              "164                                      Keiron O'Shea  cs.CV, cs.LG, cs.NE   \n",
              "317                      Chuiwen Ma, Hao Su, Liang Shi  cs.CV, cs.LG, cs.RO   \n",
              "15                         Oleg Chertov, Taras Slipets         cs.CV, I.5.4   \n",
              "297           Junshen Kevin Chen, Wanze Xie, Yutong He                cs.CV   \n",
              "\n",
              "                                              keywords  \n",
              "260                     arXiv, Administrators, License  \n",
              "164  Greedy Restrictive Boltzmann Machines, MNIST, GPU  \n",
              "317  Pose Estimation System, Image Training Set, Pa...  \n",
              "15   Kunchenko's Polynomials, Template Matching, Cr...  \n",
              "297  Single-letter classifier, Dynamic Programming,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f409c1ac-a6e0-4c79-aafe-db040f8210fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>tags</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>Title Redacted</td>\n",
              "      <td>arXiv admin note: This version removed by arXi...</td>\n",
              "      <td>Shivang Bharadwaj, Bhupendra Niranjan, Anant K...</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>arXiv, Administrators, License</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Massively Deep Artificial Neural Networks for ...</td>\n",
              "      <td>Greedy Restrictive Boltzmann Machines yield an...</td>\n",
              "      <td>Keiron O'Shea</td>\n",
              "      <td>cs.CV, cs.LG, cs.NE</td>\n",
              "      <td>Greedy Restrictive Boltzmann Machines, MNIST, GPU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>Pose Estimation Based on 3D Models</td>\n",
              "      <td>In this paper, we proposed a pose estimation s...</td>\n",
              "      <td>Chuiwen Ma, Hao Su, Liang Shi</td>\n",
              "      <td>cs.CV, cs.LG, cs.RO</td>\n",
              "      <td>Pose Estimation System, Image Training Set, Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Kunchenko's Polynomials for Template Matching</td>\n",
              "      <td>This paper reviews Kunchenko's polynomials usi...</td>\n",
              "      <td>Oleg Chertov, Taras Slipets</td>\n",
              "      <td>cs.CV, I.5.4</td>\n",
              "      <td>Kunchenko's Polynomials, Template Matching, Cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>Motion-Based Handwriting Recognition and Word ...</td>\n",
              "      <td>In this project, we leverage a trained single-...</td>\n",
              "      <td>Junshen Kevin Chen, Wanze Xie, Yutong He</td>\n",
              "      <td>cs.CV</td>\n",
              "      <td>Single-letter classifier, Dynamic Programming,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f409c1ac-a6e0-4c79-aafe-db040f8210fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f409c1ac-a6e0-4c79-aafe-db040f8210fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f409c1ac-a6e0-4c79-aafe-db040f8210fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d33dd1e9-e375-45ef-9da4-de31eedf2a61\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d33dd1e9-e375-45ef-9da4-de31eedf2a61')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d33dd1e9-e375-45ef-9da4-de31eedf2a61 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Massively Deep Artificial Neural Networks for Handwritten Digit\\n  Recognition\",\n          \"Motion-Based Handwriting Recognition and Word Reconstruction\",\n          \"Pose Estimation Based on 3D Models\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Greedy Restrictive Boltzmann Machines yield an fairly low 0.72% error rate on\\nthe famous MNIST database of handwritten digits. All that was required to\\nachieve this result was a high number of hidden layers consisting of many\\nneurons, and a graphics card to greatly speed up the rate of learning.\",\n          \"In this project, we leverage a trained single-letter classifier to predict\\nthe written word from a continuously written word sequence, by designing a word\\nreconstruction pipeline consisting of a dynamic-programming algorithm and an\\nauto-correction model. We conduct experiments to optimize models in this\\npipeline, then employ domain adaptation to explore using this pipeline on\\nunseen data distributions.\",\n          \"In this paper, we proposed a pose estimation system based on rendered image\\ntraining set, which predicts the pose of objects in real image, with knowledge\\nof object category and tight bounding box. We developed a patch-based\\nmulti-class classification algorithm, and an iterative approach to improve the\\naccuracy. We achieved state-of-the-art performance on pose estimation task.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Keiron O'Shea\",\n          \"Junshen Kevin Chen, Wanze Xie, Yutong He\",\n          \"Chuiwen Ma, Hao Su, Liang Shi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"cs.CV, cs.LG, cs.NE\",\n          \"cs.CV, I.5.4\",\n          \"cs.CV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Greedy Restrictive Boltzmann Machines, MNIST, GPU\",\n          \"Single-letter classifier, Dynamic Programming, Auto-Correction, Domain Adaptation\",\n          \"Pose Estimation System, Image Training Set, Patch-based, Multi-class Classification, Tight Bounding Box\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "klist = [[word.strip() for word in keywords.split(\",\") if word]\n",
        "         for keywords in df[\"keywords\"].tolist()]\n",
        "klist[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA9LRyJEH7Vh",
        "outputId": "97425175-2df6-4995-9e71-5f7b66ea4999"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Paper', 'Ali Pourmohammad'],\n",
              " ['Matching Pursuit', 'K-SVD', 'Translation invariant'],\n",
              " ['ObjectDetection', 'HOG', 'Feature Pyramid', 'Template Matching']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = list(chain(*[list(combinations(words, 2)) for words in klist]))\n",
        "edges = [tuple(sorted(edge)) for edge in edges]\n",
        "weighted_edges = [(edge[0], edge[1], {\"weight\": edges.count(edge)}) for edge in set(edges)]\n",
        "weighted_edges[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxRMXoT0H7S-",
        "outputId": "a8458357-7bf0-4a13-9093-b3cf31392d97"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Affine Transformation', 'Logarithmic Model', {'weight': 1}),\n",
              " ('MTL', 'Multi-Task-Learning', {'weight': 1}),\n",
              " ('Dempster-Shafer', 'Stochastic Relaxation', {'weight': 1}),\n",
              " ('Covariance Matrices', 'SVM', {'weight': 1}),\n",
              " ('CNN', 'LSTM', {'weight': 2}),\n",
              " ('Contextual Clues', 'Object Recognition', {'weight': 1}),\n",
              " ('Computer Vision', 'U-net', {'weight': 1}),\n",
              " ('Convolutional NeuralNetwork', 'Skin Lesion Analysis', {'weight': 1}),\n",
              " ('Object Detection', 'Open Images Challenge', {'weight': 1}),\n",
              " ('Long Short-Term Memory', 'Object Detection', {'weight': 1})]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(edges)), len(weighted_edges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQKsTSxcH7Qa",
        "outputId": "e3a34678-f9cf-45f0-a044-f1868e9a8e3d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2748, 2748)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "G.add_edges_from(weighted_edges)\n",
        "nx.draw(G, with_labels=False, font_weight='bold', node_size=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "-2LDZLkTH7N8",
        "outputId": "63c6801e-f268-40ae-f4ec-af1f0d1be38b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кластеризация (Louvain) и визуализация\n",
        "\n",
        "- Находим сообщества Louvain.\n",
        "- Выводим число кластеров и модульность.\n",
        "- Визуализируем топ-3 сообщества статично (matplotlib) и интерактивно (Plotly).\n"
      ],
      "metadata": {
        "id": "0Gnq08q3qyjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "communities = nx.community.louvain_communities(G, resolution=0.9)\n",
        "print(f\"# of clusters: {len(communities)}, Modularity: {nx.community.modularity(G, communities)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5wxtVlQH7La",
        "outputId": "2009be24-ef17-4770-89cb-ef7cd41923c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of clusters: 248, Modularity: 0.9265888253241004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comm_data = [{\"n_of_nodes\": len(comm), \"nodes\": comm} for comm in communities]\n",
        "cdf = pd.DataFrame(comm_data)\n",
        "cdf.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Hcs7vVwQH7I6",
        "outputId": "d5ba0e51-c552-40ba-e21b-103edd931a1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       n_of_nodes\n",
              "count  248.000000\n",
              "mean     6.173387\n",
              "std     11.663908\n",
              "min      2.000000\n",
              "25%      3.000000\n",
              "50%      4.000000\n",
              "75%      4.000000\n",
              "max    118.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-793eb8e8-2a7e-47d1-8b41-876ff95038da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_of_nodes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>248.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.173387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.663908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>118.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-793eb8e8-2a7e-47d1-8b41-876ff95038da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-793eb8e8-2a7e-47d1-8b41-876ff95038da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-793eb8e8-2a7e-47d1-8b41-876ff95038da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c19fb47-9708-49c1-ba78-6e400234c51e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c19fb47-9708-49c1-ba78-6e400234c51e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c19fb47-9708-49c1-ba78-6e400234c51e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"cdf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"n_of_nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.41250923044912,\n        \"min\": 2.0,\n        \"max\": 248.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          248.0,\n          6.173387096774194,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top3_comm = cdf.nlargest(3, \"n_of_nodes\")\n",
        "top3_comm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "XxD8qwrwH7Gj",
        "outputId": "19f36aab-f058-409f-a000-81a8b5c0d002"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     n_of_nodes                                              nodes\n",
              "87          118  {Artificial Neural Networks, Algonauts, CNN+Tr...\n",
              "103          64  {Single-view Metrology, CycleGAN, Omnidirectio...\n",
              "202          61  {Image Augmentation, Ensemble Methods, Gelomet..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c07a42fd-86e8-43c4-b24a-87559c3fe942\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_of_nodes</th>\n",
              "      <th>nodes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>118</td>\n",
              "      <td>{Artificial Neural Networks, Algonauts, CNN+Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>64</td>\n",
              "      <td>{Single-view Metrology, CycleGAN, Omnidirectio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>61</td>\n",
              "      <td>{Image Augmentation, Ensemble Methods, Gelomet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c07a42fd-86e8-43c4-b24a-87559c3fe942')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c07a42fd-86e8-43c4-b24a-87559c3fe942 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c07a42fd-86e8-43c4-b24a-87559c3fe942');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b7925fd7-adfd-4e5f-8a6f-6d1f27812d3f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7925fd7-adfd-4e5f-8a6f-6d1f27812d3f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b7925fd7-adfd-4e5f-8a6f-6d1f27812d3f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7b9b382c-c1a0-46c9-90ec-57ae9375c72c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top3_comm')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7b9b382c-c1a0-46c9-90ec-57ae9375c72c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top3_comm');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top3_comm",
              "summary": "{\n  \"name\": \"top3_comm\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"n_of_nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 61,\n        \"max\": 118,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          118,\n          64,\n          61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nodes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = list(chain(*top3_comm[\"nodes\"].tolist()))\n",
        "S = G.subgraph(nodes)"
      ],
      "metadata": {
        "id": "NUDV0c76H7ER"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, nodes in enumerate(top3_comm[\"nodes\"], start=1):\n",
        "    sub_keywords = [kw for kw in nodes]\n",
        "    print(f\"\\nКластер {i}, размер: {len(nodes)}\")\n",
        "    print(pd.Series(sub_keywords).value_counts().head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKRzDEMsT5Uq",
        "outputId": "ff7d98c5-6cbf-4c4c-a502-1148c3c299a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Кластер 1, размер: 118\n",
            "Artificial Neural Networks    1\n",
            "Algonauts                     1\n",
            "CNN+Transformer               1\n",
            "Cyclic Convolutional Layer    1\n",
            "EscherNet 101                 1\n",
            "U-Net                         1\n",
            "Biomedical Images             1\n",
            "X-ray computed tomography     1\n",
            "Pytorch                       1\n",
            "Diagnosis                     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Кластер 2, размер: 64\n",
            "Single-view Metrology         1\n",
            "CycleGAN                      1\n",
            "Omnidirectional Video         1\n",
            "Hand Pose Recognition         1\n",
            "Satellite Image               1\n",
            "Macaque IT                    1\n",
            "Line Detection                1\n",
            "Hyperspectral Imagery         1\n",
            "Image-to-Image Translation    1\n",
            "Image-level Classification    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Кластер 3, размер: 61\n",
            "Image Augmentation            1\n",
            "Ensemble Methods              1\n",
            "Gelometric Model              1\n",
            "Feature Transformations       1\n",
            "Metropolis-Hastings Method    1\n",
            "FDDB                          1\n",
            "Accuracy                      1\n",
            "Circle Fitting                1\n",
            "Watershed                     1\n",
            "Topological Constraints       1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_community_node_colors(graph, communities):\n",
        "    colors = list(set(mcolors.TABLEAU_COLORS.values()))\n",
        "    node_colors = []\n",
        "    for node in graph:\n",
        "        current_community_index = 0\n",
        "        for community in communities:\n",
        "            if node in community:\n",
        "                node_colors.append(colors[current_community_index])\n",
        "                break\n",
        "            current_community_index += 1\n",
        "    return node_colors"
      ],
      "metadata": {
        "id": "jWe1L1D7H7CA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_communities(graph, communities, i):\n",
        "    node_colors = create_community_node_colors(graph, communities)\n",
        "    title = f\"Visualization of Top-3 Communities\"\n",
        "    pos = nx.spring_layout(graph, iterations=100, seed=23)\n",
        "    plt.title(title)\n",
        "    nx.draw(\n",
        "        graph,\n",
        "        pos=pos,\n",
        "        node_size=50,\n",
        "        node_color=node_colors,\n",
        "        edge_color=\"gray\",\n",
        "        with_labels=False\n",
        "    )\n",
        "    plt.text(0.05, 0.95, \"Цвет = кластер\", transform=plt.gca().transAxes)\n",
        "\n",
        "\n",
        "visualize_communities(S, top3_comm[\"nodes\"].tolist(), 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "4ZlSgMrFKM7l",
        "outputId": "e376cbb1-f88b-4fa2-a5a5-688fe92ef8d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGbCAYAAABZBpPkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA4rxJREFUeJzsnXd8VFX6/993aiaZ9N4rJaGEXkSqoIhixd5Q1113dV33+9v+3XXd/W6v7urqqmt37V1sgAJSpYQQICQhvfee6XPP74+QkZCQTEKABM7b17xk7px7znNnJnM+9znPeR5FCCGQSCQSiURy3qI52wZIJBKJRCI5u0gxIJFIJBLJeY4UAxKJRCKRnOdIMSCRSCQSyXmOFAMSiUQikZznSDEgkUgkEsl5jhQDEolEIpGc50gxIJFIJBLJeY4UAxKJRCKRnOdIMXCe8fzzz6MoCqWlpaPOjiVLlrBkyZIzbsvZGnco1NXVsWbNGkJDQ1EUhUceeeRsmyQZJZSWlqIoCs8//7xX7RVF4eGHHz6tNknGHlIMjHGuuOIKfH196ejoOGmbW265BYPBQFNT0xm0bHSRm5vLww8/fNZF0HD5/ve/z2effcZPf/pTXnrpJVauXNmnzdq1a1EUZdDH2rVrT7u9VquVu+++m8mTJxMYGIjZbCYzM5N//OMfOJ1Or/upq6vjBz/4ARMnTsTX1xc/Pz9mzpzJb37zG1pbW0/fBYxxPv74YznhS4aEImsTjG1ef/11brzxRl544QVuv/32Pq9bLBYiIiJYtmwZH3zwAW63G6fTidFoRFGUs2BxN88//zx33nknJSUlJCUlAeBwOAAwGAwjPt5bb73Fddddx6ZNm/p4AU7nuCNFVFQUy5cv5+WXXz5pm507d1JUVOR5XlJSwkMPPcQ3v/lNFi5c6DmemprK/PnzT6u9zc3NrFq1ikWLFpGUlIRGo2HHjh28/PLL3HjjjbzyyiuD9rFnzx5WrVpFZ2cnt956KzNnzgRg7969vPbaa1xwwQWsX7/+tF7HWEAIgd1uR6/Xo9VqAbj//vv517/+RX8/7zabDZ1Oh06nO9OmSkYx8tswxrniiivw9/fnlVde6VcMvP/++3R1dXHLLbcAoNVqPT8Yo42zNRmPZhHQQ319PUFBQQO2mT9/fq9Jfu/evTz00EPMnz+fW2+99TRb2JuQkBB27drV69i9995LYGAgjz32GH/729+Iioo66fmtra1cffXVaLVa9u/fz8SJE3u9/tvf/pann376tNg+1lAUBR8fH6/bD6Wt5PxBLhOMcUwmE9dccw2ff/459fX1fV5/5ZVX8Pf354orrgD6X6vfu3cvl1xyCWFhYZhMJpKTk7nrrrs8r2/evBlFUdi8eXOvvvtbq8zJyWHt2rWkpKTg4+NDVFQUd911l1dLFCeu3SclJZ3U1d1jS1lZGd/5zneYMGECJpOJ0NBQrrvuul7X9/zzz3PdddcBsHTp0j599BczUF9fz913301kZCQ+Pj5kZmbywgsv9Hv9f/nLX3jqqadITU3FaDQye/Zs9uzZM+j1AhQXF3PdddcREhKCr68v8+bN46OPPuplu6IoCCH417/+5bH9VHjzzTeZOXMmJpOJsLAwbr31Vqqqqnq1Wbt2LWazmeLiYi655BL8/PyIiYnh17/+db93m97S4wUazMX/5JNPUlVVxd/+9rc+QgAgMjKSn//8572OPf7440yaNAmj0UhMTAz33Xdfn3GWLFnC5MmTycnJYfHixfj6+pKWlsZbb70FwJYtW5g7dy4mk4kJEyawcePGXuc//PDDKIpCQUEBt956K4GBgYSHh/OLX/wCIQQVFRVceeWVBAQEEBUVxV//+tde558sZqe/v7EeW3Nzc1m6dCm+vr7Exsbypz/9qde5J/4drl27ln/9618Avf5meugvZqCqqoq77rqLyMhIjEYjkyZN4tlnn+3zvj/66KNMmjQJX19fgoODmTVrlldeHsnoR3oGzgFuueUWXnjhBd544w3uv/9+z/Hm5mY+++wzbrrpJkwmU7/n1tfXc/HFFxMeHs5PfvITgoKCKC0t5Z133hmWLRs2bKC4uJg777yTqKgoDh8+zFNPPcXhw4fZtWvXkCayRx55hM7Ozl7H/v73v5OdnU1oaCjQ7UresWMHN954I3FxcZSWlvLEE0+wZMkScnNz8fX1ZdGiRTzwwAP885//5Gc/+xnp6ekAnv+fiNVqZcmSJRQWFnL//feTnJzMm2++ydq1a2ltbeV73/ter/avvPIKHR0dfOtb30JRFP70pz9xzTXXUFxcjF6vP+n11dXVccEFF2CxWHjggQcIDQ3lhRde4IorruCtt97i6quvZtGiRbz00kvcdtttrFixol/vz1DoWZ6ZPXs2v//976mrq+Mf//gH27dvZ//+/b28D263m5UrVzJv3jz+9Kc/8emnn/LLX/4Sl8vFr3/9a6/GczgctLe3Y7Va2bt3L3/5y19ITEwkLS1twPM++OADTCYTa9as8Wqchx9+mF/96lcsX76cb3/72+Tn5/PEE0+wZ88etm/f3utzaGlp4fLLL+fGG2/kuuuu44knnuDGG2/kv//9Lw8++CD33nsvN998M3/+859Zs2YNFRUV+Pv79xrvhhtuID09nT/84Q989NFH/OY3vyEkJIQnn3ySZcuW8cc//pH//ve//OAHP2D27NksWrTIq+s4kZaWFlauXMk111zD9ddfz1tvvcWPf/xjpkyZwqWXXtrvOd/61reorq5mw4YNvPTSS4OOUVdXx7x581AUhfvvv5/w8HA++eQT7r77btrb23nwwQcBePrpp3nggQdYs2YN3/ve97DZbOTk5PDVV19x8803D+v6JKMIIRnzuFwuER0dLebPn9/r+L///W8BiM8++8xz7LnnnhOAKCkpEUII8e677wpA7Nmz56T9b9q0SQBi06ZNvY6XlJQIQDz33HOeYxaLpc/5r776qgDEl19+eVI7hBBi8eLFYvHixSe144033hCA+PWvfz3geDt37hSAePHFFz3H3nzzzX6vob9xH3nkEQGIl19+2XPM4XCI+fPnC7PZLNrb23tdf2hoqGhubva0ff/99wUgPvzww5NeixBCPPjggwIQW7du9Rzr6OgQycnJIikpSbjdbs9xQNx3330D9ncie/bs6fX5OBwOERERISZPniysVqun3bp16wQgHnroIc+xO+64QwDiu9/9rueYqqrisssuEwaDQTQ0NHhlQ89n3/OYNWuWyMnJGfS84OBgkZmZ6dUY9fX1wmAwiIsvvrjXe/bYY48JQDz77LOeY4sXLxaAeOWVVzzH8vLyBCA0Go3YtWuX5/hnn33W5/v9y1/+UgDim9/8pueYy+UScXFxQlEU8Yc//MFzvKWlRZhMJnHHHXd4jvX3vRei/7+xHluP/x7b7XYRFRUlrr32Ws+x/v4O77vvPnGyn3dA/PKXv/Q8v/vuu0V0dLRobGzs1e7GG28UgYGBnr+xK6+8UkyaNKnfPiVjH7lMcA6g1Wq58cYb2blzZy/34yuvvEJkZCQXXXTRSc/tuRNct27dkKK8T8bxHgibzUZjYyPz5s0DICsra9j95ubmctddd3HllVf2cg8fP57T6aSpqYm0tDSCgoKGPd7HH39MVFQUN910k+eYXq/ngQceoLOzky1btvRqf8MNNxAcHOx53hOsV1xcPOg4c+bM4cILL/QcM5vNfPOb36S0tJTc3Nxh2X8y9u7dS319Pd/5znd6rRtfdtllTJw4sdfyRA/He5p67hwdDkcf9/nJWLp0KRs2bODNN9/k3nvvRa/X09XVNeh57e3tfe7GT8bGjRtxOBw8+OCDaDRf/6Tdc889BAQE9Lkus9nMjTfe6Hk+YcIEgoKCSE9PZ+7cuZ7jPf/u73P8xje+4fm3Vqtl1qxZCCG4++67PceDgoKYMGHCoN+DgTCbzb3iPQwGA3PmzDmlPo9HCMHbb7/N6tWrEULQ2NjoeVxyySW0tbV5/o6CgoKorKz0eglMMraQYuAcoSdAsGf9rrKykq1bt3LjjTcOGDC4ePFirr32Wn71q18RFhbGlVdeyXPPPYfdbh+WHc3NzXzve98jMjISk8lEeHg4ycnJALS1tQ2rz/b2dq655hpiY2N58cUXey01WK1WHnroIeLj4zEajYSFhREeHk5ra+uwxysrK2PcuHG9Jhb4elmhrKys1/GEhIRez3uEQUtLy6DjTJgwoc/xk41zqvT019+YEydO7DOeRqMhJSWl17Hx48cDeERnQ0MDtbW1nseJyzqRkZEsX76cNWvW8MQTT3D55ZezYsUKamtrB7Q1ICBgwO2y3lyXwWAgJSWlz3XFxcX1Wa4KDAwkPj6+zzHo/3M88TMPDAzEx8eHsLCwPscH+x4MRH+2BgcHn1Kfx9PQ0EBraytPPfUU4eHhvR533nkngCcW6cc//jFms5k5c+Ywbtw47rvvPrZv3z4idkjOPlIMnCPMnDmTiRMn8uqrrwLw6quvIoTwiISToSgKb731Fjt37uT+++/3BBLNnDnT88N+snV+t9vd59j111/P008/zb333ss777zD+vXr+fTTTwFQVXVY17Z27Vqqq6t57733CAgI6PXad7/7XX77299y/fXX88Ybb7B+/Xo2bNhAaGjosMcbKicTW+I82LU7e/ZsoqOjPY+//OUvA7Zfs2YNnZ2dvP/++wO2mzhxIgUFBZ5tnyPJyT6voXyO/bX15vyh/C0N1abh0PM3cuutt7Jhw4Z+HwsWLAC6RWp+fj6vvfYaF154IW+//TYXXnghv/zlL0fEFsnZRQYQnkPccsst/OIXvyAnJ4dXXnmFcePGMXv2bK/OnTdvHvPmzeO3v/0tr7zyCrfccguvvfYa3/jGNzx3uidGZp94x9XS0sLnn3/Or371Kx566CHP8aNHjw77mv7whz/w3nvv8c477/QbVf7WW29xxx139IrattlsfWwdSuBiYmIiOTk5qKrayzuQl5fneX0kSExMJD8/v8/xkR7n+PEA8vPzWbZsWa/X8vPz+4ynqirFxcUebwBAQUEB8PWugP/+979YrVbP6yd6Ek6kp+1gXpvVq1ezc+dO3n777V7LNf1x/HUdP77D4aCkpITly5cPeP6ZxNu/pVPF2+97eHg4/v7+uN1ur94nPz8/brjhBm644QYcDgfXXHMNv/3tb/npT38qtyyOcaRn4Byixwvw0EMPkZ2dPahXALon8BPvMqZNmwbgWSpITExEq9Xy5Zdf9mr3+OOP93recxdzYn/DTZ27ceNGfv7zn/O///u/XHXVVf220Wq1fcZ79NFH+9xp+fn5AYNvaQNYtWoVtbW1vP76655jLpeLRx99FLPZzOLFi4d2IQOMs3v3bnbu3Ok51tXVxVNPPUVSUhIZGRkjMk4Ps2bNIiIign//+9+9loE++eQTjhw5wmWXXdbnnMcee8zzbyEEjz32GHq93hOHsmDBApYvX+559EzGjY2N/d69/uc///HYMhD33nsv0dHR/L//9/88AuR46uvr+c1vfgPA8uXLMRgM/POf/+w15jPPPENbW1u/13W2SE1NBej1t+R2u3nqqadGdBxvv+9arZZrr72Wt99+m0OHDvV5vaGhwfPvE7cHGwwGMjIyEEKMSLyR5OwiPQPnEMnJyVxwwQUeF6w3YuCFF17g8ccf5+qrryY1NZWOjg6efvppAgICWLVqFdC97nndddfx6KOPoigKqamprFu3rk9eg4CAABYtWsSf/vQnnE4nsbGxrF+/npKSkmFdz0033UR4eDjjxo3rk3lvxYoVREZGcvnll/PSSy8RGBhIRkYGO3fuZOPGjZ6thz1MmzYNrVbLH//4R9ra2jAajSxbtoyIiIg+437zm9/kySefZO3atezbt4+kpCTeeusttm/fziOPPOJ1YNtg/OQnP+HVV1/l0ksv5YEHHiAkJIQXXniBkpIS3n777T4xC6eKXq/nj3/8I3feeSeLFy/mpptu8mwtTEpK4vvf/36v9j4+Pnz66afccccdzJ07l08++YSPPvqIn/3sZ4SHhw841ssvv8y///1vrrrqKlJSUujo6OCzzz5jw4YNrF69uo9n4kSCg4N59913WbVqFdOmTeuVgTArK4tXX33Vk2ApPDycn/70p/zqV79i5cqVXHHFFeTn5/P4448ze/bsM55waSAmTZrEvHnz+OlPf0pzczMhISG89tpruFyuER2n57164IEHuOSSSzxBxv3xhz/8gU2bNjF37lzuueceMjIyaG5uJisri40bN9Lc3AzAxRdfTFRUFAsWLCAyMpIjR47w2GOPcdlll43Y34TkLHIWdjBITiP/+te/BCDmzJnT7+snbm3KysoSN910k0hISBBGo1FERESIyy+/XOzdu7fXeQ0NDeLaa68Vvr6+Ijg4WHzrW98Shw4d6rOlqbKyUlx99dUiKChIBAYGiuuuu05UV1f32c7kzdZCjtuSduKjZwtWS0uLuPPOO0VYWJgwm83ikksuEXl5eSIxMbHXli4hhHj66adFSkqK0Gq1vfrob0tjXV2dp1+DwSCmTJnS6zqF+HpL15///Oc+7/OJ13syioqKxJo1a0RQUJDw8fERc+bMEevWreu3v1PdWtjD66+/LqZPny6MRqMICQkRt9xyi6isrOzV5o477hB+fn6iqKhIXHzxxcLX11dERkaKX/7yl7227w009nXXXef5Xvn5+YkZM2aIv/3tb8LpdHp9DdXV1eL73/++GD9+vPDx8RG+vr5i5syZ4re//a1oa2vr1faxxx4TEydOFHq9XkRGRopvf/vboqWlpVebxYsX97s9LjExUVx22WV9jp/4vvdsLTxxa2XP+3Ui/Y1XVFQkli9fLoxGo4iMjBQ/+9nPxIYNG/rdWtifrXfccYdITEz0PO9va6HL5RLf/e53RXh4uFAUpdc2w/6+m3V1deK+++4T8fHxQq/Xi6ioKHHRRReJp556ytPmySefFIsWLRKhoaHCaDSK1NRU8cMf/rDP5yAZm8jaBBKJpA9r167lrbfe6rM7QCKRnJvImAGJRCKRSM5zpBiQSCQSieQ8R4oBiUQikUjOc2TMgEQikUgk5znSMyCRSCQSyXmOFAMSiUQikZznSDEgkUgkEsl5jhQDEolEIpGc50gxIJFIJBLJeY4UAxKJRCKRnOdIMSCRSCQSyXmOFAMSiUQikZznSDEgkUgkEsl5jhQDEolEIpGc50gxIJFIJBLJeY4UAxKJRCKRnOeMOjGwdu1arrrqqj7HN2/ejKIotLa2nnGbJBKJRCI5lxl1YkAikUgkEsmZZUyLAUVRPI+AgABWrFhBUVGR53W73c4PfvADYmNj8fPzY+7cuWzevBn42tNwssfptPm9994DQAjB7bffztSpU2lpafG0KS0t7demHq9IUVERV155JZGRkZjNZmbPns3GjRt7jWO32/nxj39MfHw8RqORtLQ0nnnmmZP23fMoLS0F4NChQ1x66aWYzWYiIyO57bbbaGxs9PS/ZMkS7r//fu6//34CAwMJCwvjF7/4BbIitkQikYw9xrQYAHjuueeoqanhyy+/pL6+np/97Gee1+6//3527tzJa6+9Rk5ODtdddx0rV67k6NGjXHDBBdTU1FBTU8Pbb78N4HleU1Nz0vF6JsiTPSZNmuS17Q888AA7duxg/fr1BAcHe473TKgbN27sZV8PnZ2drFq1is8//5z9+/ezcuVKVq9eTXl5uafN7bffzquvvso///lPjhw5wpNPPonZbCY+Pt5zjbt37wZg9+7dnmPx8fG0traybNkypk+fzt69e/n000+pq6vj+uuv72XHCy+8gE6nY/fu3fzjH//gb3/7G//5z3+8vn6JRCKRjA50Z9uAUyUoKIioqChMJhP+/v4EBgYCUF5eznPPPUd5eTkxMTEA/OAHP+DTTz/lueee43e/+x1RUVEAhISEAHieD8R//vMfrFbrSV/X6/Ve2f3zn/+cd999l23btvUZ1+l0euyJiory2NdDZmYmmZmZnuf/93//x7vvvssHH3zA/fffT0FBAW+88QYbNmxg+fLlAKSkpHja94xns9kACA8P72XDY489xvTp0/nd737nOfbss88SHx9PQUEB48ePByA+Pp6///3vKIrChAkTOHjwIH//+9+55557vHoPJBKJRDI6GPNi4KabbkKr1WKxWJgyZQq///3vATh48CBut9szcfVgt9sJDQ0d9nixsbGnZC90T7aff/45y5YtIykpqc/r7e3tAPj5+fV7fmdnJw8//DAfffQRNTU1uFwurFarxzOQnZ2NVqtl8eLFw7LvwIEDbNq0CbPZ3Oe1oqIiz3s6b968Xksq8+fP569//StutxutVjussSUSiURy5hnzYuDvf/87y5cvp7W1lf/93/9l7dq1fPjhh3R2dqLVatm3b1+fiam/Sc5bLr30UrZu3XrS1xMTEzl8+PCAfezevZuPP/6YtWvX8uSTT/Ktb32r1+vV1dVoNJqTeip+8IMfsGHDBv7yl7+QlpaGyWRizZo1OBwOAEwm0xCvqjednZ2sXr2aP/7xj31ei46OPqW+JRKJRDL6GPNiICoqirS0NAC++93vcsUVV+B0Opk+fTput5v6+noWLlw4YuONxDLBI488wqWXXsrjjz/OnXfeyaWXXkpCQoLn9T179jBx4kR8fHz6PX/79u2sXbuWq6++GuievHsC/wCmTJmCqqps2bLFs0wwFGbMmMHbb79NUlISOt3JvyJfffVVr+e7du1i3Lhx0isgkUgkY4xRKQba2trIzs7udaywsBDodv9Pnz7dc3ff2tpKbW0tbW1tPPPMM6SkpKDX6xk/fjy33HILt99+O3/961+ZPn06DQ0NfP7550ydOpXLLrtsWLaNxDJBTwzAtddey5tvvsk3vvEN1q9fj8Ph4PXXX+dvf/sbv/rVr056/rhx43jnnXdYvXo1iqLwi1/8AlVVPa8nJSVxxx13cNddd/HPf/6TzMxMysrKqK+v7xME2B/33XcfTz/9NDfddBM/+tGPCAkJobCwkNdee43//Oc/nsm+vLyc//mf/+Fb3/oWWVlZPProo/z1r389xXdHIpFIJGccMcq44447BDDgY9OmTUII0euYv7+/WLx4sdi/f7+nL4fDIR566CGRlJQk9Hq9iI6OFldffbXIycnpNeamTZvEmXorAPHuu+96njc0NIiIiAjx5JNPir1794qUlBTx+9//Xrjd7j72tbS0CCGEKCkpEUuXLhUmk0nEx8eLxx57TCxevFh873vf85xjtVrF97//fREdHS0MBoNIS0sTzz77bC9bSkpKBCBKSkr62FlQUCCuvvpqERQUJEwmk5g4caJ48MEHhaqqQgghFi9eLL7zne+Ie++9VwQEBIjg4GDxs5/9zPO6RCKRSMYOihBja2N4UlISzz//PEuWLDnbppzXLFmyhGnTpvHII4+cbVMkEolEcoqMuTwDGRkZpxQAKJFIJBKJpDejMmZgID7++OOzbYJEIpFIJOcUY26ZQCKRSCQSycgy5pYJJBKJRCKRjCxSDEgkEolEcp4jxcB5htPupqPZhq3LebZNkUgkEskoYcwFEEoGx251UZrTiK3TiY+fjsQpYXQ02di/oZyiffWoaneYSFRKAJkXJZA6I/y0lm2WSCQSyehGBhCeQ7idKjvfLeLQl1W4XSqKAkKARgOqoPv514kKPa9PWRrHwuvHSUEgkUgk5ylymeAcQXWrfPzvHA5sqsDt6p7xe2SeqgKitxA4/vWDmyrJ21lz5oyVSCQSyahCioFzhLxdtZQfbu5OzjwM9q8vRzqJJBKJ5PxEioFzhJwvKuAUvPwttRZaai0jZ5BEIpFIxgwygPAcwGFz0VTVdcr9yB0GEolEcn4iPQPnAKp7ZNz7JrN+RPqRSCQSydhCioFzAKNJh4/fKUzkCoTFmQmK9B05oyQSiUQyZpBi4BxA0ShMWhTDsHcGCph+SYLcWiiRSCTnKVIMnCNMXRqPj78BZQifaE/bWauSGD876vQYJpFIJJJRj0w6NEpxu1SK9zdQcqABh82NOdjIhHnRRKUEnPQOvqW2i3WPHqC9yeZJKNS911DBN0BP7PhgSg404nKqCASJk0LJvCiehIzQM3lpEolEIhllSDEwCqkraeejJ3Kwtjs8k7qiURCqIDotkFX3TsXnJMF+brdKaU4jR/fUYWl30GVvo9Z6lAd+cSdGowFVFWz7cgfbd2zlpz/7yRm+MolEIpGMRuQywSijuaaL9/6eha3DAXydJVAcqydQW9zGB//Mxu1U+z1fq9WQOj2Cld+cwjU/mMnKb07Boq+ltLQEAI1GITg0AIfTjt1uP/0XJJFIJJJRjxQDo4w9H5XgdqmczF8jVGgo7+Dovjqv+gsPDycsLIwjR454jvn7+wPQ0dFxyvZKJBKJZOwjxcAowtrpoCiroU8NgRNRFDi4ucrrftPT08nPz8ftdgNSDEgkEomkN1IMjCJa66ye5YCBEAKaqzu97jcjIwObzUZJSfdSgRQDEolEIjkeKQZGERqN9/v8h9I2MjKS4OBgz1KBwWDAaDRKMSCRSCQSQNYm6IXL4ebo3npKDzbisLrwD/Fh4vxootMCz0hCnpBYP/RGLU67e8B2igZixgd53a+iKKSnp5Odnc1ll12GRqPB399figGJRCKRAFIMeKg+2srHT+Rgt7i6q/8d2853ZEcNUamBrPr2FExmw2m1QW/Qkr4gmoObKweMGxAqTFkcN6S+MzIy2LFjB+Xl5SQlJeHv709np/dLDRKJRCI5dzlvxYDd6qLgq1oaqzqxd7koOdDw9Xr9Cdv56kra+PAf2Vz7o1lo9ad3ZWX2ZcmUHWyivcl20viBCfOiiM8IGVK/MTExBAQEkJub6xEDra2tI2CxRCKRSMY6513MgBCC7I3lPPfDbXz5WgFHttdQlFWP6hYDb+er6KQwq/602+fjp+eaH84kcdKxyV7p9lAACNzEzTCx7Pb0IS9b9CwVHDlyBCEEZrNZLhNIJBKJBDgPPQPZGyrY8U6h57k30fsAKHBwcyUT5p7+HP6+AQYuuy+T9kZrd/yCzY05yEhW4RYq2wuAud0GDZH09HS++uorKisrPTEDQghZoEgikUjOc84rz4C108Gu94qGd7LoThNcuO/0ewd6CAgzMXVpPLMuTWLi/GgWLb2QxsbGXgmEhkJ8fDx+fn7k5ubi7++Py+WSWQglEolEcn6JgbwdtainWIrhs6cPUXKgYYQsGhpxcXGkpKSwdetWhlNSQqPRMHHiRI4cOYLZbAZkrgGJRCKRnGdioKGiYxjO9b58+VqB98sLI8yiRYuoq6ujoKBgWOdnZGTQ1taG1WoFpBiQSCQSyTkeM9Bab6EitxmXUyUgzGfEJvDOFjsVR5pJmHTmS/8mJiaSkJDA1q1bGT9+/JDX+5OSkjCZTFRUVABSDEgkEonkHBUDHc02Nr2cR0VuM9CdpEeooDVoTrpjYCgoGmis7DwrYgC6vQMvv/wyxcXFpKamDulcjUbDhAkTyMvLw2QySTEgkUgkknNvmaCzxc5bf9xLZV6z51hPAh+3Y5AKQN4iGE4w/4iRkpJCTEwMW7duHdb5GRkZNDc3SzEgkUgkEuAcFAM73inE2uEctPLfqSAERCUHnL4BBkFRFBYtWkRZWRllZWVDPj8pKQlfNRyqYqjcDp+/kEvZoaazFgchkUgkkrPLObVMYGl3ULiv/vROagoERfgSnRZ0+sbwgvHjxxMZGcnWrVtJTEz0+ryOZhsf/esAvnUTEQgcQH5zHXk7awmKMHHZ/ZkERfiePsMlEolEMuo4pzwDdSVtp1UICAQaRWHprRPPeqIeRVFYuHAhRUVFVFVVeXWOrcvJu3/JornG0t0HCqB43rO2Rhvv/iULS7vjdJktkUgkklHIOSMGnA43+z4dust8MJTj0gGrGjuTrwggZlzQiI8zHNLT0wkNDfU6duDQlko6W05e80CoAmungwOfV4ykmRKJRCIZ5ZwTYkAIwWdPHaKutH3k+kTg1tpInRvCjEsSuOTeDNqi9rHjwEZU9TQGJAwBjUbDwoULyc/Pp7a2dsC2QggObqkadDeFUOHwl1W43aPjGiUSiURy+jknxEBVQStlh5o81QZPhR4vgDHETWvYfnIaNjBpWQRp06JYcOECbDYbX3zxxakPNEJMnjyZoKAgtm3bNmA7h82Npc0797/d6sLa7hwJ8yQSiUQyBjgnxMDhLytRRuBKwhP8mbI4lut+Oou7/u8iElPisFgsvPTSSzidTpYuXYrJZGLnzp2jJqe/Vqvlwgsv5PDhwzQ2Np603VBDHEbi/ZRIJBLJ2OCc+MlvqOg89a2EClz2naksvGE8EYkBaLVabrrpJsLCwmhoaODNN98E4PLLL0dVVd55551TN3yEyMzMxN/ff0DvgMFHR0i0n1f5EfxDffANMIyghRKJRCIZzZwTYkCjPbXIfoHAbmwg92hOrwJABoOBO+64A19fX44ePcrGjRvJyMggPDycgoIC6uvPXAXDgdDpdCxYsICcnBwa6pqoLW6jqqCFzpbe3oupy+IGX0pRYOrSuLO+W0IikUgkZw5FDKf83Sjjy1fzObS1etjbCnU+0BD8FW4cxMTEcNNNN3mq+gE0NTXx73//G5fLxVVXXUVMTAyPP/444eHhfOc73xmpyzglOtusPPO799B3RiDcX0/kiZNDmbM6mYjEANwulQ//mU310dZ+AwkVBSISA7jqf6ajM2jPoPWSs0VXVyG1dR/gcDSh1wUSEXEpAQFTzrZZEonkDHNOiIGG8g7e+N2eYZ8/c1Uik5ZG8Nprr1FdXY1Wq+XSSy9l5syZnjbl5eU8//zzANx5551s3bqVo0ePcv3115Oenn6ql3BK2LqcvPPnfbTUWfrc+Sua7pwEl9+fSXx6CE6Hm62vF5C3sxahCgQqPWsHgQlww/8sxuBzTuWikvSD09nG4cPfp6l5C4qipfs7IBDCTWDgTKZMfhSjMfJsmymRSM4QY36ZwGFz8eVr+afUh9bswN/fn2984xtcdtllCCFYt24dzzzzDF1dXQAkJCRw7bXXIoTgpZdeYvny5Wg0Gj788EPOtp768rUCWuut/S4BCBVUVfDJkwdx2FzoDVqW3ZbO2j8sYPFN41EimugKKCJ+hY1KZTduIXcRnOu43Tb277+NpubuGBMh3AjhQgg3AO3t2ezecw319Z/R2roXt9t6Ns2VSCRngDEvBja9lEddyXDzCwjcGjsff/kGjzzyCDk5OcycOZPvf//7xMXFUVlZyd///neys7MBmDRpEhdddBFOp5OXX36ZuXPnYrVa2bx580hdzpDparMPnoJZgNPmpuCrr3MR+AYYmLw4DnOqDZtfDePSk1FVld27d58BqyVnk+qaN+nozAXc/b4uhBuHo5aDh77Dvqwb2LptHkeP/g6Xq/PMGiqRSM4YY9of3N5opXDfqQTxKSy7NYPDFe3k5+fz3nvv8emnnzJv3jzWrl3LgQMH+Pjjj3n//ffZt28fN998MxdeeCFNTU1kZ2dTWlqK0Whk27ZtLFiwAIPhzEfgV+Q2ex0rUXygkcmL43odCwgIAAFdXV1MmzKDfZ+VULnJQFeLA51BQ9LUMKYsiSM83v90mC85C1RWvjik9m53J+UVz9Hcsp2ZM15Dp5PfBYnkXGNMxwxkfVbGrveKBs2qdzLmXZXCzJVJADgcDr744guysrJwOp1otVqmTJnCwoULee+996ioqECr1bJ69WqmTp3Kiy++SGlpqceDMHHiRG644YaRuzgvydlUydbXC7xqG5USwLU/mgVAc00XBzdVcnhHJcKloGgFGo0Wl9N9rGZBN4qmu3bBgjVpTFuecFquQXLmUFU7mzZnDPNsLTHRa0hP/92I2iSRSM4+Y3qZwNLh8GQMHDIKtBwr2APd2whXrlzJT3/6Uy655BJ8fHzIzs7msccew2AwsHz5cgDee+89nnvuOdasWUNISAiVlZWYTCby8vJobm4eicsaEuZgo1ftFA2YQ3wAKNxXz+v/t5vD26oRru73T7gV3E61lxAAPF6H7W8VnqIXRjL2cVNT+y5OZ9vZNkQikYwwY9ozsPfjEnavKxl2wiGNVuFb/1yMRtu/JsrPz2f9+vWeST4iIgIhBA0NDWi1WlauXMkXX3yB1dodYBURFMe0hMW01FrQaBVixwczYW4UBtPpW41xO1We+8k27F2uQduufiATk7+BN3+/d+jbMBUIifbjxl/MkTkIxjg7d63AYilhuPm7J09+jMiIS0fWKIlEclYZ02KgpbaLVx7+6pT6aIvbTWR0OLGxsURHRxMdHU1YWBgazdcCoa6ujo8++oiKiu5qfiaTCZvNhhCCmJgY6mrr8WlOwmSNRlFACDz/1+k1LLsjnXGzTt82rf0bytnxduFJX1c0CmFxZq77ySw+f+EIBXvqhp2T4YafzyYk2g+XQ0Vn1KIZrmdGctaorHyZ/IKHGa4YyEj/E9HR146oTRKJ5OwypsUAwAf/zKYid3jueYFKU9R2ULr34ve8FRqNhuDgYGJiYkhMTCQ6OpqIiAhsNhsff/wx+fn5qKrqOcfcOg6jNbKPi/14Vn1nKslTw4Zl56DXIQTb3yrkwOcVnjX+7usTKCgY/XQkTwsnOiWQLa/ko7qH/5FHpwVSW9yOUAUarcL4OZFkXhRPWJwMKhsruN029mXdSEfHyXcUDMT0aS8REnLByBsmkUjOGmNeDFTmNfP+I9lDPk/RKIyfE0HmZRE0NDTQ2NhIXV0dtbW1tLa29lum2Gw2ExYWRmxsLC0tLRQUFCCsBoIbZ/YzQm8Cwk3c+ut5p9XFXlPYysEtVVQcacZld+NyuhF0Cx2NRjklEeChOzfN10+PeQZW3JVxWr0fkpHF6Wzn4KEHaWnZwtehQ4OvtxmNUSy44MtjiYokEsm5wpjeWgjQVNXVZ4LyBiEE5iQnTU1N6PV64uLiSExMRKvVotFosFgstLW10dTURG1tLc3NzXR0dFBaWkppaamnH7M1CYGKMkgsZnuDleqCVmInBA/9Ik+wWwj6dc9HpwURnRZE3q4aPn/+CPT4KgQjIwSO9dXr6TEvxIZncwmO8iMsztzPSZLRhl4fgNv1bbL2BXP56kignYaGT48FB55cFCQnPyCFgERyDjLmxYDqFp71eW/oSb/bGZjPZ1saTmlsRVHQOEyDCoHuxt3b+YYqBjpb7NgtTupK28nbWUNtURtCQECYiSlLYslYENMrQNHpcPPla95tNRxpcr6oYNntZzc1s8Q7hBDs27ePhIQ5pE/s3hKbnHQfm7dchV7fyPEKW1G0COEmOfl7xMac+e2zEonk9DPmxUBwtK/3uwkUmDA7mqnL4gmNW4zb7R7w4XK5Bm2T/6mVztrBlYgQgp27dtKsRBAbG0tMTAy+vr4nbXt0bx3ZGypoKO/ot017o5XtbxdycEsVV//PdMzBx7YN7q3HaRv6OvCpIlRBwe46lt46cfjbPSVnjKqqKurq6jxbZgEKChrYs/tiLr88Cpf7cyyWMjQaPaGhi4mLu40A/8ln0WKJRHI6GfNiIGFSKL6BBixtjkHb3viLOYTGfO3G1ulO/fI1jSXs/ahkUM+EgkJ9Zyk1m3M9x/z9/YmLiyM6OpqYmBiio6MxmUxse+MoOZsqGTS8QEBHk5V1jx3ghv+dg6JRaChrR6MdXnxAT8DhcHG7VEoPNpI0NUxuPxzl7Nu3j6CgIFJTU4HuDJSffvopGRnTmD79WuC+s2ugRCI5o4x5MaDRKCxYk8aGZ3IHbJe+ILqXEBgpJl0Yw96PSwaMWRAIXPoO3HoLGo0GHx8fLBYLHR0dFBYWenYnAAQrSWir47vP82I+F2p33ERlXgvxGSGneDUCTkEMAHz8xEECwk0su20iseNPLT5Ccnqw2WwcOnSIRYsWeUTbZ599hhCCSy655CxbJ5FIzgZjOgNhD+NnR7H01olotEqvuazHXZ2+IJrFN084LWP7BRlZcO24k74uEKCodAYeBUBVVSyW7syHPUGLJpMJAJ1Wh6YprPucIaBoFPKPFSEKT/Q/hWDBkbmbb2+08sEj2VTlt4xIf5KR5cCBA6iqyvTp0wEoLCzk4MGDXHLJJZjNMgBUIjkfGfOegR4yLowheVoYR3bUUF3QiqoKQqL9yLgwhpBov9M6duZF8eiNWna+W4Sty3lMhIju8sF6Cx1BBbh13QLAx8cHm80GdK/bCiGIjY1l3rx5tJQ7Ka8chntfFXS12QFImxXJ1teP4rQPPW7gVJYIehsEKoLPXzzCbf83X8YQjCJ6AgcnTJiA2WzG4XCwbt06kpOTyczMPNvmSSSSs8Q5IwYATGYDMy5OZMbFiWd87IwLY5gwL4rSnMbudMS67nTE9R1lvPNOlqed3W4nICAAu92Ow9Ed51BXV0dNWRPBjTNQGPq2LUUBo68eAL1By5zVyWx/6+QZCQfm1JcKerrpaLJRmd9CfPqpLl9IRoqKigoaGho8ywFffPEFXV1d3H777TLOQyI5jzmnxMDZRqvTkDojotexCDGZgwcPUl5ejt1uRwiB0+lEURTGjRtHQUEBWq0Wn44EEMNbtRECUmeEI4Rg78el7FlXcpLcC95M9CM7IRzZXi3FwChi3759BAcHk5KSQmVlJV999RUrVqwgJER+RhLJ+cw5ETMwmlEUhcsvvxwhBNHR0QBYrVb8/Pw4evQoc+fOJdgYg9EWPiw3vUBg9NOQMj2crM/K2P3hsZ0N/a42nPk7v6N769n+1lHGeKLLcwKr1crhw4eZMWMGqqry4YcfEh0dzbx58862aRKJ5CwjxcAZICAggBUrVlBTU8O4cd3Bhk1NTcSFp5L3kRVXfpx3iYv6QUGhVVdK8dESdn9YMpJmM9xCNieSvbGCvJ21I9KXZPgcOHAAIQTTpk1jx44dNDQ0sHr16l5FuSQSyfmJ/BU4Q8ycOZPExEQaGhpISUlB7zbTlROO3hVwah0rEBQSwHvPbx65lMPHdz5CZK0vk96Bs0hP4ODEiROx2Wxs2bKF+fPne7xVEonk/EaKgTOEoiisXr2azs5OQkNDCexIRxFaEKc44QqYM38mwabIY6mWvTvJ2+2LQ93meDJaay00V3eNSF+SoVNeXk5jYyMzZsxg3bp1BAQEsGTJkrNtlkQiGSVIMXAGCQ0NZenSpezfcQSsPiOylU+gsv2rLRicwV71p2ggJM4XbyrUfX3S8O07HluXc2Q6kgyZffv2ERISQktLC2VlZaxevRq9Xn+2zZJIJKMEKQbOMPPmzSPUJ56RWI8XCNA7UIviaG+04c2sLVRoqbKi8XV5ddevoIxU6AA+fnLyORtYLBZyc3OZNGkSGzduZNq0aSQnJ59tsyQSyShCioEzjEajISYo5ZTmV3HsP61BoDiNwNASBgkBWI2evgYax6XtIijaiHKK35SgSF9CYk5v8idJ/xw4cACA2tpadDodF1988Vm2SCKRjDakGDjDVBe2UnGo/ZSWCFStDUdQFapDw3B9+EJ0n3lSOxQAQWfQURbfkYYpUOcRIcNhxiUJMqnNWaAncDAmJoajR49y6aWXetJfSyQSSQ9SDJxh9n1cekpr8HqThpsenkugf9AIBPcdM0RzLHWx8vVkb/SHttAcXIYOgsL8iF/qwmVsG1rvx75dmRfFMXG+jFo/UzgcTTQ0rKeu7iMKCjbS1NREQ0MD48ePJyMj42ybJ5FIRiEyA+EZpKvNTnlu87DPFwjatKVs2FBNqP84qpSOEVjPF7iwEz3dQEVxNTq9jk5Rz/QF6VTt6QBAr9dTXVuJGmJHqQnyuufo1CAyL4onOVOWND4T2B2NFB79PXX16xDC5Tk+fUYIFeWzueyyb8vPQSKR9IsUA2eQrlb7KZ2v6J1Y/aooKQGfRgUfIjj1UH8FrWqiYT+4zSr+qVZaazro7OzwtNBqtVRWVuJW3PiZUnFaxYDLHBqtwq3/Nw//EOmOPlPY7Q3s3XsNNnsd0LtIla9vMxPT12OxrCQg4IqzY6BEIhnVyGWCM4jeOPQiRD0oGrjtl4u54eY1REVF4TS2nHqOgp6+j0UP+HUm4a4LBKCxsRHoDnisr6/H6XSiCpWkBYMHHl543TgpBM4w+QUPY3f0FQLQXcgKBLlHfoTD0XSmTZNIJGMAKQbOIEERvviH+gz5PIHA4lPNa++8REtLCzfccAPX37MKRacOuhtgqLirg0HV0N7eDoBOp6O8vBxFUQgJCaGk8SBqfDlCcyxngCLQaLtFid6oZcktE5iyJG7I40qGj81eS0PDeoQYuGy1EC6qa946Q1ZJJJKxhFwmOIMoGoXMZfFse/PokM+1+9bSWRXI1oI8vnzrCJHJ/kxelcyhdW0Itf9qhMPasSA0GG3h2DV1QHe8QI8YiIyM5MiRI2i1WoxJjfi6o5iaOgdF0RAaayZtVgR6w/C9H5Lh0dK8E++SSAmaGjeRlPit022SRCIZY0gxcIaZsjSOqoIWSg40Dt74WBni1BlhlB+egcuOJ+Vw50EN2bm1OAJrCBSJOFpHahIW6N1+9EQ3aLVaSktLUVWVxsZGfHx8cLvd2B127vjmJURERAzYm+T0o6rex6K4VetptEQikYxV5DLBGUajUVj5zcnMuyoF3wBDr9dODPQOizMzaVEMxVlNuI793itoPBUONW4ffFqSaNTn0hK2D7e5hZFIF6ged5ep0WiwWq3o9XoaGhqw2Ww4nU4uvfRSKQRGCSZTvFftFEWLrynp9BojkUjGJNIzcBbQaDXMXJnE9BUJ1Jd14LC58As0EhhhoqGsA6fDjTnIB99AA8/9aNtJ++kJ/AtsyaDLVIHbIRh+GqKePjU4Da2e52539zq0wWDA7XYjhCA9PZ0ZM2acwiiSkSQ4eB5GYxR2+8BlooVwExNzwxmySiKRjCWkGDiLaLQaolICex2LTguis8VGU1UXB74o96ossXBp8e1I6nk2bHsEAlVrx2loRev0Res24XZrURQLXV3dFQcDAgK44oor5H71UYSiaElN+X/kHvnhAK20BAbOIDh4/hmza7hYrZU4nS3o9SGYTLFn2xyJ5LxAioFRRFN1J7veLaL0UNMpzOnDTE+MAAQO/1oCm6ahd/p7XjOhYvOtw+Jfyg033IDRaByucZLThI/PUioq5hEXtwtQUJSeL5AWcBMYkEnm1CdHtYirq1tHWflTdHQc9hwLCMgkMfFbRIRfchYtk0jOfRQhxAjVpJOcCvVl7bz71yzcLhUxhOrCQ6Vn0lfQeLYeKig4dR04fJrw7Uz0HDvxPJ8ADbf+8kJZfXCU4XQ6efbZZ7FYLDgclURHF5CQ2InBoODnm0Zs7E2Ehi5CUUbvTo/Cor9QVvYE3WFMx/8BdD9PSf4+ycn3nx3jJJLzAOkZGAWoquCTJw/idqqcbmmmKAo+Exuob6hF4/AFwGnoQNXYCamf093mJNsUHZ2CbW8cZfmdMr/92aCrq5DKqv/S2rIbgYq/OYOYmJvYvLmcxsZGxo8fz9GjVsrK5nD99T/Ex2foOS3OBg2Nnx8TAtB3i2T38+KSv2M0RtHRmUtd3Trc7k70+hCio68lNvYmfIxRZ9RmieRcQ3oGRgGlOY189HjOCPd6LPeAIo4tOSi4tVY6Ao/iMrYREBCAyWSiq6uLzs5OTB3x+HYmDpqbQKNRWPunBZjMhgHbSfrSPZm/Qkf7QVAUAgOmERt7E76+yQOeJ4SguPivlJY9gaJoPcmFev7d2JhAUuJv2LBhE0FBQfj7+3PHHXeciUsaEfZl3UJr6268yZVw/PV3o0Gr8SEz82mCg+edNhslknMd6RkYBZQdakKjUVDVkdNlArCZalC1dlAELn0HTkObJ6Sgs7OTzs5OerSgwR7iVb+qKqjMa2HcrMgRs/VcRwiVgoL/o7LqxV6TWVtbNuUVz5AQ/w3Cwy/G7e7CaIzCbB7f6/zy8qcpPXbnfPxE2PPv0NBy2jt+Q0hoEh3tFmbOXH2GruzUcbk6aG3d5XX7vlkWVdyqjewD32De3E8xmWT2S4lkOEgxMApwOtxepQ4+vs1gd/AKCk7fJlw+X5cd1hzLTyCE4ESHkCK0XmcsdNpdgzeSeCgq+jOVVS8BJ05m3f8ur/gP5RX/8Rw1mzNITr6fiPBLcLutlJQ+NmD/igKKUsCECQUIAXp9HRZL1KAeh9GAy9U5Ar2oqKqDysoXGTfuZyPQn0Ry/iGXCUYBX31QzL5PSr2KFwgI86G90TZoO/8QI7f95gJsdhuNjY2eR09t+5aWll6CwL85HYM9xJPQaCBaQ3IIitWTkZHB+PHjiY6ORqOR+av6w+5oZPv2CwatG9Cb7tST48f9Ap0+iNzc/zfEUbVotb7Mmvk6ZvOEIZ57ZnG7rWz5MnOI70//6HQBLF60fwSskkjOP6QYGAXUlbbx1h/2edXWYNLhsA52Zy4wjGugVa3AYrF4jppMJrRaLQ6HA4fDAXRnGFRVFb0thMCWSYP02p2HoCV8T68djFqtloSEBMaPH09SUhKRkZGjegvbmaSs7EkKi/6Cd7UDTkQhNuYmqmveQIihemO0+PomM2/up6P+szh06HvUN3wyIoJg6ZIjaDQynkUiGSpymWAUUFXQ6nVbp23gSUEgUAwORHMA4eFpqHGtNLc00dXVhc1mIyAgAB8fH48YUNXuSUr4teMD2Ns46dZGBYWMpeFkFZuwWr/Oce92uykpKaGkpAQAo9FIamoqSUlJJCcnExoaOuonpNOFxVI67HMVRUNHx+E+Szre4cZiKaS1dTfBwXOHbcOZICHhG9Q3fHLK/SiKHkWR214lkuEgxcAooCirweu2g80LCoDDiKNJ4GzyAZ0fUZn+OELaqaqqoq2tDV/f7i2FPRP07NmzWbJkCcKp5aX/24yrQ9ctKo7d/iuaboFwwbVpTF+RwEViFoWFhaxfv57Gxr4Fl+x2O/n5+eTm5gLg5+dHSkqKRxwEBwd7fb2jHSFUmpu3UVPzDjZ7NTqtP+ERFxMVuRqt1rf7zRuWV6A7vsBiLaUntmCoKIqOpqbNo14MBARMYdKkRzh8+PvD8IB0oyhawsOXn7eiUyI5VaQYGAUM7vYfCscm8GP/Fy4tLVkBiNQGgoODaWpqwmbrjjlIT09n+fLlnsm5obOBWr9dGLSh+FiiMOtDMPn5kDgplMmLYwmO8uvuW1EYN24caWlplJaWsmXLFsrKylAUxXMX63a7Pc8dDgdFRUUcPHgQgKCgII8wSEpKIiAgYASv/8xht9eTfeBuOjtz6cn0BwpNzZspLPwDU6c8icvVcUpjuFxt9E3E4z1jpUphZMQqzH4T2bHzahSls0/RrsEQwk183NrTYptEcj4gxcAowBxspK3ecloSDikoKEKLtToAR1gZAHFxcVx88cXExn6d910Iwdtvvw2KwGFqxGFq5MZvfpPo6OiT960oJCcnk5ycTEVFBVu3buXo0aNotVpPUSPozpDXg06nQ6PRUFxcTHZ2NgChoaG9xIGfn9+Qr7O1zsKhrVU0VXaiaBSiUwPJuDAGv8DTkzrZ7baStf82rNaSniPH/t99zS5XJ/uz70CrNY3AaMP1LKj4+IydrXa+vslUVc4jPmHjEM7qFkqpqT8iKGjW6TJNIjnnkWJgFJB+QTSVeS2ncQQFH0sEPuZWll98ERMmTOjjTj1y5Ah1dXXodDpcLhdarXZIJYrj4+O5+eabqampYdu2beTm5mIwdAdyORwOjyAQQmCz2bBYLGg0GsLDwzEajRQXF7NvX3cQZUREhEdkJCYmDphJT1UFW18v4NCWKhSNgjiWq6HySDN7PirhgmvSmLY8YUjvljfU1r6PxVI4QAsVIVzH7uzPDoqiEBV11Vkbf6g0NzdTXh5JauoEHM5CvFke8fefRFLSt2XtAonkFJFiYBSQOj2Cr8KK6Wi2eyazkUZBy41rbic0xr/Pa06nk3Xr1gHgcrnw8fEhNDQUrXboueyjo6O57rrraGhoYNu2bRw8eBCj0Yivry+tra243W7PDoeeQMb6+nqEEERHRxMSEoLb7SYvL4+vvvoKRVGIjo72eA4SEhI8IgNg+5tHObSlCqDXeye6SzCw/a1CdAYtkxeNbPW7yqr/0rMF8OScxiITg6IQG3srRkPYWbRhaBQXF6MoembMeIEDB27Cais5SUstqan/Q0T4Snx9k86kiRLJOYsUA6MArV7DFd+bznt/z6Kz2X7axtHp+/+4v/zyS6xWK8HBwbS0tKDVanstIQyH8PBwrr76apYsWcK2bdvIzs5Gr9cTExNDQ0MDXV1dWCwWjzAIDQ0FID8/H5fLRVhYGLNmzcJkMtHS0kJOTg47duxAo9EQGxtLUlISUSFx5GyqHNSWXe8WMXF+FDr9yBXqsVhKOJVy0aebkOAFjEsbWwl4iouLiYuLw2bLG0AIAKgUFz9CeNjFZ8w2ieRcR4qBUUJguImbfjGXIztrOPxlFe2NVtyukZtsfAMN+If2dbe3tLSwY8cOFEXBbrejKApdXV3ExMSMyLjBwcGsXr2axYsXs2PHDvbt24dGoyEzM5O2tjbKy8tRVZWmpiagO+9BYmIiWq2Ww4cPY7Va8ff3Z+LEiURHR+N0OikvLydr10F0Ne3o8B80c6Ld6qI4u4Hxs0emmI3dXsfZvesfDA3NLdsoLv4rqak/GhMR9qqqUlJSwvz58yktexIhji/DfCICUKmsepEJ4x8+g1ZKJOcuUgyMIgwmHZnL4slcFo8Qgud/vB1Lu+OU+1UUmLo0Do2m76TwySefoKoqEyZMID8/n8jISOrq6k7ZM3AiAQEBrFy5koULF7Jz50727NmDqqrMmDEDo9HIwYMHaW9vR1VVKioqUFUVk8nEpEmT0Gg0FBYWsnfvXoxGI0nh6fhVT0EdwiaMskNNpywGnM428vIfor7+Y0ZODGhRFAVVdQ05gv7kdNtWVv4URp8Y4uNuG6mOTxvV1dXY7XYSEoIpLtk56HshhJuamnelGDgOt9tKU9MWHM5m9LpAQkMXodP1XRaUSPpDioFRiqIoTFkSy+4PS05pl4GiQHhiAFOXxfd5rbCw0BP930NkZCStra0et/1I4+fnx/Lly1mwYAG7d+9m165dOBwOMjMzSU9PZ/fu3RQXFwNgs9k4cuQIqqoSHh7OvHnzcNsVSj7VIFThdS0FgJrCUwvkc7k62Jd1A11dxYykV0CrNRIbextlZU9xOpYdSkv/RWzMTWg0o/tPvbi4GKPRSFiYkeKBVgiOw+3uRFVdo/7aTjeq6qKk5B9UVL6A293lOa7R+BAbezNpqT9Aozk9u2ok5w4yofwoZvLiOPyCjd15a4aBRqMwYV40Vz44Db2h93q5y+Xio48+QlEU5s6dS1FRETqdDrvdTkxMzGl3LZtMJhYvXsyDDz7IsmXLKCgo4NVXX8VkMnHPPfewYsUK/P39PRkSW1tb+eqrrzi0tQJUZUhCAKCjyUZny/DjMUrL/k1XVxHDTQB0MtxuO0GBM1FV/WnZWupwNNAyhKqAZ4vi4mKSkpLo6PD+/dVofM57ISCEyuHDD1Ja9kQvIQCgqjYqKp5l956rqKp6jZbWPcPMZik5Hzi//5JGOT5+eq7+nxmse+wALbWWwYPXe1AgMimAy74zFZN//3nad+3aRWtrK0ajkYiICFwuFxkZGVRUVDB16tQRvY6BMBqNLFiwgDlz5rB//362b9/OwYMHSU9P58Ybb0Sr1bJx40aKiooQQuBjjUTAEKVAN1m7D3DhillDLqqkqnaqql7h9MQJuMk5+E202sGzSw4Xu7329HQ8QjgcDioqKrjkkkvYv78EtzsCP3MjA73fiqIlMvLyM2fkKKWubt2gqZy7ugrIy/9fAEymRNJSf0RExMozYZ5kDCE9A6OcgDATNz00l9XfzWTC3CiCo30HP0nAhdePO6kQaG9vZ8uWLQAsWrTIs79/8uTJdHR0jHi8gDfo9XrmzJnDAw88wOrVq6mtreWpp55iw4YNLFy4kJ/97GdcfPHFaFTDkL0CPWzZtpknnniCvLy8Id0hdXUV4nK1D2vModDtjFE8okBRRsa1q9OaR6Sf00VZWRmqqhIbG8uBAwcwGq9gMOElhCA+7o4zY+AopqLyeYbyM261lnPw0H1UVb9+2mySjE2kGBgDKBqFhEmhLF+bwU2/mMu42f0nA+rx7F9wTRpRyYEn7W/Dhg0IIfD39/d4A4xGo2dpYKR2EgwHrVbLjBkzuP/++7nmmmtoa2vj2Wef5eWXXyYyMhJfv6Fn9BMIFKOD5asW4u/vz+uvv85zzz1HeXm5d+ePQDU97+lWAhqNL5Mn/f2Ue9NoDAQHX3DK/ZxOiouLCQgIoLy8HJfLRU6OjoryKcde7f0TpShaQCF94u/x988447aOJtxuO+3tBxiax6r7+5WX9wtso9xjJDmzyGWCMYaiUVhx5yQikwM5sLGcjuPyEoTF+zPr0iRSpoef9PzS0lIOHToEwNKlSzl8+DAAU6ZMoaqqCrPZPCpqBWg0GqZMmcLkyZPJy8tj69atvPzCK4R2zGeoiwQKCrrodtav/4qoqCgWLVpEfn4+zz33HBMmTGDZsmUDZls0meJRFO0ZEwWKAqpqpbZ2xyn2pCE6eg16/defp9ttoab2PaqrXsVqq0KjMRIedhFxcbdhNk84xfGGR3FxMcnJyezatQutVovVasXH50amTvkOZeXP0Na291hLhdDQpSQm3CNTDwNCnMpOI0F19RukJD8wYvZIxjZSDIxBFI1C5rJ4pi6Jo6m6E4fVhW+AkaDIgZcQVFXlk08+wWg04u/vz9SpU3nssccAmD59Op9//vkZCR4cCoqikJ6ezsSJE/nizf3k1Q0tbbNAIIwW0hdEsyh8Krt37+bLL78kPDycWbNmcfToUf7973+TmZnJ0qVL+xVCen0w4eEraaj/FDHCAYQDWV5fvxO7wxej0TKMbYcK/v6TSEv9ieeI1VpB1v5bsdkqOT4ApbrmDaqqXyUt7ackJnxjpC7AKzo7O6mvryc8PJz29nZP6ulVq1YREBBAePjFOBzNuFwd6PXBvYTN+Y5Wa0avD8bpHE4qc5Wmpi1SDEg8yGWCMYyiUQiL8ydmXPCgQgBgz5491NfXY7fbWbZsGXV1dbS2tmI2m4mKiqK6uvqsLhEMhKIouNoNDHVWVFDoCixi06ZNvPXWWwQFBXHllVcSFBTE3r170Wg0TJo0ifz8fB599FE2bNiA1dq30l9y8ndRNAZO9U9mSEGCShF22/DW+3W6QGbOeAWdrrvok9ttJ2v/bdjtNT2WHGdTt8ApLPw9dXXrhjXecOnZRnr48GH0ej02m42FCxf2EmUGQwi+volSCJyAoihERlyPEMMT76p66jlMJOcOUgycBwgh6Ozs5IsvvsDX15fY2FgmTpxIVlYWANOmTaOlpQWbzXZWgge9RbiHFm6vKKAzu3AbuxBC4Ha7ycnJ4f3338fhcLB8+XIiIyM5dOgQer2epKQkdu/ezT//+U+2b9/eq9qi2W8cM6a/iF7fE4sx9B9gRTEMScsoCgQE1uNydQeCDkVIaDVGtNqvBWJ9/TpstopBljoUikv+cUa3n+3Zs8fz7+DgYIKCgrjggtEd4zBaqKioYMMGFy6XD8P5KffzTRl5oyRjFrlMcI5i7XSQu62aw19W0dFiB0VgMo7Dpm8gPnIGm17Oo+BgC1qDH1OnTqW6uho4u8GDgxEc7YdyoMHLSVGARmHZ7emkTVlBdnY227dv96Q9rqiooKysDLPZzJw5c+jo6CAvLw9fX1+Cg4P5/PPP2b17N0uWLCEzMxONRoOf3ziSEu+jrn4dNls1oMHh8D4ISwjn4I1OQFFAp3PQ3BxDdJQBu6PUm7Mw+vT+HKuq36Cn3O8AFmKxFNPRcZCAgNO7vVQIwZdffkllZSW+vr64XC7q6+u5/vrr0enkz9JACCHYsWMHn3/+ObGxsUzLfInCou8e5/XpFo6DCc/gkIWn2VLJWEL+1Z2DNFd38d4j+7F1OL6eOIWCzhqMvzWEwp2tKEorBjUaI7Fse6kCfUo9wcHB+Pp6sXXxLJG+IJq9n5R61VZrdtPql8sr724lckck6enp3HDDDRiNRjZu3EheXh6qqtLZ2cnu3bvRaDRMmDABVVUpLCzEaDTi4+PDBx98wM6dO5k3X6Gt7TFU1c7X6+1D9Q4M745bUSA4uJFZs3axectF6HQtg/zQC2Jjru91xGarwtuoc5u9hgBOnxhQVZVPP/3U4xWw2+0YDAaSkpKYOHHiaRv3XKCrq4v33nuPwsJCFixYwNKlS9FoNNTV/YOjBc8QFJxFQECDVx6ozo7DwJrTbrNkbCDFwDmG0+Hmg3/sx9bp6HMH7dmfL47dORxzLdYUtkK5QvS80btEABAQaiJzWRwHPh+4UuGsVUnMvSIFh2MJhYWFHDlyhB07drB582bCwsJIT0/nzjvv9JRZbmhoQFVV8vLygO6UzL6+vpSVlWEwGPAx5dLS8slxd1sehXVar/d4FMXB+g3/pqpyKuMnbBmgpRajMZLIyNWeI3Z7Ay5Xh9djaTWnTxC6XC7ee+89cnNzmTRpErm5uaiqitVqZeXKlaMqeHW0UVpayjvvvIPb7eaWW24hLS2N4uJiNmzYQG1tLenpS0hPn0ZV1R+96q+jM/c0WywZS0gxcI5xdE8dXW1DCwwSKgibDm3rybckjhYuuHYcQoWcTZUomm7bAVBAoyhceP04piyJA8BgMJCRkUFGRgYul4uioiKOHDnCnj172Lp1K8HBwaSnp7NixQoOHz5Mbm4uTqeTuro6oDs7Ynh4KFFRr3jldu2P4Z7XH2WlBahqJhUVNuLjvzphu6NyzOZwZkx/Ea22Ox+D1VrDrq+uwu3u9MoOt1tPWZmeoCB3r5oVI4HdbueNN16ks3Mnq1alU1a+F4PBiNOpY+bMmURGRo7oeOcKqqqydetWtmzZQkJCAtdeey0Wi4X//ve/FBYWEhcXx5133klCQgJVVa963a8y3DznknMSRchk1ecU7/x5HzXFbUO+aRUIfPx03PXnRf1WNxxttDVYyd1WTVNVJ4pGITo1kPQLok+adfF43G43JSUlHDlyhLy8PCwWCwEBAaSnp+Pr68vhw4epr68HIDi4kkmTv/DCouPfMw3gRlU1KIo6YmIgP+8GOjoCuf322zGbW6mseomGho2oqg0fnzhiY28iOuoqdDp/7HY7+/fvp6b255jNpWg03nwhNFgs88nal0pAQADz589nxowZGAyDv6eD0d7ewvoN3yYgIAut1k3PUovbraW+Pp2rrnwRs/nkibLOVzo7O3nnnXcoKSlh8eLFTJs2jS1btnDgwAGCg4O56KKLSE9PB7o9BwcOfIR/gDfJqjQkJn6LtNQfnN4LkIwZpBg4x3jp5ztob7QN+/y1f1yAX+D5U+FMVVXKyso4cuQIR44cobOzE7PZTGpqKhaLBYfjA+Li96Iog/+ZBAdfSGTEpbhcbegNoRj0c9mz9zIMhq5Bzx0IIcBqDeXwoau54461REdHn7RtT0Gn/fv3o9G0MGPm217ZDgoBAZnMmP4yzc2dnhoRRqOROXPmMGfOnEHjSRyOJlyudnS6QAyGEM/xpqZ6tm67CbO59CTCSCEkZBGZU5867wsPHU9RURHvvvsuiqJw+eWXU1lZya5duzAYDCxevJiZM2fS0dHBgQMHyM7O9lQbzZj0PkKUMnCMiMIF8zdjMsWdoauRjHakGDjHeP23u2ms6Bz2+eebGDgeIQQVFRUeYdDW1kZKyiGiY7IGvbsXAnTamVx44Su9ouEPHvo9dXXPDDghf12LoP/XFAUKCi7mqisfOqkQqKioYNeuXRw5cgSj0cjMmTNJSiqjrPx3g143gI9PHPPmfoZW6+M51trays6dO8nKykJRFGbMmMH8+fMJDOx9B9/YtJmysqdpPa46YnDQPBITv4nDMZ5PPv05CQmbB30PJ074LbGxN3pl77mMqqps2rSJbdu2kZyc7MnO6HA4mDdvHnPnzqW0tJT9+/dTXFzsWQ6bPn068fHxdHQeZt++61FVJycTBCnJD5Kc/N0ze2GSUY0UA+cAbW1tZGdn09zcTFepD20FxmHEtgl8A4zc8YcFY2KZ4HQjhKC8/BBHC29DUQYPvhMCSktm0No6lxUrVjBlyhQ0Gg12ewM7dq44tmbf90Pp/utTcDh8MRq7EELxtOtJJlNaeiGrLv1dn22fqqpy5MgRdu3aRWVlJSEhIcybN4/MzEy0WsGur1Zis3lXfyEwcCazZr7R72tdXV3s3r2b3bt343A4mDp1KgsWLCAsLIyysicpLPoTfbctagE35eVziIwswWhsZOAvpYKfXxpz53xyXgcRtre38/bbb1NeXu5JEd7c3ExmZiaTJk2ioKCAQ4cOYbPZSEhIYPr06WRkZPRZymlvz+Fw7v/DYin21HMQwoVW60tK8veJj7/zvH6fJX2RYmAM43a7+eyzz3olbtGoeoLrZgOaoVX3U2Du6mRmrUoeeUPHKAcPPUB9/Sd4syVPVTXs/mrNsQQwEBQUxKpVq0hLS6Oj4xD7sm7D7e4WFT2/wUJ0VygsKFhEa0siwSElREYWYPLpAMVIQ0MsTY0Z3Hjjd3sJAZvNRlZWFrt376atrY2kpCTmzZvH+PHjcTqdlJSUUFr6D7S6z7yMV9ASFXUlkzL+PGAru93Ovn372LVrFx0dHUyZqicw8BlvBvCaRQv3n5OZBoUQtLTspKrqFTo781A0ekKCLyA29hb8/LqT/xQUFPDee++hKApms5n6+nqSk5OJjo6mqKiIuro6zGYz06ZNY9q0aYSGhg46ZmvrblpadqEKJ36+yURErPIEl0okxyPFwBjmgw8+8GQRPB6DPZiAlknA19sHB0Ig8A81cuPP52E0yTVb6N6Ot237BQxeSrd7ci8qnEtNTd9CP+Hh4VxxxRVERprJynqMuvp3MBisuN16WppjcatatFo3qltHc3McbW2RaLU63G43er2etWvXeoRAS0uLJx7A5XIxZcoU5s6di0ajobCwkMLCQsrLyxHCydx5b6PTeR87YrXcz+LF38Df33/Qtt2VBXMor/ghfn5lgwQndnsIvGXhhV9hMIQN2MZiKaGq6lXa2vYjUAnwn0Js7E1nrdDSYLjdFnIO3kdz85cn7ADpfm+SEh+gqGgiO3fuwmw209nZSXBwMP7+/lRWdm+jnTBhAtOnTyc1NRWNRu4CkIw8UgyMUWpra/n3v/990td1TjO+nfEY7WF4It0VFYQGFBBCRaPRIlSB09DKN359KeYgecfQQ23dhxw+/KCXrcMpKf4GVVVVJ20RHR3N1VdfTVFREevXf0xa2ldERBbS7b7tbqPRCCyWAPKOLMHhCPMIgZ54gLy8PHx8fMjMzCQsLIzKykqKioro6OjwpFNOS0sjOtpCwdG7vb5WjSadPbsX4nK5mT9/PhdccAFG48BxI263lc1bpjCSuRa0Wn8WLdx70iBCIQTFxX+ltOwJjhcZPRNsbMzNTJjw8DG3+OjhQM43aWzcxEDCsqhwDjU1EzEYDGg0Gmw2GxEREUyfPp0pU6bg5+d35gyWnJdIMTBGWbduHVlZWajqwHeuiqpj5UWr2bDxM9xaKxctXEV1bic1lfXMvWAWpS0H6XI3cffd3k8e5wM1NW+Te+RHXrUVIobQkH/i5+dHQ0MDeXl5nju6E4mJiSYh8SO02kP9uvBVVUFV9aSmPIvVambXrl1UV1cTGBhIZGQkFouFqqoqhBCEh4eTlpZGSkoKAQEBtLW10dzcTHPLDgyGx7y8Ui2LFu7F5dKzefNm9u7di8FgYOrUqcTGxmKz2bDZbFit1l4Ph6ORceOf9HIMb/ItaElIuItxaT85aYvS0icoKv7LgOPEx93J+PE/99qu0017+0H27L1q0HZOp4HdX12HweDLlClTmD59OtHR0XJdX3LGkD7hMUp1dfWgQgBAaFxo/Zy4dVY0Gg2zL5zKZtdm6pUG5l2Zyp5HPyYtLe0MWDy2MJkSvWonBHR06Nm+7QPPsZCQENLS0lAUhfr6etra2jyvWax70ekOnbQ/jUagKC6yDzzM4UMXYDabMRqNtLW1YbVaiYyMZNKkSeh0Orq6usjPz+err77yfBe0Wi3h4ZA2zjvbLZYA/vSnR3G5XJ7jNpuN3bt3H7NHg6+vLyaTCR8fH0wmEyEhIZhMcHwZ5IHHUXA59Wh1zn6XFITQACaaGqehuvMJCgoiKCgIo9FIZ2c+tXUfYrfXUlv7Qd/OT6Ci8gUSE+/BaBzZBEYuVwdWayWKosXXNwmNxrvcC9U1b52wNNA/er2DS1fFMS3zTvR6/UiYLJEMCSkGxihDuWPQarVoNBpCQ0MxGo3Y7XaMRiNWq5Xm5uZRXanwbBEYOBOTKQGrtYKBJjxFgYCAcu5Ym4het4K6ujrq6+upr6+nrq4Oi8XSq310dD6qqgy4zq4oKkFBRej103E4DCiKgqIoOBwOKioqqKysxGAwoNfr0Wg0mM1m3G43DocDp9NJbS1ERITj70WO+s6OGZ5/+/r6kpCQQFpaGmZzt1eitLSUkJAQVqxYQVxcHC5XF7lHfkhDw2devY9CaGhoSCAifC1Gn39jt9ce5yXoSTxkpqz0Surr9+J2fwWATmcnPWM7gYGVx8SC8DJfQrdXJynpO161HQyrtZyS0seprX0fIRzHbAsiLvYmEhO/hU43cIyF1VI6qBDoRktEhCKFgOSsIcXAGCU+Pp7q6mqvys1qtVpUVfUkjbHb7fj4+IyJSoVnC0VRSE39IYcOebMXW1BU9H9Myghhxowrer3S1dXlEQh1dXX4mN7yKhugogh8/Vppa+0dx2EwGPD19fXcrR9/x378QxVTqK7+4cn7R4vRJ4Lrr/8bimKirKyMvLw88vPzycvLw2QyMW7cOBYtWsSRI0d45plnmDRpIvEJb9PZud+L96Rn26RKasq9zJlzHV1dV/L88w8QE1NJXHwgBn0okVGriQi/BI3G4Cm13dxcS2npt3G5q4+9F94VWOpuq2CxlHjdfiA6Oo6Qtf8m3G5Lrwnd5WqltOxJ6hs2MGvm6+j1QX3OtVqtlJaW0tDYjkbjTUpqFY3m/MzvIRkdSDEwRpk1axa7du0asI2iKMTHx1NWVoZer8dutwN4PANVVVUYjcZBtyidr0RGrMI5oZX8/Ifwxh1eVPQXIiMvR1E02O12mpqaPI/m5maampqITzi1EB2Hw4EQArfbjdPpxOFwYLfbsdvtnrV9Hx8ffHySCAx8kLa2fx4787giDggMxkhmTH8Jnc4MQEpKCikpKVx66aXU1NR4hEFOTg46nY6oqCiam78gOGSfV3b25EgoLFzElVdcCEB+fiGNjcmMG3czs2dd3OccRVHw9/entfUdXO5ShhecqKB46cIfCFV1cSDnG7hcFvrfDaFisZRw5MhPmTr1CRwOB+Xl5ZSUlFBSUkJNTXc54YSEQOITvBlREBJ84SnbLZEMFykGxihhYWFceOGFbNu2rd/XFUVBq9WyYsUKXn75ZWJjY6mtrQW6xYC/vz/V1dXExMTIIKUBiIu9mebmbTQ0rGewyclmr+LV1x6muiqArq6vUxD7+fkRGhpKaGgobncCOl3BoC5vIRQsXUF9jmu1Ws/dv8FgQKvV4nK5aG9vp76+3hPw1yP8jMariIrOJyysHI3Ghd3uR2NjOl2dGRw6+Okx4dD96Cnb3BMXsHTpUuz2TurqPsZufxODscKrwktCQGvrOKZN+zElxUf573//y1133cX+/d0ehYyMjAHPr6x8aeABBhzbRXDwvGGf30Nj4+fY7bWDtHLT0LieF1/8M2VlNlRVxd/fn6SkJCIjI8nPz6eqKo7YOB0ajeuk75uClqCg2Z58AxLJ2UCKgTHMRRddhMFg4Msvv/QEgGk0GlRVJSQkhGuuuYampiYcDgcTJ06ktLQUq9WKzWbDaDRSWFhIZmbmWb6K0Y/dVoN3gXLgb7Yya9Yyz+QfEhKCxWLx5AfwD0gkIyN/4H5UhYbGRJzOvls9VVVFVVUsFgtNTU2ez12n0xEaGkp8fDxhYWGEhYUREBCAyWTC6XR6RILNZiMq0ub5HvR4FFpaWjyeBZvNhtPpxNe3hUmTN2I0WjFpva++qChgt89n544K9Ho9DoeDxx9/HLfbjaIobNq0aQAB6iI6ZrhufgW9PpiI8EuGef7XdMdEDJ4jQQiIiv4vEyb8leTk7oyBmzZtoqOjO8GUn18Q+XkLyZjUU3a695KHghadPpD09D+css0SyakgxcAYRlEUFi1axJw5c3j66aeB7ruulJQUkpKSUBSFL774gsTEROLj4wFobm7GbrejKAqdnZ0yeNALNMfl6x8IRYFZs+YRHb3EU+fg/fffJy8vD19fX+bPn8+sWd+lpETQ0LiR/gSGqiq43XrKy6YDYDKZ0Gg0Hk+DEAK73Y6qqrjdbnQ6HWFhYfj7+6MoCm1tbRQVFWG1Wrtt12gICQkhPDyc8PBwwsLCSE5OJiwsrFcNhROxWKrYs3c1Lpfdc21DobmpGYfDD6PRSHBwMA0NDZ7r8fHp/X72jnsZbkIdDYqiYdKkv3sd6T8QTlc73iRLUhTQajuwWv/Mf/97Me3t3SIgJCQEIQRdXV1cccWPCAu/m8LCP9DRcfxOEg1h4csZP+7n+PjIuB3J2UWKgXMAHx8fnE4n06ZNY9myZZ7jbW1tFBcXc8UVVxAS0l1FrqWlBbvd7pkspBgYnNCQhbS27sWbtMRm83QOHTrEzp07qa6uJiwsjMsvv5ypU6d6IsUnT/4H+QW/oqqquxaAEAparQYhXDgcQRw+tBCbrTtKXVVVrFYr0dHRBAUFUVhYiNPp9NxZ99x5l5aW4nQ60ev1JCQkEBMTg7+/P6qq0tTURGNjI1lZWXR2dhexUhSFoKCgXiKh5/9Go5Gq6pdwuTq9uua+6Bk3bjFNTRZPvETPhG+xWGhtbSU8PNzjPQkLCyMkJMQjTnbueg6LpXhII5rNExk/7hcEB88Zhr3Q2XWU6qrX6Ow6ikbR4XC2MJTsiW71KLFxVjTVi5kyZQn79u3DYDBw9913ExERAcCc2e/T0XGELkshGkVPQOA0fIxRw7JXcvrpDmjNw26vRav1JTBw2jkd5CnFwDmAw+Ggo6OjTyDggQMH0Ov1ZGRkYDQaMZlMnmWDrq4uzGazV+lnz3eiY66nqNibGvHw9ju/p6w0jpSUFG6++WZPvoHj0WiMREf9iPfedRERUUx0jA9JSZMIC70IH58pZO//G9Dt/rfb7RgMBqxWKzU1NWRmZhIdHc3hw4epqKjA4XDgcDhwu90EBgYSEhKCw+Hgq6++wuFwYDAYSEhIIDU1lYsuuojg4GCamppoaGigoaGBxsZGDh061CsXQkCAmclTXkKj8T6NcA9CKJjNFzFv2dWeY21tbTzyyCNAtwjp8XLk5+djs32dMjkoKKhblESEo9UOLgaEAIW5zJ79EwICpg7ZVgBVdZKX/wtqat48IR+AdzkUjic0tIrQ0PfJyuoiPHwK119/fZ+yz/7+6fj7pw/LVsmZo67+Y0pK/klX11HPMZ0ukLi420hOum9EvE+jDSkGzgGampoAeokBIQTZ2dkeIQAQHBxMY2Mj0F0dLTY2VgYPeoFBH4JOF4DL1TpgOyEgJiaPS1f+hsjIgZPe5OTk4HD4UVk5hcmTVzIuba7ntTvvvNOz7AN4JvwJEyZQUFDAkSNHWLhwIZdddhk5OTlkZ2djsVhwOp1UVFTgcrkICQkhPj4eo9FIY2MjW7ZsYePGjRiNRhISEkhKSmLq1KlERkai0WhwOBw0NjYeEwklKBrv6xp8jRZVNbHpCzNtrZ+xfPlytFotBQUFQPdkv3LlSl5//XVSU1O5++67sVqtNDY2erwXTU1NtLbaCQnxYmlCdC/hDFcIAOTlP0RNzVvd3fXKByC8CpY80SBV7SJz2naWLvkDOp3MGTAWKSv/D4WFv4cTCr25XG2Ulv6LtrZ9TMt89pwTBFIMnAP0TPBhYV8XeCkvL6elpYUrrvh633twcDAtLS1A93LBpEmTzqyhYxS7o35QIQA968fVhIUFDthOCOGJrIfenxt0531YtWoVH3/8ca/j+fn5pKamEhQUxBdffEFWVhYrVqxg6dKlFBQUsH//fgoLC9HpdCiKwpEjR3A4HISEhDB79mzCwsLo6OigrKyMTZs2sWHDBnx8fEhMTCQpKckjENzuVLZ86f37o6BF4CYgYAqTMh4hwL+KDRs2UFFRwZo1a8jNzUWn05GWlsaECRNYvXo1H3zwAWazmaVLl+Ln50di4tcZHwuOFlNRcZBBg/dQTqloT1dXITU1/ZdthqHHSQDHckg00Nb+FaEhcqvgWKOjI/eYEID+PUOClpZdFBf/ndTUH51TN1NSDJwDNDU14efn1yswKzs7m6CgoF4/ssHBwZSWlgLgdDplvIC3iKGtmw+Wca6iooLW1lbP8/7yPMyePZvy8nIOHeoOOOvZJVJcXIy/vz/XXnst2dnZvPHGGyQlJXHJJZdwyy230NbWxv79+9m/fz8Oh4OgoCBMJhNZWVnYbDaCg4PJyMhgyZIlqKpKaWkppaWlbNy4EbfbjY+PD8nJIYQOXDjwOEwkJt5NeMQKAvwnAzBvXjxxcXF88smjvPfed3C5nZjNIaSkdC8dTJ8+na6uLj7//HN8fX2ZO3durx4D/KfgXfCeQK/3Iu/ySaiqft2rVMFDRVF0NDR8JsXAGKSi8iUvvhOCsvKnqK37iIT4tcTG3oJWO/ZjCaQYOAdoamrqNaE4HA5yc3OZP39+L+UaFBiMrVWgxQ9Va5OZB73EYAhDp/PH5eoYtK3REIlW6ztgm+zsbHQ6HS6XC41GQ0BAQL/trr76aqqrqz0BeHq9HpfLRVdXF++88w4rV65k9uzZbNiwgaeeeorp06ezbNkylixZwqJFiyguLiYrK4v8/COEhFQxfrwTjaacwsI8tm8PJygohIyMDJYvX05ERARlZQcpL38Rt/q8V++LENDZ4cvGjb4sW2bE3yxQFIXW1r1UVP4vKamFnuRDiiJobDpEQ8OvCA9fzoIFC+jq6uLTTz/Fz8+PyZMne/qNiLiE/IJAXK52Blq3V1Udvr5LvLK1P7q6Cr0SAj2bHby9CRRCPRZ8KRlrNDZu9Foc2u1VHC38HfUNnzJ92vOD/t2PdqQYOAdoamoiKurrqOQe93BPDgGH1UXW+jJyNrUTbJsJgEBlxxslzLw0iaCIsf0lPt1oNAZiYm6gvPw5Br5j1RAXd/uArkOn00lubq7neUhIyEld3RqNhrvuuot//OMfOJ1OVFXFZDJ5gu4+/vhjJk+ezJ133snBgwfZvHkzhw8fZtGiRcydO5e0tDQCA0uJiv4Ep7MBITQIIRg3XpCaFoDVcg3Z2dns2LGDyEiVtHHvoyhdaDTeeUIUBSIiE2lpMfDKK6+QkJDABReEU1X9/xDHvCnHJ1ey22vJOXgvkyf/k8iIVVx88cVYLBbeffddTCYTqampx67byMQJv+bQ4e8xUCBfcdFs4mKHHwCrUbz7+VOUrwWBd+0VjMaIYVolOZuo6lBjZQRtbfvJL/g/MtJ/P3jzUczwF9wkowIhRB/PQHZ2NklJSQQHB2PrcvL2n/eR9WkZTtvXP/IKGvK/quON3+2hoXzwO97znYT4uzEYgunebtYXBS0+PjHExt40YD95eXnY7XZcLpcnR8BA+Pn5cfvttwPgdrtxu90eT0JPXMCzzz5LUlIS3/3ud5k6dSobN27k8ccfJ2v/M+QcvBens/FYe9VTF0FR2vH1e56U1HaWLl1Iato6YKhbCTWY/WJYu3YtN998M3a7jcLC/0VV3f320z2pCg4f/hFutwVFUbjiiitISUnh9ddf99TKAIiMvJzJk/7hKQSkKLpjBYtAq/UnOflX1NWNGzBXwmD4mad7PBeDMZSlYSHcREddM0yrJGcLVVVRlNAhCb9jZ1Jb+w4OR/PpMOuMIcXAGKejowOHw+GZVFpaWigtLWXatGkAbH4lj5barn6/4EIVuBxu1j12ALdrOPvJzx+MxghmzngNk6k7eZOiaHv9389vHDNnvIpeP3Dw4IEDBwgODga+Tgg0GHFxcVxySXdWPafTidvtJjw8HEVRcLvdWCwWnn76afLz81m1ahV33XUVCYk7aG7+Hd131X0/fEXpfvj7v8PBQ8+j0bR6XRXwa1S+3OrwBAOuuW4SPqbOAftRFFBVK+vX/xan04lWq+W6664jMjKS//73v56dMdAtCBZeuItJGX8jLvZWHI4FFOQvIH3ihwQFrgIYdpW/mpoaPv6oFSGGdtc/OFpCQhZjNk8YyU4lpxGLxcK2bdt49NFHKcgfXulrIVw0Nm4cYcvOLHKZYIxz4rbCAwcOYDAYSE9Pp7PFTnFWw4A/dkIFS7uD4uwGxs0a2Rrw5xq+vsnMn7eBpuYvqa/7CKerrbvyXuRqgoPnDxpZ3N7eTlFRkScJjcPh8LpI1Lx58ygvL+fIkSNYrVaMRiNxcXFUVlZis9nw9/fngw8+oKJiO4GBz2A2e+ft0WptZGbWY7MpQxQDGjSaGMLDFpGXl0d2djbjxh8hIkIzaJVBRdHQ2raPZ555hjVr1hAWFsZNN93Ec889x0svvcTdd9/tyX+h0RiJirqSqKgrcToPs2f3WxQVVXiWFIYqBoQQZGVl8fHHH6OqKu3t4wgKKhhSH/2jAVQCAiYzZfI/RqA/yemmqqqKPXv2eIJ0p04NIzomko727t0xQ0OL09U2eLNRjBQDY5ympiYURSE4OBghBAcOHCAjIwODwUDBriqv7noUBYr3SzHgDYqiISx0CWGhS4Z8bk8FwObmr92JQ6kYee211/L444/T3NxMa2srPj4+jBs3jvz8fKxWKwEBPugNT+B02b2e2IXQ0NlZiV7vbfvu/9vtJg7mzMFu755INRoNTocVIYQXLnWFceOS2bXTxVNPPeXJ0Hjrrbfy7LPP8vLLL3PnnXf2SVucktJdyKe4uNizS2YoYsDpdPLBBx94fvxTUlLw8flgGPkEjrsSRQdoMJsnEB93O5GRl59z+89HM52d+TQ3b8Ot2jCZEggPW4F2gPThLpeLw4cPs3v3bqqrqwkMDGTJkiWEhW2jqvrPvYTA0L4Xbgz6wb18oxkpBsY4jY2NBAcHo9VqKS0tpbW11bNE4LC6UDQKQh2sQh7Yra4zYO35S08SqMTERIqKivDx8cFmsw1JDGi1Wu644w4ee+wxnE4nNTU1pKSkMG3aNLKzs4mKKkSvtw1xfRvcbgWdzrsfPp0uALPfNdTVTcRgqMBu78BsNpOenk58fBT1DYcG7wSV4KAMvvnNb/LRRx/x7rvvUlpayqWXXsqtt97Kc889x6uvvsqtt97aa7LvqdRYV1eH0+kEvBcDzc3NvPzyy7S0tHhiNYqLi4mKbh+2EABIn/g7oqOvHX4HkmFhsZSSe+RHtLXto6cuhRAutFp/UpK/S3z8Xb08da2trezdu5f9+/djsVhITU3lxhtvJCEhgSNH/kFVdXeSr+M9AkP5XiiKgbCwFSN1eWcFKQbGOE1NTZ54gezsbIKDg0lI6C6g7htoGFQIACgaBb9AeTdzOqmqqqKpqYm4uDgURSEgIAAhBH5+fkPqJyAggBtvvJGXXnoJIQRFRUVMnTqV+fPn09Gxfsh2KYpKYMAc7I7Ng7bVaHxYcMGX6PXdLvxVqwSVlZXk5uaSm5vLvn3NzJ1nQKt1DNiPELBuXSsXXHCA1atXk5SUxMcff0xlZSXXXXcdN998My+++CJvvfUWN9xwQ6/dFqGhodTW1uJwdI/hjRjIzc3lnXfewe124+/vT1dXF7W1tcfO1QP2Qfs4GX5+44d9rmR4WK0V7N235tjWUwDVs3vF7e7gaOHvcLraSEn+PsXFxezZs4eCggIMBgOTJ08mIiKClpYWtmzZQn19JbPnvMEpxKECEBw8F72+/y3CYwUZQDjG6dlJYLfbyc3NZdq0aR5FnJIZjlY/+EcsVMGEedGn29TzmuzsbPz9/T1LBAaDgdDQ0GFlMEtJSWHp0qWoqoperyc7OxuNRkNwsG7Id7larYnZs/+EXh/KwD8HCrGxN3uEAHTvZoiPj+eSSy7hwQcf5M47vwUMHEUvBDgdFxEZOY6PP/6Yxx9/HJ1Oxz333APAU089RUNDA2vWrKGwsJAPP/ywV1XD+Ph4hBCerJsD7SZQVZUPP/yQN998E7fbjcFgoKOjA1VViYyM7N6J0xiNqg7PNWA2pxMQMGVY50qGT8HR3+BytQ+YD6C09F88/fSvefnll6mpqSE+Ph6z2cy+ffv45JNPyMvLIzw8nOXLQ9HpnKdsk9VadkL1zbGH9AyMYVwuF62trYSGhpKbm4vT6fTkFgAwmHRMXRrH/vXlJ+1D0SiExZmJHR90Biw+P+lZp5w+fTq7du1CCIHL5SI8PHzYfS5cuJCKigoKCwsJCgpi+/btLFociFCrGEqBndSUH2A0hjJt2rPs338rbrel149s97qpQnDwBaSl/uCk/SiKQlxcHHFxv2XzZgWX6zXoFbfQPeHabIs4fCgZmy2fhIQE3G4377zzDpGRkZ60yh988AFTp07lsssu48MPP8TPz4/ly5cDMHHiRHbv3k15efd3+mSegY6ODl588UUaGxs92RsdDgd+fn5YLBbq6uoAaGycSnhEqdfv1/GEh13c67nNVkNV9as0NGxEdVvxMcUTG3MD4eErTjmOwO22Ule3jra2LAQCs3kC0VHXDLp75VzDZqumsfFzBvuOC1XBz28vMIv29na0Wi0RERFMmDDBszXXZrPR3r4ZjXbwoNfBsFrLaWvPIihw5in1czaRYmAM09LSghCC0NBQNm3aREpKCoGBvX8c5l2ZQkeTjcJ99XT/AfW+CwqMMHHZfVPPqRzbo42e6nyhoaEIIdDpdHR0dDBhwvC3nymKwnXXXcfjjz9Oa2sr0dHR5OcFMG68t0JAR0nxNJyOKBISIMB/MnNmr6O84j9UV7+FqnaXuLZaA4iKvJlpmQ+i0Xi3Pp+XF0dX1y2kjasnKdGN1WahsyOIgoJIGhpUTCYNCQkJdHR00NLSgr+/Pw6HgzfeeIP4+HgWLlzIrl27qK6uZv78+Wzfvh2z2cy8efM8gYMNDQ0oioJW2zfvw9GjR3njjTdwubrjYFRVRavV4na7PRUTFUVBCIHZnInJx4DV9paX79vXlJb9i7CwpQQETKGm5l2O5P342N1h98RitVXS0rIdX980pk9/YdjlimvrPiQv739xu7uOBSwKhFApLPwjqSnfJyHhm+fk368QAqfTid1ux2azYbfbaW7egDdiV9EI/AO+zlvR0tLiqcvSg0ajITa2joTEkbmjt9mqQYoBydmgx1Wq1WopLy/n6quv7tNGo9Vw8d2TGDc7gnXP70BjMwMKwVG+TF0Sz8T50eiN/SfSkYwMBw4cIC4ujsbGRnQ6HdHR0VRUVAwpeLA/DAYDt912G0888QQ1NTUkJi7C4diPweBg8ORBbtLGadi1ayMRERHMmDEDkymOCeMfZlzaT3E4mlAUPS+99B5dnf7Mnu2dEGhsbDx2161h4oQHewmeiy4S1NTUeGIMWlpaMBqN6HQ6Wlpa0Gg0NDY2UlFRQWJiIh0dHezZs4fU1FQ+++wzTCYjUdG1ZGZuwM/cfWe/Z88e4uJuJzLyCjQaA59++im7d+/ue7Xur70d/v7+TJ8+nWnTpnl24VTXzKC05F/Y7FVeXWc3grKyp4iJWUPukR/Sd5I6JgqsJezffztzZn845Bz2dfUfc/jwg1+PKFzH/dtJYdGfEEKQlHTvkPo9nRw/iZ/46JnUB3vYbDYcDkcf13tYeAkTJ3pnh6J0L6Pp9XoMBgM+Pj74+Pjg6+uLwWBAo9Gg1UaiKHtG5LqtlrIR6edsIcXAGKapqQmj0cjRo0cxGo2kp/dfJ13RKPjHKrQEH/Acu/MHPxhy8Jpk6HR0dFBYWMiqVas8k1RoaOiIiIGevtasWcPrr79OeXktWt0tRES8hE7n4nhB0HeblMDt3sesWYf4/PPufnruujUaIz4+3XUrpkyZyvr167FYLPj6Dp62+vDhw2g0Gnx9fRk3rncRIUVRiImJISYmhosuuoja2lqPMOgeV+MJDKyqqsLlchEcHExRURHBwWYKjj5IY1MlZv+vcyJ0dOZxJO8nlFe8TNa+hTQ0dPVrl6IoZGRkMGPGDJKTk3vdSSuKQmzMDcREX0dr2z7stjqO5P3E4x05GUK4qW/4FIu1lIHSJgvhxmIpor7hE6Kjrhr0PexBVZ3k5z88aLvikr8TE3MdBsOpfZ96lq+8mbh7JuuTtRto/Vyv12M0Gvs8/Pz8+hzz8fHp9VxVy8k9stWLa1Ho6gzG6XQihMBms/UqDhYQEEBwcDAhIVH4KGkIUczJBLS3Wwwrq14hKenbnkRkYw0pBsYwTU1NhISEkJOTw6RJkwaMrC4pKfG4RgHP+qnk9HLw4EE0Gg2JiYl89NFHQPcWORhajoGBmDhxIgsWLGD79u1UV2lxOu4kMPBTgkOqEaI7OKr/HzM3imJn8uRdvPFGJPfccw9BQUG9WkyePJnPPvuM3NxcZs2aNagtPXv4p0+fPmB5YUVRiI6OJjo6mmXLllFXV0dubi6HDx+mubnZcyff49oNCd1IcHDlsXOPn2i6f8A7Ow8TEdlEQ0Pv7V1hYWHMnTuXyZMn98lb4OlBVenq6qKjo4OOjgDa252DCoHjx+/szB28GRqqql4dkhhoatqE09k0aDsh3FRWvkFExG2ndDdut9tR1ZN7lHQ6Xb8TdUhIiOfOu79J/vi2BoOh36Ud74mksmoq7e2HGMj7pSiCBQv+l4kTQykrK6OkpIS2tu6kQP7+/vj5+aGqKtXV1VitM0jPqECrdXjSdffuyzvLHI46mpq+JCxs6XAu7KwjxcAYpqmpCR8fH2pqajy5BU5GSUkJ/v7+uFwuLBaLZ5+25PTRk1tg4sSJvfLuK4qC2WzGaBy5sqfLli2jsrISu30DsXHZ6HQ2VNWbHzI3BmMNgYGtvPrqq9x9990YDF8Hu/n5+ZGWlkZOTs6gYqC+vt6zdDV9+nSvbVcUhaioKKKioli6dCm1tWUcObKLI0eKaGx0otfbiIo6OuC1KIogOLgGP79mrNYwMjMzmTdvHv7+/nR0dFBVVXVssu+gvb2dzs7OXv/ufScrWHDhUDMyDoZKQ0Muf/7zn3td90BERe8mMlIzaOEoIQRf7X6Lgvz6fl/XarX9TtRBQUEDTtwnPk5tEh850tJ+xv79txyrK9HfZ6QhLHQpcXHLiI9XPL+NbW1tlJaWUlZWRmlpqUdohoXF4bD/ALP5YwTZJ+lzcBRFR2vbPikGJGeOrq4umpqaqKurIzAwkNDQUOLi4k7aXghBaWmpJ7jQYrF43LGS00dNTQ0NDQ2sWLGCQ4cOYTKZMJvNtLe3j5hXoAeNRsOFF3ZRVr7Lc8z7mDINF1wQwIcftvLOO+9www039JqopkyZwjvvvENLS4unrkJ/HD58GEVRPEWyhkpXVxFlZU9RW/c+AicT08FgiMduC8ebH2hVVYiLq6CqKoHDhw+TnZ3dx12tKIrncTJXtk5nR1U1aDTuAd9DIcBmM2MyeVeu2O1WsFgsfY4fb9PXfQucThdeBcspCrGxYWROXYmvb2SvSd1gMJxSMafRSHDQbKZOfYpDh76H291JTypoRdEihJuI8JVkZPy5j9gKDAwkMzPTs+Oqvb3dIwzKyspoapqCwZDC9OmfodN3DiMZldIrpmOscW59S84wdrudgwcPkpWVRXt7O0ajkYyMDGbNmtUnqn8kaGhoYMuWLeTm5nrcefX19cTFxWG1Wk+6pltbW4vNZiM4OBg/Pz/q6uqkGDgDZGdnYzabSUlJ4YMPPvBsv6utre1VcnoksForKCv/+7DOVVVBS2sd1157L6+++ipffPEFF110kef1CRMmoNfrOXjwIIsWLeq3DyEEOTk5CCGYMWPGkG1oad1DdvZahHD22trocFSiaCq86qP7x7uNzs6TT87d6ZK7f+W1Wm2vh16vR6fTERH5xaBCoGe8wMA1OBzPe2VfVORMvv3tb9Pa2kprayvNzc00NjbS2NjocWFD93p2YGAgen0XGs2BAXr0XBVO515qam8mMHAWiQnfICRkbGfDG4yw0CUsvHAndXXraGreiqraMZkSiIm+zusiUQEBAUyZMoUpU7pzRXR0dFBSkkdD49vDskkIJ2a/cYM3HKVIMTBMGhoaePHFF+no+LogTGdnJ9u2bWP79u1cc801TJ48ecTGq6qq4oUXXvAExJz42tNPP83dd9+N2Wzuc25JSQk6nQ673U5MTHdgmFwmOL24XC4OHTrE9OnTaWpq8kxQcXFxHD58mEmTJo3oeFVVr9J9hzTUAivdLvbDh+tA1LF8+XI2buzeYdDzI9lT+ConJ4eFCxf2696ur6+ntbUVg8HARG/DvY/hdLZz4MA3UNX+dkF477IVAtyqYcC7fsAjpN1ud5+/A53OTUrqAa/uChUlHJNPLN7oaiGgoqKYjz564ti53fVEwsPDmTx5MmFhYYSGhtLe3s6BAwc4evQoBoM/UVFBKEob3r4PbW1Z5By8l+Sk75KS8qBX54xVtFpfYmKuJybm+hHpz9/fn/T0CTQMHp94EnvMRESsGhFbzgZSDAwDq9XKCy+84NmzfDxCCIQQvP322/j7+3sitE8Ft9vNq6++2q8Q6Bmzra2N9957j1tvvbXP66WlpcTHx1NRUeFx30rPwOnl6NGjWK1WMjMzKSoq8iS+CQ0NHVK1Qm9pad3FcIQAgBA6mhqT+eKLL5g3bx5Tp07l/fffJyQkhNjYWACmTp1KTk4ONTU1HkF5PAcPHgRg2rRpQ3ZL19S+jdvdxXDXanvQaARWy0SEEGi1WuLi4oiNjSU0NBSNRkNXVxednZ20t7fT0dFBZ2cnFosFu/3rdMS+vo1otd65eu32NvYVbCQ1bfAlGUWBgECdp0pjaGio533q7OwkKyuLzZs309bWRnR0NKtXr2by5Ml0dFxI9oFvHOvFm/enW+iUlD6Kf8AUwsMuGqS95Hh0OjN6fahXgZsnkpb6Q7Ra02mw6swgxcAw2LVr14CuyB62bNnC7bfffsrj5eXlDTqeqqoUFhbS3NxMSMjX1bPcbjdlZWXMnTuXkpISz2vSM3B6OXDgADExMURERLBhwwYCAwOx2Wyeu9KRFgOqOrzPUwiorMwgODiGhoYGdu3axdSpU4mKiuK1117jnnvuISAggOTkZMxmMzk5OX3EQE+gJMDMmQMnXRFCpbl5O1XVr2G1lKLR+mC313KqQgA0mEzx3HXXX2hubuHo0aMUFRXx1Vdf4Xa7CQoKIi0tjbS0NJKTk3sFSfYkI+rs7KSxcTsNjZ95NaKvrw+XXXYt+QVfedFaITg4xuMREkJQUlLC3r17ycvLQ6PRMHnyZGbNmuURYAChoYvJnPoUR/J+isPRgKLoji2jDPZ+aSgv/48UA0NEUTTExd1KScmjDJ6rA3qKJKWl/pi4uL43YmMJKQaGQGtrK+vXr/fsix4IIQTFxcU0NDRgNptRVRUhBKqqnvTfJzu2d+/eQV2f0O16zM/PZ/78+Z5j1dXVOBwOjwgIDAxEp9NJz8BppKuri6NHj3LJJZfgcrkoKyvD39+f+Ph4mpubPS7ikcRsnkBXV/6A+dr7Pc9vLpMyvsf69Rswm810dnaSk5NDamoq7e3tvP7666xduxa9Xs/kyZM5ePAgF198ca9tgzU1NXR1dREWFkZERMRJx3I62ziQcw9tbfs8wV5Dpb8930IouFx6YmLuo7jk71gsRZj9dSxeModrQr5DZWUjhYWFFBYWsnfvXrRaLQkJCR5xEB4eTkBAAAEBAYSELqSh8eQ5A75Gg69vCkZjgNfXEh5+MRaLhQMHDrBv3z5PkbGLL76YzMzMk259DAtbyoILttHU9AUtLXupqHzWi3dKpbV1Nw5HMwbD2C6te6aJj7uN6urXsdsb6N/bpqAoeoKD5xMcNIeYmDUYDGFn2swRR4oBL2lpaeE///kPVqu3+4+7+de//nXKqUK9LYChKEqfSb6kpASDweC5EwoMDMRgMEjPwGmkx2U+efJkKisrcTqddHR0eOIHgoKCRjzCOy72Zmpr3/W6vRDgdBrZvm08CxZ0cscdd7Bu3TpPtHtRURGRkZE0NDTwwQcfcM011zB16lR27dpFcXExaWlpnr6ysrIAmDdv3gDjqRw48A3a2g8ce+4+4XXvdj80NSUSEdGIqnYv0amqhs6OKWi0bqqqfoSiaOhJu11f/wkazR9In/h7Vq264tj5TR5hsGnTJjZs2EBAQIBHGKSkpBAWupTGpi0MvOyi0tGRS85BbzL/aVAUI/v26jl06G8IIcjIyGD16tUkJCQM+vsghMBisdHc7KKy6l2G4kVxudqlGBgien0wM2e8RvaBu7FYio4Te1rAjcmUwLTMZ/D1TT7bpo4oUgx4yfvvv4/Vah0wKUd/rFixgpCQEM/WIYfDgcViwWKx0NXV5XFP9iQ96cmnDt2Tu16v7zctZ3+oqoq/v3+vY6WlpSQlJdHR0YFWq/Wk4pSegZGlrq6O5uZmdDodWVlZTJgwAV9fX4qLi/Hx8cFmsxEfH8/OnTtHfIkAICBgOuFhF9PQuJHB3JtCgBAa8vMWI4TCjh072Lt3L/+/vfsOj+o+E77/PdM1Mxr13gVCnd67DRgbbAMuFBdwYjtOso6z2c3uXvu++7TdZ9u7ebLZzSbO4xg7LtjghjE2BtsU06tAAiQhioR679JI0877x3iOEWojoQb6fa5LF2jmlN9RO/f5lfueO3cuzc3NZGVloVarqaqqwmKxcOnSJUJDQ1m4cCHBwcHk5OQowYAsy1y6dAmVSqVMOOxJXd23NDVn9fq+N4GAzWYgOOhvWLxoCe3WIvZ+uYcrV+qJTzhLRMS177byXLv798Xl6uBy7l+gVhsICXmAoKAggoKCmDNnDna7nZs3byrBQVZWFiqVisTERMIjjnx3jN6/lrJsu+3znq5DhSzDpYsLgCqWLl3KtGnTekz4ZbVaqauro76+vtu/Wm0Zk6fsRZJcA1ryplINXS6L8cTHJ4a5c/ZSX3+Eyqrd2G11aLWBhIU9TFDQ4rs2y2BfRDDghZqaGoqKiga8n06no66ujsLCQhobG2lqaupys9fpdPj7++Pv709oaCiyLH83blmrFCEKDAwkJCSEnJycfs+n0WhIS0tTPnc4HJSUlHD//ffT1NSExWJRAgzRMzA0rl27xv79+6moqOjyel1dHf/rf/0vJEnCx8dHScVbV1dHYmLikLdDkiTS039Dbt4vqa7e02PXtedm5XSGk58/g7lzn+LAgQPY7XacTifffvstRqORGTNmcOnSJVwul7Jk9sCBAwQHBzN58mSOHDmCzWZDp9N9l+iok6SkpC7j8LcrK9+B58lqsGqqp7Fhw1LUaj2+5hSCgsrx8dlDRMTVfvctuPqPBAcv/67nwE2r1So9AuDu/fMEBrmXV5A06Rs0GvcN330D7rv93YcvoL4+EpVqDatXP8qECROw2+3U1dVRVFTU5YZfV1fXpdfRbDYTFBREeHg4aWlpuOR/YTC/spcv/4Jp097xusiU8D1JUhEUtISgoCWj3ZQRIYIBL1y/ft2rMfvbuVwuKioqlMlLnhu/n58fFouFhoYGCgsLuXHjBtnZ2TidTiwWi1KvPjExEZPJhCzLSoKMvtowZ86cLuOOpaWlOBwOEhISOHr0qJL7QPQMDI2cnBw++eSTHt/zpNOVZVlZdZKXl0d9fT2zZs0alvao1XoyM35La+vLlJXvwNpeiCTp8DHGodeHcO3qTS5caMRui8JkMpOdnc1jjz3Gjh07iIqK4ubNm1itVs6dO4fZbMbX15fa2lo6OztRqVR88sknrFs3l5jYoxw9th1Z7sDlMhCfEMfceT0vqfL0HJSVnUWvH0wg4L4BV1QkkZ7+512yNoaEhBASko/LJfWYRvaWVtDRUUpDwwkCAxf0ulVAQACzZs1i1qxZOBxPUlRUwI0bH9BuPY7D0Ybd7kNIyM1+y93KMtTVpqDRPE5QYBxtbW0cPXqUXbt2dZkI7OPjQ1BQEIGBgSQlJREYGKh8fut1trZe4dTpvH6/Uj1pbDpDdfUewsPXDGp/YfwQwYAX7Hb7oIKBxYsXd0nS0tjYyPXr17l48SKFhYVYrVZ0Oh3x8fGsWLGCCRMmEBQU1G0MUZIk1q9fzzvvvENFRUWPbcnMzOT+++/v8lphYSE+Pj6EhYXR3NysTCIUPQN3rqWlhU8//XRA++zcuVMpOT2czOZkkif9926vx8bI1NZ+QH5+Pj4+LqqrqykuLiYhIYHm5mZeeeUVsrKyOH36NK2trbS2tipDHO5lkdcor3iTiIjv57GoVG1EReVx8+YWLJbfExy0FHAvl9u/fz+XL1/GbrczdRp4m31ZrTZ/l1lOIsB/NvlXomhtiWfaNHcyI0+ApVKpMJoa+gkE+G4f+Pbb9+noKEalUikfkiT1+blavQiL72L3U7t8DEkq9Ooa9IYasi+UoFKVKel9fX19CQ4OVj6/dd5Ic3Mzzc3NFBUVKcuTPR8azWl8+q8R1QsVJaVviWBA6JcIBrwQEBAw4LkC4F5a6O/vT0lJCTdu3FBmkkdFRTFr1iwSExOJjo72Kue30Wjk+eef5/Lly3z77bfKsWRZZsmSJSxdurRbEFFYWEhMyEQufVtGS6GWYL0Fl0sWPQNDICsra8DBocdwBwO9kSSJxx9/nNdff52qqipCQkI4ceIEDz/8MJ9//jlXr17l/vvvZ9GiRWRnZ3P06NHvi7tYapmUfPS749x+XBmXy0ZOzk8ICf5Pjhy5Sk1NjXJOgIaGKEymRi/y/asJCvwxnTY7dlsoV6/C1YIrREVpef3115UgxfO1T0tXeTX5UJJApS6iuTkTp9OJy+XC6XQq/7/149aVPLd+j0NCygjwYi6eJKHkKnC5XMococGQJInQ0DKSJg1qdzwTHQWhPyIY8EJycjJ6vb5LchJvOJ1OPvnkEwIDA0lMTGT58uUkJCT0uoSoPxqNhilTpmCz2dizZw/BwcGoVCoaGhq65jV3yVSVNNJ8IRCrzcLhUwWoiaSkBt7KOYYm2oTs1zioNghuV65cGXAw4Nl+KAsUDZRGo2Hz5s38/ve/p6amBn9/fw4fPkxGRgaHDh0iMzMTg8HAzJkzmTFjhjLr3s//ELLcV3e8jMtl50L2v1NTM0c5l16vp62tjcqKSURHX+qzbe4vj5Pqml8prxl8AggKmk1nZzBarRaLxYK/v78SCLe2hhEQUN7rMW+l11+jqqoMWVZ3qaDneUL3lPD1zKG49ftrMBjw8Ynq7dC3XYdER4c7E6jRaCQ0NJSQkBBl8qJWq1WCEW/+tTuScDiOenVuQRgsEQx4QavVsmTJEr766qsB7eee1JXOE088MaTtaW1tVZYHTps2jePHj2O32SnKqefiwVIqrruf5jR8v7JAwh0stDfZoMmMJnZgSySFru5kmKW9vV0pYzwajEYjP/jBD/jDH/5AY2OjsmKls7OTo0ePsnz5csD985uUlERCQjjfHv43+lvSJkkyYWHXqShfQmenDYfDoUyY7ew0c+P6bCZMPN1LrgDPMbq+bjI1kJK6j2vX7LS0pCg3cc+/NTVTgPNeXbdWa2fyFIma6kgaGxu7pBLXarUEBAQQFhZGQEAAAQEB+Pv7K/9qtVpk2cXxE0fp6Cjr9+tQX5f23f8lmpubqaioUB4m/P39iYqKIjIyksjISCIiIvoJEOdz5uzHNDdn410inFup8PUdurTowr1LBANemjdvHlarlSNHvE9c7ZlJPtRaWlrQ6/XY7XbS0tI4dPBbdv7nGWqudXT5Y+oJAHriKA6mrakTk59YejQYgYGB1NbWDmqooK9Z9yMlKCiIp556irfffhuHw0FBQQHJycmcPHmSWbNmdSm0ZbPV4+1NSK120NnZgsvVffZ6RUUKdoeeuLjzXSr99RYIeF6TZZgw4VuyzkXS2anvUuHP4ZBob7dgMjX32zZZlnA6KggNnU5ycrJy0w8ICMBoNPa73l+SVCQm/Dm5eX/VxzZqjMZEfvj8f3DjehE5OTlcuXIFl8tFTEwMYWFhSJJEVVUVhw4dUoLK4ODgLgFCeHh4lzkFyZP+O2fPbUCW7QwsW6OLmOg7z4Iq3PtEMOAlSZJYtmwZGRkZfPXVV1y/fr3ffVwuF7GxsUPeFs/ErsbGRkJCQgh2pFJzzYq7hKZ3x5CBvGPlzFx1byXOGCnTp0/nypUrA97PM0t/LEhISFDmC6jVaiVB1YEDB1i3bp2yndVa7fUxZVnC5eo6B0alUmEwGDCbzRiN8VjbVyFRjl7fjEbrwOnc1ucxJQkkycX8+TIazX3fncc9nl9RUUGH1RejsdmreQOzZs8jNmbwk+kiIh6js7Oa6zf+7bblm+4yuj4+CUyb+hZajZ7k5GSSk5Pp6OggNzeXixcvcvbsWbRaLSkpKSxYsACLxUJFRQXl5eWUl5dz8eJFXC4XKpWKsLAwJTiIiopi2tR3uJC9BZerw8vWqvD3n01o6EODvl5h/BDBwACFhYXx1FNP8etf/7rHQkW38vHxITU1dcjb0Nraio+PDzU1NXS025HqgwaV2b30SiMz794iW6MqKSmJiIgIKisrB9Q7kJzsXXnVkTJjxgyqq6s5ffo0sixjMpnIyclh9uzZyLLMuXPnaG7ZSkRE/5P0ZBnq6qJx3xjdPAWaPJPoPGmMPRNyw8KvM9GLQj8gY/YtZtrUeV1evXptL4WFlV5erUx9fRixMV5u3ov4+B8THHwfpWXvUlt7CJerE6MxnqjITYSGrkKt7trbZjAYmD59OtOnT6epqYmLFy+Sk5PDxYsXMZlMZGRkMG3aNFatWoXT6aSqqkoJDoqLizl37tx3x3ExY2an10mHwkJXkZr6zyLHgOAVEQwMglqtZu3atbz33nu93ggkSWLt2rVDnnYW3MME0dHRANw4X4088IUOSEi4nIPYUQDcN7mnn36ad999l8rKSq+XnvaVpW+4OJ1Wqqp2U1b2PtaOElQqPcHBy4iOehqzOZkHH3yQmpoaCgsLaWhoQKvV8uabbyq5EmbOvOllSV8wm2agVquVfW9fhePr66usZmlpaUGl8j73gNPZ9Ym4re0GpaW/RKVyetE+NQ5HDF98fp7QkKk9Vl4cCLM5mZTkf4ABxnZ+fn4sXLiQBQsWUFlZqQQFp06dIjg4mMzMTCZPntwlF4XNZqOiooKbN/+E3eFd4KlSGcjI+I+BNU4Y11T9byL0JCkpiWeeeUYpOHPrOKa/vz9PPfXUsDwFulwu2tralHSmLQ1WpEF8F2VcBEZ0T4kqeM9sNvPiiy/y5JNPKgV6TCZTj6lmPXbv3n1HyxIHymot49Tp1eTl/y3NLZew2xvo7KykvHw7p06vorh4K52dnaSmpipLXD2z6T3UGu9v2CWlnfzsZz9j3bp1PRYtamlpoba2lqamJlQqFb6+iV4FGrIM7W1GSkpK6OhwBwWFRf+Fy+XNk7KERmNi7pxXCQsLY/v27V0mD44GSZKIiIhg5cqV/MVf/AXPPPMMkZGRHD16lP/4j//gzTff5Ny5c0ouEl/fMuyOdwdw/HsvXa4wvCR5pP4q3aM8pUjLy93LmyIiIkhISOhS1W0otbS08Otf/5olS5bw7bffsnre05z6pHhQx3rsb6YRkTC01fPGqwsXLrBr1y7+7u/+jvLycrZu3drn9lOmTGHNmjVD/nPictmpqf2asrL3aWu7ht1e32/J24IrS6iujus1/8SUqV9gNtd5ddPOOvcodnsIL730EkFBQVRUVHDq1CllLPxWGo0GHx89qWlvotV29Hv8hoZwLl9aAUiEhHQwKfkDr9qkUumZM3sPRqO7Rscf//hHfH19lWqMY4nNZiM/P5+cnBxu3LiBSqVi0qSJhIb+B05XLd5N5FQTEDCX6dPeHu7mCvcQMUxwhyRJIjExcVjyzffEk87UMwktLMmEpGJgQwUSdOirsYSO/qz2e4XnCU6tVnPjxo1+t8/OziYqKorZs2cPWRtstnouZP+AlpZLeCa09UeWISb2AtXVsT0GAgaDAbVqFrC33+O0tQYyY8YjHDlyhFdffZUtW7YQExPD2rVreeCBBzh//jynT5+mublZyYLZ0uLgZtE0kiad6LetAQGVbNqUgrUjkdqaH9PHYpkuXK5OfHzcEwV8fX3ZuHEjb775plKN8U6rig4lnU7H5MmTmTx5Mq2trVy8eJFr13fhdHk/iROcxEQ/O2xtFO5NYpjgLuPp3rRYLABoDJA0M8y7rtbvng4jUoy0+heILIRDqL29HaPRnTM2N9e7jG/Hjx8fVGbLnsiyi+ycF2ht8eSw9+64kgQ+Pk2YzXWAey5EeHg4AGZzLROTPsdo2uvVTP3q6rlcvnyZjRs3Issyb775Jvn5+YA7t8GCBQv4+c9/zsaNG4mJcd+cdTodLS2ZOJ39P5fIskTRzTfp7PwWpCavrs9Nza1/6iIjI1m7di2XLl0a0FLhkWY2m5k3bx4L5kfgvgbvBAcvJzh42fA1TLgniZ6Bu8ztwYDdbmfJpmTqK9qoLWn5rpL7rX+5ZSSVhG+IlqqWmzzxo2WoTQ4uviGL+gRDyGq1KjklamtrvdqnsbGR6upq5eZ7J+rrj32XlGZwgoMl1q//IdHR0UiSxIEDv8PperfH9MG3Jg2SXZJ7zor8FNXVemS5iaKiIl544QXeeOMNduzYwerVq5k5cyYADkc9vpaLLF3qZO68FK4W6Lly5YSSvrcvkiSjUl2noqIOk8m7sseyLOHvP6vb0396ejo1NTUcPHiQkJCQYVn1M1RkXN9NUO1/Wx+fODIzftulOqMgeEP8xNxlWltbMZlMSsYyu92OzkfDY7+cQerSEGTV9zd4SQ0dxkrW/FUGj/31dNr8rtNir1WS3oiegaHjCQZkWe4y+a4/nslwd6q84gMG8vR4u5mz9ISFmZAkiZKSa9gdv0WSXD0GA55EQKCjvDyF6Kg3mDv3b5AkidjYWE6ePIndbufP/uzP0Ov1fPHFFxw8uIfLuX/J0WPzycv7Gwqu/iPFxf8PRtP/YPGSgfSOyJjNNq+X10mSzIXzgVy+fLnbpM0lS5aQnp7Ozp07u5WgHkvM5mRkuf9gCVRERjyJSiWG/4SBE8HAXaalpUVZngXfp8XV6tXctyETx8Q8ou/v5Kn/OYfN/zwXe2gJudeyMZlMBAUFUVxcrEyaEj0DQ8dqtWI0GmlsbBzQfmaz+Y7PXVNTQ1XVJWAwJYLdKis/5eSpB/jqqzf5Ys//QK2293nDdb9np7wijbY2MyaTienTp1NeXk5kZCS7du3CZDLxyiuvYLHoaW7571RU7LolSY87AHA6W2lo+MTrZFl2uz+dnd7PeW5pjsNsns9HH33Eu+++26XXRpIk1qxZQ3BwMNu3b+9SXngsCQlejlbb/0RfSZKIiHxyBFok3ItEMHCXaW1txWw293hDlySJtPQ0rpXk4h9mxGwxMmPGDM6dO0dnZycxMTGUlJSInoFh4Kk3UFVV5dX2kiQRHh5OcHDwoM7X1tbGqVOneO211/j9739Pa4vN6xtqz1zYbI04Xb8iNKTcy0l1MhHhdUoANH/+fBwOB7GxsTQ1NXHgwAGMRiOrH1b1WbHQnWEQ+v9zJJGe9jKRkQ95sS04nWpychaQmTmZp556ioaGBl599VX279+v/OxrtVo2btyIy+Vix44dSi2FsUSl0pGU9Hf9bhcf92fodYP7eRIEEQzcZVpaWjCbzUoyo9uf7tPS0mhtbaWkpASAOXPmYLfbOX/+PLGxsVRXVyuT1kTPwNDxDBNUVlYq35u+bqiyLLNo0aIBncPhcHD58mXef/99fv3rX/PVV1/h5+fH+vXrSUlZj9fT63shSTJabQfhESq8y3+vwmTSKsGAxWJh6tSp5OTksGTJEk6ePMnNm9epqNjhRelicPcW9PwnSZYlrFYzu3fX0d42u9/2yTKUl6Uhyxo++ugjLly4wOrVq1m0aBEnTpzg97//PXl5eciyjMViYePGjVRWVrJ79+4RywExEBHha0lN+WdUKj3u77NK+ZAkNQnxr5CQ8MroNlK4q4kJhHeZ1tZWJkyYgCRJaDSabjf06OhofH19yc3NJTY2FovFQnp6OqdOnWLTpk3Isqw8vYqegaHj6RkoLi5Gp9MRERFBVVVVr1/jZcuWkZ6e3u11u92uLFM0GAzIskxJSQnZ2dlcvnyZzs5OoqKiWLlyJRkZGbS0tHDixAny8qqZOUsFeJONr3eSJGG3N9yWd783LvT6cGpqGpVXFixYQFZWFlqtlujoaPbte4sJExt7PUJPx3RzL430tMNsTiYh4e/p7Chi//5cIqNmEx9/CveNsevNW5YlWpqDKSnJ/O6aoKHhHHu+3IufJZylSx/g5s1SPvjgAyZOnMiDDz5IVFQUjz76KJ988gkhISEsXLhwAG0eGZGR6wkNfYiKyp00NZ0H2YXZnExExJPo9SGj3TzhLieCgbuIu357q5JjwLNW+1aSJJGamkpeXh4rV65EkiTmzp3LxYsXqampwWg0Ulpa2mMgIQyO3W7H4XBgNBqpqKjAZrMxadIk1qxZw+9//3skScLpdCpZKp999lkSEroWiKqqquLEiRNcvHhRmYBosVhwuVy0trbi7+/P7NmzmTx5MkFBQdy4cYNPPvmE69evY7FYWLJkNaFhUykq+ltkWb6DgEAGZC8CATejqZHGqxbl84CAADIzMzl3bg8LF6m4du3gINogoVGbMfumYTCEEx6+jsCA+UiSigmJM3jggQc4d+4c1677Exp6EpPp+2WGarWZiPANHD7sh0rVQGhoPtExORgM39cRaW3bidOVSVraOkpLK3j11VdZsGABCxcuZNGiRezfv5/AQDUGnzOUl3+AzVaDWu1DSPBKYmI24+vbPYgbKRqNLzHRm0UlQmHIiWDgLtLe3o7L5VImnfUUDIB7qOD06dOUlZURHR1NZGQkcXFxnDx5ssu8AdEzMDSsVivg/n54usxjYmIoLS1FlmWWL1/OV199xQ9+8APefPPNbvtfvXqV7du343K5unRRNze7y/KmpKSwfv16ZFnm0qVLfPTRR1RVVREeHs5jjz1GUlISe/bs4Ztv8rBYVjAx6TI+PmWDvh6tNgCTaZL76bPfSYm78TG65wpoNBpcrk5i477B4reX2loV/v6uLksRvSPjcDYTHbWJsLCHu73r6+vL0qVLWbRoEZcvXyY753MaG25gMPiRkrKamJi5PPOMxOdfPEdg4Nlucym02k4iI8/SUF9Nc/NiQkLCOHr0KDk5Od/1uJgoKf0hGo0DT0+Fw9FCZdVOKio/ZlLSfyMmZstALkgQxjwRDNxFbs8+2FswEBMTg8lkIjc3VyloNG/ePLZv386sWbO4cOECPj4+IhgYIp5goL29HXD3zkRFRfHtt9+SkJCAWq1Gq9USExODr68vV65cUXoG6uvref/99/tMPpSfn8+HH35IWVkZLS0tJCUlsXLlSuLi4jh48CC7du3C6XTi7+/P2rVbiIuL48qVv6e07B28TT70PRVhoauIjX2BM2cfw2q92efWsgwJCWc5eux/kp62jIqKD2hs/Oa7d13ffT0G2ITv2lFatq3HYMBDrVYr2foqKio4ffo0hw+f4NtvjzN1qo7AwLO9nl+SICCwmPCIAmqqtUplxU8++ROzZu9Gkux0H35wB0YFV/8eH58YgoPvH8yFCcKYJIKBu4gn4ZDRaCQvLw+r1cr169c5d+4cGRkZSu4BlUpFamoqubm5rFixAkmSmDRpEoGBgdTU1GC32zGZTGKYYIh4ggBPsBYeHk5raytFRUWsXbuWpqYm9Hq98n24cuUKGRkZXLx4kaysLK+yEObl5TF16lTmz59PaGgoZ8+eZfv27dhsNgwGA2vWrOlSEVGl1iJJKuQB5qmWJDVRUU+h0fiiVlv630MCrdaGw/E+ORffH8C5+uOire2611tHRESwZs0aVqxYwfnz56mu+e/oXRIqVe+TAd3fjxL8LI9y9eo1bDYb0TFXkaT+6iSoKCz6nQgGhHuKCAbuAk1NTVy4cIFr164hyzKvvfaakqymra2N3bt3s3fvXpYtW8acOXPcSwzT0jh79iwVFRVERkYqcwf27NmDWq3G5XKJnoEh4ukZaGxsRK1WExMTQ3Z2NjqdjtTUVL799lv0ej1NTU04HA4aGxvZunUrZrN5QIWKQkNDaW5u5p133qG1tRWNRsN9993HokWLuq1c0OlCBhgIqAGZ9PR/R6XSc+bs47S2XvR6byUj4YCHBHqnkgb+58loNDJ//nwOHirxYlWAjMtVwdRpsUyfPoOKigqsHbu8OIuL5uYLtLffxGiMG3AbBWEsEsHAGOZ0Otm7dy9nz7q7Oz1/3HrKWme329m7dy9Op5MFCxYQFxeH0WgkNzdXqd0+depUDn5zBH1bKFKdmcoqPQeb80lbGElYfP9PgULPrFYrkiRRVVWF0+kkOjqaAwcOkJaWhizLlJWV0draym9+8xvUajUqlYqMjAzWrFnDv/zLv3h9nq+++gpw9/xMnz6dhx56SFnGeLuwsIe5du1fvT52UOBC4uN/isUylbNnH6O1Nd/rfW81VIGAJKkJDBzY0ksPWXZ4PQES4LNdH2G1+gMwb36r19dgs9WIYEC4Z4hgYAzbvXs3Fy5cGNA++/fvZ8qUKZjNZlJSUsjLy2PZsmVIksS1M7WYiqcqQYXdKpF3vILco+UkTAlmxfPpaHWiDvpAtbe3YzAYqKmpAdzdz42NjTQ3N/OrX/0Kh8OhdOWnpKTw0UcfcfPmTT7++OMBD9UEBATwox/9SKmD0BuDPpzw8LVUVn5K7/MGVFh8M5k8+f8qS9Oqq/fR0np5QG0aDrLsJDr6mUHtq1Jp0WmDsdm9qRGh5vnn/xJJMuJ0Ormc+xlOZ6NX52ls7MDPTx5TVQ8FYbBE0qExqry8fMCBALh7D7KysgD3qoL6+nqqqqq4fr6aA2/ngewuZOQpZiS73IFBUU4tX73ePX+70D+r1Yper1dm1O/a5e5qbm5uZvHixURHR+Pn58eNGzf43e9+x/Xr12lqaqKhoUGp3uctWZb7DQQ8UpL/gYCA+d99duuvuvt77+ubxtSpb3ZZo15W/j5j4c9CXOxLWCyZ/W/Yi8iojfR3HbKsIiRkJUFB0QQGBhISEkJE+CNIUt8BsSxDR4eJt976hn/7t39j7969VFZWit8d4a4megbGqDNnzqBSqQZc4laWZcrLywGIj4/HYDBw+XIu5QcN/eznDgiqCpsJT/QbdLvvVq2trWRlZXHhwgXa2trQ6/VkZmYyc+ZMAgJ6zwvf2trKzZs3lcmdnuWBcXFx+Pn5ce7cOZqa3OvgPbPfIyMj+fjjj0lLS1MyRXprIIWN1GoDU6dspbp6DyWlb9PSkoMsy5hNk4iO2Ux42FrUan2XfdrbbzDwFQhDR6sNICH+ZaKj72zpXnTU05SWvoPD0UpPyyNl2f1xPiuMuNgm/PzcP/PR0c9QWrat3+OXl6UBElarlVOnTnHq1Cl8fX3JzMwkIyOD8PBw0WMg3FUkWYSzY9Krr77qdZ772yUnJ7Np0yYAdu3aRUl+HVJhfL/7SSqJ5DlhLNuSNqjz3q2Ki4vZtm0bNputy9OdJ0nQE088QVra918Tu91Ofn4+OTk5XL9+HVmWUavVOJ3OLss9w8LCiIuLIzc3l9DQUCZMmEBdXR21tbWUlpYqgd5AfgWDg4N5+eWXB3WdnvP0dZM6cXLFdwHByAoJfoCIiMcJClo8ZFX3WlpyOX9hC3Z7w3eveL7OKpxOiSv599HUFINOp+Pxxx9nwoQJAJSXf0he/t/i7kG5NTByZzvU6RZw8MCEPmtB+Pn5kZ6eTnp6OhEREQMKDGy2etraCgAwmSah0wV6va8gDJboGRijBvtUIUkSERERyudpaWnkHT+Arxf7yi6Z+or2QZ33btXY2Mi7776L3W7vdlOWZRlZlvnoo4/44Q9/iMPhIDs7m9zcXGw2GyaTCaPRSFtbm5I1UJIkjEYj0dHRNDY2cu7cOZxOp1IvIigoCK1Wq5zrkUcewWw28/777/cbFEiSxLRp0wZ9rd78TAUFLcFqvTmgCXh9kWWpn7oEKjQaC0HByygt28a16/+KWm0iJGQFkZEb7qjwjq9vGvPnHaCychflFR9h66xGo/UjPOwRamtTqK8/gkYj4XK5ePfdd1m6dCmLFy8mMvJJDIZIiop+T0PjSeV4Pj4xxMT8kOiop5k2tZ233nqL2traLj14KpUKWZZpamri1KlTHD9+HD8/P9LS0khPT1dW9vTEai3h+o1/p7r6C6VksSRpCA19iAmJf4GPT+ygvxaC0B/RMzBGffHFF5w7d27AwwSSJPGLX/wCi8W9OsDhcPCb//EnfOoSvdo/YoIfj/3VjAG392719ddfc/z48X5vxJ7lmJIkKdvq9Xp0Oh2tra1d9jcYDERERBAUFERwcDAHDhxg1qxZLF68mK+++opz586RlJTE1atX8fPzU4YR+mqDJEno9XpeeeUVjEbjEFx5z9rbCzlxcgXeFSrqjURo6CqCAhdSVp7NzZuHCAioxFNvwEOWJTQaM1qtHx0dpbe97y7Ak57+74SFPnQHbemZLMvs3LmT/Px8JElSvo8TJ05k3bp1yte4o7MSW2c1arUJozGxy41clmUOHjzIkSNHAPDx8VGWmWo0GvR6PW1tbeh0OmRZxm634+fnR2pqKunp6URFRSnHa2u7ztlz63E6W7oFYpKkRq02M3PGB5hME4f8ayEIMBZmCgk9mjVr1oADAYAlS5YogQC4/yjFpQXjzR93SYLolP7rpo8FnZ2dNDU10dnZeUfHycrK8qqb3ul0Kj0F4A4OLBYL0dHRqNXuCWd6vR6tVssvfvELNm/ezLJlyzCZTNhsNiW3QHZ2Ng888IDyvW1qaiIhIYFf/vKXLF26FKBb7gHPzeqZZ54Z1kAAwGhMIGni3w5qX5fLfWOrr0siPu7viYh4kuwLCdTWPIu1/edUV8eCrMOd3CiQsrLJtLer6Oio8Bzh1qMhyw4uXXqFhoaTt5/qjkmSxOrVq7FYLPj6+ioZHEtLS3nttdeUeTcGfTgWy2RMpgndnuglSeL+++/npZdewmg0YrVaMRqN+Pr64nA4lEAgKChI+bmRZZnz58+zdetWfvOb37B3716Kiq5y/sIWHI7mHntkZNmJw9FCTs6PxSRFYdiInoExbN++fZw4caLPbW59UjUYDPz5n/85BkPXyYJXrlxhz+8uoncE0lceGkkFW/5pASZ/fe8bjbKioiKOHz/O1atXvyvIIzFx4kTmz5/frfhPf2w2G//0T//k9fae/A3BwcH4+/srXcL/8A//gCzL6HQ60tLSeOihh/j66685f/48DodD2V+SJEJCQpQliEajEYfDwV//9V8rAUVRURGnTp2ioKAAp9OJ0WhkxowZzJo1q0uQN9wqKj/l2rX/D5vNu3krHR1+tLbEUV2dgtUaQHR0NBkZGezcuZMtW9wpkk+cOMHXX39NWloqa9euo7BoGyUl/9DPkVX4+89kxvShzG74vcrKSl5//XVSUlIoKirCYDCg1WqpqanhwQcfZMaMGV4NrzgcDnbu3Elubi7gnrdTXFysTPjUaDTExcXR2tpKZWUlBoMBf38/fHwOExZ+7rs6CP0LDFxCasr/xmCIHPxFC0IPRDAwhrlcLg4fPszRo0dxOBzKE6PL5VK6JIOCgpg5cybx8fG8+eabTJkyhdWrV3c5jsPh4Ff/9J/4103FZafXgGDJpklkLIke7ssatNOnT7Nnz54uARCgjNk++OCDzJ07t9t+LpeLhoYGqqurKSoqorCwkIaGhgGv8f/FL36hzDr36Ojo4F//9fvkPs888wyHDh1SihT1RKPRsH79esxmM3/84x/ZvHlzt0DG0wsxkAyFQ02WXZw5u46Wllx6W2HgzjioxeL7f9mz5xAajYYJEyZw5coV9Ho9CQkJbNiwQdk+Ly+PTz75hLCwMDIyP6et7XKvx77VvLkHhi3Bz9mzZ/niiy944IEHOH78OAaDgaioKLKzs5k8eTIPP/wwWq3Wq2N5rs/hcBAaGkp8fLyy1Nfz85CWloZKJWHt2EpISN4AEzVJaLX+zJj+ASaTd0N/guANMYFwDFOpVCxdupQ5c+Zw6dIl6uvr0Wg0JCYmEh8fT3Z2tlKkJiIiguXLl/Pll1+SlpbW5eai0WhISo+jpqyIKNc0SvPds6tlZCQkDL5qFj2ZzKTZ4aN1qf26efMme/bsAbqPrXu63Pfu3YvZbEan01FTU0NlZSUlJSU0Nzf3eGP21AvwZrleYGBglyfz4uJizpw5o6SIBveYcUlJSZ+BALiDM89ET4vFQn5+frdgwLOSYTRJkorMjN9z5uw6HI7GHrqw3bPrS4of4NlnF3LiRDZqtZqCggJCQ0Oprq5m6tSpXfZITU3lueeeY/v27TQ1XUWj8W4ozNpRMmzBwIwZM7h58yaHDh3iySefZNeuXZSVlfHQQw/xzTffUFlZyfr16wkKCur3WKmpqfz85z/nvffeo6Kigrq6OpYtW0ZNTQ0XLlxAr9eTn5+P2VxCekbeIForY7c3c/HiT5gzZ++o/4wI9w7RM3CXO3jwIIcPH1aWv7311ls0NTXxk5/8BJ3u+yVaeXl5fPDBB/zsZz9DZTdw+MuzXMkvwK5qY/riFB58cOWItbm2tpZz584p47LR0dHMmDGDwMDel1Bt376dgoICr+ZR9PQHUq1WExAQQHx8PGlpacTFxdHW1sYbb7xBQ0NDD0fpfsxZs2Zx3333ceTIEY4fP95jHghvckNIksSECRN45pln+OKLL7h69So///nPx+wf9o6OcgoK/jc1tV9z61O82ZzKtWtTuHZVx1/91V9x7do1du7cicVioaOjkpiYQvz9ywkO8cdsnkhU5Eb8/d21M5qamjhxcjFabatXbZg+fTsB/rOG6Qrdc1Bee+01dDoda9euZdu2beh0OlatWsWePXtoaWlhzZo1XZaYyrJMS+tlOjur0KhN+PlNQ6XSK+8dO3aMAwcOIMsyEyZMYPHixRw7doyCggIyJx/B4luE1Echpf5Mn/YeAQFz7vjaBQFEMHDX88yKzs3NZcuWLZjNZl599VWmTp3KqlWrlO3sdjv/9m//xuLFi1m4cCHHjx/n4MGDOBwOAgICeOWVV4a9rS6Xi6+//poTJ0506er3/H/RokXcf//9XW6KVquV8vJy3nnnHa/PI0kSFouFiIgIkpKSSEtL65a1Lzs7m927d+N0OvHx8VEqD/YkMzOTiIgIvv32W2RZHpICT2q1mv/23/4b169f59133+Wll14iPHzs9syAe2Z9U1MWssuB0ZSIxTeD3NxcPvzwQxYsWMCyZcv4wx/+gF5/iti4o+48h98tK5RQI+MkIGA+kzN/j0bjy4ULL1FX/02f5wSQJB1LFmehVnuXeXGwKioq2Lp1K9OnT2fu3Lm89dZbqNVqNm3axKFDh8jNzWXu3LksX76cmto9FBb+F+3t15T9NRo/oqOfJSH+z5RcCZWVlbz33nu0tLSg1+tZt24der2eq9dWolJ5N0+gJ5KkITp6M5OS/t87vm5BADFMcNeTJIlHH32UpqYmtm/fzgsvvKAMF6Smpirdz1qtlqSkJPLy8li4cGGXG25DQwP19fV9PpkPhYMHDyoTIm+NQT3/P3LkCDU1NQQEBFBdXU11dXW3ZXveuHVp5e3a29vZuXMn165dQ5Ik5syZw9mzZ0lISKC1tVWZ3AfuxDHz589n1qxZqFQq0tLS+O1vfzvQy+6RJ1NhfHw8er2eK1eujPlgwKAPxxC6qstrSUnxRERcw9qxh0Pf/jmTkp1A92BJ/i4LYEPDCU6dfoTYmB/ikr1bCaJS6ZQn7uEUERHBypUr2bNnD/Hx8Tz33HO89dZbvP/++2zevJmYmBi+/vprWlo/IiDgAJ60zh4ORxNFRb+jqekcU6e8gUqlIzw8nJ/97Gd8/vnn5OTksH37dqZOM2A2Dz4Q8HA6vOtVEQRviKWF9wCNRsOGDRswGAxs27aNjIwM4uLi+Oyzz7o8xaalpVFeXk5jY6MyE94zMerzzz/nq6++Ijs7e8AT67zR1tbGsWPH+t0uPz+fvLw8bDYbAQEBhIaGej15C9zBUW9P+VevXuW3v/0t165dw2w28/TTT5Obm0tERARPP/00P/3pT/npT3/K5s2b+dGPfsTPf/5z5syZo0ziq66uVpIL3Sl/f38kSUKtVjNx4kSuXLkyJMcdSZ2dNZw9t47ECcfx8anF5bICtj4z84FMR0cJBVf/noaGI16dx+lspa3t6lA0uV8zZ84kLS2Nzz77DFmWee6555BlmbfeeouUlBQ2bJj3XSAAPS/XlWloOEVx8evKK1qtlnXr1rF+/Xp0Ogm9/k/9fI36J8syev3YDh6Fu4sIBu4RRqORp59+mvb2dj788ENWr15Na2sr33zzfTdsUlISGo2G3NxcJMmdec2zfv7GjRucPHmSnTt38qtf/Ypz587dUXucTic1NTVcvnyZgwcP8vbbb3udN6GxsZHS0lLq6+sJCAhg8eLFxMXFeTWzXpZl/vCHP/CHP/yBS5cuAe7x4F27dvHee+/R0dFBUlISP/nJTzh8+DCyLLN+/Xo0Gg2SJBEaGkpiYiKRkZHdzufN3AJvzZr1/fh3cnIyFRUVSvKhu4Esu8jOfh6rtRBJ6lq62LupDwO7Gzqd1gFtP1iSJPHII49gNBr56KOPMJvNPPfcc0iSxJ/+9Cfa2j8H+qvs6aKk9G1crq5P/6mpqWzYMAGt1jYEpZ5dhIevvdODCIJCDBOMkra2Ns6fP8+lS5ewWq34+voydepUMjMz0esH1yUaGBjIxo0befvttzl27BjLli1j3759pKWlER8fj06nY+LEieTl5REREdHt5uz5vLOzk927d+NyubrctHoiy7KybK+6upqamhqqq6upra1Vjmc0Gr0OBDyT6x5++GH8/PyU4YyEhARef/31fvb+XlVVFR999BHXrl2jsLCQlpYWJEli5cqVzJ49my+//JLS0lK2bNmCr2/3ZM2tra1UVVVRWVlJVVUVpaWlQxoMdHR0KHkSkpKSUKlU5OTkkJycjI+PT49tGkvq64+NaKljvT50xM5lMBh44okneOONN/j666956KGHlCGD6uqv0Wj67x2y2Wpoa7uCr296l9fbrWe4PRPjYISGrhq21RXC+CSCgVFw7do1duzYgcPhUMbDm5qaKC0t5eDBg2zevJmwsLBBHTs2NpY1a9bwySef4O/vT2xsLJ999hk//vGPlaQ4H3/8MdXV1f0ea+/evWRkZODj44MsyzQ3Nys3++rqaqqqqqitrVUS62g0GgwGA2q1GpPJRGdnJzabjfb2dq/H/T1P5/7+/l1ej46O5tFHH+Wzzz7zasa+53wXLlxApVJhNpvZsGEDUVFRXLhwgTNnzrB69WqioqKorq5WbvqeAKCtrQ34Ptf8rdkHvaHRaLolHJJlmYCAAJKSkjhy5AiNjY088sgjFBcXo9Vq2b9/P/v37wcgJiaGBQsWkJKS4vU5R1JF5Se4n5CHZtikdyoC/GePeJKdyMhIHnjgAb788kvi4+NJTU1ly5YtnDrt/ZyRnnozXK5O7izVs1tKcn/JmgRhYEQwMMIqKyt5//33ex17bm93F0D56U9/itlsHtQ5MjMzaWho4ODBg6xYsYKDBw+yf/9+HnroISZNmoRKpfIqja/T6eSNN97A5XLR1NTUpRgPdF/vr9Vq8fX1VVK8+vn5YbFYsFgsVFVV8eWXX/Z7TpfLRXx8fI/vTZ8+ndDQUE6ePElubq7XvQ0Gg4Gf/OQngLs09N69ewkMDOTs2bPs3btXuS6TyaTkHvBQqVQ4HA70ej1TpkyhoaFByX7YG61Wy8svv0xBQQG5ublden5SUlJQq9XExsaya9cubt682ePwQGlpKdu3b+e+++5jyZIlXl3nSOroKGP4AwEAmfj4PxuB83Q3a9YsioqK2L37Q5B8qav7CJXK+2vuKYAxGKKRJNUdFYJSqUxoteOvzLgwvEQwMMKOHj3a501MlmWsVisnT55k+fLlgz7PvHnzqKmp4cCBA6SmpnL69GksFgsBAQEYjUZaW72biVxTU4MkSWi1WiwWC/7+/gQFBXW50Xs+NJref5xiYmI4fPhwn70EkiTh6+vLxIm9F2OJjo7mvvvuo66ujoqKil63u1V7ezuvvvoqLS0tyms6nY7AwECCg4NpaWlRegPsdjs+Pj5Kj0BCQgLTpk1j0qRJqNVqrFYrb775Zp89KxMnTsTPz49Zs2b1OsySkZFBR0cHn3/+eY/ve75GBw8eJDIykqSkJK+udaRo1L54kg4NB/dSRJm01H8hMHD+sJyj3zZIEg8+OI+jx/6VsrKmfqovdqXVBvQYDERGPEFJyRt30CY1kZFPDHp/QeiNCAZGUEdHB7m5uf12N8uyzNGjRykrK2PSpEkYjUaly93z763/7+nfWwMOz0Q6z2TCgXR3T5o0SZlgdyfUajWPPfYY27Zt67ENkiShUql4/PHH+5wo2NDQwOuvv+5V1sBbpaSkcOPGDVpbW0lNTaW0tFSZSBkeHk5ERAR1dXW0trZisVi4//77mTx5crexex8fH9asWcMf//jHbkMB4A7CTp48yYkTJ5g3b16fbSooKOiWWvl2kiRx4sSJMRcMhISsoK7+0JAdT6XSo9dHYrPVoFabCAtbRXTU0xiNA6s3MZRkWaag4C/Q61sYaNBjtzfS0VGBwRDR5XWzOZnQkAeprvmKgc8bkAA1MdGbB7ifIPRPBAMjqKSkZECVCAsLCyksLATcN1NPydzb//X19UWn06HVarHb7TQ0NNDc3Exra+uAxutvJ0kSsbGxdxwIeEyYMIHNmzezZ8+ebk/WYWFhrF69mpiYGCWxj0ajUQr4yLJMY2MjH3/8sVIm1lsqlYorV67Q3NwMwI0bN4iPjychIUFJWazT6cjIyGDatGldSsv25OjRowQEBPDSSy9RWlrKu+++C6AEFgsWLOCrr77C19eXjIyMHo9ht9v7HW7wXPeNGzfo7Owc9MTS4RAe/ihXCv4XLtdQzIxXExP9HBMn/vVQNG3INDdn09ScNci9ZRqbzhJueKTbO2lpv8J56WXq6g4N4HgqVCotmZm/x2iMH2SbBKF3IhgYIXV1dXz00UcD3s/TRf+LX/xCyaLnuTHeuHGDmzdvUl5e3mM5X41Gg4+PD06ns8t7M2bM8Kp0ryRJTJs2bcBt7kt8fDw/+clPKCsrU7r5o6KiiIyMpLGxkX379pGVlaW012KxoNfraWpqGnTmP8+ch9TUVFJTUykqKuLy5cvYbDYSEhJYt24dqampXuUzKCsrIz8/n7Vr12IwGEhM7Frj/ujRo/z0pz+lpaWFTz/9FJPJ1GM1RZvNNqAgbawFA2q1Eb0uA2vHYG+WbhJqtLogYmJ/OEQtGzpVVbuRJA2yPLgEQbKr5/3Uah+mTH6d4pI3uXbtH704koqYmC1ERz0jAgFh2IhgYITs3LnTq0l7t/M8JW/fvl2pvnf7075KpcJkMhEeHo7ZbMblclFZWUlDQ4OyVC8kJIRjx45hMBgoLCwkLi6OoqKiPs993333YTKZBtzm/kiSRHR0NFFRUTQ3N1NVVcXu3bs5f/58t54Tz9N8TEwMCQkJHD58eFDnVKvVVFZWkp+fj5+fH/PmzWPKlCkEBAQM6Dj79+8nJCSEzMxMwP21NxgMdHR0oNVqqa2tpampiUcffZS2tjZ27NjBD37wg26rQwwGg1erIm49x1jidDopr3AREHBn8wZ8fGKZMuV19LrgoWvcELHbG5D7qvndD2MfVQUlSSI25gc0Npyktu4gPQ8ZuIPM6dPeISCgezVOQRhKIhgYAZWVlZSWlt7RMW7evIkkSRgMBsLCwggPDychIYHIyEiqqqooKCigoKCAmzdvYjabSU5OJjk5mYSEBKWbPzw8nA8//JCOjg5l6d6tNyTP+LVKpeL+++9nwYIFd9TmWzkcDqWS4K1L+Dzr7ftTUlJCaOjg15p7kitt3ryZ+Pj4QRUFunHjBoWFhWzYsKHLvAaTydRl7sCRI0d45JFHePLJJ3nrrbfYtm0bzz//fJfyx2q1mszMTC5evNhnQKBSqUhNTe1SdGosOHfuHKUlYQQGDj4QmDjhb4mN/SGSNDZzn2m0ft/N/B/42L7JNBGL7+S+t5IkMjL+k9zcv6K6Zg+SpP5ulYE7D4FabSQj/T9EICCMCBEMjIDr16/3O1GsP35+frzyyiuo1Wqampq4cuUKOTk57Nq1C5fLRVhYGLNnzyY5OZmIiIgeb3ZpaWksX76cr7/+mhs3bgB0uxFptVpSUlJYuHDhoNva2tra7aZfW1urXH9gYCDh4eHMmzePsLAwSktLOXr0aL9fn5ycnEG3Cdy9DGFhYYMKBGRZ5sCBA0RFRZGcnNzlPR8fHzo6Omhra0OtVnPx4kVWr16NXq/nqaeeYuvWrbz77rv88Ic/7FIwae7cuVy8eLHf886fPzqz6XtjtVo5dOgQKSkrMZuLaWsrGOBSOTV+ftOIjX1+zFZqBAgLXU1p6dsD3Mt9PRMn/I1X16ZWG8jM/C2trS9TXvEh1vabqNQGAgMWEB7+KGq1cRAtF4SBE8HACPDUr7+TiXwmk4nDhw9TUFBAZWUlKpWK+Ph4Vq5cyaRJk7ol6enNvHnzyM7O7nFpnCzL2O12cnNzWbt2rTJ5rzdOp5Pa2touN/6qqiolYY9OpyMsLIy4uDhmz55NeHg4oaGh3Z5yPWVe+2O325Uu+cFwuVzcvHmT1NTUAe975coVysrK2Lx5c7c/8kajEavVSltbGzExMRQVFZGfn09aWhpms5lnnnmGN954g/fff59nn31WmZsQERHB448/zscff6y0z8Pz8zJx4kSioqIGdb3D5dtvv8XpdHL//ctQq2dyLms9nZ019J93wP3E6+ubxpTJfxjTgQCAn98MfH3TaW3JVwot9U1CkrSkpf4rwcH3DehcZnMyk5L+bnANFYQhIIKBERAQEDCgVQS3k2WZ8vJyGhoaSEpKYsGCBUycOHFQ48g3btzoN/ug0+nk4MGDXfIctLe3d3var6mpUa7L39+fsLAwZsyYQXh4OGFhYZjNZqxWK1arlfb2dpqamqioqFBe87x+a6XA/ixatIgDBw4oVf8GajCFhlwuFwcOHCAxMbHHyYA+Pj7KUIzR6H6SO3r0KGlpaQAEBQWxadMm3n77bT755BOefPJJZZghPT2dkJAQTp8+TU5ODjabDa1WS2ZmJj4+Phw/fpzc3FzlWKOtrq6OM2fOsHTp0u+SYpmZPWsXxcVbKSt/H4fDnctBqw0kOOg+HM42GhvPIMsOTKYkoqOeJjT0QaXE71gmSRKTM//AuayNdHRU0H1cX0KjsWA0JqBRmwkMWkRkxONotQObhyIIY4EIBkZASkoKOp1u0LPhdTod69evJyEhod+n9f6cOnWq/14KGU6fOo0sy0raYU/CHrVajZ+fH2azmaSkJHQ6HSqVCpvNhtVqJT8/n/Pnz2O1WrutwQf3H1ij0YiPjw8+Pj4YjUZ0Op3XT/v19fWkpqYquRMGaqATBgEuXrxITU0Na9as6fF9Hx8f7HY7kiRRX1+PxWKhoqKCxsZGpccmOjqaJ554gu3bt/Pll1+yatUq5ck4NDSUhx9+mIcffhin09llOWVTUxO7du0iNDSU4ODRn2T39ddf4+vry9y5349j63TBTJz4NyQm/oLOzipAQq8PR6W6+/+8GAyR7mCn5E+UlW3DbnfXp9Drw4iO2kx09LNoNEM/yVYQRpok38lAtuC1Y8eO8fXXXw94P41Gw0svvURISMgdt0GWZf7+7//e6ydqn9YYOn3LkHuZLa7T6ZQb++03+N5euz3dL7i7nQ8ePOj1dRgMBjIyMrBYLNTU1NDQ0ODVBM2QkBB++tOfDqh72ul08l//9V9ERESwfv36Hrc5cuQIJ0+eRK1W09HRofRezJ07l5UrV3bZNisri927d3PfffexePHifs/f2dnJ66+/jiRJvPDCC6M6kbCwsJC3336bxx9/vNf8Cfcyl8uB3V4HqNDpgsbsxEdBGIy7P3S/S8yfP5+Ojg6OHPGuhju4n6JnzJgxJIEAfD+j3lt6aygah5FW/wLPvKgubDYbLpeLjo4OWlpa0Gg0vX6o1epe3xuo5557jvDw72u5u1wutm7dSnl5eZ/Xt2zZsgGPU587d46mpiaeeuqpXrfxzBlITEzk+vXrJCcnc+DAAbKysli+fHmX3pzp06fT0tLCwYMH8fX17TePg16vZ/369fzxj39k9+7dPPbYY6My1u5yudi3bx/R0dGkp6f3v8M9SKXSoNcProCYIIx1IhgYIZIksWzZMjIzM9m3bx/Xr1/vdx9ZlocsDa0sy1w+U4jk0iKr7F7sIKF26dF2mFi6ZBrBiT44HI4BfTidTuX/nZ2dfW43EHZ71/arVCqefvpptm3bRllZWZdhEEmSlBr1A60AaLPZOHz4MFOmTOkzIPNUdYyNjeX69evU1NQQExNDSUkJV65c6Tbev3jxYpqbm9m9e7cy3NKXkJAQHn30UT7++GNiYmKYPXv2gK5jKFy4cIGqqiqef35srwAQBGFwRDAwwkJDQ9m0aRO//vWvsVqtfRbt8fPzIzGx98Ql3mhubiYnJ4dzxy+iLpyIwRSO1VTS45O+QgZ9RzAq2f3jcXJHORNnhjJtRSyhEyx31J7e/J//83+6FBLqS0+JkIxGI88//zzXr1/n3Llz1NXVodVqSUpKYsaMGVgsA2/3qVOnsFqt/VYN9EwajIhw56EvKChg9uzZlJSUcOLEiW7BgCRJrF69mra2Nj788EO2bNnS74qBjIwMSktL2bdvHxEREcTExAz4egars7OTAwcOkJmZSXR09IidVxCEkSOCgVGg0Wh4/PHH+yzao1ar+y3a0xu73U5+fj7Z2dlKjgNTwwTUsgqf9kg6jBXIOHoOCGQACWNb15vN9awarmfVsPLFdCZMG3zyn95MnTq131wDkiQRERFBYGBgj++rVCqSkpIG1ZvS3t6uLLn01Bg4evQoM2fO7HfZpid3gMFgQJIkysrKePjhh9FoNJSWllJfX9+tzZ6iTG+//Tbvvfcezz//fK/X5bFixQrKy8v58MMPeemll4YlO2RPjhw5QmdnJ8uWLRuR8wmCMPJEMDBKPEV7vvzyS6qqqrq8FxkZyapVqwa0vlyWZUpKSrhw4YKSd9+Ty97P1x91RRgS7q5///rJNAZc/H64oEtGWRV+DWloHOaux3e5N/jq9cs89T998QvxYSjNnDmTEydO9DmvQZblO0qG1Nsxjxw5wqFDh5BlWekC9yyZvD2NcE88PQNWqxWLxUJjYyMajYa0tDSys7N5/fXX6ezsVHJDzJ49m4kTJ6LVatm0aRNvvPGGkpTIvVyvZ2q1mieeeILXXnuNjz/+mGeeeWZQwWJfmpqauHTpEq2trRgMBmJiYjh58iQLFizokkFREIR7i1hNMMo8OQSKi4spKSlR1uHrdDrS09OZOXMmQUFBve7f2NhIdnY2OTk51NfX4+Pjg0qloq2tTSkAdP7UJfyrZnbZzyU56DRU0+FTiUttQ3JpMXSEYLCGo3L1PmNdUsGUZbEseHzikH0NPG7cuMF7773XLSDwzAFYtmwZixYtGtJzHjp0iEOHDvW5zcaNG/ucb+BwOPjHf/xH1q5dS35+Pnl5eTzzzDN89tlnSm0FD8+1TJkyhTVr1qBSqWhsbGTr1q1YLBa2bNnS74qBwsJC3nnnHRYsWDBkT+s2m43du3dz8eJFZZ6FLMvIsoxarebll18e1LJMQRDuDiIYGAMqKyt5++23aW9v7/K65yl17dq1TJkyRXndZrORm5tLdnY2RUVFaDQawsLCaGpqorW1lQkTJjBz5kxOnTpFUVERallPQOXQTToz+un4wb8O7RO6R319PadOneL8+fPYbDZUKhXJycnMmTOH+Pj4IT1Xc3Mz//7v/97vCguLxcKf//mf9/kU/s///M/KPIH+CkB5LFmyhPvuc2eqq6ys5M033yQmJoZNmzb1m0/i6NGj7N+/n40bN3ZLjzxQDoeDd955h+Li4h6/FpIkERAQwIsvvtglnbIgCPcOEQyMsra2Nn73u9/1OZkQYMuWLQBkZ2eTm5uL3W4nNjYWs9nMzZs3aWtrIz09nQULFtDc3Mwnn3yCzWbD398fvd5A56VINA4jfc8c9I5Gq+Kl3y694+P0RZZlHA4HarV6yLvCPb799ltleKA/Tz31FJMmTer1/V/96ldKNUlvf6V0Oh2//OUvlZ6AwsJC3n33XTIzM1mzZk2fs/ZlWWbHjh0UFRXx0ksv3dFTe1ZWFp999lmf20iSxKJFi7j//vsHfR5BEMYukTVjlGVlZfUbCABs27aNt99+m+LiYmbNmsXMmTOpqqriypUrJCcn8/LLL/PII49w4sQJtm/fjs1mY9q0aVgsFqqqKjHF2RiKQADAYNYOyXH6IkkSWq122AIBcD+Ne3PjVqlUVFZW9vp+e3s7bW1tA06RbLPZuHLlivJ5QkICa9euJTs7mwMHDvS5ryRJrF27FqPRyAcffNBtueVAnD59ut/lgrIsc+bMmUGlcxYEYewTwcAocrlcnDp1yqsbiMPhYNWqVUyYMEHJYz99+nR+/vOf88gjj9Da2sp//dd/cfHiRbRaLRs2bKCxsZHi4mJiY2P5wV+sA7+WXrMJAqjU/QcLkgQp8yIGdJ13u1snFvbkwoULg6qTIElSt+WUmZmZrFixgqNHj3LmzJk+9zcYDGzYsIHa2lr27NkzqDa4XC6vgyKr1UpTU9OAzyEIwtgnVhOMkubmZrZt20Zra6vX+3zxxReo1WoyMjJYuXIlRqMRh8PBvn37OHnyJOBeifDkk0/y+eefU1hYSHR0NFu2bOHKlSvU+lwg0ncyneUmJNf333ofXy3THojD5Kfj6zdye2+ABGqNivRFkYO+7rEkKiqK/Pz8fm+EsiwTGdn7NWdnZw/q/LIsKxUMbzV//nxaWlrYs2cPZrO5zyqLYWFhPPzww3z66adERUVhMBi4cOECzc3NGAwG0tLSmDJlSq9j/Q0NDQNusyAI9x4RDIwCm83G22+/TV1d3YD3lWWZ7Oxs2tvbWbx4MZ9++in19fUALFy4kKVLl7Jjxw6uX79OREQEP/jBD5Blmd27dyOpJB59cT5/ePX/EhOQzKL5SzH4aolK8keldncSNVa1c+aLIiQVyLcUaZNUEiq1xKo/m4w5YODVEseiadOm9Vs+WZIk/P39e6xW6HH7xM+BOHDgAA0NDUybNq1LlsMHHniA1tZWPv74YzZu3EhtbS1nzpyhvr4etVpNXFwcc+bMISkpiSlTpnDt2jU+//xzpc2eayouLubAgQNs3LiRxMREmpubKSwspKioiMLCwgE96ev1+kElbxIEYewTwcAoyMnJoba2dlD7eta/X716latXr6JWqzEajTzxxBPEx8ezfft2rl69SlhYGM8//zwqlYr9+/djtVqZPXs2Fy5cAElm8eoZTJzYfQ397EcSiUjyJ2d/CUWX6kAGjU5F6oJIJt8XjX+o8U4ufUwxmUysWLGCffv29bndI4880ufcBaPR6HX2RA9JkoiJiSEyMpILFy5w4sQJYmJimDZtGunp6eh0OtasWUNjYyPbtm3rErA4HA5u3LjB9evXmTp1KitXruTmzZvK+7cHNzabjXfeeQeLxaIsdQwLCyMlJYX4+Hjq6ur6LaIlSRLTp0/vsSdDEIS7nwgGRsHZs2eH7FihoaE888wzGI1GduzYQUFBASEhIbzwwguo1Wra2to4fvw4Op2OFStW8J//+Z9oNBomTJjQ6zFjUgKJSQnE5XThsLvQ6tRIqnszH/28efNQq9V88803ylJGcAddvr6+rF27tt+U0JmZmd0SR/VHlmWKi4uprq5WuvcbGhr47LPP2Lt3L+np6UydOlVZodDT/uCer9DS0tItn0FP26tUKp588kni4uK6ZC9sbm7m4MGDPZacBvcESpPJxIIFCwZ0jYIg3D1EMDAKBjM80JuKigo+/PBDAG7evElQUBAvvviiUg1w586duFwuVq5cSVtbGy0tLUyYMMGrYjMqtQqd+t6fYzp79mymTp3K5cuXqa6uRqVSERMTw6RJk7xazTBt2jQOHTrU6830Vmq1mnnz5jFnzhzq6uqUZFM3btygo6MDSZLQ6XRcvnyZrKwsr9rvTdErcCeouj0QsFqtbN++vcefB5VKhcvlIjg4mE2bNvWZHVEQhLubCAZGwVAvl/MkuTGbzfzoRz9SunJLSkq4fv06/v7+TJs2jT179gCIJ7we6HS6fssJ98ZkMrF06VK++eabLuP1t4qLi8Pf35+CggLuu+8+1Go1vr6+SiIlWZapqamhuLiY0tJSiouL6ezsvJNL6kaWZZqampRgwGq18s4779DQ0IBKperS9pSUFCwWC2lpacTFxYlKhYJwjxPBwChITEzkypUryvj/UOns7FSOKcsyn3zyCQCPPfYYkiSRl5eHVqsd8kx+45ksy5SWlipj9hqNptuaf0mSuHnzJnq9HqvVytWrV7ulN5YkidDQUEJDQ5k50506+rXXXqO8vHxI2+vpMfIEAo2NjURGRlJYWIharcbpdKJWq9m4ceOQnlcQhLHt3u8DHoNmz5495IEAuKsVepa5nTt3jsbGRhITE4mJiaG+vp62tjYSEhLEU94QsdvtfPDBB2zdupVr164pr93O87R99epVZemfN0wm05B+r8xmM0FBQV0Cgfnz53Pjxg1kWVYSCokaBIIw/ohgYBTEx8cza9asYTl2Xl4eHR0dfPXVV0iSxKOPPgq4y9CCGCIYSp999hn5+fmAd+vvZVmmo6ODgoICr5YjpqamDtm6fkmSmDVrlrKyoLGxkSeeeIJjx46hUqm6FMOKiYnp40iCINyLRDAwCiRJYtWqVSxfvhyDYWjX7BcVFfHqq69is9mYOnUq5eXlXLp0SRkiEH/oh0Z1dTUXL14c8M1akiRcLheXLl3qd9uMjAx8fHy86h3oq7CRJElER0czffp0JRB49tlnOXXqFA6HA41GQ3NzszKEkJaW5v0FCYJwTxDBwCiRJImFCxfyy1/+koyMjCHtDvYkkjl//jw7duzgo48+UmaqX716dcjOM56dP39+UBNBZVlGp9N5lbVQp9OxadMmNBpNv+fydPHfvp1Go2HWrFk8+eSTvP/++zQ2NrJ582aqqqooKCjA4XCQlpaG3W5XAlMxp0QQxh8RDIwyjUbDnDlzhiXN6+3H7Ozs5L333ht0+lzhe3V1dYOe9+Hj40N5eTk1NTX9bhsbG8uPfvQj0tPTu9zojUYjS5YsYerUqUiShCRJmEwmXC4XkiSRkJDAY489xi9/+Uvuu+8+3n//fWpqaoiJieHIkSN8/vnnmM1m/P39qa6uBtzzHYxGo9JDIAjC+CF+68eA6OhoQkNDqampGZHc77t27WLChAli3fgd0Gg0vS4j7ItKpSIpKYnLly+TnZ3N8uXL+90nJCSExx9/nFWrVtHY2IharSYoKAi1Wo3L5cJut5Ofn097ezvh4eHU19dTVFRERUUFNpuNI0eOKL1FV69eVYKYlpYWpkyZwsWLFwkMDKS+vr7fBEuCINybRM/AGCBJEo899phygxlusix7ndBG6FliYuKgqwTOnj2bjIwMcnJyBtS74OPjQ0REBKGhococAZVKxbp164iPj0ej0VBXV0dAQABJSUl0dnby+eefd6k/cPv5srOzcblc6PV6ZFnuMzOlIAj3LhEMjBHh4eG88MILI7KsS5ZlCgoKhv0897LMzEx0Ot2A91uwYAGhoaFMmTKFlpYWJWHUndBoNGzYsIGwsDA0Gg1tbW2UlZWh1+u9PoYnn8Hhw4e9XvooCMK9QwQDY0hYWBjPPvvsiJzLm9S5Qu/0er2SzKkvnvdVKhUajYa5c+cC7vLJQUFBQzZ/Q6fT8dRTT2E2m7Hb7bS1tdHR0THg43R0dPDpp59y5syZIWmXIAh3BxEMjDEBAQFMmjRpWIcLJEkiMDBw2I4/XqSkpPDss88SFta9+mNkZCRGoxGdTseDDz7IK6+8gl6vZ+/evYD7ezB58mTy8vKGLO2w0WgkMzNzSI735Zdf3lFpZkEQ7i4iGBiDVq9ejclkGvIaBh6yLDNjxoxhOfZ4k5iYyI9//GNefPFF1q5dy2OPPcYrr7zCj370I3784x9jMBjIzs7Gx8eHhx56iNzcXCVR0ZQpU7Db7eTl5Q1JW9ra2jh06NCQHEuWZc6fPz8kxxIEYewTwcAY5Ofnx4svvkhycvKw9BBERkaSkJAw5McdryRJIioqiqlTpzJ58mSl18VisfD000/T0NDAhx9+SEpKCpMmTeKLL76go6MDPz8/4uPjh2SooKOjg61btw5ZmmtPiWVBEMYHEQyMUX5+fmzYsIFf/OIXPPHEE6xbt44XX3wRo9F4x8d+9NFHh63XQegqNDSUDRs2UFhYyBdffMGqVauw2Wx8/fXXgLt3oKioiMbGxkGfo6Ojg3fffZfm5uYhDR6Ho36GIAhjk7gjjHEWi4WMjAymTJlCVFQUmZmZd/QHX8wXGHkJCQmsXbuWCxcukJWVxYoVK8jKyqKwsJDU1FS0Wi05OTmDOrYnEKirq2P69OlD1mZJknqcCyEIwr1JBAN3mVmzZg06GFCpVINeEifcmczMTJYvX87hw4eRJIm4uDh2796NSqUiNTWV7OzsAectuDUQ2Lx5M+np6UOWtErMKxGE8UUEA3eZ4OBgZUnbQLv6JUli/vz5w9QyoT/z589n1qxZfPHFF2RmZtLc3MyhQ4eYMmUK9fX1lJWVeX2s2wOBiIgIYmNjCQ4OHpKhgjlz5ohSxoIwjohg4C6UkZHBCy+80G2CYUhISI955SVJUhLThIeHj2RThVtIksSDDz7IpEmT2LdvH9OnT+fEiRPodDosFovXyX56CgQ8x1+zZg0qleqOAoK5c+eycuXKQe8vCMLdR5JHIhm+MGw6Oztpa2tDr9djMplobW0lKyuLCxcu0N7ejsFgYPLkycyYMQM/P7/Rbq6AuyDQ22+/TX19vbKEdMKECWRlZfGXf/mXfRYK6i0QuFVJSQmfffYZNTU1A6qfMHfuXObOnYu/v/9gL00QhLuUCAYEYRS0t7ezdetWnE4nzc3NzJ49m1OnTvHkk0+SlpbW4z63BgLPPvsskZGRvR5flmVyc3PZt28fzc3N/bbn8ccfJzMzc9DXIwjC3U0MEwjCKDAajTz99NPY7XbMZjNnz54lNDRU6dFpaWnB6XQq2w8kEAB3RcIvv/ySlpYWr9rz2WefcenSpTu6JkEQ7l6iZ0AQRlFZWRl/+tOfANBqtV1SAOv1embMmMG0adP47LPPqK2t9SoQANi9ezfnz58fcK6AjRs3kpKSMqB9BEG4+4lgQBBGWV5eHjt27OjxPUmSkCQJrVbLli1bvAoEOjo6+NWvfjWoYlQBAQH87Gc/E0mpBGGcEb/xgjDKbt682et7sizjcrnQaDSEhoZ6dbzq6upBV6VsaGgYkrLKgiDcXXqftiwIwrDr6Ojg7Nmz/W7X1tZGXl4eGRkZdHZ20tTU1OWjubmZxsZGGhsbvZ4n0BNJkqipqSExMXHQxxAE4e4jggFBGEUFBQVeP8Xv3LmTTz/9tNs8gNuXD97JyJ8sy8NaPlsQhLFJBAOCMIqsVqvXuQBkWcbX1xeDwYDRaMRsNmM2m/Hx8cFgMGAwGNDr9RgMBo4fP05BQcGgAoPY2NjBXIogCHcxEQwIwigyGo1e3bAlSSI5OZmNGzd6dVw/Pz+Ki4vp6OjwOiCQJInIyEiRpVIQxiExgVAQRlFSUlKfGQc9ZFkeUFIgf39/fvjDHxIUFATQb4piT8rqRx55xOtzCIJw7xBLCwVhlO3bt4+TJ0/2+gQvSRIWi4VXXnkFtVo9oGPLskxRURH5+fnYbDZaW1spLi6ms7MTlUqFLMvIskxYWBhr167tMb2xIAj3PhEMCMIoczgc7Nixg6tXr3Z7T5IkjEYjzz33HCEhIUN2vitXrlBbW4tarSYuLo7o6GgxcVAQxjERDAjCGNDS0sJvfvMbgC5piKdOncqyZcvw9fUdpZYJgjAeiDkDgjAGnDx5Eo1Gg8lkUl5TqVQEBweLQEAQhGEnggFBGGXt7e2cPXuWKVOm0NLSoqQgNpvN3LhxY7SbJwjCOCCCAUEYZadOncLlcnWbvKfT6SgpKRl0amFBEARviWBAEEZRR0cHp06dYubMmdTW1mIwGAD3xEGVSoXD4aCkpGSUWykIwr1OBAOCMIpOnz6Nw+Fg/vz5lJaW4ufnh1arRavV4nA4MJlMYqhAEIRhJ4IBQRglNpuNkydPMm3aNIxGI+Xl5fj4+GA2m9FqtdhsNhISEigsLBztpgqCcI8TwYAgjJKzZ8/S2dnJwoULqaqqwuFwoNFoMJvN6HQ67HY7CQkJlJeX09HRMdrNFQThHiaCAUEYBXa7nePHjzNlyhT8/PwoLS1FpVLhdDoxmUwYDAYcDgeJiYlKFkFBEIThIoIBQRgFWVlZtLe3s3DhQgBKS0uJiIjAarViNpsxGo24XC78/f0JCAgQ8wYEQRhWIhgQhBHmcDg4duwYmZmZBAYGAu5gIDo6mtbWVkwmE0ajEXBnIxTzBgRBGG4iGBCEEXbhwgVaWlpYtGgRAG1tbTQ0NBAdHU1bWxtms1nJOtjU1ERiYiK1tbU0NzePZrMFQbiHiWBAEEaQ0+nk2LFjpKenExwcDLh7BQACAwORZblLMFBfX09CQgKA6B0QBGHYiGBAEEbQxYsXaWxsVHoFAEpKSjCbzahU7l9Hk8mEv78/4O4ZMBqNhIeHi3kDgiAMGxEMCMIwk2UZWZZxuVwcOXKE5ORkwsLClPdv3ryJXq9nz549yLJMQUGBkonQMzSQmJhIYWEhosioIAjDQTPaDRCEe5Hdbic7O5vTp09TU1MDQEBAAPX19axbtw5wBwkHDhzolm74yJEjHD9+HFmWaWlpASAhIYHjx49TW1tLSEjIyF6MIAj3PNEzIAhDrL29nTfeeIPPP/+c6upqpWegvr4egAMHDmC32zl06BBHjhzp8RhOpxOAsrIyAGJjY1Gr1WLegCAIw0IEA4IwxD766CMqKyt7fb+wsJBPP/2010DgVtXV1TgcDnQ6HdHR0WLegCAIw0IEA4IwhCoqKrhx40afY/uyLHP58mVcLle/x5Nlmby8PMDdO3D9+nUOHjzIsWPHqK6uHrJ2C4IwvkmymJEkCENm3759nDp1yqsbvbdSUlIICQnhxIkTOBwOJEkC3IFCXFwc69atU1YfCIIgDIYIBgRhCH388cdcunRpxGb9S5KEyWTixRdfxM/Pb0TOKQjCvUcMEwjCENLr9cqT+0iQZZn29nb2798/YucUBOHeI4IBQRhCaWlpQzpE4A2Xy8WlS5doa2sb0fMKgnDvEMGAIAyhhIQEgoODR7R3ANwBQUVFxYieUxCEe4cIBgRhCEmSxKZNm/Dx8RmVgEAQBGEwRDAgCEMsKCiIH//4x8yaNQutVjti5xWZCQVBGCyxmkAQhpHNZqOxsRGbzcaf/vQnHA7HkJ9DkiQSExN59tlnh/zYgiCMD6JnQBCGkU6nIzQ0lOjoaB599NFet5MkSfkYCEmSUKvVLFu27E6bKgjCOCaCAUEYIZMnT2bDhg1KPoBbb/zh4eGsX78erVbrVUDg2cZgMPDss88SGRk5PI0WBGFcEMMEgjDCXC4XhYWFVFdXo1KpiImJUW7mxcXFvPXWW0qhotv5+fkRFhaGXq8nKSmJtLQ0NBpRfFQQhDsj/ooIwghTqVRMmDCBCRMmdHuvoKCg10AAoLm5mfj4eKUMsiAIwlAQwwSCMEZYrVZOnDjR5zayLJOdnU1DQ8MItUoQhPFABAOCMEZcvHixz14BD0mSOH/+/Ai0SBCE8UIEA4IwRjQ2NqJSefcr2djYOLyNEQRhXBHBgCCMEd4mKJIkaUSTGQmCcO8TwYAgjBETJ070KqWwy+Vi4sSJI9AiQRDGCxEMCMIYER0dTVhYWJ95BiRJwmw2M2nSpBFsmSAI9zoRDAjCGCFJEo8//jh6vb7HgMCTbXD9+vWo1epRaKEgCPcqkXRIEMaYuro6vvrqKwoKCrj11zMxMZEVK1YQERExiq0TBOFeJIIBQRijmpqaOHLkCFlZWbz88ssEBgaOdpMEQbhHiWECQRij/Pz8iI6ORpZlpZ6BIAjCcBDBgCCMYZ4lhHa7fZRbIgjCvUwEA4IwholgQBCEkSCCAUEYw3Q6HQA2m22UWyIIwr1MBAOCMIaJngFBEEaCCAYEYQwTwYAgCCNBBAOCMIZ5hglEMCAIwnASwYAgjGGengExZ0AQhOEkggFBGMPEMIEgCCNBBAOCMIaJYEAQhJEgggFBGMMkSUKj0YhgQBCEYSWCAUEY47RarZgzIAjCsBLBgCCMcTqdTvQMCIIwrEQwIAhjnFarFcGAIAjDSgQDgjDGiWBAEIThJoIBQRijbDYbWVlZNDU1ce3aNQ4ePEhjY+NoN0sQhHuQJMuyPNqNEAShq7y8PD799FM6OzuV1yRJQpZlZs+ezcqVK1Gr1aPYQkEQ7iUiGBCEMebatWts27aNvn41Z8yYwSOPPDKCrRIE4V4mhgkEYQyRZZkvv/yyz0AA4Ny5c9TU1IxQqwRBuNeJYEAQxpDi4mLq6ur63U6SJM6ePTsCLRIEYTwQwYAgjCFVVVVebSfLMpWVlcPcGkEQxgsRDAjCGCJJ0rBsKwiC0BcRDAjCGBIdHe3VdpIkERsbO8ytEQRhvBDBgCCMIREREURFRXn11D9jxowRaJEgCOOBCAYEYYx5+OGHUavVfQYE999/P35+fiPYKkEQ7mUiz4AgjEFlZWXs3LmT2tpaVCp3zO5yudDr9dx///3MmTNnlFsoCMK9RAQDgjBGybJMcXExRUVFOJ1OgoODSU1NRavVjnbTBEG4x4hgQBAEQRDGOTFnQBAEQRDGOREMCIIgCMI4J4IBQRAEQRjnRDAgCIIgCOOcCAYEQRAEYZwTwYAgCIIgjHMiGBAEQRCEcU4EA4IgCIIwzolgQBAEQRDGOREMCIIgCMI4J4IBQRAEQRjnRDAgCIIgCOOcCAYEQRAEYZwTwYAgCIIgjHMiGBAEQRCEcU4EA4IgCIIwzolgQBAEQRDGOREMCIIgCMI4J4IBQRAEQRjnRDAgCIIgCOOcCAYEQRAEYZwTwYAgCIIgjHMiGBAEQRCEcU4EA4IgCIIwzolgQBAEQRDGOREMCIIgCMI4J4IBQRAEQRjnRDAgCIIgCOOcCAYEQRAEYZwTwYAgCIIgjHMiGBAEQRCEcU4EA4IgCIIwzolgQBAEQRDGOREMCIIgCMI4J4IBQRAEQRjn/n+WZ6dwBzVEdgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "communities = top3_comm[\"nodes\"].tolist()\n",
        "pos = nx.spring_layout(S, iterations=100, seed=23)\n",
        "\n",
        "# edges coordinates\n",
        "x_nodes, y_nodes = zip(*pos.values())\n",
        "edge_x, edge_y = [], []\n",
        "for edge in S.edges():\n",
        "    x0, y0 = pos[edge[0]]\n",
        "    x1, y1 = pos[edge[1]]\n",
        "    edge_x.extend([x0, x1, None])\n",
        "    edge_y.extend([y0, y1, None])\n",
        "\n",
        "# degree labels\n",
        "node_labels = [f\"Node {n}<br>Degree: {S.degree(n)}\" for n in S.nodes()]\n",
        "node_degrees = [S.degree(n) for n in S.nodes()]\n",
        "node_colors_list = create_community_node_colors(S, communities)\n",
        "\n",
        "fig = go.Figure()\n",
        "# add edges\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=edge_x, y=edge_y,\n",
        "    line=dict(width=1, color=\"gray\"),\n",
        "))\n",
        "\n",
        "# add nodes\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=x_nodes, y=y_nodes, mode=\"markers\",\n",
        "    marker=dict(size=[deg*1.1+5 for deg in node_degrees], color=node_colors_list),\n",
        "    hoverinfo=\"text\",\n",
        "    text=node_labels\n",
        "))\n",
        "\n",
        "# background settings\n",
        "fig.update_layout(\n",
        "    title=f\"Interactive Visualization of Top-3 Communities\",\n",
        "    showlegend=False,\n",
        "    plot_bgcolor=\"white\",\n",
        "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "oVFPoMHAKM4n",
        "outputId": "853e4e33-3eb8-49cb-af18-5c5859ec7a06"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e5352bb5-6677-4047-9bba-0d0ec62b5889\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e5352bb5-6677-4047-9bba-0d0ec62b5889\")) {                    Plotly.newPlot(                        \"e5352bb5-6677-4047-9bba-0d0ec62b5889\",                        [{\"line\":{\"color\":\"gray\",\"width\":1},\"x\":[-0.059285993681578185,-0.05150569433029976,null,-0.059285993681578185,0.02861751720288711,null,0.25530150722382017,0.18060824987066992,null,0.25530150722382017,0.21599179594707124,null,0.25530150722382017,0.277594166695859,null,-0.31437686637997736,-0.2826575424186942,null,-0.31437686637997736,-0.2938298352089581,null,-0.31437686637997736,-0.3394478256624994,null,-0.31437686637997736,-0.3014365112240544,null,0.15160906771204477,0.23663756380550682,null,0.15160906771204477,0.02861751720288711,null,0.0006498684496106419,-0.03893570476917425,null,0.0006498684496106419,-0.016292176805238513,null,0.0006498684496106419,0.07425007382384027,null,-0.4809074362975592,-0.4901690131007754,null,-0.4809074362975592,-0.358722572333496,null,-0.4809074362975592,-0.4964893272821436,null,-0.4809074362975592,-0.5060079720855933,null,-0.21285602402302212,-0.3648939464198347,null,-0.21285602402302212,-0.03893570476917425,null,-0.21285602402302212,-0.2090678908752118,null,0.31026074032826373,0.277594166695859,null,0.31026074032826373,0.32310651218220976,null,0.31026074032826373,0.3428104312489601,null,0.36019625997031784,0.21599179594707124,null,0.36019625997031784,0.4542103996319127,null,0.36019625997031784,0.3966096834223085,null,0.36019625997031784,0.3453921879925257,null,0.36019625997031784,0.36733124780740023,null,0.4875264321372589,0.3966096834223085,null,0.4875264321372589,0.486963869543913,null,0.4875264321372589,0.4677488900556446,null,0.3428104312489601,0.32310651218220976,null,0.3428104312489601,0.277594166695859,null,0.19256820534185443,0.20654667970663415,null,0.19256820534185443,0.22702291008801448,null,0.19256820534185443,0.21599179594707124,null,0.19256820534185443,0.20503119881445203,null,0.9818269056970753,0.9637482324415548,null,0.9818269056970753,1.0,null,0.9818269056970753,0.8824216153977748,null,0.9818269056970753,0.9950729293827221,null,-0.42919930424013863,-0.44950560663072026,null,-0.42919930424013863,-0.3394478256624994,null,-0.46066058165426654,-0.3648939464198347,null,-0.46066058165426654,-0.4570408273991243,null,0.0561718695432072,0.0587467879655703,null,0.0561718695432072,0.0778311214500394,null,0.0561718695432072,0.0469594798971936,null,0.32310651218220976,0.277594166695859,null,-0.6560391681481028,-0.6737321124898505,null,-0.6560391681481028,-0.6781934405608715,null,-0.6560391681481028,-0.5439173527694454,null,-0.4570408273991243,-0.3648939464198347,null,-0.3958896862185362,-0.4115514915479605,null,-0.3958896862185362,-0.3394478256624994,null,-0.08923244273171997,-0.03893570476917425,null,-0.2826575424186942,-0.2938298352089581,null,-0.2826575424186942,-0.3394478256624994,null,-0.2826575424186942,-0.3014365112240544,null,0.0778311214500394,0.0469594798971936,null,0.0778311214500394,0.0587467879655703,null,-0.04635159899460189,-0.028900204844833136,null,-0.04635159899460189,0.02861751720288711,null,0.4542103996319127,0.21599179594707124,null,0.4542103996319127,0.5744215629527019,null,0.4542103996319127,0.5867457861400039,null,0.4542103996319127,0.5605767306644166,null,0.4542103996319127,0.3966096834223085,null,0.4542103996319127,0.5535439405315726,null,0.4542103996319127,0.3453921879925257,null,0.4542103996319127,0.36733124780740023,null,0.4542103996319127,0.5652636535269082,null,0.4542103996319127,0.5802467262261533,null,-0.012861829967222677,0.02861751720288711,null,-0.012861829967222677,-0.028316962958408312,null,-0.012861829967222677,-0.03893570476917425,null,-0.012861829967222677,-0.0001816053917977161,null,0.9955143433247566,0.9637482324415548,null,0.9955143433247566,0.8824216153977748,null,0.9955143433247566,0.9782713092334949,null,-0.045982191407776,0.02861751720288711,null,-0.045982191407776,-0.048648131647875195,null,0.3288498264414838,0.3453921879925257,null,0.3288498264414838,0.22088797981646807,null,0.3288498264414838,0.3269080765982416,null,-0.6609199553838955,-0.6501095214398317,null,-0.6609199553838955,-0.671172454352229,null,-0.6609199553838955,-0.6421146160806568,null,-0.6609199553838955,-0.5439173527694454,null,0.0469594798971936,-0.027853414624651417,null,0.0469594798971936,0.17959597070127892,null,0.0469594798971936,0.0587467879655703,null,0.0469594798971936,0.15208765606104926,null,0.0469594798971936,-0.010083795165695719,null,0.0469594798971936,0.03783794923627862,null,0.0469594798971936,-0.03893570476917425,null,0.0469594798971936,0.13372190897771857,null,0.0469594798971936,0.021303528650741303,null,0.0469594798971936,-0.003064642627481575,null,-0.027853414624651417,-0.03893570476917425,null,-0.027853414624651417,-0.010083795165695719,null,-0.15648725131882424,-0.08650445908325728,null,-0.15648725131882424,-0.16964342570496654,null,-0.15648725131882424,-0.14714110547938117,null,0.11427984805162399,0.04018895326203896,null,0.3966096834223085,0.36733124780740023,null,0.3966096834223085,0.4677488900556446,null,0.3966096834223085,0.21599179594707124,null,0.3966096834223085,0.486963869543913,null,0.3966096834223085,0.3453921879925257,null,-0.02148645862856977,-0.017794420126836706,null,-0.02148645862856977,0.02861751720288711,null,-0.02148645862856977,0.004279483924492915,null,-0.45102239198689775,-0.43609475615980997,null,-0.45102239198689775,-0.4310679397180599,null,-0.45102239198689775,-0.414011715712754,null,-0.45102239198689775,-0.3394478256624994,null,0.11912473211144807,0.21599179594707124,null,0.11912473211144807,0.1971545982299811,null,0.11912473211144807,0.13219574301524142,null,0.11912473211144807,0.1401685740067246,null,0.11912473211144807,0.02861751720288711,null,-0.03893570476917425,0.05168415276062511,null,-0.03893570476917425,0.02861751720288711,null,-0.03893570476917425,-0.08650445908325728,null,-0.03893570476917425,0.21599179594707124,null,-0.03893570476917425,-0.016292176805238513,null,-0.03893570476917425,-0.028316962958408312,null,-0.03893570476917425,-0.0001816053917977161,null,-0.03893570476917425,0.0448929334080501,null,-0.03893570476917425,-0.2090678908752118,null,-0.03893570476917425,-0.010083795165695719,null,-0.03893570476917425,0.07425007382384027,null,-0.03893570476917425,-0.3648939464198347,null,0.13936712694079278,0.13654070847916366,null,0.13936712694079278,0.21289758198072678,null,0.13936712694079278,0.11917830401758958,null,0.13936712694079278,0.15394252403128642,null,0.004279483924492915,0.02861751720288711,null,0.004279483924492915,-0.017794420126836706,null,0.5652636535269082,0.5535439405315726,null,0.5652636535269082,0.5867457861400039,null,0.5652636535269082,0.5744215629527019,null,0.5652636535269082,0.5802467262261533,null,0.5652636535269082,0.5605767306644166,null,0.3089387603846261,0.31407742200527355,null,0.3089387603846261,0.21599179594707124,null,0.1166547927409436,0.18457506810446628,null,0.1166547927409436,0.16315223429489636,null,0.1166547927409436,0.07938540783410898,null,0.1166547927409436,0.02861751720288711,null,0.1166547927409436,0.09943641549603949,null,0.049052728396085335,0.02861751720288711,null,0.049052728396085335,0.0718701068061601,null,-0.005284880320948689,-0.0001816053917977161,null,-0.005284880320948689,0.04018895326203896,null,-0.47927043764775096,-0.3648939464198347,null,-0.47927043764775096,-0.4915074680421084,null,0.4346756529672312,0.3453921879925257,null,0.4346756529672312,0.4377874718408758,null,0.4346756529672312,0.458895561799462,null,-0.2938298352089581,-0.3394478256624994,null,-0.2938298352089581,-0.3014365112240544,null,0.3453921879925257,0.34939144368349706,null,0.3453921879925257,0.46205573799674066,null,0.3453921879925257,0.22088797981646807,null,0.3453921879925257,0.5055632938297895,null,0.3453921879925257,0.47238472695352257,null,0.3453921879925257,0.5992593748571182,null,0.3453921879925257,0.36733124780740023,null,0.3453921879925257,0.458895561799462,null,0.3453921879925257,0.4570282873886123,null,0.3453921879925257,0.21599179594707124,null,0.3453921879925257,0.1982792857651305,null,0.3453921879925257,0.23663756380550682,null,0.3453921879925257,0.48526477319195366,null,0.3453921879925257,0.17959597070127892,null,0.3453921879925257,0.02861751720288711,null,0.3453921879925257,0.3269080765982416,null,0.3453921879925257,0.5370137388136961,null,0.3453921879925257,0.1998363743394671,null,0.3453921879925257,0.31140847919034037,null,0.3453921879925257,0.5059920711482435,null,0.3453921879925257,0.2827643624806449,null,0.3453921879925257,0.4377874718408758,null,0.3453921879925257,0.21289758198072678,null,0.3453921879925257,0.4634210603816112,null,0.3453921879925257,0.4845452646999587,null,-0.2403822139301277,-0.08650445908325728,null,-0.2403822139301277,-0.358722572333496,null,-0.47460415035572234,-0.47381888762745045,null,-0.47460415035572234,-0.3394478256624994,null,0.2339353431743282,0.1971545982299811,null,0.2339353431743282,0.2558779409220579,null,0.2339353431743282,0.2735940169323006,null,0.2339353431743282,0.23851923458896065,null,0.2339353431743282,0.25972147478779695,null,-0.42124408777297523,-0.3394478256624994,null,-0.42124408777297523,-0.4413240760165562,null,0.6338916097455147,0.5370137388136961,null,0.6338916097455147,0.6528840334761078,null,0.6338916097455147,0.6530220951280931,null,0.14564082428403338,0.124435985726018,null,0.14564082428403338,0.1613890242205152,null,0.14564082428403338,0.17959597070127892,null,0.14564082428403338,0.07425007382384027,null,0.14564082428403338,0.14048028292531098,null,0.3773726171118301,0.3731985458668834,null,0.3773726171118301,0.21599179594707124,null,0.3773726171118301,0.48526477319195366,null,-0.37149593956640153,-0.387086469460287,null,-0.37149593956640153,-0.3394478256624994,null,-0.37149593956640153,-0.4002443401071849,null,0.47238472695352257,0.4634210603816112,null,0.47238472695352257,0.5370137388136961,null,0.47238472695352257,0.4845452646999587,null,-0.5060079720855933,-0.4964893272821436,null,-0.5060079720855933,-0.358722572333496,null,-0.5060079720855933,-0.4901690131007754,null,-0.1546553964660012,-0.3394478256624994,null,-0.1546553964660012,0.02861751720288711,null,-0.1546553964660012,-0.1589227222712193,null,-0.1546553964660012,-0.151822073102289,null,-0.4964893272821436,-0.358722572333496,null,-0.4964893272821436,-0.4901690131007754,null,0.30290347581120586,0.3026670790226142,null,0.30290347581120586,0.1971545982299811,null,-0.4230949239306514,-0.4301728293129212,null,-0.4230949239306514,-0.4059724074813355,null,-0.4230949239306514,-0.3648939464198347,null,-0.4230949239306514,-0.3991372536892955,null,0.14048028292531098,0.1613890242205152,null,0.14048028292531098,0.07425007382384027,null,0.14048028292531098,0.17959597070127892,null,0.14048028292531098,0.124435985726018,null,-0.4640097885033951,-0.4115514915479605,null,-0.016292176805238513,0.07425007382384027,null,-0.3735122171313382,-0.3746440713725381,null,-0.3735122171313382,-0.35357995846547274,null,-0.3735122171313382,-0.33709889905006374,null,0.3264021749575983,0.23663756380550682,null,-0.44950560663072026,-0.3394478256624994,null,-0.5969526826307123,-0.6073808832119391,null,-0.5969526826307123,-0.5439173527694454,null,-0.5969526826307123,-0.6194192656877852,null,-0.5969526826307123,-0.6295325231980975,null,0.22702291008801448,0.20503119881445203,null,0.22702291008801448,0.21599179594707124,null,0.22702291008801448,0.20654667970663415,null,0.34939144368349706,0.23663756380550682,null,0.5535439405315726,0.5744215629527019,null,0.5535439405315726,0.5867457861400039,null,0.5535439405315726,0.5802467262261533,null,0.5535439405315726,0.5605767306644166,null,0.23851923458896065,0.1971545982299811,null,0.23851923458896065,0.2558779409220579,null,0.23851923458896065,0.2735940169323006,null,0.23851923458896065,0.25972147478779695,null,0.6292207927139831,0.48526477319195366,null,0.6292207927139831,0.6216731991169193,null,0.6292207927139831,0.6079930967292341,null,0.0587467879655703,0.06332286264834305,null,-0.017794420126836706,0.02861751720288711,null,-0.4715555468128839,-0.3394478256624994,null,-0.4715555468128839,-0.4804700028299716,null,-0.4715555468128839,-0.4966324866261999,null,-0.4715555468128839,-0.5439173527694454,null,-0.4715555468128839,-0.48954517945940224,null,-0.6194192656877852,-0.6073808832119391,null,-0.6194192656877852,-0.5439173527694454,null,-0.6194192656877852,-0.6295325231980975,null,-0.6501095214398317,-0.671172454352229,null,-0.6501095214398317,-0.6421146160806568,null,-0.6501095214398317,-0.5439173527694454,null,0.07938540783410898,0.02861751720288711,null,0.07938540783410898,0.09943641549603949,null,-0.44021218721680017,-0.3648939464198347,null,-0.44021218721680017,-0.47334552020230125,null,0.5992593748571182,0.5059920711482435,null,0.5992593748571182,0.8824216153977748,null,0.5992593748571182,0.5055632938297895,null,0.5992593748571182,0.48526477319195366,null,0.21289758198072678,0.15394252403128642,null,0.21289758198072678,0.2827643624806449,null,0.21289758198072678,0.13654070847916366,null,0.21289758198072678,0.11917830401758958,null,0.21289758198072678,0.21599179594707124,null,-0.3014365112240544,-0.3394478256624994,null,-0.39691793998809116,-0.3773640384495448,null,-0.39691793998809116,-0.3830759637374944,null,-0.39691793998809116,-0.3394478256624994,null,-0.16964342570496654,-0.08650445908325728,null,-0.16964342570496654,-0.14714110547938117,null,-0.5714251798387358,-0.5554995080755668,null,-0.5714251798387358,-0.5570415767027547,null,-0.5714251798387358,-0.4413240760165562,null,0.0718701068061601,0.02861751720288711,null,-0.5554995080755668,-0.4413240760165562,null,-0.5554995080755668,-0.5570415767027547,null,-0.17107714537736463,0.02861751720288711,null,-0.17107714537736463,-0.167915484966163,null,-0.17107714537736463,-0.3394478256624994,null,0.030696981974305128,0.02861751720288711,null,0.030696981974305128,0.011887095261928868,null,0.030696981974305128,0.04512551406988936,null,0.2540531852676487,0.2770892614074666,null,0.2540531852676487,0.21599179594707124,null,0.2540531852676487,0.29317442471933325,null,0.2540531852676487,0.27273633777468964,null,-0.33499591829826,-0.3121386607651001,null,-0.33499591829826,-0.3394478256624994,null,0.5370137388136961,0.6530220951280931,null,0.5370137388136961,0.4634210603816112,null,0.5370137388136961,0.4845452646999587,null,0.5370137388136961,0.6528840334761078,null,0.3269080765982416,0.22088797981646807,null,0.5802467262261533,0.5605767306644166,null,0.5802467262261533,0.5744215629527019,null,0.5802467262261533,0.5867457861400039,null,0.277594166695859,0.18060824987066992,null,0.277594166695859,0.21599179594707124,null,0.6530220951280931,0.6528840334761078,null,0.6079930967292341,0.48526477319195366,null,0.6079930967292341,0.6216731991169193,null,1.0,0.9950729293827221,null,1.0,0.8824216153977748,null,1.0,0.9637482324415548,null,0.486963869543913,0.4677488900556446,null,-0.4002443401071849,-0.387086469460287,null,-0.4002443401071849,-0.3394478256624994,null,0.1998363743394671,0.02861751720288711,null,0.1998363743394671,0.1982792857651305,null,0.04512551406988936,0.02861751720288711,null,0.04512551406988936,0.011887095261928868,null,-0.448550287721623,-0.3394478256624994,null,-0.448550287721623,-0.4538231952471651,null,-0.448550287721623,-0.46380856112534075,null,-0.448550287721623,-0.4721539465039138,null,-0.448550287721623,-0.5439173527694454,null,0.13372190897771857,0.17959597070127892,null,0.13372190897771857,0.15208765606104926,null,-0.14714110547938117,-0.08650445908325728,null,0.16315223429489636,0.18457506810446628,null,-0.3121386607651001,-0.3394478256624994,null,0.09246088141992229,0.1027083360530624,null,0.09246088141992229,0.07620904990709525,null,0.09246088141992229,0.02861751720288711,null,0.458895561799462,0.4377874718408758,null,-0.3773640384495448,-0.3830759637374944,null,-0.3773640384495448,-0.3394478256624994,null,-0.3553519112066584,-0.3713679139666828,null,-0.3553519112066584,-0.3394478256624994,null,-0.08650445908325728,0.0448929334080501,null,-0.08650445908325728,0.21599179594707124,null,-0.08650445908325728,-0.358722572333496,null,-0.08650445908325728,0.05168415276062511,null,-0.08650445908325728,-0.17681602481473987,null,-0.6421146160806568,-0.671172454352229,null,-0.6421146160806568,-0.5439173527694454,null,0.4570282873886123,0.46205573799674066,null,0.1982792857651305,0.02861751720288711,null,0.22088797981646807,0.14111852307635775,null,0.22088797981646807,0.13359080024858752,null,0.22088797981646807,0.02861751720288711,null,-0.3394478256624994,-0.48954517945940224,null,-0.3394478256624994,-0.40412417018890917,null,-0.3394478256624994,-0.36513312366975414,null,-0.3394478256624994,-0.43609475615980997,null,-0.3394478256624994,-0.47381888762745045,null,-0.3394478256624994,-0.4538231952471651,null,-0.3394478256624994,-0.46380856112534075,null,-0.3394478256624994,-0.414011715712754,null,-0.3394478256624994,-0.42072470684187124,null,-0.3394478256624994,-0.34386793618941736,null,-0.3394478256624994,-0.4115514915479605,null,-0.3394478256624994,-0.167915484966163,null,-0.3394478256624994,-0.1589227222712193,null,-0.3394478256624994,-0.387086469460287,null,-0.3394478256624994,-0.3713679139666828,null,-0.3394478256624994,-0.4310679397180599,null,-0.3394478256624994,-0.36916634645092505,null,-0.3394478256624994,-0.4804700028299716,null,-0.3394478256624994,-0.4966324866261999,null,-0.3394478256624994,0.02861751720288711,null,-0.3394478256624994,-0.5439173527694454,null,-0.3394478256624994,-0.3830759637374944,null,-0.3394478256624994,-0.4413240760165562,null,-0.3394478256624994,-0.4721539465039138,null,-0.3394478256624994,-0.151822073102289,null,-0.151822073102289,0.02861751720288711,null,-0.151822073102289,-0.1589227222712193,null,0.5059920711482435,0.5055632938297895,null,0.5059920711482435,0.48526477319195366,null,0.04018895326203896,-0.0001816053917977161,null,-0.4915074680421084,-0.3648939464198347,null,0.6216731991169193,0.48526477319195366,null,0.07620904990709525,0.1027083360530624,null,0.07620904990709525,0.02861751720288711,null,0.27273633777468964,0.29317442471933325,null,0.27273633777468964,0.2770892614074666,null,0.27273633777468964,0.21599179594707124,null,0.48526477319195366,0.21599179594707124,null,0.48526477319195366,0.3731985458668834,null,0.48526477319195366,0.6168178391809179,null,0.48526477319195366,0.6074372212355406,null,0.48526477319195366,0.5055632938297895,null,-0.45407860353818674,-0.4413240760165562,null,-0.45407860353818674,-0.3648939464198347,null,-0.45407860353818674,-0.43636655099250643,null,-0.3830759637374944,-0.41171447186352494,null,-0.3830759637374944,-0.3746440713725381,null,-0.3830759637374944,-0.39520129896276895,null,-0.4059724074813355,-0.4301728293129212,null,-0.4059724074813355,-0.3648939464198347,null,-0.4059724074813355,-0.3991372536892955,null,-0.028900204844833136,0.02861751720288711,null,-0.40605974416809804,-0.36916634645092505,null,-0.40605974416809804,-0.38097106639582806,null,0.3026670790226142,0.1971545982299811,null,0.013423470871069012,0.035419996996833784,null,0.013423470871069012,0.02861751720288711,null,0.013423470871069012,0.01093957511180508,null,-0.4966324866261999,-0.4804700028299716,null,-0.4966324866261999,-0.5439173527694454,null,-0.4966324866261999,-0.48954517945940224,null,0.03783794923627862,0.021303528650741303,null,0.5867457861400039,0.5605767306644166,null,0.5867457861400039,0.5744215629527019,null,0.5605767306644166,0.5744215629527019,null,-0.41171447186352494,-0.39520129896276895,null,-0.41171447186352494,-0.3746440713725381,null,-0.2090678908752118,-0.3648939464198347,null,0.25972147478779695,0.2735940169323006,null,0.25972147478779695,0.1971545982299811,null,0.25972147478779695,0.2558779409220579,null,0.23663756380550682,0.02861751720288711,null,0.20654667970663415,0.20503119881445203,null,0.20654667970663415,0.21599179594707124,null,-0.5439173527694454,-0.4804700028299716,null,-0.5439173527694454,-0.4538231952471651,null,-0.5439173527694454,-0.671172454352229,null,-0.5439173527694454,-0.46380856112534075,null,-0.5439173527694454,-0.6073808832119391,null,-0.5439173527694454,-0.6295325231980975,null,-0.5439173527694454,-0.6737321124898505,null,-0.5439173527694454,-0.48954517945940224,null,-0.5439173527694454,-0.6781934405608715,null,-0.5439173527694454,-0.4721539465039138,null,-0.35357995846547274,-0.3746440713725381,null,-0.35357995846547274,-0.33709889905006374,null,-0.4310679397180599,-0.43609475615980997,null,-0.4310679397180599,-0.414011715712754,null,0.1401685740067246,0.1971545982299811,null,0.1401685740067246,0.21599179594707124,null,0.1401685740067246,0.02861751720288711,null,0.1401685740067246,0.13219574301524142,null,-0.43636655099250643,-0.3648939464198347,null,-0.43636655099250643,-0.4413240760165562,null,0.1231969937759269,0.13634453192860524,null,0.1231969937759269,0.18060824987066992,null,0.1231969937759269,0.02861751720288711,null,0.1231969937759269,0.21599179594707124,null,0.29317442471933325,0.2770892614074666,null,0.29317442471933325,0.21599179594707124,null,0.6168178391809179,0.6074372212355406,null,-0.4301728293129212,-0.3648939464198347,null,-0.4301728293129212,-0.3991372536892955,null,0.13654070847916366,0.11917830401758958,null,0.13654070847916366,0.15394252403128642,null,0.0448929334080501,0.05168415276062511,null,0.0448929334080501,0.21599179594707124,null,0.18060824987066992,0.21599179594707124,null,0.18060824987066992,0.13634453192860524,null,0.18060824987066992,0.02861751720288711,null,0.13634453192860524,0.21599179594707124,null,0.13634453192860524,0.02861751720288711,null,0.31407742200527355,0.21599179594707124,null,0.4634210603816112,0.4845452646999587,null,-0.414011715712754,-0.43609475615980997,null,0.02861751720288711,0.01093957511180508,null,0.02861751720288711,0.09943641549603949,null,0.02861751720288711,0.011887095261928868,null,0.02861751720288711,0.14111852307635775,null,0.02861751720288711,0.21599179594707124,null,0.02861751720288711,-0.0001816053917977161,null,0.02861751720288711,-0.167915484966163,null,0.02861751720288711,-0.1589227222712193,null,0.02861751720288711,-0.05150569433029976,null,0.02861751720288711,0.13359080024858752,null,0.02861751720288711,-0.048648131647875195,null,0.02861751720288711,0.1971545982299811,null,0.02861751720288711,0.13219574301524142,null,0.02861751720288711,0.1027083360530624,null,0.02861751720288711,-0.028316962958408312,null,0.02861751720288711,0.035419996996833784,null,-0.33709889905006374,-0.3746440713725381,null,-0.0001816053917977161,-0.028316962958408312,null,-0.5570415767027547,-0.4413240760165562,null,-0.3746440713725381,-0.39520129896276895,null,0.31140847919034037,0.21599179594707124,null,-0.34386793618941736,-0.36916634645092505,null,-0.34386793618941736,-0.36513312366975414,null,-0.6295325231980975,-0.6073808832119391,null,0.13359080024858752,0.14111852307635775,null,-0.4804700028299716,-0.48954517945940224,null,-0.3648939464198347,-0.4413240760165562,null,-0.3648939464198347,-0.3991372536892955,null,-0.3648939464198347,-0.47334552020230125,null,0.9637482324415548,0.8824216153977748,null,0.9637482324415548,0.9950729293827221,null,0.9637482324415548,0.9782713092334949,null,-0.358722572333496,-0.4901690131007754,null,0.9950729293827221,0.8824216153977748,null,0.15208765606104926,0.17959597070127892,null,0.1613890242205152,0.124435985726018,null,0.1613890242205152,0.17959597070127892,null,0.1613890242205152,0.07425007382384027,null,0.21599179594707124,0.2770892614074666,null,0.21599179594707124,0.3731985458668834,null,0.21599179594707124,0.2827643624806449,null,0.21599179594707124,0.36733124780740023,null,0.21599179594707124,0.05168415276062511,null,0.21599179594707124,0.1971545982299811,null,0.21599179594707124,0.20503119881445203,null,0.21599179594707124,0.13219574301524142,null,-0.4721539465039138,-0.4538231952471651,null,-0.4721539465039138,-0.46380856112534075,null,0.01093957511180508,0.035419996996833784,null,0.2558779409220579,0.1971545982299811,null,0.2558779409220579,0.2735940169323006,null,-0.42072470684187124,-0.40412417018890917,null,0.9782713092334949,0.8824216153977748,null,0.13219574301524142,0.1971545982299811,null,0.17959597070127892,0.124435985726018,null,0.17959597070127892,0.07425007382384027,null,-0.4538231952471651,-0.46380856112534075,null,0.1971545982299811,0.2735940169323006,null,0.11917830401758958,0.15394252403128642,null,-0.36916634645092505,-0.36513312366975414,null,-0.36916634645092505,-0.38097106639582806,null,0.07425007382384027,0.124435985726018,null,-0.6781934405608715,-0.6737321124898505,null],\"y\":[0.11649965661465234,0.14049567120046985,null,0.11649965661465234,0.09948236090636726,null,0.03570850021549773,0.03383949410839906,null,0.03570850021549773,-0.07486819495477083,null,0.03570850021549773,0.12577663713286016,null,0.35030443333248634,0.345523913151438,null,0.35030443333248634,0.3654725841261129,null,0.35030443333248634,0.26076742382099005,null,0.35030443333248634,0.32984066398966005,null,0.15962294805135419,0.11552958219357258,null,0.15962294805135419,0.09948236090636726,null,-0.3367997917746649,-0.22861744987078406,null,-0.3367997917746649,-0.3453702935699518,null,-0.3367997917746649,-0.36834084850276105,null,-0.27268934204854595,-0.2925630382652267,null,-0.27268934204854595,-0.2483829310772731,null,-0.27268934204854595,-0.2560686189021928,null,-0.27268934204854595,-0.27638987715438723,null,-0.2822529558178622,-0.2945988967363953,null,-0.2822529558178622,-0.22861744987078406,null,-0.2822529558178622,-0.2998942714457143,null,0.26023267026479846,0.12577663713286016,null,0.26023267026479846,0.24369352310786294,null,0.26023267026479846,0.25011058648039575,null,-0.11598016487608546,-0.07486819495477083,null,-0.11598016487608546,-0.16069686531255423,null,-0.11598016487608546,-0.15916589786938373,null,-0.11598016487608546,-0.016174942528235696,null,-0.11598016487608546,-0.10286182028457586,null,-0.25797606253112604,-0.15916589786938373,null,-0.25797606253112604,-0.23598541133881426,null,-0.25797606253112604,-0.26411722939518323,null,0.25011058648039575,0.24369352310786294,null,0.25011058648039575,0.12577663713286016,null,-0.17499888704487726,-0.18848121913466323,null,-0.17499888704487726,-0.17208141773745994,null,-0.17499888704487726,-0.07486819495477083,null,-0.17499888704487726,-0.15650038784091563,null,-0.018470032513432724,0.014768884988252242,null,-0.018470032513432724,-0.00939768261578156,null,-0.018470032513432724,0.008673383957650594,null,-0.018470032513432724,0.010527112908534033,null,0.2660711178379747,0.279717432104078,null,0.2660711178379747,0.26076742382099005,null,-0.4007160411615402,-0.2945988967363953,null,-0.4007160411615402,-0.3643226649730541,null,-0.619227681020131,-0.6579003662829986,null,-0.619227681020131,-0.6143801096224186,null,-0.619227681020131,-0.4852238452570139,null,0.24369352310786294,0.12577663713286016,null,0.4178540885529418,0.40137615883699956,null,0.4178540885529418,0.42659990409650844,null,0.4178540885529418,0.39793916643420585,null,-0.3643226649730541,-0.2945988967363953,null,0.3884173234872046,0.43206651487103137,null,0.3884173234872046,0.26076742382099005,null,-0.3338567823722778,-0.22861744987078406,null,0.345523913151438,0.3654725841261129,null,0.345523913151438,0.26076742382099005,null,0.345523913151438,0.32984066398966005,null,-0.6143801096224186,-0.4852238452570139,null,-0.6143801096224186,-0.6579003662829986,null,0.18911249670967617,0.21758405344882545,null,0.18911249670967617,0.09948236090636726,null,-0.16069686531255423,-0.07486819495477083,null,-0.16069686531255423,-0.20453121961242343,null,-0.16069686531255423,-0.21822038142574993,null,-0.16069686531255423,-0.21739790476645934,null,-0.16069686531255423,-0.15916589786938373,null,-0.16069686531255423,-0.2358385436094524,null,-0.16069686531255423,-0.016174942528235696,null,-0.16069686531255423,-0.10286182028457586,null,-0.16069686531255423,-0.24871510011217862,null,-0.16069686531255423,-0.23655052844910845,null,-0.07041799469584092,0.09948236090636726,null,-0.07041799469584092,-0.06883329686824452,null,-0.07041799469584092,-0.22861744987078406,null,-0.07041799469584092,-0.11466303641059751,null,0.03865973831038148,0.014768884988252242,null,0.03865973831038148,0.008673383957650594,null,0.03865973831038148,0.05296437314663861,null,0.0628806558128276,0.09948236090636726,null,0.0628806558128276,0.08686567379788572,null,0.06791359069392154,-0.016174942528235696,null,0.06791359069392154,0.0860864517928534,null,0.06791359069392154,0.08599066339298718,null,0.4826287439979106,0.4514617448624333,null,0.4826287439979106,0.46117353300678765,null,0.4826287439979106,0.47132138559796644,null,0.4826287439979106,0.39793916643420585,null,-0.4852238452570139,-0.3917498759166121,null,-0.4852238452570139,-0.3387211069242755,null,-0.4852238452570139,-0.6579003662829986,null,-0.4852238452570139,-0.47805041709342877,null,-0.4852238452570139,-0.3878000514175271,null,-0.4852238452570139,-0.5954741529921709,null,-0.4852238452570139,-0.22861744987078406,null,-0.4852238452570139,-0.47408598671506363,null,-0.4852238452570139,-0.6133035524744289,null,-0.4852238452570139,-0.5985509042425224,null,-0.3917498759166121,-0.22861744987078406,null,-0.3917498759166121,-0.3878000514175271,null,-0.24988462201503978,-0.1970455122437319,null,-0.24988462201503978,-0.26666585389129116,null,-0.24988462201503978,-0.28082447742989514,null,-0.3646527972727061,-0.25916125200701023,null,-0.15916589786938373,-0.10286182028457586,null,-0.15916589786938373,-0.26411722939518323,null,-0.15916589786938373,-0.07486819495477083,null,-0.15916589786938373,-0.23598541133881426,null,-0.15916589786938373,-0.016174942528235696,null,0.16777818942984823,0.1942198636203749,null,0.16777818942984823,0.09948236090636726,null,0.16777818942984823,0.19339503620969947,null,0.21630514833409242,0.2342538853883128,null,0.21630514833409242,0.20487732759551044,null,0.21630514833409242,0.22204223979862592,null,0.21630514833409242,0.26076742382099005,null,-0.0275321392501781,-0.07486819495477083,null,-0.0275321392501781,-0.1277098472935026,null,-0.0275321392501781,-0.02625370005182628,null,-0.0275321392501781,-0.014640170100033803,null,-0.0275321392501781,0.09948236090636726,null,-0.22861744987078406,-0.173356733873613,null,-0.22861744987078406,0.09948236090636726,null,-0.22861744987078406,-0.1970455122437319,null,-0.22861744987078406,-0.07486819495477083,null,-0.22861744987078406,-0.3453702935699518,null,-0.22861744987078406,-0.06883329686824452,null,-0.22861744987078406,-0.11466303641059751,null,-0.22861744987078406,-0.1601029315392917,null,-0.22861744987078406,-0.2998942714457143,null,-0.22861744987078406,-0.3878000514175271,null,-0.22861744987078406,-0.36834084850276105,null,-0.22861744987078406,-0.2945988967363953,null,-0.11134605920497041,-0.1507134802372798,null,-0.11134605920497041,-0.09153335414105289,null,-0.11134605920497041,-0.12050323912553279,null,-0.11134605920497041,-0.13810817456124902,null,0.19339503620969947,0.09948236090636726,null,0.19339503620969947,0.1942198636203749,null,-0.24871510011217862,-0.2358385436094524,null,-0.24871510011217862,-0.21822038142574993,null,-0.24871510011217862,-0.20453121961242343,null,-0.24871510011217862,-0.23655052844910845,null,-0.24871510011217862,-0.21739790476645934,null,-0.08671172277447489,-0.11337467016928823,null,-0.08671172277447489,-0.07486819495477083,null,0.30152519727039256,0.418586778141929,null,0.30152519727039256,0.4290988566602368,null,0.30152519727039256,0.24948944888939367,null,0.30152519727039256,0.09948236090636726,null,0.30152519727039256,0.2381570501171828,null,0.21507210853510683,0.09948236090636726,null,0.21507210853510683,0.21709021836828707,null,-0.21750398418521474,-0.11466303641059751,null,-0.21750398418521474,-0.25916125200701023,null,-0.3415742560015482,-0.2945988967363953,null,-0.3415742560015482,-0.36031218295170625,null,0.054942829731166924,-0.016174942528235696,null,0.054942829731166924,0.028348997566992228,null,0.054942829731166924,0.031240814978811277,null,0.3654725841261129,0.26076742382099005,null,0.3654725841261129,0.32984066398966005,null,-0.016174942528235696,0.10030743778420384,null,-0.016174942528235696,-0.0029001716005161186,null,-0.016174942528235696,0.0860864517928534,null,-0.016174942528235696,-0.025381667851397442,null,-0.016174942528235696,0.06972220843083958,null,-0.016174942528235696,-0.008750049607469395,null,-0.016174942528235696,-0.10286182028457586,null,-0.016174942528235696,0.031240814978811277,null,-0.016174942528235696,-0.027591825835842975,null,-0.016174942528235696,-0.07486819495477083,null,-0.016174942528235696,0.05224946925569809,null,-0.016174942528235696,0.11552958219357258,null,-0.016174942528235696,-0.05994780140120706,null,-0.016174942528235696,-0.3387211069242755,null,-0.016174942528235696,0.09948236090636726,null,-0.016174942528235696,0.08599066339298718,null,-0.016174942528235696,0.10505714368390698,null,-0.016174942528235696,0.06874137378111005,null,-0.016174942528235696,-0.03350062340147141,null,-0.016174942528235696,-0.007769756223030876,null,-0.016174942528235696,-0.053106144597217936,null,-0.016174942528235696,0.028348997566992228,null,-0.016174942528235696,-0.09153335414105289,null,-0.016174942528235696,0.08410741782251735,null,-0.016174942528235696,0.05709987655720104,null,-0.23391191878126583,-0.1970455122437319,null,-0.23391191878126583,-0.2483829310772731,null,0.23776152560991937,0.2606993940364203,null,0.23776152560991937,0.26076742382099005,null,-0.24207638919967808,-0.1277098472935026,null,-0.24207638919967808,-0.2337465808927593,null,-0.24207638919967808,-0.24415914425124796,null,-0.24207638919967808,-0.25974606276203993,null,-0.24207638919967808,-0.25871860888805215,null,0.10869148919265731,0.26076742382099005,null,0.10869148919265731,-0.037615438447694854,null,0.18440334853110624,0.10505714368390698,null,0.18440334853110624,0.15392232915302653,null,0.18440334853110624,0.1752836128026285,null,-0.43612106214475554,-0.4283119936154009,null,-0.43612106214475554,-0.42473082818247043,null,-0.43612106214475554,-0.3387211069242755,null,-0.43612106214475554,-0.36834084850276105,null,-0.43612106214475554,-0.4150925396304882,null,-0.07571684360736851,-0.05813128762533492,null,-0.07571684360736851,-0.07486819495477083,null,-0.07571684360736851,-0.05994780140120706,null,0.29885594862621667,0.3189620804606704,null,0.29885594862621667,0.26076742382099005,null,0.29885594862621667,0.2895349112064701,null,0.06972220843083958,0.08410741782251735,null,0.06972220843083958,0.10505714368390698,null,0.06972220843083958,0.05709987655720104,null,-0.27638987715438723,-0.2560686189021928,null,-0.27638987715438723,-0.2483829310772731,null,-0.27638987715438723,-0.2925630382652267,null,0.2084834256651096,0.26076742382099005,null,0.2084834256651096,0.09948236090636726,null,0.2084834256651096,0.18127648088714307,null,0.2084834256651096,0.19598029029284444,null,-0.2560686189021928,-0.2483829310772731,null,-0.2560686189021928,-0.2925630382652267,null,-0.20653498978004683,-0.22716138640224862,null,-0.20653498978004683,-0.1277098472935026,null,-0.40368943613631797,-0.4222404020757114,null,-0.40368943613631797,-0.42577676592395924,null,-0.40368943613631797,-0.2945988967363953,null,-0.40368943613631797,-0.4073668243637883,null,-0.4150925396304882,-0.42473082818247043,null,-0.4150925396304882,-0.36834084850276105,null,-0.4150925396304882,-0.3387211069242755,null,-0.4150925396304882,-0.4283119936154009,null,0.5514922093260491,0.43206651487103137,null,-0.3453702935699518,-0.36834084850276105,null,-0.31933777388003276,-0.18425589371292797,null,-0.31933777388003276,-0.31179612732943734,null,-0.31933777388003276,-0.32705494661246737,null,0.20536101782314023,0.11552958219357258,null,0.279717432104078,0.26076742382099005,null,0.5015443381112532,0.5199825637792153,null,0.5015443381112532,0.39793916643420585,null,0.5015443381112532,0.4919525728787619,null,0.5015443381112532,0.5104300358090186,null,-0.17208141773745994,-0.15650038784091563,null,-0.17208141773745994,-0.07486819495477083,null,-0.17208141773745994,-0.18848121913466323,null,0.10030743778420384,0.11552958219357258,null,-0.2358385436094524,-0.20453121961242343,null,-0.2358385436094524,-0.21822038142574993,null,-0.2358385436094524,-0.23655052844910845,null,-0.2358385436094524,-0.21739790476645934,null,-0.25974606276203993,-0.1277098472935026,null,-0.25974606276203993,-0.2337465808927593,null,-0.25974606276203993,-0.24415914425124796,null,-0.25974606276203993,-0.25871860888805215,null,-0.06304279450633707,-0.05994780140120706,null,-0.06304279450633707,-0.037993350544401554,null,-0.06304279450633707,-0.058578647034265505,null,-0.6579003662829986,-0.780683042405329,null,0.1942198636203749,0.09948236090636726,null,0.33393932354052397,0.26076742382099005,null,0.33393932354052397,0.3176115336536533,null,0.33393932354052397,0.3176274454515524,null,0.33393932354052397,0.39793916643420585,null,0.33393932354052397,0.33804375359161704,null,0.4919525728787619,0.5199825637792153,null,0.4919525728787619,0.39793916643420585,null,0.4919525728787619,0.5104300358090186,null,0.4514617448624333,0.46117353300678765,null,0.4514617448624333,0.47132138559796644,null,0.4514617448624333,0.39793916643420585,null,0.24948944888939367,0.09948236090636726,null,0.24948944888939367,0.2381570501171828,null,-0.38052335508442875,-0.2945988967363953,null,-0.38052335508442875,-0.38281602156054795,null,-0.008750049607469395,-0.007769756223030876,null,-0.008750049607469395,0.008673383957650594,null,-0.008750049607469395,-0.025381667851397442,null,-0.008750049607469395,-0.05994780140120706,null,-0.09153335414105289,-0.13810817456124902,null,-0.09153335414105289,-0.053106144597217936,null,-0.09153335414105289,-0.1507134802372798,null,-0.09153335414105289,-0.12050323912553279,null,-0.09153335414105289,-0.07486819495477083,null,0.32984066398966005,0.26076742382099005,null,0.14191260025310806,0.1401080598553181,null,0.14191260025310806,0.029936369567875133,null,0.14191260025310806,0.26076742382099005,null,-0.26666585389129116,-0.1970455122437319,null,-0.26666585389129116,-0.28082447742989514,null,-0.05521273068817138,-0.07162971684860518,null,-0.05521273068817138,-0.03921496563617404,null,-0.05521273068817138,-0.037615438447694854,null,0.21709021836828707,0.09948236090636726,null,-0.07162971684860518,-0.037615438447694854,null,-0.07162971684860518,-0.03921496563617404,null,0.1711514922333469,0.09948236090636726,null,0.1711514922333469,0.1918465129949595,null,0.1711514922333469,0.26076742382099005,null,0.1744978098041819,0.09948236090636726,null,0.1744978098041819,0.14768999522434487,null,0.1744978098041819,0.1524075982766828,null,-0.16210730514485022,-0.13606155350598806,null,-0.16210730514485022,-0.07486819495477083,null,-0.16210730514485022,-0.15263024401606515,null,-0.16210730514485022,-0.16874196335776365,null,0.3783578052369583,0.39053714703684966,null,0.3783578052369583,0.26076742382099005,null,0.10505714368390698,0.1752836128026285,null,0.10505714368390698,0.08410741782251735,null,0.10505714368390698,0.05709987655720104,null,0.10505714368390698,0.15392232915302653,null,0.08599066339298718,0.0860864517928534,null,-0.23655052844910845,-0.21739790476645934,null,-0.23655052844910845,-0.20453121961242343,null,-0.23655052844910845,-0.21822038142574993,null,0.12577663713286016,0.03383949410839906,null,0.12577663713286016,-0.07486819495477083,null,0.1752836128026285,0.15392232915302653,null,-0.058578647034265505,-0.05994780140120706,null,-0.058578647034265505,-0.037993350544401554,null,-0.00939768261578156,0.010527112908534033,null,-0.00939768261578156,0.008673383957650594,null,-0.00939768261578156,0.014768884988252242,null,-0.23598541133881426,-0.26411722939518323,null,0.2895349112064701,0.3189620804606704,null,0.2895349112064701,0.26076742382099005,null,0.06874137378111005,0.09948236090636726,null,0.06874137378111005,0.05224946925569809,null,0.1524075982766828,0.09948236090636726,null,0.1524075982766828,0.14768999522434487,null,0.37680457825191604,0.26076742382099005,null,0.37680457825191604,0.35452171327642806,null,0.37680457825191604,0.3729550905067433,null,0.37680457825191604,0.3571921992824322,null,0.37680457825191604,0.39793916643420585,null,-0.47408598671506363,-0.3387211069242755,null,-0.47408598671506363,-0.47805041709342877,null,-0.28082447742989514,-0.1970455122437319,null,0.4290988566602368,0.418586778141929,null,0.39053714703684966,0.26076742382099005,null,0.17016888171579175,0.1958884628007197,null,0.17016888171579175,0.18736573237299983,null,0.17016888171579175,0.09948236090636726,null,0.031240814978811277,0.028348997566992228,null,0.1401080598553181,0.029936369567875133,null,0.1401080598553181,0.26076742382099005,null,0.3482899814550976,0.36811830787229544,null,0.3482899814550976,0.26076742382099005,null,-0.1970455122437319,-0.1601029315392917,null,-0.1970455122437319,-0.07486819495477083,null,-0.1970455122437319,-0.2483829310772731,null,-0.1970455122437319,-0.173356733873613,null,-0.1970455122437319,-0.21878127458134725,null,0.47132138559796644,0.46117353300678765,null,0.47132138559796644,0.39793916643420585,null,-0.027591825835842975,-0.0029001716005161186,null,0.05224946925569809,0.09948236090636726,null,0.0860864517928534,0.13440555500131457,null,0.0860864517928534,0.1162121039845653,null,0.0860864517928534,0.09948236090636726,null,0.26076742382099005,0.33804375359161704,null,0.26076742382099005,0.3483042508195348,null,0.26076742382099005,0.4083881248018299,null,0.26076742382099005,0.2342538853883128,null,0.26076742382099005,0.2606993940364203,null,0.26076742382099005,0.35452171327642806,null,0.26076742382099005,0.3729550905067433,null,0.26076742382099005,0.22204223979862592,null,0.26076742382099005,0.3217263994461065,null,0.26076742382099005,0.4125776239840935,null,0.26076742382099005,0.43206651487103137,null,0.26076742382099005,0.1918465129949595,null,0.26076742382099005,0.18127648088714307,null,0.26076742382099005,0.3189620804606704,null,0.26076742382099005,0.36811830787229544,null,0.26076742382099005,0.20487732759551044,null,0.26076742382099005,0.4701730654582074,null,0.26076742382099005,0.3176115336536533,null,0.26076742382099005,0.3176274454515524,null,0.26076742382099005,0.09948236090636726,null,0.26076742382099005,0.39793916643420585,null,0.26076742382099005,0.029936369567875133,null,0.26076742382099005,-0.037615438447694854,null,0.26076742382099005,0.3571921992824322,null,0.26076742382099005,0.19598029029284444,null,0.19598029029284444,0.09948236090636726,null,0.19598029029284444,0.18127648088714307,null,-0.007769756223030876,-0.025381667851397442,null,-0.007769756223030876,-0.05994780140120706,null,-0.25916125200701023,-0.11466303641059751,null,-0.36031218295170625,-0.2945988967363953,null,-0.037993350544401554,-0.05994780140120706,null,0.18736573237299983,0.1958884628007197,null,0.18736573237299983,0.09948236090636726,null,-0.16874196335776365,-0.15263024401606515,null,-0.16874196335776365,-0.13606155350598806,null,-0.16874196335776365,-0.07486819495477083,null,-0.05994780140120706,-0.07486819495477083,null,-0.05994780140120706,-0.05813128762533492,null,-0.05994780140120706,-0.08995949762894676,null,-0.05994780140120706,-0.10857714283051234,null,-0.05994780140120706,-0.025381667851397442,null,-0.18031278262653394,-0.037615438447694854,null,-0.18031278262653394,-0.2945988967363953,null,-0.18031278262653394,-0.1760663377706984,null,0.029936369567875133,-0.09277298274959321,null,0.029936369567875133,-0.18425589371292797,null,0.029936369567875133,-0.0863152603881126,null,-0.42577676592395924,-0.4222404020757114,null,-0.42577676592395924,-0.2945988967363953,null,-0.42577676592395924,-0.4073668243637883,null,0.21758405344882545,0.09948236090636726,null,0.5954429907610062,0.4701730654582074,null,0.5954429907610062,0.598522327381284,null,-0.22716138640224862,-0.1277098472935026,null,0.2447696876434216,0.23801386292256674,null,0.2447696876434216,0.09948236090636726,null,0.2447696876434216,0.22478316559836578,null,0.3176274454515524,0.3176115336536533,null,0.3176274454515524,0.39793916643420585,null,0.3176274454515524,0.33804375359161704,null,-0.5954741529921709,-0.6133035524744289,null,-0.21822038142574993,-0.21739790476645934,null,-0.21822038142574993,-0.20453121961242343,null,-0.21739790476645934,-0.20453121961242343,null,-0.09277298274959321,-0.0863152603881126,null,-0.09277298274959321,-0.18425589371292797,null,-0.2998942714457143,-0.2945988967363953,null,-0.25871860888805215,-0.24415914425124796,null,-0.25871860888805215,-0.1277098472935026,null,-0.25871860888805215,-0.2337465808927593,null,0.11552958219357258,0.09948236090636726,null,-0.18848121913466323,-0.15650038784091563,null,-0.18848121913466323,-0.07486819495477083,null,0.39793916643420585,0.3176115336536533,null,0.39793916643420585,0.35452171327642806,null,0.39793916643420585,0.46117353300678765,null,0.39793916643420585,0.3729550905067433,null,0.39793916643420585,0.5199825637792153,null,0.39793916643420585,0.5104300358090186,null,0.39793916643420585,0.40137615883699956,null,0.39793916643420585,0.33804375359161704,null,0.39793916643420585,0.42659990409650844,null,0.39793916643420585,0.3571921992824322,null,-0.31179612732943734,-0.18425589371292797,null,-0.31179612732943734,-0.32705494661246737,null,0.20487732759551044,0.2342538853883128,null,0.20487732759551044,0.22204223979862592,null,-0.014640170100033803,-0.1277098472935026,null,-0.014640170100033803,-0.07486819495477083,null,-0.014640170100033803,0.09948236090636726,null,-0.014640170100033803,-0.02625370005182628,null,-0.1760663377706984,-0.2945988967363953,null,-0.1760663377706984,-0.037615438447694854,null,0.02046025781067703,0.03139634619706863,null,0.02046025781067703,0.03383949410839906,null,0.02046025781067703,0.09948236090636726,null,0.02046025781067703,-0.07486819495477083,null,-0.15263024401606515,-0.13606155350598806,null,-0.15263024401606515,-0.07486819495477083,null,-0.08995949762894676,-0.10857714283051234,null,-0.4222404020757114,-0.2945988967363953,null,-0.4222404020757114,-0.4073668243637883,null,-0.1507134802372798,-0.12050323912553279,null,-0.1507134802372798,-0.13810817456124902,null,-0.1601029315392917,-0.173356733873613,null,-0.1601029315392917,-0.07486819495477083,null,0.03383949410839906,-0.07486819495477083,null,0.03383949410839906,0.03139634619706863,null,0.03383949410839906,0.09948236090636726,null,0.03139634619706863,-0.07486819495477083,null,0.03139634619706863,0.09948236090636726,null,-0.11337467016928823,-0.07486819495477083,null,0.08410741782251735,0.05709987655720104,null,0.22204223979862592,0.2342538853883128,null,0.09948236090636726,0.22478316559836578,null,0.09948236090636726,0.2381570501171828,null,0.09948236090636726,0.14768999522434487,null,0.09948236090636726,0.13440555500131457,null,0.09948236090636726,-0.07486819495477083,null,0.09948236090636726,-0.11466303641059751,null,0.09948236090636726,0.1918465129949595,null,0.09948236090636726,0.18127648088714307,null,0.09948236090636726,0.14049567120046985,null,0.09948236090636726,0.1162121039845653,null,0.09948236090636726,0.08686567379788572,null,0.09948236090636726,-0.1277098472935026,null,0.09948236090636726,-0.02625370005182628,null,0.09948236090636726,0.1958884628007197,null,0.09948236090636726,-0.06883329686824452,null,0.09948236090636726,0.23801386292256674,null,-0.32705494661246737,-0.18425589371292797,null,-0.11466303641059751,-0.06883329686824452,null,-0.03921496563617404,-0.037615438447694854,null,-0.18425589371292797,-0.0863152603881126,null,-0.03350062340147141,-0.07486819495477083,null,0.4125776239840935,0.4701730654582074,null,0.4125776239840935,0.4083881248018299,null,0.5104300358090186,0.5199825637792153,null,0.1162121039845653,0.13440555500131457,null,0.3176115336536533,0.33804375359161704,null,-0.2945988967363953,-0.037615438447694854,null,-0.2945988967363953,-0.4073668243637883,null,-0.2945988967363953,-0.38281602156054795,null,0.014768884988252242,0.008673383957650594,null,0.014768884988252242,0.010527112908534033,null,0.014768884988252242,0.05296437314663861,null,-0.2483829310772731,-0.2925630382652267,null,0.010527112908534033,0.008673383957650594,null,-0.47805041709342877,-0.3387211069242755,null,-0.42473082818247043,-0.4283119936154009,null,-0.42473082818247043,-0.3387211069242755,null,-0.42473082818247043,-0.36834084850276105,null,-0.07486819495477083,-0.13606155350598806,null,-0.07486819495477083,-0.05813128762533492,null,-0.07486819495477083,-0.053106144597217936,null,-0.07486819495477083,-0.10286182028457586,null,-0.07486819495477083,-0.173356733873613,null,-0.07486819495477083,-0.1277098472935026,null,-0.07486819495477083,-0.15650038784091563,null,-0.07486819495477083,-0.02625370005182628,null,0.3571921992824322,0.35452171327642806,null,0.3571921992824322,0.3729550905067433,null,0.22478316559836578,0.23801386292256674,null,-0.2337465808927593,-0.1277098472935026,null,-0.2337465808927593,-0.24415914425124796,null,0.3217263994461065,0.3483042508195348,null,0.05296437314663861,0.008673383957650594,null,-0.02625370005182628,-0.1277098472935026,null,-0.3387211069242755,-0.4283119936154009,null,-0.3387211069242755,-0.36834084850276105,null,0.35452171327642806,0.3729550905067433,null,-0.1277098472935026,-0.24415914425124796,null,-0.12050323912553279,-0.13810817456124902,null,0.4701730654582074,0.4083881248018299,null,0.4701730654582074,0.598522327381284,null,-0.36834084850276105,-0.4283119936154009,null,0.42659990409650844,0.40137615883699956,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#7f7f7f\",\"#9467bd\",\"#7f7f7f\",\"#9467bd\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#7f7f7f\",\"#7f7f7f\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#9467bd\",\"#7f7f7f\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#9467bd\",\"#7f7f7f\",\"#9467bd\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#7f7f7f\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#7f7f7f\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#9467bd\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#9467bd\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#7f7f7f\",\"#7f7f7f\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\",\"#9467bd\",\"#bcbd22\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#7f7f7f\",\"#7f7f7f\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#9467bd\",\"#bcbd22\",\"#7f7f7f\",\"#9467bd\",\"#9467bd\",\"#7f7f7f\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#9467bd\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#bcbd22\",\"#7f7f7f\"],\"size\":[7.2,8.3,9.4,7.2,8.3,9.4,8.3,8.3,10.5,8.3,8.3,9.4,9.4,7.2,7.2,8.3,8.3,8.3,7.2,7.2,6.1,9.4,8.3,7.2,17.1,9.4,8.3,7.2,8.3,9.4,18.200000000000003,8.3,8.3,6.1,13.8,8.3,9.4,10.5,24.8,9.4,8.3,11.600000000000001,7.2,10.5,7.2,7.2,7.2,8.3,9.4,38.0,7.2,7.2,10.5,7.2,8.3,10.5,8.3,8.3,9.4,9.4,9.4,9.4,7.2,9.4,10.5,6.1,8.3,8.3,6.1,7.2,9.4,9.4,7.2,11.600000000000001,10.5,8.3,9.4,6.1,8.3,10.5,9.4,9.4,8.3,7.2,8.3,10.5,12.700000000000001,9.4,8.3,8.3,8.3,7.2,8.3,8.3,8.3,9.4,7.2,12.700000000000001,8.3,11.600000000000001,11.600000000000001,8.3,8.3,9.4,8.3,8.3,8.3,8.3,10.5,8.3,8.3,7.2,7.2,8.3,8.3,8.3,7.2,16.0,9.4,7.2,8.3,11.600000000000001,55.6,9.4,9.4,8.3,7.2,8.3,7.2,8.3,9.4,18.200000000000003,6.1,8.3,11.600000000000001,9.4,7.2,7.2,9.4,7.2,8.3,10.5,7.2,11.600000000000001,11.600000000000001,8.3,8.3,10.5,10.5,9.4,27.0,8.3,9.4,10.5,8.3,9.4,9.4,7.2,9.4,9.4,9.4,8.3,11.600000000000001,9.4,7.2,9.4,9.4,58.900000000000006,8.3,8.3,11.600000000000001,8.3,8.3,11.600000000000001,7.2,8.3,9.4,8.3,7.2,7.2,7.2,10.5,22.6,9.4,11.600000000000001,11.600000000000001,9.4,8.3,10.5,13.8,43.5,7.2,10.5,9.4,9.4,8.3,9.4,11.600000000000001,8.3,10.5,7.2,8.3,8.3,7.2,10.5,8.3,14.9,12.700000000000001,10.5,18.200000000000003,7.2,8.3,7.2,6.1,8.3,9.4,10.5,8.3,10.5,13.8,10.5,8.3,8.3,10.5,8.3,9.4,9.4,7.2,9.4,9.4,8.3,9.4,10.5,8.3,7.2,9.4,9.4,10.5,7.2,8.3,8.3,8.3,9.4]},\"mode\":\"markers\",\"text\":[\"Node Artificial Neural Networks\\u003cbr\\u003eDegree: 2\",\"Node CNN+Transformer\\u003cbr\\u003eDegree: 3\",\"Node Single-view Metrology\\u003cbr\\u003eDegree: 4\",\"Node EscherNet 101\\u003cbr\\u003eDegree: 2\",\"Node Metropolis-Hastings Method\\u003cbr\\u003eDegree: 3\",\"Node FDDB\\u003cbr\\u003eDegree: 4\",\"Node Watershed\\u003cbr\\u003eDegree: 3\",\"Node Biomedical Images\\u003cbr\\u003eDegree: 3\",\"Node X-ray computed tomography\\u003cbr\\u003eDegree: 5\",\"Node Pytorch\\u003cbr\\u003eDegree: 3\",\"Node Diagnosis\\u003cbr\\u003eDegree: 3\",\"Node Texture Independent\\u003cbr\\u003eDegree: 4\",\"Node Recurrent Neural Networks\\u003cbr\\u003eDegree: 4\",\"Node Omnidirectional Video\\u003cbr\\u003eDegree: 2\",\"Node Resolution Enhancement\\u003cbr\\u003eDegree: 2\",\"Node Innsbruck\\u003cbr\\u003eDegree: 3\",\"Node Evaluation Measures\\u003cbr\\u003eDegree: 3\",\"Node Satellite Image\\u003cbr\\u003eDegree: 3\",\"Node Brain MRI\\u003cbr\\u003eDegree: 2\",\"Node Macaque IT\\u003cbr\\u003eDegree: 2\",\"Node Hierarchical Multilevel Thresholding\\u003cbr\\u003eDegree: 1\",\"Node Line Detection\\u003cbr\\u003eDegree: 4\",\"Node Austria\\u003cbr\\u003eDegree: 3\",\"Node Ape-specific\\u003cbr\\u003eDegree: 2\",\"Node MRI\\u003cbr\\u003eDegree: 11\",\"Node Sequence Modeling\\u003cbr\\u003eDegree: 4\",\"Node Lesion Classification\\u003cbr\\u003eDegree: 3\",\"Node Image Retrieval\\u003cbr\\u003eDegree: 2\",\"Node Filter Based\\u003cbr\\u003eDegree: 3\",\"Node Image-level Classification\\u003cbr\\u003eDegree: 4\",\"Node Pattern Recognition\\u003cbr\\u003eDegree: 12\",\"Node Kolmogorov Complexity\\u003cbr\\u003eDegree: 3\",\"Node Kernel Analysis\\u003cbr\\u003eDegree: 3\",\"Node Plane Images\\u003cbr\\u003eDegree: 1\",\"Node GAN\\u003cbr\\u003eDegree: 8\",\"Node Super Resolution Network\\u003cbr\\u003eDegree: 3\",\"Node Distributed Computing\\u003cbr\\u003eDegree: 4\",\"Node RNNs\\u003cbr\\u003eDegree: 5\",\"Node Image Segmentation\\u003cbr\\u003eDegree: 18\",\"Node Variable Metric\\u003cbr\\u003eDegree: 4\",\"Node Cornea Scans\\u003cbr\\u003eDegree: 3\",\"Node x-ray\\u003cbr\\u003eDegree: 6\",\"Node Globetarget Tracking\\u003cbr\\u003eDegree: 2\",\"Node Medical Imaging\\u003cbr\\u003eDegree: 5\",\"Node Optimization Techniques\\u003cbr\\u003eDegree: 2\",\"Node Keynote Knearest Neighbors Algorithm\\u003cbr\\u003eDegree: 2\",\"Node Handwriting Segmentation\\u003cbr\\u003eDegree: 2\",\"Node Bianco\\u003cbr\\u003eDegree: 3\",\"Node Android App\\u003cbr\\u003eDegree: 4\",\"Node Convolutional Neural Network\\u003cbr\\u003eDegree: 30\",\"Node Self Organizing Map\\u003cbr\\u003eDegree: 2\",\"Node NLP\\u003cbr\\u003eDegree: 2\",\"Node Spatially-sparse\\u003cbr\\u003eDegree: 5\",\"Node Electronic Archery\\u003cbr\\u003eDegree: 2\",\"Node ImageSimilarity Challenge\\u003cbr\\u003eDegree: 3\",\"Node Topological Models\\u003cbr\\u003eDegree: 5\",\"Node Light Field Synthesis\\u003cbr\\u003eDegree: 3\",\"Node Data Mining\\u003cbr\\u003eDegree: 3\",\"Node ACRIMA\\u003cbr\\u003eDegree: 4\",\"Node WIDER\\u003cbr\\u003eDegree: 4\",\"Node DL\\u003cbr\\u003eDegree: 4\",\"Node IJB-A\\u003cbr\\u003eDegree: 4\",\"Node Natural Handwriting\\u003cbr\\u003eDegree: 2\",\"Node Gelometric Model\\u003cbr\\u003eDegree: 4\",\"Node Feature Transformations\\u003cbr\\u003eDegree: 5\",\"Node Image Intensity\\u003cbr\\u003eDegree: 1\",\"Node Topological Constraints\\u003cbr\\u003eDegree: 3\",\"Node Neural Radiance Field\\u003cbr\\u003eDegree: 3\",\"Node Adversarial Perturbations\\u003cbr\\u003eDegree: 1\",\"Node Equirectangular Projection\\u003cbr\\u003eDegree: 2\",\"Node Simulation\\u003cbr\\u003eDegree: 4\",\"Node Noise Estimator\\u003cbr\\u003eDegree: 4\",\"Node Correlation Filters\\u003cbr\\u003eDegree: 2\",\"Node Deletable Templates\\u003cbr\\u003eDegree: 6\",\"Node Spatial-Sparse\\u003cbr\\u003eDegree: 5\",\"Node Person-MinkUNet\\u003cbr\\u003eDegree: 3\",\"Node OAGM\\u002fAAPR\\u003cbr\\u003eDegree: 4\",\"Node Austrian Association for Pattern Recognition\\u003cbr\\u003eDegree: 1\",\"Node Ophtamologist\\u003cbr\\u003eDegree: 3\",\"Node Beehive Monitoring Device\\u003cbr\\u003eDegree: 5\",\"Node Data Models\\u003cbr\\u003eDegree: 4\",\"Node SLAMs\\u003cbr\\u003eDegree: 4\",\"Node Histopathology\\u003cbr\\u003eDegree: 3\",\"Node Motion Stereo Reconstruction\\u003cbr\\u003eDegree: 2\",\"Node Cognitive Reasoning\\u003cbr\\u003eDegree: 3\",\"Node ISIC Challenge\\u003cbr\\u003eDegree: 5\",\"Node 3D Object Recognition\\u003cbr\\u003eDegree: 7\",\"Node Android\\u003cbr\\u003eDegree: 4\",\"Node Perceptual Loss\\u003cbr\\u003eDegree: 3\",\"Node Linear Discriminant Analysis\\u003cbr\\u003eDegree: 3\",\"Node Stereo Matching Algorithms\\u003cbr\\u003eDegree: 3\",\"Node Photorealistic Style Transfer\\u003cbr\\u003eDegree: 2\",\"Node Reliability\\u003cbr\\u003eDegree: 3\",\"Node Vision Transformers\\u003cbr\\u003eDegree: 3\",\"Node MR-Images\\u003cbr\\u003eDegree: 3\",\"Node Rotation invariance\\u003cbr\\u003eDegree: 4\",\"Node YOLO v1\\u003cbr\\u003eDegree: 2\",\"Node Vision Transformer\\u003cbr\\u003eDegree: 7\",\"Node Inbetweening\\u003cbr\\u003eDegree: 3\",\"Node Medical Images\\u003cbr\\u003eDegree: 6\",\"Node Image Captioning\\u003cbr\\u003eDegree: 6\",\"Node Self-supervised Learning\\u003cbr\\u003eDegree: 3\",\"Node Person Detection Network\\u003cbr\\u003eDegree: 3\",\"Node ISBI 2017\\u003cbr\\u003eDegree: 4\",\"Node Lip Synchronization\\u003cbr\\u003eDegree: 3\",\"Node Molybdenum\\u003cbr\\u003eDegree: 3\",\"Node Skin Lesion Classification\\u003cbr\\u003eDegree: 3\",\"Node Parkinson Disease\\u003cbr\\u003eDegree: 3\",\"Node UNet\\u003cbr\\u003eDegree: 5\",\"Node Translationally Invariant Features\\u003cbr\\u003eDegree: 3\",\"Node Parametric Component Analysis\\u003cbr\\u003eDegree: 3\",\"Node EBSR\\u003cbr\\u003eDegree: 2\",\"Node Real-time\\u003cbr\\u003eDegree: 2\",\"Node Representational Dissimilarity Matrices\\u003cbr\\u003eDegree: 3\",\"Node Color Constancy\\u003cbr\\u003eDegree: 3\",\"Node Hair Translation\\u003cbr\\u003eDegree: 3\",\"Node Cheirality Constraint\\u003cbr\\u003eDegree: 2\",\"Node Face Recognition\\u003cbr\\u003eDegree: 10\",\"Node Activation Map\\u003cbr\\u003eDegree: 4\",\"Node Colouring\\u003cbr\\u003eDegree: 2\",\"Node Inception-v3\\u003cbr\\u003eDegree: 3\",\"Node Animation\\u003cbr\\u003eDegree: 6\",\"Node Computer Vision\\u003cbr\\u003eDegree: 46\",\"Node Edge2Train\\u003cbr\\u003eDegree: 4\",\"Node Jaccard Index\\u003cbr\\u003eDegree: 4\",\"Node Optical Character Recognition\\u003cbr\\u003eDegree: 3\",\"Node Offline Handwriting\\u003cbr\\u003eDegree: 2\",\"Node Minkowski Engine\\u003cbr\\u003eDegree: 3\",\"Node Compareive Language-Image Pretraining\\u003cbr\\u003eDegree: 2\",\"Node Algonauts\\u003cbr\\u003eDegree: 3\",\"Node Cyclic Convolutional Layer\\u003cbr\\u003eDegree: 4\",\"Node U-Net\\u003cbr\\u003eDegree: 12\",\"Node Image Augmentation\\u003cbr\\u003eDegree: 1\",\"Node Circle Fitting\\u003cbr\\u003eDegree: 3\",\"Node CycleGAN\\u003cbr\\u003eDegree: 6\",\"Node Sparse Signal Representations\\u003cbr\\u003eDegree: 4\",\"Node Visual Behaviour Recognition\\u003cbr\\u003eDegree: 2\",\"Node Hand Pose Recognition\\u003cbr\\u003eDegree: 2\",\"Node Skin Lesion Segmentation\\u003cbr\\u003eDegree: 4\",\"Node Printed Format\\u003cbr\\u003eDegree: 2\",\"Node Action Recognition\\u003cbr\\u003eDegree: 3\",\"Node Hyperspectral Imagery\\u003cbr\\u003eDegree: 5\",\"Node Dipole Vectors\\u003cbr\\u003eDegree: 2\",\"Node Segmentation\\u003cbr\\u003eDegree: 6\",\"Node Localization\\u003cbr\\u003eDegree: 6\",\"Node Image-to-Image Translation\\u003cbr\\u003eDegree: 3\",\"Node Multiscale Framework\\u003cbr\\u003eDegree: 3\",\"Node Convolutional Automoencoder Networks\\u003cbr\\u003eDegree: 5\",\"Node Image Classification\\u003cbr\\u003eDegree: 5\",\"Node Multiple-frame\\u003cbr\\u003eDegree: 4\",\"Node Semantic Segmentation\\u003cbr\\u003eDegree: 20\",\"Node Image Synthesis\\u003cbr\\u003eDegree: 3\",\"Node Parallel Computing\\u003cbr\\u003eDegree: 4\",\"Node Acceleration Sensor\\u003cbr\\u003eDegree: 5\",\"Node Numerical Stability\\u003cbr\\u003eDegree: 3\",\"Node Convolutional Models\\u003cbr\\u003eDegree: 4\",\"Node Translation Invariance\\u003cbr\\u003eDegree: 4\",\"Node Attention Architecture\\u003cbr\\u003eDegree: 2\",\"Node MNIST Digit Classification\\u003cbr\\u003eDegree: 4\",\"Node Variable Kernel\\u003cbr\\u003eDegree: 4\",\"Node Medical Image Processing\\u003cbr\\u003eDegree: 4\",\"Node Facebook AI\\u003cbr\\u003eDegree: 3\",\"Node LSTM\\u003cbr\\u003eDegree: 6\",\"Node GRU\\u003cbr\\u003eDegree: 4\",\"Node ConvolutionalNeuralNetworks\\u003cbr\\u003eDegree: 2\",\"Node Drishti\\u003cbr\\u003eDegree: 4\",\"Node Complex Networks\\u003cbr\\u003eDegree: 4\",\"Node Deep Learning\\u003cbr\\u003eDegree: 49\",\"Node NeRF\\u003cbr\\u003eDegree: 3\",\"Node L1WGAN-GP\\u003cbr\\u003eDegree: 3\",\"Node OCR\\u003cbr\\u003eDegree: 6\",\"Node Depth Information\\u003cbr\\u003eDegree: 3\",\"Node Group Convolutions\\u003cbr\\u003eDegree: 3\",\"Node Artifact Reduction\\u003cbr\\u003eDegree: 6\",\"Node Surgical Cuttings\\u003cbr\\u003eDegree: 2\",\"Node Jarvis Algorithm\\u003cbr\\u003eDegree: 3\",\"Node Surface Reconstruction\\u003cbr\\u003eDegree: 4\",\"Node Triangle Mesh\\u003cbr\\u003eDegree: 3\",\"Node Retrieval\\u003cbr\\u003eDegree: 2\",\"Node Example-based super-resolution\\u003cbr\\u003eDegree: 2\",\"Node Brightness Map\\u003cbr\\u003eDegree: 2\",\"Node Varroa\\u003cbr\\u003eDegree: 5\",\"Node Algorithm\\u003cbr\\u003eDegree: 16\",\"Node Bernoulli Mixture Model\\u003cbr\\u003eDegree: 4\",\"Node Deep Convolutional Networks\\u003cbr\\u003eDegree: 6\",\"Node Face Detection\\u003cbr\\u003eDegree: 6\",\"Node Hybrid Method\\u003cbr\\u003eDegree: 4\",\"Node Rotationally\\u003cbr\\u003eDegree: 3\",\"Node Ensemble Methods\\u003cbr\\u003eDegree: 5\",\"Node Accuracy\\u003cbr\\u003eDegree: 8\",\"Node CNN\\u003cbr\\u003eDegree: 35\",\"Node Feature Clustering\\u003cbr\\u003eDegree: 2\",\"Node PSPNet\\u003cbr\\u003eDegree: 5\",\"Node Digital Twins\\u003cbr\\u003eDegree: 4\",\"Node Real-time Imaging\\u003cbr\\u003eDegree: 4\",\"Node Selenium\\u003cbr\\u003eDegree: 3\",\"Node Image\\u003cbr\\u003eDegree: 4\",\"Node Ultrasound\\u003cbr\\u003eDegree: 6\",\"Node Shallow Learning\\u003cbr\\u003eDegree: 3\",\"Node 3D Objects\\u003cbr\\u003eDegree: 5\",\"Node Neuroscience\\u003cbr\\u003eDegree: 2\",\"Node ISIC 2017\\u003cbr\\u003eDegree: 3\",\"Node Pixel Level Cycle Consistency\\u003cbr\\u003eDegree: 3\",\"Node Machine Thinking\\u003cbr\\u003eDegree: 2\",\"Node Gyroscopic Sensor\\u003cbr\\u003eDegree: 5\",\"Node Motion Implantation\\u003cbr\\u003eDegree: 3\",\"Node Classification\\u003cbr\\u003eDegree: 9\",\"Node Lesion Segmentation\\u003cbr\\u003eDegree: 7\",\"Node FCN\\u003cbr\\u003eDegree: 5\",\"Node Handwriting Recognition\\u003cbr\\u003eDegree: 12\",\"Node Camera Pose Estimation\\u003cbr\\u003eDegree: 2\",\"Node Breast Cancer\\u003cbr\\u003eDegree: 3\",\"Node Mobile Robotics\\u003cbr\\u003eDegree: 2\",\"Node Glyphoment invariants\\u003cbr\\u003eDegree: 1\",\"Node Fast FourierTransform\\u003cbr\\u003eDegree: 3\",\"Node Bayesian Methods\\u003cbr\\u003eDegree: 4\",\"Node Hand Tracking\\u003cbr\\u003eDegree: 5\",\"Node Hand Gestures\\u003cbr\\u003eDegree: 3\",\"Node U-net\\u003cbr\\u003eDegree: 5\",\"Node Sampling\\u003cbr\\u003eDegree: 8\",\"Node Geometrical Models\\u003cbr\\u003eDegree: 5\",\"Node ConvNets\\u003cbr\\u003eDegree: 3\",\"Node DFCNet\\u003cbr\\u003eDegree: 3\",\"Node SegNet\\u003cbr\\u003eDegree: 5\",\"Node Dense Fusion Classmate Network\\u003cbr\\u003eDegree: 3\",\"Node Glaucoma Detection\\u003cbr\\u003eDegree: 4\",\"Node Table Extraction\\u003cbr\\u003eDegree: 4\",\"Node Embedded Computers\\u003cbr\\u003eDegree: 2\",\"Node Video Analytics\\u003cbr\\u003eDegree: 4\",\"Node Pedestrian Detection\\u003cbr\\u003eDegree: 4\",\"Node Iterative Algorithms\\u003cbr\\u003eDegree: 3\",\"Node 2-D Symbol Recognition\\u003cbr\\u003eDegree: 4\",\"Node 4D Objects\\u003cbr\\u003eDegree: 5\",\"Node Analysis of Space-Time Objects\\u003cbr\\u003eDegree: 3\",\"Node Feature Maps\\u003cbr\\u003eDegree: 2\",\"Node WSSS\\u003cbr\\u003eDegree: 4\",\"Node Character Recognition\\u003cbr\\u003eDegree: 4\",\"Node Generative Adversarial Network\\u003cbr\\u003eDegree: 5\",\"Node Content-Based Image\\u003cbr\\u003eDegree: 2\",\"Node Hand-crafted Features\\u003cbr\\u003eDegree: 3\",\"Node ISISPA\\u003cbr\\u003eDegree: 3\",\"Node Regression\\u003cbr\\u003eDegree: 3\",\"Node Faster R-CNN\\u003cbr\\u003eDegree: 4\"],\"x\":[-0.059285993681578185,0.25530150722382017,-0.31437686637997736,0.15160906771204477,0.0006498684496106419,-0.4809074362975592,-0.21285602402302212,0.31026074032826373,0.36019625997031784,0.4875264321372589,0.3428104312489601,0.19256820534185443,0.9818269056970753,-0.42919930424013863,-0.46066058165426654,0.0561718695432072,0.32310651218220976,-0.6560391681481028,-0.4570408273991243,-0.3958896862185362,-0.08923244273171997,-0.2826575424186942,0.0778311214500394,-0.04635159899460189,0.4542103996319127,-0.012861829967222677,0.9955143433247566,-0.045982191407776,0.3288498264414838,-0.6609199553838955,0.0469594798971936,-0.027853414624651417,-0.15648725131882424,0.11427984805162399,0.3966096834223085,-0.02148645862856977,-0.45102239198689775,0.11912473211144807,-0.03893570476917425,0.13936712694079278,0.004279483924492915,0.5652636535269082,0.3089387603846261,0.1166547927409436,0.049052728396085335,-0.005284880320948689,-0.47927043764775096,0.4346756529672312,-0.2938298352089581,0.3453921879925257,-0.2403822139301277,-0.47460415035572234,0.2339353431743282,-0.42124408777297523,0.6338916097455147,0.14564082428403338,0.3773726171118301,-0.37149593956640153,0.47238472695352257,-0.5060079720855933,-0.1546553964660012,-0.4964893272821436,0.30290347581120586,-0.4230949239306514,0.14048028292531098,-0.4640097885033951,-0.016292176805238513,-0.3735122171313382,0.3264021749575983,-0.44950560663072026,-0.5969526826307123,0.22702291008801448,0.34939144368349706,0.5535439405315726,0.23851923458896065,0.6292207927139831,0.0587467879655703,0.06332286264834305,-0.017794420126836706,-0.4715555468128839,-0.6194192656877852,-0.6501095214398317,0.07938540783410898,-0.44021218721680017,-0.010083795165695719,0.5992593748571182,0.21289758198072678,-0.3014365112240544,-0.39691793998809116,-0.16964342570496654,-0.5714251798387358,0.0718701068061601,-0.5554995080755668,-0.17107714537736463,0.030696981974305128,0.2540531852676487,-0.33499591829826,0.5370137388136961,0.3269080765982416,0.5802467262261533,0.277594166695859,0.6530220951280931,0.6079930967292341,1.0,0.486963869543913,-0.4002443401071849,0.1998363743394671,0.04512551406988936,-0.448550287721623,0.13372190897771857,-0.14714110547938117,0.16315223429489636,-0.3121386607651001,0.09246088141992229,0.458895561799462,-0.3773640384495448,-0.3553519112066584,-0.08650445908325728,-0.6421146160806568,0.4570282873886123,0.1982792857651305,0.22088797981646807,-0.3394478256624994,-0.151822073102289,0.5059920711482435,0.04018895326203896,-0.4915074680421084,0.6216731991169193,-0.47381888762745045,0.07620904990709525,0.27273633777468964,0.48526477319195366,-0.17681602481473987,-0.45407860353818674,-0.3830759637374944,-0.4059724074813355,-0.028900204844833136,-0.40605974416809804,0.5055632938297895,0.3026670790226142,0.013423470871069012,-0.4966324866261999,0.03783794923627862,0.5867457861400039,0.5605767306644166,-0.41171447186352494,-0.2090678908752118,0.25972147478779695,0.23663756380550682,0.20654667970663415,-0.5439173527694454,-0.35357995846547274,-0.4310679397180599,0.1401685740067246,-0.43636655099250643,0.1231969937759269,0.29317442471933325,0.6168178391809179,-0.4301728293129212,0.13654070847916366,0.0448929334080501,0.6528840334761078,0.18060824987066992,0.13634453192860524,0.31407742200527355,0.4634210603816112,-0.414011715712754,0.02861751720288711,-0.33709889905006374,0.4677488900556446,-0.0001816053917977161,-0.5570415767027547,0.1027083360530624,-0.3746440713725381,0.31140847919034037,-0.34386793618941736,-0.6295325231980975,0.13359080024858752,0.46205573799674066,0.18457506810446628,0.021303528650741303,-0.4804700028299716,-0.3648939464198347,-0.3991372536892955,0.9637482324415548,-0.358722572333496,0.9950729293827221,0.15208765606104926,0.1613890242205152,-0.4413240760165562,0.21599179594707124,-0.3713679139666828,-0.4721539465039138,-0.6073808832119391,-0.43609475615980997,-0.387086469460287,0.20503119881445203,0.5744215629527019,0.01093957511180508,0.2558779409220579,-0.42072470684187124,0.9782713092334949,-0.39520129896276895,-0.40412417018890917,0.13219574301524142,0.14111852307635775,0.17959597070127892,0.8824216153977748,-0.4538231952471651,0.1971545982299811,-0.47334552020230125,0.09943641549603949,-0.05150569433029976,-0.003064642627481575,-0.167915484966163,0.11917830401758958,-0.36916634645092505,-0.36513312366975414,-0.48954517945940224,0.07425007382384027,0.124435985726018,-0.4115514915479605,-0.6781934405608715,-0.46380856112534075,-0.6737321124898505,0.4845452646999587,-0.028316962958408312,-0.38097106639582806,-0.1589227222712193,0.05168415276062511,0.3731985458668834,0.2770892614074666,0.2735940169323006,0.2827643624806449,0.6074372212355406,-0.671172454352229,0.15394252403128642,0.36733124780740023,-0.048648131647875195,0.035419996996833784,0.4377874718408758,0.011887095261928868,-0.4901690131007754],\"y\":[0.11649965661465234,0.03570850021549773,0.35030443333248634,0.15962294805135419,-0.3367997917746649,-0.27268934204854595,-0.2822529558178622,0.26023267026479846,-0.11598016487608546,-0.25797606253112604,0.25011058648039575,-0.17499888704487726,-0.018470032513432724,0.2660711178379747,-0.4007160411615402,-0.619227681020131,0.24369352310786294,0.4178540885529418,-0.3643226649730541,0.3884173234872046,-0.3338567823722778,0.345523913151438,-0.6143801096224186,0.18911249670967617,-0.16069686531255423,-0.07041799469584092,0.03865973831038148,0.0628806558128276,0.06791359069392154,0.4826287439979106,-0.4852238452570139,-0.3917498759166121,-0.24988462201503978,-0.3646527972727061,-0.15916589786938373,0.16777818942984823,0.21630514833409242,-0.0275321392501781,-0.22861744987078406,-0.11134605920497041,0.19339503620969947,-0.24871510011217862,-0.08671172277447489,0.30152519727039256,0.21507210853510683,-0.21750398418521474,-0.3415742560015482,0.054942829731166924,0.3654725841261129,-0.016174942528235696,-0.23391191878126583,0.23776152560991937,-0.24207638919967808,0.10869148919265731,0.18440334853110624,-0.43612106214475554,-0.07571684360736851,0.29885594862621667,0.06972220843083958,-0.27638987715438723,0.2084834256651096,-0.2560686189021928,-0.20653498978004683,-0.40368943613631797,-0.4150925396304882,0.5514922093260491,-0.3453702935699518,-0.31933777388003276,0.20536101782314023,0.279717432104078,0.5015443381112532,-0.17208141773745994,0.10030743778420384,-0.2358385436094524,-0.25974606276203993,-0.06304279450633707,-0.6579003662829986,-0.780683042405329,0.1942198636203749,0.33393932354052397,0.4919525728787619,0.4514617448624333,0.24948944888939367,-0.38052335508442875,-0.3878000514175271,-0.008750049607469395,-0.09153335414105289,0.32984066398966005,0.14191260025310806,-0.26666585389129116,-0.05521273068817138,0.21709021836828707,-0.07162971684860518,0.1711514922333469,0.1744978098041819,-0.16210730514485022,0.3783578052369583,0.10505714368390698,0.08599066339298718,-0.23655052844910845,0.12577663713286016,0.1752836128026285,-0.058578647034265505,-0.00939768261578156,-0.23598541133881426,0.2895349112064701,0.06874137378111005,0.1524075982766828,0.37680457825191604,-0.47408598671506363,-0.28082447742989514,0.4290988566602368,0.39053714703684966,0.17016888171579175,0.031240814978811277,0.1401080598553181,0.3482899814550976,-0.1970455122437319,0.47132138559796644,-0.027591825835842975,0.05224946925569809,0.0860864517928534,0.26076742382099005,0.19598029029284444,-0.007769756223030876,-0.25916125200701023,-0.36031218295170625,-0.037993350544401554,0.2606993940364203,0.18736573237299983,-0.16874196335776365,-0.05994780140120706,-0.21878127458134725,-0.18031278262653394,0.029936369567875133,-0.42577676592395924,0.21758405344882545,0.5954429907610062,-0.025381667851397442,-0.22716138640224862,0.2447696876434216,0.3176274454515524,-0.5954741529921709,-0.21822038142574993,-0.21739790476645934,-0.09277298274959321,-0.2998942714457143,-0.25871860888805215,0.11552958219357258,-0.18848121913466323,0.39793916643420585,-0.31179612732943734,0.20487732759551044,-0.014640170100033803,-0.1760663377706984,0.02046025781067703,-0.15263024401606515,-0.08995949762894676,-0.4222404020757114,-0.1507134802372798,-0.1601029315392917,0.15392232915302653,0.03383949410839906,0.03139634619706863,-0.11337467016928823,0.08410741782251735,0.22204223979862592,0.09948236090636726,-0.32705494661246737,-0.26411722939518323,-0.11466303641059751,-0.03921496563617404,0.1958884628007197,-0.18425589371292797,-0.03350062340147141,0.4125776239840935,0.5104300358090186,0.1162121039845653,-0.0029001716005161186,0.418586778141929,-0.6133035524744289,0.3176115336536533,-0.2945988967363953,-0.4073668243637883,0.014768884988252242,-0.2483829310772731,0.010527112908534033,-0.47805041709342877,-0.42473082818247043,-0.037615438447694854,-0.07486819495477083,0.36811830787229544,0.3571921992824322,0.5199825637792153,0.2342538853883128,0.3189620804606704,-0.15650038784091563,-0.20453121961242343,0.22478316559836578,-0.2337465808927593,0.3217263994461065,0.05296437314663861,-0.0863152603881126,0.3483042508195348,-0.02625370005182628,0.13440555500131457,-0.3387211069242755,0.008673383957650594,0.35452171327642806,-0.1277098472935026,-0.38281602156054795,0.2381570501171828,0.14049567120046985,-0.5985509042425224,0.1918465129949595,-0.12050323912553279,0.4701730654582074,0.4083881248018299,0.33804375359161704,-0.36834084850276105,-0.4283119936154009,0.43206651487103137,0.42659990409650844,0.3729550905067433,0.40137615883699956,0.05709987655720104,-0.06883329686824452,0.598522327381284,0.18127648088714307,-0.173356733873613,-0.05813128762533492,-0.13606155350598806,-0.24415914425124796,-0.053106144597217936,-0.10857714283051234,0.46117353300678765,-0.13810817456124902,-0.10286182028457586,0.08686567379788572,0.23801386292256674,0.028348997566992228,0.14768999522434487,-0.2925630382652267],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"showgrid\":false,\"zeroline\":false,\"showticklabels\":false},\"yaxis\":{\"showgrid\":false,\"zeroline\":false,\"showticklabels\":false},\"title\":{\"text\":\"Interactive Visualization of Top-3 Communities\"},\"showlegend\":false,\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e5352bb5-6677-4047-9bba-0d0ec62b5889');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка центральностей\n",
        "\n",
        "Вычисляем: degree, betweenness, closeness, eigenvector.\n",
        "Выводим топ-5 узлов по каждой метрике. Интерпретация:\n",
        "- degree → локальная важность,\n",
        "- betweenness → «мосты» между кластерами,\n",
        "- eigenvector → влияние через влиятельных соседей.\n"
      ],
      "metadata": {
        "id": "0epn3KEkKUNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top-10 nodes by degree centrality\n",
        "[(node[0], round(node[1],2))\n",
        "for node in sorted(nx.degree_centrality(S).items(), key=itemgetter(1), reverse=True)][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku5QCls_KM14",
        "outputId": "a6eecee8-2ab4-4445-db3e-587cd93249cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Deep Learning', 0.2),\n",
              " ('Computer Vision', 0.19),\n",
              " ('CNN', 0.14),\n",
              " ('Convolutional Neural Network', 0.12),\n",
              " ('Semantic Segmentation', 0.08),\n",
              " ('Image Segmentation', 0.07),\n",
              " ('Algorithm', 0.07),\n",
              " ('Pattern Recognition', 0.05),\n",
              " ('U-Net', 0.05),\n",
              " ('Handwriting Recognition', 0.05)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top nodes by degree centrality in top-3 communities\n",
        "\n",
        "for i, nodes in enumerate(top3_comm[\"nodes\"].tolist(), start=1):\n",
        "  s = G.subgraph(nodes)\n",
        "  top_node = max(nx.degree_centrality(s).items(), key=itemgetter(1))\n",
        "\n",
        "  top3_nodes = [(node[0], round(node[1],2))\n",
        "  for node in sorted(nx.degree_centrality(s).items(), key=itemgetter(1), reverse=True)][:3]\n",
        "\n",
        "  print(f\"# of cluster: {i}, Central node by degree: {(top_node[0], round(top_node[1], 2))}\")\n",
        "  print(f\"Top-3 nodes: {top3_nodes}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TrVgoLtKMzH",
        "outputId": "95200fc3-8c9f-4da2-8f11-4504354066c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of cluster: 1, Central node by degree: ('Deep Learning', 0.33)\n",
            "Top-3 nodes: [('Deep Learning', 0.33), ('CNN', 0.26), ('Convolutional Neural Network', 0.25)]\n",
            "\n",
            "# of cluster: 2, Central node by degree: ('Computer Vision', 0.68)\n",
            "Top-3 nodes: [('Computer Vision', 0.68), ('Semantic Segmentation', 0.32), ('CycleGAN', 0.1)]\n",
            "\n",
            "# of cluster: 3, Central node by degree: ('Image Segmentation', 0.27)\n",
            "Top-3 nodes: [('Image Segmentation', 0.27), ('Algorithm', 0.27), ('Pattern Recognition', 0.2)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\n",
        "    \"degree\": nx.degree_centrality(S),\n",
        "    \"betweenness\": nx.betweenness_centrality(S),\n",
        "    \"closeness\": nx.closeness_centrality(S),\n",
        "    \"eigenvector\": nx.eigenvector_centrality(S)\n",
        "}\n",
        "\n",
        "for name, values in metrics.items():\n",
        "    top5 = sorted(values.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"\\nTop-5 {name} centrality:\")\n",
        "    for node, val in top5:\n",
        "        print(f\"{node}: {val:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y7GscJMTend",
        "outputId": "72b4a9db-35cd-4ba9-cb51-8ad6a1ddf4a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top-5 degree centrality:\n",
            "Deep Learning: 0.202\n",
            "Computer Vision: 0.190\n",
            "CNN: 0.145\n",
            "Convolutional Neural Network: 0.124\n",
            "Semantic Segmentation: 0.083\n",
            "\n",
            "Top-5 betweenness centrality:\n",
            "Deep Learning: 0.566\n",
            "Computer Vision: 0.438\n",
            "CNN: 0.288\n",
            "Convolutional Neural Network: 0.261\n",
            "Image Segmentation: 0.220\n",
            "\n",
            "Top-5 closeness centrality:\n",
            "Deep Learning: 0.449\n",
            "CNN: 0.409\n",
            "Convolutional Neural Network: 0.391\n",
            "Image Segmentation: 0.385\n",
            "Computer Vision: 0.382\n",
            "\n",
            "Top-5 eigenvector centrality:\n",
            "Deep Learning: 0.464\n",
            "CNN: 0.350\n",
            "Convolutional Neural Network: 0.259\n",
            "Computer Vision: 0.253\n",
            "Image Segmentation: 0.156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Граф публикаций и поиск похожих статей\n",
        "\n",
        "Узлы = статьи. Ребро между статьями если у них есть общие ключевые слова.\n",
        "Вес = число общих ключевых слов.\n",
        "\n",
        "Реализована функция `find_similar_papers(paper_title, graph, top_n=5)` для поиска похожих работ.\n"
      ],
      "metadata": {
        "id": "1waeqb7IMTPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Предполагаем, что у нас есть df с колонками 'title' и 'keywords'\n",
        "# keywords - это строка с ключевыми словами, разделенными запятыми\n",
        "\n",
        "G_papers = nx.Graph()\n",
        "\n",
        "# Добавляем узлы (статьи)\n",
        "for i, row in df.iterrows():\n",
        "    G_papers.add_node(row['title'], abstract=row['abstract'], authors=row['authors'])\n",
        "\n",
        "# Добавляем взвешенные ребра\n",
        "for i, row1 in df.iterrows():\n",
        "    # Извлекаем ключевые слова для первой статьи и приводим к множеству\n",
        "    keywords1 = set(kw.strip() for kw in row1['keywords'].split(','))\n",
        "    for j, row2 in df.iterrows():\n",
        "        if i < j: # Чтобы не проверять пары дважды (A-B и B-A)\n",
        "            keywords2 = set(kw.strip() for kw in row2['keywords'].split(','))\n",
        "            # Находим пересечение ключевых слов\n",
        "            common_keywords = keywords1.intersection(keywords2)\n",
        "            weight = len(common_keywords)\n",
        "            # Если есть общие ключевые слова, добавляем ребро\n",
        "            if weight > 0:\n",
        "                G_papers.add_edge(row1['title'], row2['title'], weight=weight)\n",
        "\n",
        "# Дополнительная визуализация\n",
        "plt.figure(figsize=(12, 8))\n",
        "pos = nx.spring_layout(G_papers, k=0.5, iterations=50)\n",
        "nx.draw(G_papers, pos, node_size=20, alpha=0.6, edge_color='gray', width=0.5)\n",
        "plt.title(\"Граф публикаций по компьютерному зрению\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "k_fxnBw2MV8l",
        "outputId": "86128633-68d7-488d-a1ed-a2abfb1ba143"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_papers(paper_title, graph, top_n=5):\n",
        "    if paper_title not in graph:\n",
        "        return \"Статья не найдена в графе.\"\n",
        "\n",
        "    # Собираем всех соседей и вес связи с ними\n",
        "    neighbors = []\n",
        "    for neighbor in graph.neighbors(paper_title):\n",
        "        weight = graph[paper_title][neighbor]['weight']\n",
        "        neighbors.append((neighbor, weight))\n",
        "\n",
        "    # Сортируем по убыванию веса связи\n",
        "    neighbors_sorted = sorted(neighbors, key=lambda x: x[1], reverse=True)\n",
        "    return neighbors_sorted[:top_n]\n",
        "\n",
        "# Пример использования\n",
        "input_paper = df.iloc[3]['title'] # Берем первую статью для примера\n",
        "similar = find_similar_papers(input_paper, G_papers)\n",
        "for paper, weight in similar:\n",
        "    print(f\"Статья: {paper} | Общих ключевых слов: {weight}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00npDEwcMXMI",
        "outputId": "2e9bdceb-f382-4177-8c05-5f2d5f0c2c07"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Статья: Logical methods of object recognition on satellite images using spatial\n",
            "  constraints | Общих ключевых слов: 1\n",
            "Статья: Visual Vocabulary Learning and Its Application to 3D and Mobile Visual\n",
            "  Search | Общих ключевых слов: 1\n",
            "Статья: Synthesising Dynamic Textures using Convolutional Neural Networks | Общих ключевых слов: 1\n",
            "Статья: The Effect of Top-Down Attention in Occluded Object Recognition | Общих ключевых слов: 1\n",
            "Статья: The use of Octree in point cloud analysis with application to cultural\n",
            "  heritage | Общих ключевых слов: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Количество статей (узлов): {G_papers.number_of_nodes()}\")\n",
        "print(f\"Количество связей (ребер): {G_papers.number_of_edges()}\")\n",
        "print(f\"Плотность графа: {nx.density(G_papers):.3f}\")\n",
        "print(f\"Средняя степень связности: {sum(dict(G_papers.degree()).values()) / G_papers.number_of_nodes():.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpX8VBxvMXGu",
        "outputId": "7de0ea09-5079-4065-c182-e0a848ab037d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество статей (узлов): 500\n",
            "Количество связей (ребер): 1149\n",
            "Плотность графа: 0.009\n",
            "Средняя степень связности: 4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метрики графа и качества кластеризации\n",
        "\n",
        "Реализованы:\n",
        "- Coverage разбиения,\n",
        "- Conductance для сообщества,\n",
        "- Средняя conductance,\n",
        "- Silhouette на спектральных эмбеддингах.\n",
        "\n",
        "Эти метрики помогут оценить качество найденных сообществ.\n"
      ],
      "metadata": {
        "id": "eHnzcQuxrEs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import SpectralEmbedding\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Метрики графа и кластеризации ---\n",
        "def coverage_of_partition(G, communities):\n",
        "    m = G.number_of_edges()\n",
        "    if m == 0:\n",
        "        return 0.0\n",
        "    intra = 0\n",
        "    for comm in communities:\n",
        "        intra += G.subgraph(comm).number_of_edges()\n",
        "    return intra / m\n",
        "\n",
        "def conductance_of_community(G, community):\n",
        "    comm = set(community)\n",
        "    cut_edges = sum(\n",
        "        G[u][v].get(\"weight\", 1.0)\n",
        "        for u in comm for v in G.neighbors(u)\n",
        "        if v not in comm\n",
        "    )\n",
        "    vol_comm = sum(G.degree(u, weight=\"weight\") for u in comm)\n",
        "    vol_rest = sum(G.degree(u, weight=\"weight\") for u in G if u not in comm)\n",
        "    denom = min(vol_comm, vol_rest)\n",
        "    return cut_edges / denom if denom > 0 else 0.0\n",
        "\n",
        "def average_conductance(G, communities):\n",
        "    return np.mean([conductance_of_community(G, c) for c in communities])\n",
        "\n",
        "def silhouette_on_embeddings(G, communities, n_components=16):\n",
        "    nodes = list(G.nodes())\n",
        "    # матрица смежности в формате csr, затем приведение индексов к int32\n",
        "    A = nx.to_scipy_sparse_array(G, nodelist=nodes, weight=\"weight\", format='csr')\n",
        "    A.indices = A.indices.astype(np.int32)\n",
        "    A.indptr = A.indptr.astype(np.int32)\n",
        "    embed = SpectralEmbedding(n_components=n_components, affinity='precomputed').fit_transform(A)\n",
        "    label_map = {}\n",
        "    for cid, comm in enumerate(communities):\n",
        "        for n in comm:\n",
        "            label_map[n] = cid\n",
        "    labels = np.array([label_map.get(n, -1) for n in nodes])\n",
        "    mask = labels >= 0\n",
        "    if len(set(labels[mask])) < 2:\n",
        "        return float(\"nan\")\n",
        "    return silhouette_score(embed[mask], labels[mask])\n",
        "\n",
        "\n",
        "# communities_all = полный список сообществ по всему графу ключевых слов\n",
        "communities_all = nx.community.louvain_communities(G, resolution=0.9)\n",
        "\n",
        "print(\"=== Метрики для графа ключевых слов ===\")\n",
        "print(\"Модульность:\", nx.community.modularity(G, communities_all))\n",
        "print(\"Coverage:\", coverage_of_partition(G, communities_all))\n",
        "print(\"Средняя conductance:\", average_conductance(G, communities_all))\n",
        "print(\"Silhouette (по спектральным эмбеддингам):\", silhouette_on_embeddings(G, communities_all))\n",
        "print()\n",
        "print(\"=== Общие метрики графа ===\")\n",
        "print(\"Число узлов:\", G.number_of_nodes())\n",
        "print(\"Число рёбер:\", G.number_of_edges())\n",
        "print(\"Плотность графа:\", nx.density(G))\n",
        "print(\"Средний clustering coefficient:\", nx.average_clustering(G))\n",
        "if nx.is_connected(G):\n",
        "    print(\"Средняя длина пути:\", nx.average_shortest_path_length(G))\n",
        "else:\n",
        "    print(\"Средняя длина пути: граф несвязный\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xALVN6prlaGC",
        "outputId": "2e0b3a18-1d21-4edf-fd42-34e8b3fc0163"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Метрики для графа ключевых слов ===\n",
            "Модульность: 0.9278269117118848\n",
            "Coverage: 0.9563318777292577\n",
            "Средняя conductance: 0.00407611341902984\n",
            "Silhouette (по спектральным эмбеддингам): 0.6999433577599133\n",
            "\n",
            "=== Общие метрики графа ===\n",
            "Число узлов: 1531\n",
            "Число рёбер: 2748\n",
            "Плотность графа: 0.0023462814256989535\n",
            "Средний clustering coefficient: 0.8925876055260235\n",
            "Средняя длина пути: граф несвязный\n"
          ]
        }
      ]
    }
  ]
}