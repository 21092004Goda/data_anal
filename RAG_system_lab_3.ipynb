{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMbD2pJfGN3i7AURWtWgtfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21092004Goda/data_anal/blob/main/RAG_system_lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --quiet langchain_huggingface\n",
        "!pip install --quiet sentence-transformers\n",
        "!pip install --quiet faiss-gpu\n",
        "!pip install --quiet rapidfuzz\n",
        "!pip install --quiet arxiv"
      ],
      "metadata": {
        "id": "1aaJge2dPQmA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "class ArxivTopicFetcher:\n",
        "\n",
        "    def __init__(self, max_results_per_request: int = 100, delay_seconds: float = 3.0):\n",
        "        self.client = arxiv.Client(\n",
        "            page_size=max_results_per_request,\n",
        "            delay_seconds=delay_seconds,\n",
        "            num_retries=3\n",
        "        )\n",
        "        self.common_categories = {\n",
        "            'machine_learning': 'cs.LG',\n",
        "            'artificial_intelligence': 'cs.AI',\n",
        "            'computer_vision': 'cs.CV',\n",
        "            'nlp': 'cs.CL',\n",
        "            'robotics': 'cs.RO',\n",
        "            'databases': 'cs.DB',\n",
        "            'security': 'cs.CR',\n",
        "            'networks': 'cs.NI',\n",
        "            'algorithms': 'cs.DS',\n",
        "            'hci': 'cs.HC'\n",
        "        }\n",
        "\n",
        "    def build_query(self, category: str) -> str:\n",
        "        if category in self.common_categories:\n",
        "            category = self.common_categories[category]\n",
        "        return f\"cat:{category}\"\n",
        "\n",
        "    def fetch_articles(self, query: str, max_results: int = 50,\n",
        "                       sort_by: str = 'submittedDate',\n",
        "                       sort_order: str = 'descending') -> List[Dict[str, Any]]:\n",
        "\n",
        "        sort_criterion = {\n",
        "            'relevance': arxiv.SortCriterion.Relevance,\n",
        "            'lastUpdatedDate': arxiv.SortCriterion.LastUpdatedDate,\n",
        "            'submittedDate': arxiv.SortCriterion.SubmittedDate\n",
        "        }.get(sort_by, arxiv.SortCriterion.SubmittedDate)\n",
        "\n",
        "        search = arxiv.Search(\n",
        "            query=query,\n",
        "            max_results=min(max_results, 2000),\n",
        "            sort_by=sort_criterion,\n",
        "            sort_order=arxiv.SortOrder.Descending if sort_order == 'descending'\n",
        "                     else arxiv.SortOrder.Ascending\n",
        "        )\n",
        "\n",
        "        print(f\"Запрос: {query}\")\n",
        "        articles = []\n",
        "\n",
        "        try:\n",
        "            for result in self.client.results(search):\n",
        "                articles.append({\n",
        "                    'arxiv_id': result.entry_id.split('/')[-1],\n",
        "                    'title': result.title,\n",
        "                    'authors': [a.name for a in result.authors],\n",
        "                    'abstract': result.summary.replace('\\n', ' '),\n",
        "                    'published': result.published.date() if result.published else None,\n",
        "                    'categories': result.categories,\n",
        "                    'pdf_url': result.pdf_url\n",
        "                })\n",
        "\n",
        "            print(f\"Получено статей: {len(articles)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Ошибка:\", e)\n",
        "\n",
        "        return articles\n",
        "\n",
        "    def fetch_by_category(self, category: str, max_results: int = 50, **kwargs):\n",
        "        query = self.build_query(category)\n",
        "        return self.fetch_articles(query, max_results, **kwargs)\n",
        "\n",
        "    def print_summary(self, articles: List[Dict[str, Any]], n: int = 5):\n",
        "        if not articles:\n",
        "            print(\"Пусто.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n=== Короткий обзор ===\")\n",
        "        for idx, a in enumerate(articles[:n]):\n",
        "            print(f\"\\n{idx+1}. {a['title']}\")\n",
        "            print(\"   Авторы:\", \", \".join(a['authors'][:3]) + (\" и др.\" if len(a['authors']) > 3 else \"\"))\n",
        "            print(\"   Дата:\", a['published'])\n",
        "            print(\"   ID:\", a['arxiv_id'])\n",
        "            print(\"   Категории:\", \", \".join(a['categories']))\n",
        "            print(\"   Абстракт:\", a['abstract'][:200], \"...\")\n"
      ],
      "metadata": {
        "id": "0dWifRB5PQqU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class TextChunker:\n",
        "\n",
        "    def __init__(self, chunk_size: int = 500, overlap: int = 50):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def chunk_text(self, text: str):\n",
        "        if not text or not isinstance(text, str):\n",
        "            return []\n",
        "\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        while start < len(words):\n",
        "            end = start + self.chunk_size\n",
        "            chunk_words = words[start:end]\n",
        "            if not chunk_words:\n",
        "                break\n",
        "            chunks.append(\" \".join(chunk_words))\n",
        "            start = end - self.overlap\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def chunk_many(self, texts):\n",
        "        return [self.chunk_text(t) for t in texts]\n",
        "\n",
        "    def to_dataframe(self, articles):\n",
        "        rows = []\n",
        "        for a in articles:\n",
        "            chunks = self.chunk_text(a[\"abstract\"])\n",
        "            rows.append({\n",
        "                \"id\": a[\"arxiv_id\"],\n",
        "                \"title\": a[\"title\"],\n",
        "                \"authors\": \", \".join(a[\"authors\"]),\n",
        "                \"published\": a[\"published\"],\n",
        "                \"categories\": \", \".join(a[\"categories\"]),\n",
        "                \"pdf_url\": a[\"pdf_url\"],\n",
        "                \"abstract\": a[\"abstract\"],\n",
        "                \"chunks\": chunks\n",
        "            })\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    def chunk_statistics(self, df: pd.DataFrame, plot: bool = False):\n",
        "        chunk_counts = df[\"chunks\"].apply(len)\n",
        "        stats = {\n",
        "            \"Total articles\": len(df),\n",
        "            \"Total chunks\": int(chunk_counts.sum()),\n",
        "            \"Min chunks per article\": int(chunk_counts.min()),\n",
        "            \"Max chunks per article\": int(chunk_counts.max()),\n",
        "            \"Mean chunks per article\": float(chunk_counts.mean()),\n",
        "            \"Median chunks per article\": float(chunk_counts.median())\n",
        "        }\n",
        "\n",
        "        print(\"\\n=== Chunking Statistics ===\")\n",
        "        for k, v in stats.items():\n",
        "            print(f\"{k}: {v}\")\n",
        "\n",
        "        if plot:\n",
        "            plt.figure(figsize=(8,4))\n",
        "            plt.hist(chunk_counts, bins=range(1, chunk_counts.max()+2), alpha=0.7, color='skyblue', edgecolor='black')\n",
        "            plt.title(\"Distribution of Chunks per Article\")\n",
        "            plt.xlabel(\"Number of Chunks\")\n",
        "            plt.ylabel(\"Number of Articles\")\n",
        "            plt.xticks(range(1, chunk_counts.max()+2))\n",
        "            plt.show()\n",
        "\n",
        "        return stats\n"
      ],
      "metadata": {
        "id": "VT4P807BPQwE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "class ArxivVectorPipeline:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        device=\"cpu\",\n",
        "        normalize=False\n",
        "    ):\n",
        "        self.embeddings_model = HuggingFaceEmbeddings(\n",
        "            model_name=model_name,\n",
        "            model_kwargs={\"device\": device},\n",
        "            encode_kwargs={\"normalize_embeddings\": normalize}\n",
        "        )\n",
        "\n",
        "        self.index = None\n",
        "        self.embedding_dim = None\n",
        "        self.chunks_df = None\n",
        "        self.embeddings = None\n",
        "\n",
        "    def _flatten_chunks(self, df: pd.DataFrame):\n",
        "        rows = []\n",
        "        for _, row in df.iterrows():\n",
        "            base = {\n",
        "                \"id\": row[\"id\"],\n",
        "                \"title\": row[\"title\"],\n",
        "                \"authors\": row[\"authors\"],\n",
        "                \"published\": row[\"published\"],\n",
        "                \"categories\": row[\"categories\"],\n",
        "                \"pdf_url\": row[\"pdf_url\"],\n",
        "                \"abstract\": row[\"abstract\"]\n",
        "            }\n",
        "\n",
        "            for idx, ch in enumerate(row[\"chunks\"]):\n",
        "                rows.append({\n",
        "                    **base,\n",
        "                    \"chunk_id\": idx,\n",
        "                    \"text_chunk\": ch\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    def _embed(self, texts):\n",
        "        if not texts:\n",
        "            return np.array([])\n",
        "\n",
        "        emb = self.embeddings_model.embed_documents(texts)\n",
        "        return np.array(emb, dtype=np.float32)\n",
        "\n",
        "    def build(self, df: pd.DataFrame):\n",
        "        self.chunks_df = self._flatten_chunks(df)\n",
        "        texts = self.chunks_df[\"text_chunk\"].tolist()\n",
        "        self.embeddings = self._embed(texts)\n",
        "        self.embedding_dim = self.embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(self.embedding_dim)\n",
        "        self.index.add(self.embeddings)\n",
        "        return self\n",
        "\n",
        "    def search(self, query: str, top_k: int = 5):\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"Индекс пуст. Сначала вызови build().\")\n",
        "\n",
        "        q_emb = self._embed([query])\n",
        "        distances, indices = self.index.search(q_emb, top_k)\n",
        "\n",
        "        results = []\n",
        "        for dist, idx in zip(distances[0], indices[0]):\n",
        "            row = self.chunks_df.iloc[int(idx)]\n",
        "            results.append({\n",
        "                \"distance\": float(dist),\n",
        "                \"chunk_id\": int(row[\"chunk_id\"]),\n",
        "                \"text_chunk\": row[\"text_chunk\"],\n",
        "                \"article\": {\n",
        "                    \"id\": row[\"id\"],\n",
        "                    \"title\": row[\"title\"],\n",
        "                    \"authors\": row[\"authors\"],\n",
        "                    \"categories\": row[\"categories\"],\n",
        "                    \"published\": row[\"published\"],\n",
        "                    \"abstract\": row[\"abstract\"],\n",
        "                    \"pdf_url\": row[\"pdf_url\"]\n",
        "                }\n",
        "            })\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "bsaQNGRtPQyr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "\n",
        "class LLMClient:\n",
        "\n",
        "    def __init__(self, api_key: str, model: str = \"gemini-2.5-flash\"):\n",
        "        self.client = genai.Client(api_key=api_key)\n",
        "        self.model = model\n",
        "\n",
        "    def ask(self, prompt: str) -> str:\n",
        "\n",
        "        response = self.client.models.generate_content(\n",
        "            model=self.model,\n",
        "            contents=f'\"role\": \"user\", \"content\": \"{prompt}\"'\n",
        "        )\n",
        "        return response.text\n"
      ],
      "metadata": {
        "id": "obZ9tsKwR_Gj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArxivQA:\n",
        "\n",
        "    def __init__(self, vector_pipeline, llm_client, top_k=5):\n",
        "        self.vec = vector_pipeline\n",
        "        self.llm = llm_client\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def answer(self, query: str) -> str:\n",
        "        hits = self.vec.search(query, top_k=self.top_k)\n",
        "        context = \"\\n\\n\".join(chunk[\"text_chunk\"] for chunk in hits)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a smart assistant. Here is the context from scientific articles:\n",
        "\n",
        "{context}\n",
        "\n",
        "Now answer the user's question:\n",
        "{query}\n",
        "\n",
        "Answer clearly and concisely.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.llm.ask(prompt)\n"
      ],
      "metadata": {
        "id": "DG_1vx-RR_DZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import process, fuzz\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SearchEngine:\n",
        "\n",
        "    def __init__(self, vector_pipeline, llm_client):\n",
        "        self.vec = vector_pipeline          # ArxivVectorPipeline\n",
        "        self.llm = llm_client               # LLMClient\n",
        "        self._build_spell_corpus()\n",
        "\n",
        "    def _build_spell_corpus(self):\n",
        "        words = set()\n",
        "        for txt in self.vec.chunks_df[\"text_chunk\"]:\n",
        "            for w in txt.lower().split():\n",
        "                if w.isalpha():\n",
        "                    words.add(w)\n",
        "        self.corpus_words = list(words)\n",
        "\n",
        "    def correct_query(self, query: str) -> str:\n",
        "        corrected = []\n",
        "        for w in query.split():\n",
        "            best = process.extractOne(w, self.corpus_words, scorer=fuzz.ratio)\n",
        "            if best and best[1] > 70:\n",
        "                corrected.append(best[0])\n",
        "            else:\n",
        "                corrected.append(w)\n",
        "        return \" \".join(corrected)\n",
        "\n",
        "    def vector_search(self, query: str, top_k: int = 5):\n",
        "        return self.vec.search(query, top_k)\n",
        "\n",
        "    def build_prompt(self, query: str, context: str, template=None):\n",
        "        if template is None:\n",
        "            template = \"\"\"\n",
        "User query: \"{query}\"\n",
        "\n",
        "Use ONLY this context:\n",
        "-----------------\n",
        "{context}\n",
        "-----------------\n",
        "\n",
        "Answer clearly and factually.\n",
        "\"\"\"\n",
        "        return template.format(query=query, context=context)\n",
        "\n",
        "    def ask_rag(self, query: str, template=None, top_k=5):\n",
        "        corrected = self.correct_query(query)\n",
        "        hits = self.vector_search(corrected, top_k)\n",
        "        context = \"\\n\\n\".join(h[\"text_chunk\"] for h in hits)\n",
        "        prompt = self.build_prompt(corrected, context, template)\n",
        "        return self.llm.ask(prompt)\n",
        "\n",
        "    def ask_vanilla(self, query: str):\n",
        "        return self.llm.ask(query)\n"
      ],
      "metadata": {
        "id": "nMrzMo14R-_D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlNj4NSGPQ2D"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetcher = ArxivTopicFetcher()\n",
        "articles = fetcher.fetch_by_category(\"machine_learning\", max_results=2000)\n",
        "fetcher.print_summary(articles, n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvTz9eRAPQ4q",
        "outputId": "0d4beee6-cd08-499b-adf9-1b0a6f4a7605"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запрос: cat:cs.LG\n",
            "Получено статей: 2000\n",
            "\n",
            "=== Короткий обзор ===\n",
            "\n",
            "1. ThetaEvolve: Test-time Learning on Open Problems\n",
            "   Авторы: Yiping Wang, Shao-Rong Su, Zhiyuan Zeng и др.\n",
            "   Дата: 2025-11-28\n",
            "   ID: 2511.23473v1\n",
            "   Категории: cs.LG, cs.CL\n",
            "   Абстракт: Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open ...\n",
            "\n",
            "2. SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments\n",
            "   Авторы: Xinyi Li, Zaishuo Xia, Weyl Lu и др.\n",
            "   Дата: 2025-11-28\n",
            "   ID: 2511.23465v1\n",
            "   Категории: cs.LG\n",
            "   Абстракт: Current world models lack a unified and controlled setting for systematic evaluation, making it difficult to assess whether they truly capture the underlying rules that govern environment dynamics. In ...\n",
            "\n",
            "3. The Price of Progress: Algorithmic Efficiency and the Falling Cost of AI Inference\n",
            "   Авторы: Hans Gundlach, Jayson Lynch, Matthias Mertens и др.\n",
            "   Дата: 2025-11-28\n",
            "   ID: 2511.23455v1\n",
            "   Категории: cs.LG, cs.AI, cs.CY\n",
            "   Абстракт: Language models have seen enormous progress on advanced benchmarks in recent years, but much of this progress has only been possible by using more costly models. Benchmarks may therefore present a war ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunker = TextChunker(chunk_size=150, overlap=15)\n",
        "\n",
        "df = chunker.to_dataframe(articles)\n",
        "\n",
        "print(df.head())\n",
        "print(df[\"chunks\"].iloc[0][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U19D0qcYQo5O",
        "outputId": "1558bd42-11d6-4e65-ef91-87b45e4bbcf8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             id                                              title  \\\n",
            "0  2511.23473v1   ThetaEvolve: Test-time Learning on Open Problems   \n",
            "1  2511.23465v1  SmallWorlds: Assessing Dynamics Understanding ...   \n",
            "2  2511.23455v1  The Price of Progress: Algorithmic Efficiency ...   \n",
            "3  2511.23449v1  Physics-Informed Neural Networks for Thermophy...   \n",
            "4  2511.23443v1  Provable Benefits of Sinusoidal Activation for...   \n",
            "\n",
            "                                             authors   published  \\\n",
            "0  Yiping Wang, Shao-Rong Su, Zhiyuan Zeng, Eva X...  2025-11-28   \n",
            "1  Xinyi Li, Zaishuo Xia, Weyl Lu, Chenjie Hao, Y...  2025-11-28   \n",
            "2  Hans Gundlach, Jayson Lynch, Matthias Mertens,...  2025-11-28   \n",
            "3                         Ali Waseem, Malcolm Mielle  2025-11-28   \n",
            "4                         Tianlong Huang, Zhiyuan Li  2025-11-28   \n",
            "\n",
            "                   categories                             pdf_url  \\\n",
            "0                cs.LG, cs.CL  https://arxiv.org/pdf/2511.23473v1   \n",
            "1                       cs.LG  https://arxiv.org/pdf/2511.23465v1   \n",
            "2         cs.LG, cs.AI, cs.CY  https://arxiv.org/pdf/2511.23455v1   \n",
            "3  cs.LG, cs.AI, cs.CE, cs.CV  https://arxiv.org/pdf/2511.23449v1   \n",
            "4              cs.LG, stat.ML  https://arxiv.org/pdf/2511.23443v1   \n",
            "\n",
            "                                            abstract  \\\n",
            "0  Recent advances in large language models (LLMs...   \n",
            "1  Current world models lack a unified and contro...   \n",
            "2  Language models have seen enormous progress on...   \n",
            "3  Inverse heat problems refer to the estimation ...   \n",
            "4  This paper studies the role of activation func...   \n",
            "\n",
            "                                              chunks  \n",
            "0  [Recent advances in large language models (LLM...  \n",
            "1  [Current world models lack a unified and contr...  \n",
            "2  [Language models have seen enormous progress o...  \n",
            "3  [Inverse heat problems refer to the estimation...  \n",
            "4  [This paper studies the role of activation fun...  \n",
            "['Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open problems. However, it relies on ensembles of frontier LLMs to achieve new bounds and is a pure inference system that models cannot internalize the evolving strategies. We introduce ThetaEvolve, an open-source framework that simplifies and extends AlphaEvolve to efficiently scale both in-context learning and Reinforcement Learning (RL) at test time, allowing models to continually learn from their experiences in improving open optimization problems. ThetaEvolve features a single LLM, a large program database for enhanced exploration, batch sampling for higher throughput, lazy penalties to discourage stagnant outputs, and optional reward shaping for stable training signals, etc. ThetaEvolve is the first evolving framework that enable a small open-source model, like DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality)', 'DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality) mentioned in AlphaEvolve. Besides, across two models and four open tasks, we find that ThetaEvolve with RL at test-time consistently outperforms inference-only baselines, and the model indeed learns evolving capabilities, as the RL-trained checkpoints demonstrate faster progress and better final performance on both trained target task and other unseen tasks. We release our code publicly: https://github.com/ypwang61/ThetaEvolve']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = chunker.chunk_statistics(df)\n",
        "print(stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7z2WBZLc6bP",
        "outputId": "cea4f8ca-a254-4a07-e1b1-ad910ea77caf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Chunking Statistics ===\n",
            "Total articles: 2000\n",
            "Total chunks: 3688\n",
            "Min chunks per article: 1\n",
            "Max chunks per article: 3\n",
            "Mean chunks per article: 1.844\n",
            "Median chunks per article: 2.0\n",
            "{'Total articles': 2000, 'Total chunks': 3688, 'Min chunks per article': 1, 'Max chunks per article': 3, 'Mean chunks per article': 1.844, 'Median chunks per article': 2.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full pipeline\n",
        "pipeline = ArxivVectorPipeline(device=\"cpu\")\n",
        "pipeline.build(df)\n",
        "\n",
        "results = pipeline.search(\"reinforcement learning for robots\", top_k=5)\n",
        "\n",
        "for r in results:\n",
        "    print(\"\\n---\")\n",
        "    print(\"Distance:\", r[\"distance\"])\n",
        "    print(\"Chunk:\", r[\"text_chunk\"][:200], \"…\")\n",
        "    print(\"Article title:\", r[\"article\"][\"title\"])\n",
        "    print(\"ID:\", r[\"article\"][\"id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-7zLkBLQo1i",
        "outputId": "3ed17cb2-a558-41c9-a0a2-516ec2d46c69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Distance: 0.8626267910003662\n",
            "Chunk: approaches may hold promise in solving offline reinforcement learning using continuous-time optimal control. …\n",
            "Article title: Operator Models for Continuous-Time Offline Reinforcement Learning\n",
            "ID: 2511.10383v1\n",
            "\n",
            "---\n",
            "Distance: 0.8880864381790161\n",
            "Chunk: We study how vision-language-action (VLA) models can improve through real-world deployments via reinforcement learning (RL). We present a general-purpose method, RL with Experience and Corrections via …\n",
            "Article title: $π^{*}_{0.6}$: a VLA That Learns From Experience\n",
            "ID: 2511.14759v2\n",
            "\n",
            "---\n",
            "Distance: 0.9049038290977478\n",
            "Chunk: We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also the …\n",
            "Article title: First-order Sobolev Reinforcement Learning\n",
            "ID: 2511.19165v1\n",
            "\n",
            "---\n",
            "Distance: 0.9419611096382141\n",
            "Chunk: The field of Offline Reinforcement Learning (RL) aims to derive effective policies from pre-collected datasets without active environment interaction. While traditional offline RL algorithms like Cons …\n",
            "Article title: A Comparison Between Decision Transformers and Traditional Offline Reinforcement Learning Algorithms\n",
            "ID: 2511.16475v1\n",
            "\n",
            "---\n",
            "Distance: 0.9459956884384155\n",
            "Chunk: Reinforcement Learning (RL) traditionally relies on scalar reward signals, limiting its ability to leverage the rich semantic knowledge often available in real-world tasks. In contrast, humans learn e …\n",
            "Article title: Prompted Policy Search: Reinforcement Learning through Linguistic and Numerical Reasoning in LLMs\n",
            "ID: 2511.21928v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLMClient(api_key=\"AIzaSyAQDkTa1BshAi4NMnDTasTZgbmijWdBA8w\")\n",
        "\n",
        "summary = llm.ask(\n",
        "    f\"Сделай короткий хардкорный конспект статьи: {articles[0]['abstract']}\"\n",
        ")\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFCKtkQSQouD",
        "outputId": "d90cc3ef-90ad-4d76-f214-fe7d096a4b78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**ThetaEvolve: Хардкорный конспект**\n",
            "\n",
            "ThetaEvolve — открытый фреймворк для математических открытий, расширяющий и упрощающий закрытую систему AlphaEvolve.\n",
            "\n",
            "**Ключевые инновации и отличия:**\n",
            "*   **RL во время инференса (RL at test-time):** Позволяет одной LLM непрерывно обучаться и интернализировать стратегии улучшения открытых оптимизационных задач, в отличие от чисто инференсного AlphaEvolve.\n",
            "*   **Архитектура:** Использует **одну LLM** (вместо ансамблей), что значительно упрощает систему.\n",
            "*   **Масштабирование и эффективность:**\n",
            "    *   Большая база программ для расширенной эксплорации.\n",
            "    *   Пакетная выборка для высокой пропускной способности.\n",
            "    *   \"Ленивые\" штрафы для предотвращения стагнации.\n",
            "    *   Формирование вознаграждения для стабильного обучения RL.\n",
            "\n",
            "**Результаты:**\n",
            "*   **Прорыв:** Первая открытая система, позволившая **небольшой открытой LLM** (DeepSeek-R1-0528-Qwen3-8B) установить **новые, лучшие известные границы** для открытых математических проблем (упаковка кругов, неравенство первой автокорреляции), упомянутых в AlphaEvolve.\n",
            "*   **Преимущество RL:** Обучение с подкреплением во время инференса стабильно превосходит чисто инференсные подходы.\n",
            "*   **Обучаемость:** Модель действительно осваивает эволюционные способности, демонстрируя более быстрый прогресс и лучшую конечную производительность как на целевых, так и на ранее невиданных задачах.\n",
            "\n",
            "**Доступность:** Код открыт: [https://github.com/ypwang61/ThetaEvolve](https://github.com/ypwang61/ThetaEvolve)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. LLM\n",
        "llm_model = LLMClient(api_key=\"AIzaSyAQDkTa1BshAi4NMnDTasTZgbmijWdBA8w\")\n",
        "\n",
        "# 5. QA система\n",
        "qa = ArxivQA(pipeline, llm_model)\n",
        "\n",
        "# 6. Вопрос\n",
        "ans = qa.answer(\"How do data augmentation techniques improve the generalization of machine learning models?\")\n",
        "print(ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VME_WNhlUIX6",
        "outputId": "2f2654df-8ed3-443d-8728-8a8da2cf49ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation techniques improve the generalization of machine learning models by:\n",
            "\n",
            "1.  **Increasing the effective size and diversity of the training data:** This exposes the model to a wider range of variations (e.g., jittering, scaling, warping), helping it learn more robust features.\n",
            "2.  **Fostering noise invariance:** By exposing the model to perturbed data, it learns to be less sensitive to minor variations and noise, making it more robust.\n",
            "3.  **Preserving invariant relationships and governing processes:** Guided augmentation ensures that the model learns fundamental patterns rather than spurious local ones, allowing it to recover original processes from augmented data.\n",
            "4.  Ultimately, this leads to improved predictions on completely unseen regions and makes the model's evaluated performance more reflective of its true generalization capabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search = SearchEngine(pipeline, llm_model)\n",
        "\n",
        "resp = search.ask_rag(\"reinforment learnig for robtos\")\n",
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP0vhDixUIVT",
        "outputId": "14038991-9d7d-469c-ec2c-386d97997f13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinforcement learning (RL) is used to improve Vision-Language-Action (VLA) models through real-world deployments. A method named RL with Experience and Corrections via Advantage-conditioned Policies (RECAP) provides for RL training of VLAs via advantage conditioning.\n",
            "\n",
            "RECAP incorporates heterogeneous data, including demonstrations, data from on-policy collection, and expert teleoperated interventions, into the self-improvement process. It begins by pre-training a generalist VLA with offline RL, referred to as $π^{*}_{0.6}$, which can then be specialized for downstream tasks through on-robot data collection.\n",
            "\n",
            "The $π^{*}_{0.6}$ model, when trained with the full RECAP method, has demonstrated the ability to:\n",
            "*   Fold laundry in real homes.\n",
            "*   Reliably assemble boxes.\n",
            "*   Make espresso drinks using a professional espresso machine.\n",
            "\n",
            "On some of the most challenging tasks, RECAP has been shown to more than double task throughput and roughly halve the task failure rate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"What are advancements in model-based RL?\"\n",
        "\n",
        "print(\"=== Vanilla LLM ===\")\n",
        "print(search.ask_vanilla(q))\n",
        "\n",
        "print(\"\\n=== RAG ===\")\n",
        "print(search.ask_rag(q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2-Wh57nUIRE",
        "outputId": "c2154554-b9c3-4ae2-dabd-b8cb01128413"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Vanilla LLM ===\n",
            "Model-based Reinforcement Learning (MBRL) has seen significant advancements in recent years, addressing many of its historical challenges and making it competitive with, and in many cases superior to, model-free methods, especially in terms of sample efficiency.\n",
            "\n",
            "The core idea of MBRL is to learn a model of the environment's dynamics (how states change given actions) and/or rewards, and then use this model for planning, policy improvement, or generating synthetic experience.\n",
            "\n",
            "Here are the key advancements:\n",
            "\n",
            "1.  **Learning More Powerful and Accurate Models (Deep Dynamics Models):**\n",
            "    *   **Neural Network-based Dynamics:** Replacing traditional tabular or simple linear models with deep neural networks (DNNs) has allowed MBRL to tackle high-dimensional, complex environments (e.g., from raw pixels). Recurrent Neural Networks (RNNs), Transformers, and other sequence models are now commonly used to predict future states from sequences of past observations and actions.\n",
            "    *   **Probabilistic/Stochastic Models:** Instead of learning a deterministic $p(s'|s,a)$, models now often learn a distribution $p(s'|s,a)$. This allows for better representation of environmental uncertainty and enables uncertainty-aware planning. Examples include using Gaussian Process models (for simpler systems) or Bayesian Neural Networks and ensemble methods (e.g., like in **PETS - Probabilistic Ensembles with Trajectory Sampling**) for more complex ones. Ensembles also provide a good estimate of model uncertainty.\n",
            "    *   **Latent Space Models (World Models):** A major breakthrough came from learning a compact, disentangled *latent representation* of the environment and then learning the dynamics model within this latent space. This significantly reduces the complexity of the dynamics model and enables faster, more efficient planning. Famous examples include **World Models** and **Dreamer (V1, V2, V3)**, which learn a state-space model from pixels and plan entirely in that learned latent space.\n",
            "    *   **Forward-Backward Consistency/Predicting Next Observation:** Modern models often try to predict not just the next state, but also the next *observation* (e.g., pixel frame) and even the reward. This forces the model to learn richer, more informative representations.\n",
            "\n",
            "2.  **Better Utilization of Learned Models for Planning and Control:**\n",
            "    *   **Model Predictive Control (MPC) with Learned Models:** Using a learned dynamics model within an MPC framework (e.g., with optimization methods like Cross-Entropy Method - CEM) has become very effective. The model is used to simulate future trajectories, evaluate them, and select the best immediate action.\n",
            "    *   **Value Equivalence Property (V-REP):** Understanding that a good model, when used with an optimal planner, can lead to a policy that is value-equivalent to an optimal model-free policy. This theoretical grounding helps in designing better model-based algorithms.\n",
            "    *   **Planning Horizons:** Dynamically adjusting the planning horizon based on model uncertainty or performance, allowing for longer-term planning when the model is reliable and shorter-term planning otherwise.\n",
            "    *   **Direct Policy Optimization with Model-Generated Data:** Policies can be trained directly by generating large amounts of simulated experience using the learned model and then applying model-free RL algorithms (like PPO or SAC) on this synthetic data. **MBPO (Model-Based Policy Optimization)** is a prime example, significantly boosting sample efficiency.\n",
            "\n",
            "3.  **Robustness to Model Error and Uncertainty Quantification:**\n",
            "    *   **Adaptive Model Learning:** Models are continuously updated and refined as more real-world data becomes available, allowing them to adapt to changes or improve accuracy over time.\n",
            "    *   **Conservative Planning/Exploration:** Leveraging model uncertainty to guide exploration (e.g., exploring states where the model is less certain) or to plan conservatively to avoid states where the model's predictions might be unreliable.\n",
            "    *   **Ensemble-based Uncertainty Estimation:** As mentioned with PETS, using an ensemble of models provides not only a more robust prediction but also a direct measure of prediction uncertainty (variance across ensemble members). This uncertainty can then be incorporated into the planning objective or used for more effective data collection.\n",
            "    *   **Combining Short-term Model Planning with Long-term Value Functions:** Some approaches use the learned model for short-term planning (where the model is more accurate) and then use a learned model-free value function to estimate the long-term return from the predicted states.\n",
            "\n",
            "4.  **Hybrid Model-Based/Model-Free Approaches:**\n",
            "    *   **Dyna-style Architectures with Deep RL:** Modern iterations of the Dyna architecture (originally from Sutton) use a learned model to generate *additional* training data for a model-free learner. The model-free agent learns from both real and simulated experiences, combining the stability of model-free methods with the sample efficiency benefits of model-based planning.\n",
            "    *   **Leveraging Models for Policy Initialization or Warm-up:** A model can be used to quickly learn a reasonably good policy in simulation, which is then fine-tuned on real data using model-free methods. This significantly reduces the amount of real-world interaction needed.\n",
            "    *   **Offline RL with Learned Models:** In the context of Offline RL (learning from a fixed dataset without new interactions), models can be used to query potential future states or rewards from the dataset, or even to generate \"imagined\" experience to augment the dataset, addressing issues of data coverage and extrapolation.\n",
            "\n",
            "5.  **Scalability and Generalization:**\n",
            "    *   **Planning in Latent Spaces:** As seen in World Models and Dreamer, learning dynamics in a low-dimensional latent space allows these methods to scale to complex pixel-based environments, which was a major hurdle for earlier MBRL.\n",
            "    *   **Modular Models:** Decomposing complex systems into simpler, interacting sub-models, making the learning problem more tractable and potentially improving generalization.\n",
            "    *   **Meta-Learning for Dynamics:** Learning to quickly adapt or learn dynamics models for new, unseen environments.\n",
            "\n",
            "**Notable Algorithms/Architectures:**\n",
            "\n",
            "*   **World Models (Ha & Schmidhuber, 2018):** Pioneer in learning a latent space dynamics model from raw pixels and planning within that space.\n",
            "*   **PETS (Probabilistic Ensembles with Trajectory Sampling, Chua et al., 2018):** Demonstrates the power of ensemble models for robust, uncertainty-aware planning in continuous control.\n",
            "*   **MBPO (Model-Based Policy Optimization, Janner et al., 2019):** Effectively combines model-based data generation with model-free policy optimization, achieving state-of-the-art sample efficiency.\n",
            "*   **Dreamer (Hafner et al., 2019, 2020, 2023):** A series of highly sample-efficient algorithms building on World Models, learning robust latent dynamics and planning entirely in imagination.\n",
            "*   **MuZero (Schrittwieser et al., 2020):** While primarily a planning algorithm (like AlphaZero), it's model-based in the sense that it *learns* a model of the environment's dynamics, reward, and value functions *without being told the rules of the game*, which is a monumental advancement.\n",
            "\n",
            "These advancements collectively have made model-based RL a formidable approach, especially when sample efficiency is paramount (e.g., in robotics, autonomous driving, or drug discovery), where real-world interactions are costly or dangerous.\n",
            "\n",
            "=== RAG ===\n",
            "Based on the provided text, there is no information directly stating that \"heat\" is an advancement in modeled RL.\n",
            "\n",
            "The text mentions \"heat\" as:\n",
            "*   A canonical benchmark for MML (a method for constructing physically grounded neural operators).\n",
            "*   In the context of \"inverse heat problems\" for estimating material thermophysical properties.\n",
            "\n",
            "It discusses \"higher downstream RL performance\" and \"accelerating RL training iterations\" as advancements, but does not attribute \"heat\" to these advancements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MFVUurMUILy"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = \"\"\"\n",
        "Provide a scientific explanation grounded strictly in the supplied corpus.\n",
        "\n",
        "Query: \"{query}\"\n",
        "\n",
        "Base your answer ONLY on the information in:\n",
        "{context}\n",
        "\n",
        "If details are absent in the corpus, respond that no relevant evidence is present.\n",
        "\"\"\"\n",
        "print(search.ask_rag(\"how transformer-based models compress high-dimensional embeddings\", template=prompt_1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_oE3pdOYBEC",
        "outputId": "1ad4c83a-c6ae-4f2b-db26-ebaaa85024b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided corpus suggests that \"meaningful computations reside in compact subspaces.\" This implies that within transformer models, computations might effectively operate on representations that are reduced in dimensionality or are more concise.\n",
            "\n",
            "However, the corpus does not explicitly detail the specific mechanisms of how transformer models compress dimensional embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = \"\"\"\n",
        "Your task is to extract factual statements from the given context\n",
        "and use only those facts to answer the user’s question.\n",
        "\n",
        "Question: \"{query}\"\n",
        "\n",
        "Relevant extracted facts must come solely from:\n",
        "{context}\n",
        "\n",
        "Do not infer or extend beyond what is explicitly stated.\n",
        "\"\"\"\n",
        "print(search.ask_rag(\"why normalization of embeddings affects similarity search accuracy\", template=prompt_2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeWcvra4YBBU",
        "outputId": "2429e2ef-49fb-44b1-fe69-dce917dd3e27"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text, the specific reason *why* normalization of embeddings affects similarity search accuracy is not explicitly stated.\n",
            "\n",
            "However, the text does state the following related facts:\n",
            "*   Current text embedding models produce outputs with a consistent bias, $μ$, across all sentences.\n",
            "*   Renormalization is a solution that involves subtracting this bias ($μ$) from the embedding vector $e$.\n",
            "*   Renormalization consistently and statistically significantly improves the performance of existing models on retrieval tasks (a type of similarity search).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_3 = \"\"\"\n",
        "Explain the answer with simple analogies suitable for a newcomer,\n",
        "but rely strictly on data from the context.\n",
        "\n",
        "Question: \"{query}\"\n",
        "\n",
        "Context to use:\n",
        "{context}\n",
        "\n",
        "If the context lacks information needed for the answer,\n",
        "state that the corpus does not cover this topic.\n",
        "\"\"\"\n",
        "print(search.ask_rag(\"trade-offs between large pretrained models and lightweight fine-tuned models\", template=prompt_3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbGEpSTWYA-Q",
        "outputId": "5f866cd9-8ed3-4c8b-906d-143933eb87af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine you have two types of smart helpers:\n",
            "\n",
            "**1. The \"Encyclopedic Generalist\" (Large Pretrained Models):**\n",
            "\n",
            "*   **What it is:** Think of this as a vast, highly knowledgeable professor who has studied almost everything (it has \"strong reasoning and tool-use skills\"). It knows a little bit about every topic.\n",
            "*   **Tradeoffs:**\n",
            "    *   **Pro:** It's very general and can understand many different types of problems.\n",
            "    *   **Con (Size & Cost):** This professor is so big and takes up so much space in your office (high \"computational demands\") that it's \"impractical for edge or cost-sensitive deployments.\" You can't just put it on a small phone or device.\n",
            "    *   **Con (Specialized Performance):** Even though it's huge, on very specific tasks (like medical operations for hospitals), smaller, specialized helpers can \"outperform\" it, sometimes by a lot (up to 70x larger generalist models were outperformed by Lang1-1B).\n",
            "    *   **Con (Misalignment Risk):** If you try to teach this big professor a new, very specific skill using data that doesn't quite fit, it can sometimes get things very wrong, exhibiting \"strongest misalignment.\"\n",
            "\n",
            "**2. The \"Specialized Craftsman\" (Lightweight Finetuned Models):**\n",
            "\n",
            "*   **What it is:** This is like a highly skilled artisan who focuses on one particular craft. It might not know everything, but for its chosen area, it's incredibly good. These models are often \"small language models\" (like Xmodel-2.5 at 1.3 billion parameters or LFM2 models from 350M-8.3B parameters) that have been specifically \"finetuned.\"\n",
            "*   **Tradeoffs:**\n",
            "    *   **Pro (Performance in Niche):** For \"specialized tasks\" (like predicting hospital operations or clinical tasks), these artisans can \"outperform\" the encyclopedic generalists, sometimes by a significant margin (Lang1-1B improved AUROC by 3.64%-6.75% over larger generalist models).\n",
            "    *   **Pro (Efficiency & Deployment):** They are designed for \"efficient on-device deployment\" and can be used as a \"drop-in agent core.\" They are much faster and lighter (LFM2 can be \"up to 2x faster prefill and decode on CPUs\"). You can put them on smaller devices because they don't have the \"computational demands\" of the big professor.\n",
            "    *   **Pro (Resistance to Misalignment):** Some specialized artisans are \"more resistant\" to getting things wrong if taught with misaligned data, showing \"dramatically lower\" misalignment rates compared to the bigger professors.\n",
            "    *   **Requirement (Training):** To become this good, the artisan needs \"explicit supervised finetuning\" and benefits from \"in-domain pretraining\" (like pretraining on Electronic Health Records for medical tasks). It means you have to specifically train them for the job.\n",
            "\n",
            "**In simple terms:**\n",
            "\n",
            "*   **Large Pretrained Models** are like a vast, general knowledge encyclopedia – impressive, but too big and slow for quick, specific tasks, and can get confused if you try to teach them specific, sensitive things incorrectly.\n",
            "*   **Lightweight Finetuned Models** are like a perfectly crafted, specialized tool for a particular job – small, fast, highly effective in their specific area, and easier to deploy where space and speed matter, especially if they are trained specifically for that domain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_4 = \"\"\"\n",
        "Compose a brief analytical report (3–4 sentences)\n",
        "based exclusively on the provided material.\n",
        "\n",
        "Question: \"{query}\"\n",
        "\n",
        "Use ONLY the content below:\n",
        "{context}\n",
        "\n",
        "Avoid adding external knowledge or assumptions.\n",
        "\"\"\"\n",
        "print(search.ask_rag(\"how synthetic data generation impacts model generalization\", template=prompt_4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR5cFNHlYA7k",
        "outputId": "55fdf5f5-73a5-4592-e03a-351c625e80dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic Data Generation (SDG) positively impacts model generalization, particularly in scenarios with scarce or poor-quality real-world data, which otherwise lead to poor generalization. Fine-tuning models on synthetic data can enable even smaller models to become universal structured generation models that rival the performance of larger counterparts. Advanced methods like Causal Generative Models (CGMs) enhance generalization by creating synthetic datasets that preserve underlying causal relationships, leading to more reliable models. This directly addresses the issue of models being prone to poor generalization and failing in real-world scenarios due to a lack of representative data.\n"
          ]
        }
      ]
    }
  ]
}